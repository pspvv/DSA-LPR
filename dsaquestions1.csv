"Topic", "Question", "Option A", "Option B", "Option C", "Option D", "Correct Answer"
"Arrays", "Which of the following is true about arrays?", "A. Arrays are dynamic data structures.", "B. Elements of an array are stored in contiguous memory locations.", "C. Arrays can store elements of different data types.", "D. Array elements are accessed using linked lists.", "B"
"Arrays", "What is the time complexity to access an element at a specific index in an array?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Arrays", "What is the default initial value of elements in an integer array in Java if not explicitly initialized?", "A. 0", "B. 1", "C. -1", "D. Null", "A"
"Arrays", "Which operation has a time complexity of O(n) in a dynamically sized array (like ArrayList in Java) when an element is inserted at the beginning?", "A. Access", "B. Deletion at end", "C. Insertion at beginning", "D. Searching", "C"
"Arrays", "If an array is declared as `int arr[10];`, what is the valid index range?", "A. 1 to 10", "B. 0 to 9", "C. 0 to 10", "D. 1 to 9", "B"
"Arrays", "Which of the following is not a common array operation?", "A. Traversal", "B. Insertion", "C. Merging", "D. Squaring", "D"
"Arrays", "What does 'jagged array' mean?", "A. An array that stores only integers.", "B. An array of arrays where inner arrays can have different lengths.", "C. An array that cannot be modified after creation.", "D. An array that is sorted.", "B"
"Arrays", "What is the space complexity of an array of size 'n'?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Arrays", "Which data structure uses contiguous memory locations for storage?", "A. Linked List", "B. Tree", "C. Graph", "D. Array", "D"
"Arrays", "What is the maximum number of dimensions an array can have?", "A. 1", "B. 2", "C. Limited by memory, theoretically infinite.", "D. 3", "C"
"Arrays", "What happens if you try to access an array element outside its bounds?", "A. Compilation error", "B. Runtime error (e.g., ArrayIndexOutOfBoundsException)", "C. The program continues to execute normally with incorrect data.", "D. The array automatically resizes.", "B"
"Arrays", "Which of the following algorithms often uses arrays as its underlying data structure?", "A. BFS (Breadth-First Search)", "B. DFS (Depth-First Search)", "C. QuickSort", "D. Dijkstra's Algorithm (on adjacency matrix)", "C"
"Arrays", "What is the purpose of an array in programming?", "A. To store heterogeneous data types.", "B. To store a collection of similar data types.", "C. To establish relationships between data points.", "D. To represent hierarchical data.", "B"
"Arrays", "In C++, what is the size of an empty array declared as `int arr[];`?", "A. 0", "B. Undefined, compilation error.", "C. 4 bytes", "D. Compiler-dependent default size.", "B"
"Arrays", "Which of these is a disadvantage of arrays?", "A. Fast random access", "B. Fixed size (in static arrays)", "C. Efficient memory utilization", "D. Simplicity in implementation", "B"
"Arrays", "What is the time complexity to insert an element at the end of a fixed-size array that is not full?", "A. O(n)", "B. O(1)", "C. O(log n)", "D. O(n^2)", "B"
"Arrays", "What is the time complexity to search for an element in an unsorted array using linear search?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Arrays", "What is the time complexity to delete an element from the middle of an array?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n log n)", "C"
"Arrays", "Which of the following data structures is not built on top of arrays?", "A. Stack", "B. Queue", "C. Linked List", "D. Heap", "C"
"Arrays", "If an array is used to implement a stack, which operation is most efficient?", "A. Push", "B. Pop", "C. Both push and pop (O(1))", "D. Both push and pop (O(n))", "C"
"Arrays", "How is a 2D array typically stored in memory?", "A. Randomly", "B. In a tree structure", "C. Row-major or column-major order", "D. As a linked list of rows", "C"
"Arrays", "Which of the following is true about dynamic arrays?", "A. Their size is fixed at compile time.", "B. They automatically resize when capacity is exceeded.", "C. They have slower random access compared to static arrays.", "D. They use less memory than static arrays.", "B"
"Arrays", "What is 'array decomposition'?", "A. Breaking down a large array into smaller arrays.", "B. Sorting an array.", "C. Merging two arrays.", "D. Searching for an element.", "A"
"Arrays", "What does 'padding' mean in the context of arrays?", "A. Adding extra elements to the array.", "B. Aligning elements in memory for performance.", "C. Removing elements from the array.", "D. Reversing the order of elements.", "B"
"Arrays", "In an array, what does the term 'base address' refer to?", "A. The address of the last element.", "B. The address of the first element.", "C. The address of the middle element.", "D. The total memory occupied by the array.", "B"
"Arrays", "Which of the following is a common application of arrays?", "A. Implementing a hash map directly.", "B. Storing pixels in an image.", "C. Representing a network graph with nodes and edges.", "D. Building a file system hierarchy.", "B"
"Arrays", "What is the primary advantage of using a static array over a dynamic array if the size is known beforehand?", "A. Easier to implement.", "B. No overhead of resizing, potentially faster.", "C. Can store more diverse data types.", "D. Automatically sorts elements.", "B"
"Arrays", "What is 'sparse array'?", "A. An array with all elements having the same value.", "B. An array with a majority of elements being zero or null.", "C. An array that is not contiguous in memory.", "D. An array that is sorted in descending order.", "B"
"Arrays", "What is the time complexity for merging two sorted arrays into a new sorted array?", "A. O(1)", "B. O(log n)", "C. O(m + n) where m and n are lengths of arrays.", "D. O(m*n)", "C"
"Arrays", "Which property makes arrays suitable for implementing caches?", "A. Their dynamic nature.", "B. Their ability to store heterogeneous data.", "C. Fast random access.", "D. Their hierarchical structure.", "C"
"Arrays", "What is the process of accessing each element of an array exactly once called?", "A. Searching", "B. Sorting", "C. Traversal", "D. Insertion", "C"
"Arrays", "When an array is passed to a function in C/C++, how is it typically passed?", "A. By value (a copy is made)", "B. By reference (address of first element)", "C. As a new array", "D. Depends on the compiler", "B"
"Arrays", "What is the consequence of adding an element beyond the allocated capacity of a static array?", "A. The array automatically expands.", "B. It leads to a compilation error.", "C. It can lead to buffer overflow or undefined behavior.", "D. The element is simply ignored.", "C"
"Arrays", "Which sorting algorithm is an in-place sort and typically uses an array?", "A. Merge Sort (usually not in-place)", "B. Bubble Sort", "C. Heap Sort", "D. Both B and C", "D"
"Arrays", "What is the purpose of the 'sizeof' operator when applied to an array name in C?", "A. Returns the number of elements in the array.", "B. Returns the size of one element.", "C. Returns the total size of the array in bytes.", "D. Returns the address of the first element.", "C"
"Arrays", "If an array is sorted, which search algorithm is most efficient?", "A. Linear Search", "B. Binary Search", "C. Jump Search", "D. Both B and C", "D"
"Arrays", "What is the time complexity of reversing an array?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Arrays", "Which of the following statements about arrays is false?", "A. Arrays can be multi-dimensional.", "B. Elements of an array must be of the same data type.", "C. Arrays are always dynamically allocated.", "D. Array elements are stored contiguously.", "C"
"Arrays", "What is the difference between an array and a pointer in C/C++?", "A. Arrays can be indexed, pointers cannot.", "B. Arrays store data, pointers store addresses.", "C. Arrays are always static, pointers are dynamic.", "D. Arrays cannot be passed to functions, pointers can.", "B"
"Arrays", "What is the most efficient way to insert an element into a sorted array while maintaining its sorted order?", "A. Insert at the beginning.", "B. Insert at the end.", "C. Find the correct position and shift elements.", "D. Replace an existing element.", "C"
"Arrays", "What is the benefit of using an array to implement a queue instead of a linked list, in some scenarios?", "A. Simpler implementation for dynamic resizing.", "B. Faster enqueue/dequeue operations (if not dealing with resizing).", "C. Better memory locality.", "D. Both B and C.", "D"
"Arrays", "What is the output of `sizeof(arr)` for `int arr[] = {1, 2, 3};` in C on a system where int is 4 bytes?", "A. 3", "B. 4", "C. 12", "D. Undefined", "C"
"Arrays", "What is an 'associative array' also known as?", "A. Linked List", "B. Hash Map or Dictionary", "C. Stack", "D. Queue", "B"
"Arrays", "Which of the following scenarios would prefer a linked list over an array?", "A. Frequent random access to elements.", "B. Known, fixed size data storage.", "C. Frequent insertions/deletions at arbitrary positions.", "D. Iterating through all elements sequentially.", "C"
"Arrays", "What is 'array bounds checking'?", "A. Checking if the array is empty.", "B. Verifying that array accesses are within valid indices.", "C. Sorting the array elements.", "D. Calculating the size of the array.", "B"
"Arrays", "When might a multi-dimensional array be preferred over a single-dimensional array?", "A. When memory is limited.", "B. When representing tabular data or matrices.", "C. When the number of elements is small.", "D. When elements need to be accessed randomly.", "B"
"Arrays", "What does it mean if an array is 'passed by value' (hypothetically, if it were possible for entire arrays in C/C++)?", "A. The function receives a pointer to the original array.", "B. The function receives a copy of the entire array.", "C. The function can modify the original array.", "D. The array's size cannot be changed.", "B"
"Arrays", "What is a 'circular array' or 'ring buffer' primarily used for?", "A. Storing elements in a random order.", "B. Implementing queues efficiently by reusing memory.", "C. Representing hierarchical data.", "D. Performing mathematical calculations.", "B"
"Arrays", "What is the purpose of 'array initializers' (e.g., `int arr[] = {1, 2, 3};`)?", "A. To specify the maximum size of the array.", "B. To assign initial values to array elements at declaration.", "C. To make the array dynamic.", "D. To declare an empty array.", "B"
"Arrays", "Which of the following is an example of an 'in-place' array algorithm?", "A. Creating a new sorted array from an unsorted one.", "B. Reversing an array without using extra space (beyond a few variables).", "C. Merging two arrays into a third array.", "D. Copying an array to another array.", "B"
"Sorting", "Which of the following sorting algorithms has the best average-case time complexity?", "A. Bubble Sort", "B. Insertion Sort", "C. QuickSort", "D. Selection Sort", "C"
"Sorting", "What is the time complexity of Bubble Sort in the worst case?", "A. O(n)", "B. O(n log n)", "C. O(n^2)", "D. O(log n)", "C"
"Sorting", "Which sorting algorithm repeatedly steps through the list, compares adjacent elements and swaps them if they are in the wrong order?", "A. Merge Sort", "B. QuickSort", "C. Bubble Sort", "D. Heap Sort", "C"
"Sorting", "What is the space complexity of Merge Sort?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Sorting", "Which sorting algorithm is a stable sort?", "A. QuickSort", "B. Heap Sort", "C. Merge Sort", "D. Selection Sort", "C"
"Sorting", "In which sorting algorithm, elements are picked one by one and placed in their correct position in the sorted part of the array?", "A. Selection Sort", "B. Insertion Sort", "C. Bubble Sort", "D. QuickSort", "B"
"Sorting", "What is the time complexity of QuickSort in the worst case?", "A. O(n log n)", "B. O(n^2)", "C. O(n)", "D. O(log n)", "B"
"Sorting", "Which of the following sorting algorithms is an in-place algorithm?", "A. Merge Sort", "B. Heap Sort", "C. Radix Sort", "D. Counting Sort", "B"
"Sorting", "Which sorting algorithm works by dividing the unsorted list into n sublists, each containing one element, and then repeatedly merging sublists to produce new sorted sublists until there is only one sublist remaining?", "A. QuickSort", "B. Insertion Sort", "C. Merge Sort", "D. Selection Sort", "C"
"Sorting", "What is the best-case time complexity of Insertion Sort?", "A. O(n log n)", "B. O(n)", "C. O(n^2)", "D. O(1)", "B"
"Sorting", "Which of the following sorting algorithms is NOT a comparison sort?", "A. Merge Sort", "B. Heap Sort", "C. Radix Sort", "D. QuickSort", "C"
"Sorting", "What is the average-case time complexity of Heap Sort?", "A. O(n)", "B. O(n log n)", "C. O(n^2)", "D. O(log n)", "B"
"Sorting", "Which sorting algorithm finds the minimum element from the unsorted part and puts it at the beginning?", "A. Bubble Sort", "B. Insertion Sort", "C. Selection Sort", "D. QuickSort", "C"
"Sorting", "What is the time complexity of Counting Sort?", "A. O(n + k) where k is the range of input.", "B. O(n log n)", "C. O(n^2)", "D. O(n)", "A"
"Sorting", "Which of the following is typically the fastest sorting algorithm for random data?", "A. Merge Sort", "B. Heap Sort", "C. QuickSort", "D. Bubble Sort", "C"
"Sorting", "Which sorting algorithm builds a max-heap or min-heap and repeatedly extracts the maximum/minimum element?", "A. QuickSort", "B. Merge Sort", "C. Heap Sort", "D. Shell Sort", "C"
"Sorting", "What is the worst-case time complexity of Selection Sort?", "A. O(n)", "B. O(n log n)", "C. O(n^2)", "D. O(log n)", "C"
"Sorting", "Which sorting algorithm is best suited for linked lists?", "A. QuickSort", "B. Heap Sort", "C. Merge Sort", "D. Bubble Sort", "C"
"Sorting", "What is the time complexity of Shell Sort in the worst case?", "A. O(n log n)", "B. O(n^2)", "C. Varies, often better than O(n^2) but worse than O(n log n).", "D. O(n)", "C"
"Sorting", "Which sorting algorithm partitions the array into two sub-arrays according to a pivot element?", "A. Merge Sort", "B. Heap Sort", "C. QuickSort", "D. Insertion Sort", "C"
"Sorting", "What is a 'stable' sorting algorithm?", "A. An algorithm that always finishes in the same time.", "B. An algorithm that does not change the relative order of equal elements.", "C. An algorithm that uses constant extra space.", "D. An algorithm that works only on sorted data.", "B"
"Sorting", "Which sorting algorithm has a worst-case space complexity of O(log n) due to recursion stack?", "A. Merge Sort", "B. QuickSort", "C. Heap Sort", "D. Insertion Sort", "B"
"Sorting", "Which of the following is an example of an external sorting algorithm?", "A. Bubble Sort", "B. Insertion Sort", "C. Merge Sort (often used for external sorting)", "D. Selection Sort", "C"
"Sorting", "What is the main idea behind Radix Sort?", "A. Comparing elements directly.", "B. Distributing elements into buckets based on digits.", "C. Repeatedly swapping adjacent elements.", "D. Finding the minimum element and placing it.", "B"
"Sorting", "Which sorting algorithm is generally considered the slowest for large datasets?", "A. QuickSort", "B. Merge Sort", "C. Bubble Sort", "D. Heap Sort", "C"
"Sorting", "What is the purpose of a 'pivot' in QuickSort?", "A. To be the smallest element in the array.", "B. To be the largest element in the array.", "C. To partition the array into elements smaller and larger than itself.", "D. To act as a placeholder for sorted elements.", "C"
"Sorting", "Which sorting algorithm is adaptive, meaning its performance improves if the input is already partially sorted?", "A. QuickSort", "B. Merge Sort", "C. Insertion Sort", "D. Heap Sort", "C"
"Sorting", "What is the time complexity of Bucket Sort in the average case?", "A. O(n)", "B. O(n log n)", "C. O(n^2)", "D. O(k)", "A"
"Sorting", "Which sorting algorithm would you use if memory space is a critical constraint, and you need an in-place sort?", "A. Merge Sort", "B. QuickSort", "C. Radix Sort", "D. Counting Sort", "B"
"Sorting", "What is the primary disadvantage of Counting Sort?", "A. It has a high time complexity.", "B. It is not a stable sort.", "C. It requires extra space proportional to the range of input values (k).", "D. It cannot sort negative numbers.", "C"
"Sorting", "Which sorting algorithm's performance degrades significantly when dealing with nearly sorted or reverse-sorted data, leading to O(n^2) time complexity?", "A. Merge Sort", "B. Heap Sort", "C. QuickSort", "D. Insertion Sort", "C"
"Sorting", "What is the 'gap' sequence in Shell Sort?", "A. The number of elements to skip during comparisons.", "B. The size of the sub-arrays to be sorted.", "C. The initial starting point for sorting.", "D. The number of iterations the algorithm performs.", "A"
"Sorting", "Which sorting algorithm is often used as a sub-routine in more complex algorithms like external sorting?", "A. Bubble Sort", "B. QuickSort", "C. Merge Sort", "D. Insertion Sort", "C"
"Sorting", "If you have a very small array (e.g., less than 20 elements), which sorting algorithm might be efficient due to its low constant factors?", "A. QuickSort", "B. Merge Sort", "C. Insertion Sort", "D. Heap Sort", "C"
"Sorting", "Which of the following correctly describes the process of Selection Sort?", "A. Repeatedly swaps adjacent elements if they are in the wrong order.", "B. Divides the array and merges sorted halves.", "C. Finds the minimum element and places it at the correct position in each pass.", "D. Builds a heap and extracts elements.", "C"
"Sorting", "When is Radix Sort most efficient?", "A. When the range of numbers is very large.", "B. When the numbers have many digits.", "C. When the numbers have a small range and fixed number of digits.", "D. When the input array is already sorted.", "C"
"Sorting", "Which of these is a divide and conquer algorithm?", "A. Bubble Sort", "B. Insertion Sort", "C. QuickSort", "D. Selection Sort", "C"
"Sorting", "What is the concept of 'inversion' in the context of sorting?", "A. An element that is out of place.", "B. A pair of elements that are in the wrong order relative to each other.", "C. The process of reversing an array.", "D. The number of swaps performed.", "B"
"Sorting", "Which sorting algorithm is generally considered to be the most robust (good performance across various data distributions)?", "A. QuickSort", "B. Merge Sort", "C. Bubble Sort", "D. Selection Sort", "B"
"Sorting", "What is the key idea behind the efficiency of Merge Sort compared to QuickSort in worst-case scenarios?", "A. It always picks the best pivot.", "B. Its partitioning is always balanced.", "C. It uses less memory.", "D. It is an in-place sort.", "B"
"Sorting", "If you need a sorting algorithm that guarantees O(n log n) worst-case time complexity, which would you choose?", "A. QuickSort", "B. Bubble Sort", "C. Heap Sort", "D. Insertion Sort", "C"
"Sorting", "Which sorting algorithm is a comparison sort that uses a tree-based data structure (heap)?", "A. QuickSort", "B. Merge Sort", "C. Heap Sort", "D. Radix Sort", "C"
"Sorting", "What is the space complexity for QuickSort in the average case?", "A. O(1)", "B. O(log n) due to recursion stack.", "C. O(n)", "D. O(n log n)", "B"
"Sorting", "Which type of sorting algorithm is Counting Sort?", "A. Comparison Sort", "B. Non-comparison Sort", "C. In-place Sort", "D. Recursive Sort", "B"
"Sorting", "What happens during the 'merge' step of Merge Sort?", "A. Elements are swapped until sorted.", "B. Sub-arrays are combined into a single sorted array.", "C. Elements are partitioned around a pivot.", "D. A heap is built from the elements.", "B"
"Sorting", "Which sorting algorithm is a good choice for nearly sorted arrays and small arrays?", "A. QuickSort", "B. Heap Sort", "C. Insertion Sort", "D. Merge Sort", "C"
"Sorting", "What is the main drawback of Bucket Sort if the input data is not uniformly distributed?", "A. It becomes O(n log n).", "B. It uses too much memory.", "C. Its performance can degrade to O(n^2).", "D. It cannot sort integers.", "C"
"Sorting", "When should you prefer Insertion Sort over Bubble Sort?", "A. For large datasets.", "B. When the dataset is completely random.", "C. For smaller datasets or nearly sorted arrays.", "D. When space complexity is critical.", "C"
"Sorting", "Which of the following is true about all comparison-based sorting algorithms?", "A. Their best time complexity is O(n).", "B. Their lower bound for time complexity is O(n log n).", "C. They always require O(n) extra space.", "D. They are always stable.", "B"
"Sorting", "What is the principle behind 'selection' in Selection Sort?", "A. Selecting a pivot element.", "B. Selecting the minimum (or maximum) element and placing it.", "C. Selecting adjacent elements for comparison.", "D. Selecting a random element for sorting.", "B"
"Searching", "What is the time complexity of a linear search in the worst case?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Searching", "Which of the following searching algorithms requires the array to be sorted?", "A. Linear Search", "B. Jump Search", "C. Sublist Search", "D. Depth-First Search", "B"
"Searching", "What is the time complexity of a binary search in the worst case?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n log n)", "B"
"Searching", "In a binary search, what does the algorithm do if the middle element is less than the target value?", "A. Searches the left half.", "B. Searches the right half.", "C. Ends the search.", "D. Reshuffles the array.", "B"
"Searching", "What is the space complexity of a linear search?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Searching", "Which searching algorithm starts checking from one end and continues until the desired element is found or the list ends?", "A. Binary Search", "B. Jump Search", "C. Linear Search", "D. Interpolation Search", "C"
"Searching", "What is the best-case time complexity of a linear search?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Searching", "When is Interpolation Search more efficient than Binary Search?", "A. When the elements are randomly distributed.", "B. When the elements are uniformly distributed.", "C. When the array is unsorted.", "D. When searching for the first element.", "B"
"Searching", "Which searching algorithm approximates the position of the target value by using linear interpolation?", "A. Binary Search", "B. Linear Search", "C. Jump Search", "D. Interpolation Search", "D"
"Searching", "What is the approximate 'jump' size typically chosen for Jump Search?", "A. log n", "B. n/2", "C. sqrt(n)", "D. n", "C"
"Searching", "Which searching algorithm involves comparing the target value with the middle element of the sorted list, then halving the search range?", "A. Linear Search", "B. Binary Search", "C. Jump Search", "D. Exponential Search", "B"
"Searching", "What is the time complexity of Jump Search?", "A. O(n)", "B. O(log n)", "C. O(sqrt(n))", "D. O(n log n)", "C"
"Searching", "For which data structure is a linear search most suitable?", "A. Sorted Array", "B. Unsorted Array", "C. Binary Search Tree", "D. Hash Table", "B"
"Searching", "If an element is not present in a sorted array, what is the value returned by a typical binary search implementation?", "A. 0", "B. -1 (or an indicator of not found)", "C. The last element checked", "D. The array size", "B"
"Searching", "Which searching algorithm is a technique for finding an element in an infinite or unbounded sorted array?", "A. Binary Search", "B. Jump Search", "C. Interpolation Search", "D. Exponential Search", "D"
"Searching", "What is the time complexity of Exponential Search?", "A. O(log n)", "B. O(n)", "C. O(sqrt(n))", "D. O(n log n)", "A"
"Searching", "Which of the following is true about Binary Search?", "A. It can be used on unsorted arrays.", "B. It is always faster than Linear Search.", "C. It works by repeatedly dividing the search interval in half.", "D. It has O(1) space complexity.", "C"
"Searching", "What is the main advantage of Jump Search over Linear Search for large sorted arrays?", "A. Simplicity", "B. Fewer comparisons on average", "C. Less memory usage", "D. Faster for small arrays", "B"
"Searching", "Which search algorithm is typically used to find an element in a binary search tree (BST)?", "A. Linear Search", "B. Binary Search (conceptually similar)", "C. Breadth-First Search", "D. Hash Search", "B"
"Searching", "What is the space complexity of Interpolation Search?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Searching", "If an array has duplicate elements, which search algorithm would typically find the first occurrence of a target element efficiently?", "A. Binary Search (standard implementation may not)", "B. Linear Search", "C. Jump Search", "D. Interpolation Search", "B"
"Searching", "What is the primary condition for using Binary Search effectively?", "A. Elements must be unique.", "B. Elements must be strings.", "C. The data structure must be sorted.", "D. The data structure must be a linked list.", "C"
"Searching", "Which of the following search techniques is suitable for searching in a hash table?", "A. Linear Search", "B. Binary Search", "C. Hash Search (Direct Addressing/Chaining/Open Addressing)", "D. Interpolation Search", "C"
"Searching", "What is the average time complexity of a successful search in a well-designed hash table?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n log n)", "C"
"Searching", "What is the worst-case time complexity of searching in a hash table with poor hash function and many collisions?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Searching", "Which of the following is NOT a common method for handling collisions in hash tables for searching?", "A. Chaining", "B. Open Addressing (Linear Probing, Quadratic Probing)", "C. Rehashing", "D. Binary Search", "D"
"Searching", "What is the primary advantage of Binary Search over Linear Search for very large sorted datasets?", "A. Simpler to implement.", "B. Much faster.", "C. Uses less memory.", "D. Works on unsorted data.", "B"
"Searching", "When would a linear search be preferred over a binary search?", "A. When the array is very large.", "B. When the array is unsorted.", "C. When quick access to any element is needed.", "D. When elements are unique.", "B"
"Searching", "In Exponential Search, after finding the range where the element might exist, what search method is typically applied?", "A. Linear Search", "B. Jump Search", "C. Binary Search", "D. Interpolation Search", "C"
"Searching", "What is the purpose of a 'guard' element in some linear search implementations?", "A. To mark the beginning of the array.", "B. To prevent array out-of-bounds access by placing the target at the end.", "C. To store the search result.", "D. To indicate an empty array.", "B"
"Searching", "Which search technique is useful when the target value is likely to be near the beginning of a sorted array?", "A. Binary Search", "B. Interpolation Search", "C. Linear Search (sometimes, or specialized searches)", "D. Jump Search", "C"
"Searching", "Consider an array `[2, 5, 8, 12, 16, 23, 38, 56, 72, 91]`. If you are searching for 23 using Binary Search, how many comparisons (approx.) would be made?", "A. 1", "B. 2", "C. 3", "D. 4", "D"
"Searching", "What is the worst-case scenario for Interpolation Search?", "A. Uniformly distributed data.", "B. Arithmetic progression data.", "C. Exponentially distributed data.", "D. Random data.", "C"
"Searching", "Which search algorithm is derived from the idea of block search?", "A. Binary Search", "B. Interpolation Search", "C. Jump Search", "D. Exponential Search", "C"
"Searching", "In the context of searching, what does 'probe' refer to?", "A. The size of the array.", "B. The number of elements found.", "C. An attempt to access a memory location (often in hash tables).", "D. The process of sorting.", "C"
"Searching", "What is 'self-organizing search'?", "A. A search that sorts the data before searching.", "B. A search that modifies the data structure to improve future search performance.", "C. A search that organizes itself into parallel threads.", "D. A search that requires no explicit algorithm.", "B"
"Searching", "Which of the following is true about searching in a Binary Search Tree (BST)?", "A. It has O(1) worst-case time complexity.", "B. It always takes O(log n) time.", "C. Its average time complexity is O(log n), worst-case O(n).", "D. It only works for integers.", "C"
"Searching", "What is the purpose of 'sentinel search'?", "A. To search for a specific sentinel value.", "B. To optimize linear search by removing the explicit end-of-array check in the loop.", "C. To search in a sorted array.", "D. To use multiple search agents simultaneously.", "B"
"Searching", "Which search method is best for very large datasets stored on disk (external storage)?", "A. Linear Search", "B. Binary Search", "C. B-tree search (or similar disk-optimized structures)", "D. Hash table search", "C"
"Searching", "What is a 'fuzzy search'?", "A. A search that finds an exact match.", "B. A search that finds results that are approximately similar to the search query.", "C. A search that works on encrypted data.", "D. A search that only works with images.", "B"
"Searching", "When would you prefer a hash table for searching over a sorted array with binary search?", "A. When memory is a severe constraint.", "B. When frequent insertions and deletions are needed, alongside fast average-case searches.", "C. When the data must always remain sorted.", "D. When the range of keys is very small and continuous.", "B"
"Searching", "What is the fundamental difference between sequential search and interval search algorithms?", "A. Sequential searches require sorted data, interval searches do not.", "B. Sequential searches check elements one by one, interval searches narrow down the search space.", "C. Interval searches are always faster.", "D. Sequential searches are only for strings.", "B"
"Searching", "Which search algorithm can be implemented efficiently both iteratively and recursively?", "A. Linear Search", "B. Binary Search", "C. Hash Search", "D. Both A and B", "B"
"Searching", "What is the disadvantage of using Linear Probing for collision resolution in hash tables during searching?", "A. It's too slow for insertions.", "B. It leads to primary clustering.", "C. It uses too much memory.", "D. It only works for integer keys.", "B"
"Searching", "Which searching technique is used to find the `k`-th smallest element in an unsorted array efficiently?", "A. Linear Search", "B. Binary Search", "C. Selection Algorithm (e.g., Quickselect)", "D. Interpolation Search", "C"
"Searching", "What is the time complexity of the Selection Algorithm (Quickselect) in the average case?", "A. O(n)", "B. O(n log n)", "C. O(log n)", "D. O(n^2)", "A"
"Searching", "What is a 'search space' in algorithm terms?", "A. The memory used by the algorithm.", "B. The set of all possible solutions or elements that could contain the target.", "C. The time taken to perform the search.", "D. The number of elements in the array.", "B"
"Searching", "Which of the following is true regarding Uniform Binary Search?", "A. It is faster than standard binary search.", "B. It avoids repeated division operations by pre-calculating jump sizes.", "C. It works on unsorted arrays.", "D. It is a type of hash search.", "B"
"Searching", "When considering the number of comparisons, which search algorithm is generally superior for very large, uniformly distributed, sorted datasets?", "A. Linear Search", "B. Binary Search", "C. Interpolation Search", "D. Jump Search", "C"
"Searching", "What is the typical method for searching in a Breadth-First Search (BFS) or Depth-First Search (DFS) algorithm?", "A. Direct element lookup.", "B. Traversal through a graph/tree structure.", "C. Hash table lookup.", "D. Binary search on an adjacency list.", "B"
"Hashing", "What is the primary purpose of a hash function?", "A. To sort data.", "B. To encrypt data.", "C. To map data of arbitrary size to fixed-size values (hash codes).", "D. To compress data.", "C"
"Hashing", "What is a 'hash collision'?", "A. When two different keys produce the same hash value.", "B. When a key cannot be hashed.", "C. When the hash table is full.", "D. When a hash function produces a negative value.", "A"
"Hashing", "Which of the following is a common method for resolving hash collisions?", "A. Sorting", "B. Linear Search", "C. Chaining", "D. Binary Search", "C"
"Hashing", "In 'chaining' for collision resolution, what data structure is typically used at each index of the hash table?", "A. Array", "B. Linked List", "C. Stack", "D. Queue", "B"
"Hashing", "What is 'open addressing'?", "A. A collision resolution technique that stores all keys in one large array.", "B. A collision resolution technique that finds an alternative empty slot in the hash table.", "C. A hashing technique for public data.", "D. A method to make hash tables dynamic.", "B"
"Hashing", "Which of the following is a type of 'open addressing'?", "A. Separate Chaining", "B. Quadratic Probing", "C. Coalesced Hashing", "D. Perfect Hashing", "B"
"Hashing", "What is the primary advantage of a hash table over a balanced binary search tree for dictionary operations (insert, delete, search)?", "A. Guarantees O(log n) worst-case time complexity.", "B. Faster average-case time complexity (O(1)).", "C. Less memory consumption.", "D. Data is always stored in sorted order.", "B"
"Hashing", "What is the 'load factor' of a hash table?", "A. The maximum number of elements it can hold.", "B. The ratio of the number of elements to the table size.", "C. The time taken to perform an operation.", "D. The number of collisions encountered.", "B"
"Hashing", "When should a hash table be 'rehashed'?", "A. When it's empty.", "B. When the load factor exceeds a certain threshold.", "C. After every insertion.", "D. When searching for an element.", "B"
"Hashing", "What is the expected average time complexity for searching in a hash table using good hash function and proper collision resolution?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n log n)", "C"
"Hashing", "Which of the following is NOT a desirable property of a good hash function?", "A. Deterministic (produces same hash for same input).", "B. Uniform distribution of hash values.", "C. Computationally expensive.", "D. Minimizes collisions.", "C"
"Hashing", "What is 'primary clustering' in open addressing?", "A. When all keys hash to the same initial index.", "B. When a collision causes subsequent insertions to fill consecutive slots.", "C. When separate chains become very long.", "D. When the hash table is full.", "B"
"Hashing", "Which open addressing technique helps to alleviate primary clustering?", "A. Linear Probing", "B. Quadratic Probing", "C. Double Hashing", "D. Both B and C", "D"
"Hashing", "What is 'double hashing'?", "A. Using two hash tables simultaneously.", "B. Using two hash functions: one for initial hash and another for step size.", "C. Hashing the hash value twice.", "D. A technique for secure password storage.", "B"
"Hashing", "What is the worst-case time complexity for searching in a hash table?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n log n)", "C"
"Hashing", "Which type of hash function is often used for strings and involves multiplying by a prime number and taking modulo?", "A. Division Method", "B. Mid-square Method", "C. Polynomial Rolling Hash (Horner's Method)", "D. Folding Method", "C"
"Hashing", "What does 'perfect hashing' guarantee?", "A. O(log n) search time.", "B. O(1) worst-case search time (no collisions for a static set of keys).", "C. Minimal memory usage.", "D. Always produces sorted output.", "B"
"Hashing", "What is 'cryptographic hashing' primarily used for?", "A. Fast data retrieval.", "B. Ensuring data integrity and security (e.g., password storage).", "C. Sorting large datasets.", "D. Dynamic memory allocation.", "B"
"Hashing", "Which of the following is a characteristic of a cryptographic hash function?", "A. Reversibility (can get original data from hash).", "B. High collision probability.", "C. Avalanche effect (small input change causes large hash change).", "D. Fast to compute but slow to verify.", "C"
"Hashing", "What is the main drawback of 'linear probing' for collision resolution?", "A. It uses too much memory.", "B. It leads to primary clustering.", "C. It is very slow for deletions.", "D. It cannot handle many collisions.", "B"
"Hashing", "What is the effect of a very high load factor in a hash table?", "A. Improved search performance.", "B. Increased memory efficiency.", "C. More collisions and degraded performance.", "D. Automatic sorting of elements.", "C"
"Hashing", "When implementing a hash table with chaining, what happens during deletion if multiple keys are in the same chain?", "A. Only the first element in the chain is deleted.", "B. All elements in the chain are deleted.", "C. The specific element is removed from the linked list.", "D. The hash table needs to be rehashed.", "C"
"Hashing", "What is the primary advantage of 'chaining' over 'open addressing'?", "A. No wasted space if the load factor is low.", "B. Simpler implementation of deletion.", "C. Avoids clustering issues.", "D. Uses less memory.", "B"
"Hashing", "What is the ideal distribution of hash values for a hash function?", "A. All values should be the same.", "B. Values should be concentrated in a few bins.", "C. Values should be uniformly distributed across the hash table.", "D. Values should be sorted.", "C"
"Hashing", "If a hash table uses `table_size = 10` and `hash(key) = key % table_size`, where would key `27` be placed?", "A. Index 2", "B. Index 7", "C. Index 0", "D. Index 10", "B"
"Hashing", "What happens when a hash table with open addressing attempts to insert a key into an already occupied slot?", "A. It reports an error.", "B. It uses a probing sequence to find the next available slot.", "C. It creates a new table.", "D. It overwrites the existing data.", "B"
"Hashing", "What is the role of a 'salt' in password hashing?", "A. To make the hash function faster.", "B. To make it harder to use rainbow tables for cracking passwords.", "C. To encrypt the password before hashing.", "D. To add complexity to the hash table size.", "B"
"Hashing", "Which of the following is NOT a typical application of hashing?", "A. Database indexing.", "B. Password storage.", "C. Checking data integrity (checksums).", "D. Maintaining data in sorted order.", "D"
"Hashing", "What is 'rehashing' in hash tables?", "A. Re-calculating the hash value for a single key.", "B. Creating a new, larger hash table and re-inserting all existing elements.", "C. Fixing a corrupted hash table.", "D. Changing the hash function.", "B"
"Hashing", "What is 'secondary clustering'?", "A. A problem where two keys that hash to the same initial position follow the same probe sequence.", "B. A problem specific to chaining.", "C. A general term for any collision.", "D. The opposite of primary clustering.", "A"
"Hashing", "Which open addressing technique eliminates both primary and secondary clustering?", "A. Linear Probing", "B. Quadratic Probing", "C. Double Hashing", "D. None, these are still susceptible to some clustering.", "D"
"Hashing", "What is 'table doubling' in dynamic hash tables?", "A. Increasing the hash table size by two when rehashing.", "B. Using two hash tables at all times.", "C. Storing each element twice.", "D. Duplicating the keys.", "A"
"Hashing", "What is the space complexity of a hash table?", "A. O(1) (if keys are small)", "B. O(n) where n is the number of elements stored.", "C. O(log n)", "D. O(n^2)", "B"
"Hashing", "In a hash table, what is the 'hash index'?", "A. The original key value.", "B. The calculated address (bucket number) where the key-value pair is stored.", "C. The load factor.", "D. The size of the hash table.", "B"
"Hashing", "Which of the following scenarios would make a hash table search approach problematic?", "A. When O(1) average-case performance is crucial.", "B. When data needs to be retrieved in sorted order.", "C. When frequent insertions and deletions are expected.", "D. When the number of elements is very large.", "B"
"Hashing", "What is the 'division method' for a hash function?", "A. Summing ASCII values and multiplying.", "B. Taking the remainder of the key divided by the table size.", "C. Squaring the key and taking middle digits.", "D. Using a random number generator.", "B"
"Hashing", "What are 'universal hashing' schemes designed to do?", "A. Guarantee O(1) worst-case performance.", "B. Avoid collisions completely.", "C. Choose a hash function randomly from a family of functions to minimize worst-case performance over any fixed set of keys.", "D. Hash any data type without issue.", "C"
"Hashing", "What is the main challenge when implementing deletion in an open-addressed hash table?", "A. It's difficult to find the element.", "B. Simply removing an element can break the search chain for other elements.", "C. It always requires rehashing the table.", "D. It causes memory leaks.", "B"
"Hashing", "To solve the deletion problem in open addressing, what is often used?", "A. Rehashing the entire table.", "B. Marking slots as 'deleted' or 'dummy'.", "C. Using chaining instead.", "D. Disabling deletions.", "B"
"Hashing", "What is the typical time complexity for inserting an element into a hash table in the average case?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Hashing", "If a hash function `h(key) = key % 7` is used for keys `10, 20, 30`, what are their hash indices?", "A. 3, 6, 2", "B. 3, 0, 2", "C. 3, 6, 4", "D. 3, 0, 4", "B"
"Hashing", "What is the primary role of a 'hash map' or 'dictionary' in programming languages?", "A. To store ordered lists of elements.", "B. To store key-value pairs for fast lookup.", "C. To implement queues and stacks.", "D. To perform mathematical calculations.", "B"
"Hashing", "Which of the following is true about the order of elements in a hash table?", "A. Elements are always stored in sorted order.", "B. Elements are stored in insertion order.", "C. The order of elements is generally not preserved and is arbitrary.", "D. Elements are stored in reverse sorted order.", "C"
"Hashing", "What is a 'bloom filter'?", "A. A type of hash table that allows exact matches.", "B. A probabilistic data structure that checks if an element is *possibly* in a set, with a chance of false positives.", "C. A perfect hash function.", "D. A method for resolving collisions.", "B"
"Hashing", "What is the purpose of 'collision resolution'?", "A. To prevent any collisions from occurring.", "B. To handle situations where different keys map to the same hash bucket.", "C. To improve the hash function's performance.", "D. To increase the size of the hash table.", "B"
"Hashing", "Which type of probing in open addressing calculates the next probe position by adding an increment that increases quadratically?", "A. Linear Probing", "B. Quadratic Probing", "C. Double Hashing", "D. Random Probing", "B"
"Hashing", "What is the primary benefit of a good hash function?", "A. It makes the hash table smaller.", "B. It reduces the number of collisions, leading to faster operations.", "C. It ensures data is always sorted.", "D. It encrypts the data before storage.", "B"
"Hashing", "If a hash table's load factor becomes too high, what is the consequence for search operations?", "A. They become O(1) asymptotically.", "B. They become slower, potentially approaching O(n).", "C. They become faster due to more elements being present.", "D. The hash table crashes.", "B"
"Hashing", "What is the disadvantage of using a very large prime number for the modulo operation in the division method of hashing?", "A. It increases collisions.", "B. It makes calculations slower.", "C. It reduces the uniformity of distribution.", "D. It only works for small keys.", "B"
"Hashing", "Which of the following statements is true about 'Uniform Hashing Assumption'?", "A. Every key is equally likely to hash to any slot, independently of other keys.", "B. All keys are uniformly distributed in the input data.", "C. Hash functions are always perfect.", "D. The load factor is always less than 1.", "A"
"Linked Lists", "Which of the following is NOT an advantage of linked lists over arrays?", "A. Dynamic size", "B. Ease of insertion/deletion", "C. Random access to elements", "D. Efficient memory utilization for varying sizes", "C"
"Linked Lists", "In a singly linked list, what does each node contain?", "A. Data only", "B. Data and a pointer to the previous node", "C. Data and a pointer to the next node", "D. Data and pointers to both previous and next nodes", "C"
"Linked Lists", "What is the time complexity to insert an element at the beginning of a singly linked list?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Linked Lists", "What is the time complexity to access the nth element in a singly linked list?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n log n)", "C"
"Linked Lists", "Which of the following is a disadvantage of linked lists compared to arrays?", "A. Dynamic size", "B. More memory overhead per element", "C. Easier insertion/deletion", "D. Flexibility in data types", "B"
"Linked Lists", "In a doubly linked list, how many pointers does each node typically have?", "A. One", "B. Two", "C. Three", "D. Zero", "B"
"Linked Lists", "What is a 'head' pointer in a linked list?", "A. A pointer to the last node.", "B. A pointer to the first node.", "C. A pointer to the current node during traversal.", "D. A pointer to the middle node.", "B"
"Linked Lists", "What is the time complexity to delete an element from the end of a singly linked list?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Linked Lists", "What is a 'circular linked list'?", "A. A linked list where nodes form a loop.", "B. A linked list with a fixed size.", "C. A linked list that stores only numbers.", "D. A linked list that can only be traversed once.", "A"
"Linked Lists", "Which type of linked list allows traversal in both forward and backward directions?", "A. Singly Linked List", "B. Doubly Linked List", "C. Circular Linked List", "D. Array-based Linked List", "B"
"Linked Lists", "What does a 'null' pointer signify in a linked list node?", "A. The node is empty.", "B. The node is the last node in the list.", "C. The node is corrupted.", "D. The node points to the head.", "B"
"Linked Lists", "What is the space complexity of a linked list with 'n' elements?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Linked Lists", "To insert a new node at a specific position (not beginning/end) in a singly linked list, what is the time complexity?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n log n)", "C"
"Linked Lists", "Which of the following is a common application of circular linked lists?", "A. Implementing a stack", "B. Implementing a queue", "C. Round-robin scheduling", "D. All of the above", "D"
"Linked Lists", "What happens if you try to access a node after its 'next' pointer is NULL in a singly linked list?", "A. The list automatically resizes.", "B. It's a valid operation.", "C. It leads to a runtime error (e.g., NullPointerException).", "D. The list becomes circular.", "C"
"Linked Lists", "What is the difference between a linked list and an array for storage?", "A. Arrays are dynamic, linked lists are static.", "B. Arrays store contiguous elements, linked lists store elements non-contiguously.", "C. Linked lists offer random access, arrays do not.", "D. Arrays only store numbers, linked lists store any data.", "B"
"Linked Lists", "How do you reverse a singly linked list iteratively?", "A. By swapping data in nodes.", "B. By changing the 'next' pointers of nodes.", "C. By using an auxiliary array.", "D. By sorting the list.", "B"
"Linked Lists", "What is a 'skip list'?", "A. A type of linked list that skips elements during traversal.", "B. A probabilistic data structure built upon linked lists that allows O(log n) average-case search, insertion, and deletion.", "C. A linked list for skipping corrupted data.", "D. A linked list with only two nodes.", "B"
"Linked Lists", "Which of the following is true about memory allocation for linked lists?", "A. Memory is allocated contiguously at compile time.", "B. Memory is allocated dynamically at runtime using `new` or `malloc`.", "C. Memory is pre-allocated in fixed blocks.", "D. Memory is only allocated when the list is full.", "B"
"Linked Lists", "What is the purpose of a 'dummy head node' in a linked list?", "A. To store dummy data.", "B. To simplify list operations (like insertion at the beginning or empty list handling) by always having a valid head.", "C. To indicate the end of the list.", "D. To provide a backup if the head node is lost.", "B"
"Linked Lists", "What is 'memory overhead' in linked lists?", "A. The extra memory used for data storage.", "B. The extra memory used for pointers in each node.", "C. The memory used for the head pointer.", "D. The memory used by the operating system.", "B"
"Linked Lists", "When checking for a cycle in a linked list, which algorithm is commonly used?", "A. Binary Search", "B. Floyd's Cycle-Finding Algorithm (Tortoise and Hare)", "C. Merge Sort", "D. Linear Search", "B"
"Linked Lists", "If a singly linked list has `n` nodes, what is the maximum number of times you might have to traverse to find the last node?", "A. 1", "B. log n", "C. n-1", "D. n", "D"
"Linked Lists", "What operation is generally faster in a linked list than in an array?", "A. Random access", "B. Searching for an element", "C. Insertion/deletion in the middle (once position is known)", "D. Traversing elements", "C"
"Linked Lists", "What is the 'tail' pointer in a linked list?", "A. Points to the first node.", "B. Points to the current node.", "C. Points to the last node.", "D. Points to the middle node.", "C"
"Linked Lists", "What is the time complexity to insert an element at the end of a doubly linked list?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Linked Lists", "Which of the following problems can be solved more efficiently with a linked list than an array?", "A. Implementing a stack where push/pop are at one end.", "B. Implementing a queue where enqueue/dequeue are at both ends.", "C. Implementing an undo/redo functionality.", "D. All of the above", "D"
"Linked Lists", "What is 'coalesced hashing' in the context of linked lists and hashing?", "A. A type of linked list used for sorting.", "B. A collision resolution technique in hash tables that uses a linked list for overflowing items in the main table.", "C. A method to merge two linked lists.", "D. A technique to find cycles in linked lists.", "B"
"Linked Lists", "Can a linked list node contain multiple data fields?", "A. No, only one data field.", "B. Yes, any number of data fields.", "C. Only two data fields.", "D. Only if it's a doubly linked list.", "B"
"Linked Lists", "What is the primary benefit of a circular linked list over a linear one?", "A. Easier to find the middle element.", "B. Allows continuous traversal from any node without a null check at the end.", "C. Uses less memory.", "D. Provides direct access to any element.", "B"
"Linked Lists", "What happens to memory when a node is deleted from a linked list?", "A. The memory is automatically freed by the garbage collector (in some languages).", "B. The memory must be explicitly freed to prevent memory leaks.", "C. The memory is never reused.", "D. The operating system handles it entirely.", "B"
"Linked Lists", "Which sorting algorithm is often implemented using linked lists due to its efficiency with non-contiguous data?", "A. QuickSort", "B. Heap Sort", "C. Merge Sort", "D. Bubble Sort", "C"
"Linked Lists", "What is the purpose of a 'sentinel node' in a linked list?", "A. To mark the current position.", "B. A special node that simplifies boundary conditions (e.g., empty list, adding to head/tail).", "C. A node that indicates a loop.", "D. A node that stores the list's size.", "B"
"Linked Lists", "When creating a new node, what is the initial value typically assigned to its 'next' pointer?", "A. The head pointer.", "B. The tail pointer.", "C. NULL (or equivalent).", "D. A random address.", "C"
"Linked Lists", "What is a 'self-referential structure' in C/C++?", "A. A structure that references itself directly.", "B. A structure that contains a pointer to a structure of the same type.", "C. A structure that cannot be modified.", "D. A structure used for recursion.", "B"
"Linked Lists", "In a singly linked list, to insert a node *before* a given node, what must you typically do?", "A. Directly update the given node's `next` pointer.", "B. Traverse from the head to find the *previous* node.", "C. It's not possible to insert before a node.", "D. Create a new head node.", "B"
"Linked Lists", "Which linked list variation is useful for implementing a LRU (Least Recently Used) cache?", "A. Singly linked list", "B. Doubly linked list", "C. Circular linked list", "D. Skip list", "B"
"Linked Lists", "What is the maximum number of nodes a linked list can have?", "A. Limited by integer overflow.", "B. Limited by available memory.", "C. Fixed at compile time.", "D. 1024", "B"
"Linked Lists", "What is the process of iterating through each node of a linked list called?", "A. Searching", "B. Sorting", "C. Traversal", "D. Hashing", "C"
"Linked Lists", "Which of the following is true about 'nodes' in a linked list?", "A. They must be stored in contiguous memory.", "B. They are always of different sizes.", "C. They are distinct entities linked by pointers.", "D. They are only used for numerical data.", "C"
"Linked Lists", "If a linked list has a loop, how would its traversal differ from a non-looped list?", "A. It would stop at NULL.", "B. It would never stop (unless a specific condition is met).", "C. It would always traverse backwards.", "D. It would automatically sort.", "B"
"Linked Lists", "What is the time complexity to search for an element in an unsorted singly linked list?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n log n)", "C"
"Linked Lists", "Can a linked list be empty?", "A. No, it must have at least one node.", "B. Yes, if its head pointer is NULL.", "C. Only if it's a circular linked list.", "D. Only if it's a doubly linked list.", "B"
"Linked Lists", "Which of these sorting algorithms uses linked lists naturally to avoid expensive data movement?", "A. Insertion Sort (can be adapted)", "B. QuickSort (not naturally)", "C. Bubble Sort (not naturally)", "D. Selection Sort (not naturally)", "A"
"Linked Lists", "What is the primary challenge with implementing arrays using linked lists?", "A. Arrays are inherently static.", "B. Random access in linked lists is O(n), not O(1).", "C. Linked lists use too much memory.", "D. Linked lists cannot store integer data.", "B"
"Linked Lists", "Which linked list type simplifies insertion/deletion at both ends, and also before/after any given node?", "A. Singly Linked List", "B. Circular Singly Linked List", "C. Doubly Linked List", "D. Skip List", "C"
"Linked Lists", "What is 'list flattening'?", "A. Removing duplicate elements from a linked list.", "B. Converting a multi-level (nested) linked list into a single-level list.", "C. Sorting a linked list.", "D. Reversing a linked list.", "B"
"Linked Lists", "What does 'pointer arithmetic' refer to when discussing linked lists?", "A. Adding numerical values to pointers.", "B. Moving pointers along the links (e.g., `current = current->next`).", "C. Calculating the size of a node.", "D. It's not applicable to linked lists.", "B"
"Linked Lists", "Which concept from linked lists is foundational for building other data structures like stacks and queues?", "A. Dynamic sizing", "B. Node-based structure with pointers", "C. Memory overhead", "D. Random access limitation", "B"
"Linked Lists", "What is a 'self-organizing list'?", "A. A list that automatically sorts itself.", "B. A linked list that reorders elements based on access frequency to improve future search times.", "C. A list that manages its own memory.", "D. A list that can detect errors.", "B"
"Stacks", "Which principle does a Stack data structure follow?", "A. FIFO (First In, First Out)", "B. LIFO (Last In, First Out)", "C. LILO (Last In, Last Out)", "D. FIFO or LIFO depending on implementation", "B"
"Stacks", "What is the operation to add an element to the top of a stack called?", "A. Pop", "B. Peek", "C. Push", "D. Dequeue", "C"
"Stacks", "What is the operation to remove an element from the top of a stack called?", "A. Push", "B. Pop", "C. Enqueue", "D. Top", "B"
"Stacks", "Which of the following is true about a stack?", "A. Elements can be accessed randomly.", "B. Elements are stored in contiguous memory locations only.", "C. Elements are added and removed from the same end.", "D. It is a linear data structure that supports non-linear access.", "C"
"Stacks", "What is the time complexity of the Push operation in a stack implemented using an array (assuming no resizing needed)?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Stacks", "What is the time complexity of the Pop operation in a stack implemented using a linked list?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Stacks", "When does a 'Stack Overflow' error occur?", "A. When trying to pop from an empty stack.", "B. When trying to push an element onto a full stack.", "C. When the stack is created.", "D. When the stack has only one element.", "B"
"Stacks", "When does a 'Stack Underflow' error occur?", "A. When trying to pop from an empty stack.", "B. When trying to push an element onto a full stack.", "C. When the stack is created.", "D. When the stack has only one element.", "A"
"Stacks", "Which of these is a common application of stacks?", "A. Implementing BFS (Breadth-First Search)", "B. Function call management (recursion)", "C. Database indexing", "D. Network routing", "B"
"Stacks", "What is the 'peek' or 'top' operation in a stack?", "A. Removes the top element.", "B. Adds an element to the top.", "C. Returns the top element without removing it.", "D. Checks if the stack is empty.", "C"
"Stacks", "What is the space complexity of a stack containing 'n' elements?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Stacks", "If a stack is implemented using an array, what happens if the array becomes full and a push operation is attempted?", "A. It automatically resizes (if dynamic array).", "B. A stack overflow error occurs.", "C. The element is silently discarded.", "D. It becomes a linked list.", "B"
"Stacks", "Which expression form is easier to evaluate using a stack?", "A. Infix", "B. Prefix", "C. Postfix", "D. All are equally easy", "C"
"Stacks", "What is the postfix expression for `A + B * C`?", "A. `+ A B C *`", "B. `A B C * +`", "C. `A B + C *`", "D. `A + B C *`", "B"
"Stacks", "What is the typical use of a stack in evaluating an expression?", "A. To store operands and operators temporarily.", "B. To sort the expression elements.", "C. To check for balanced parentheses.", "D. Both A and C", "D"
"Stacks", "Which algorithm uses a stack to keep track of visited nodes?", "A. Breadth-First Search (BFS)", "B. Depth-First Search (DFS)", "C. Dijkstra's Algorithm", "D. Prim's Algorithm", "B"
"Stacks", "How can you reverse a string using a stack?", "A. Push all characters onto the stack, then pop them off one by one.", "B. Pop all characters onto the stack, then push them off.", "C. Use a queue.", "D. Stacks cannot reverse strings.", "A"
"Stacks", "If a stack is implemented using a singly linked list, which end should be considered the 'top' for efficient operations?", "A. The head of the list.", "B. The tail of the list.", "C. The middle of the list.", "D. Either end, it doesn't matter.", "A"
"Stacks", "Which data structure is essential for implementing undo/redo functionality in applications?", "A. Queue", "B. Tree", "C. Stack", "D. Hash Table", "C"
"Stacks", "What is the time complexity of checking if a stack is empty?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Stacks", "Which of the following is an iterative application of a stack?", "A. Recursion elimination.", "B. Function call management.", "C. Infix to postfix conversion.", "D. All of the above.", "D"
"Stacks", "What is a 'stack frame' or 'activation record'?", "A. The physical memory location of a stack.", "B. A block of memory on the stack used to store information about a function call.", "C. The initial size of a stack.", "D. An error message from a stack.", "B"
"Stacks", "Can a stack store elements of different data types?", "A. Yes, always.", "B. No, only homogeneous types.", "C. Depends on the programming language and implementation.", "D. Only if it's a dynamic stack.", "C"
"Stacks", "Which of these real-world scenarios exemplifies a stack?", "A. A line at a ticket counter.", "B. A pile of plates.", "C. A deck of cards.", "D. A queue of cars at a traffic light.", "B"
"Stacks", "What is the 'top' pointer or index in a stack implementation?", "A. Points to the first element.", "B. Points to the element that was inserted first.", "C. Points to the element that will be removed next.", "D. Points to the bottom of the stack.", "C"
"Stacks", "What is the state of a stack after `Push(10)`, `Push(20)`, `Pop()`, `Push(30)`?", "A. 10, 30", "B. 20, 30", "C. 10, 20, 30", "D. 30, 10", "A"
"Stacks", "If a stack is empty, what should a `Pop` operation typically return or do?", "A. Return 0.", "B. Return null or throw an exception.", "C. Return the last pushed value.", "D. Remain idle.", "B"
"Stacks", "How is recursion typically implemented by compilers/interpreters?", "A. Using a queue.", "B. Using a hash table.", "C. Using a call stack.", "D. Using a linked list directly.", "C"
"Stacks", "What is the purpose of an 'operator precedence' table when converting infix to postfix using a stack?", "A. To determine the order of numbers.", "B. To decide when to push or pop operators from the stack.", "C. To check for valid operators.", "D. To count the number of operators.", "B"
"Stacks", "Which of the following expressions is valid after converting `(A + B) * C` to postfix?", "A. `A B + C *`", "B. `A B C + *`", "C. `A + B * C`", "D. `* + A B C`", "A"
"Stacks", "What is the space complexity of converting an infix expression to postfix using a stack?", "A. O(1)", "B. O(log n)", "C. O(n) in worst case (for operands/operators)", "D. O(n log n)", "C"
"Stacks", "What does it mean for a stack to be 'full'?", "A. It has no elements.", "B. It has reached its maximum capacity.", "C. It has more than one element.", "D. It is about to underflow.", "B"
"Stacks", "If you need to implement a stack with a fixed maximum size, which underlying data structure is most suitable?", "A. Linked List", "B. Array", "C. Hash Table", "D. Binary Tree", "B"
"Stacks", "If you need a stack that can grow and shrink dynamically without a fixed size limit, which underlying data structure is most suitable?", "A. Array", "B. Linked List", "C. Circular Queue", "D. Hash Table", "B"
"Stacks", "Which of the following is NOT an operation typically associated with a stack?", "A. isFull()", "B. isEmpty()", "C. enqueue()", "D. size()", "C"
"Stacks", "In terms of memory, which implementation of a stack might be more memory-efficient if the maximum size is known and fixed?", "A. Linked List", "B. Array", "C. Both are equally efficient.", "D. Depends on the data type.", "B"
"Stacks", "How many pointers are typically needed for a linked list implementation of a stack?", "A. Zero", "B. One (head/top pointer)", "C. Two (head and tail)", "D. Three", "B"
"Stacks", "Consider the sequence of operations: `Push(5), Push(10), Pop(), Push(15), Pop(), Push(20)`. What is the final element at the top of the stack?", "A. 10", "B. 15", "C. 20", "D. 5", "C"
"Stacks", "Which data structure is commonly used to check for balanced parentheses in an expression?", "A. Queue", "B. Stack", "C. Linked List", "D. Array", "B"
"Stacks", "When processing an expression with a stack for parentheses balancing, what happens when a closing parenthesis is encountered?", "A. It is pushed onto the stack.", "B. It is discarded.", "C. The stack is popped, and the popped element is checked against the closing parenthesis.", "D. The entire stack is emptied.", "C"
"Stacks", "What is the primary role of a stack in a browser's history feature?", "A. To store visited URLs in LIFO order (Back button).", "B. To store visited URLs in FIFO order.", "C. To sort the URLs by date.", "D. To encrypt the URLs.", "A"
"Stacks", "If you have a stack `S` and a queue `Q`, and you want to reverse the elements of `S` into `Q`, what operations would you use?", "A. Pop from `S`, Enqueue to `Q`.", "B. Enqueue to `S`, Pop from `Q`.", "C. Pop from `S`, Push to `Q`.", "D. Push to `S`, Enqueue to `Q`.", "A"
"Stacks", "What is a 'persistent stack'?", "A. A stack that never empties.", "B. A stack that saves its state after every operation, allowing access to previous versions.", "C. A stack stored on disk.", "D. A stack that uses persistent memory.", "B"
"Stacks", "What is the 'call stack' in computer programming?", "A. A list of all variables in a program.", "B. A stack that stores information about active subroutines/functions.", "C. A data structure used for parallel processing.", "D. A queue of function calls.", "B"
"Stacks", "In some systems, what is the default behavior if the call stack grows too large?", "A. The program continues normally.", "B. It leads to a 'stack overflow' error.", "C. It automatically resizes the stack memory.", "D. It converts to a linked list.", "B"
"Stacks", "Which of the following is true about dynamic stack implementations (e.g., using linked lists)?", "A. They are prone to stack overflow if not managed well.", "B. They do not have a fixed maximum size, limited only by available memory.", "C. Push/Pop operations are O(n).", "D. They use less memory than array-based stacks.", "B"
"Stacks", "What is the role of the 'base pointer' or 'frame pointer' in a stack frame?", "A. Points to the current top of the stack.", "B. Points to the bottom of the current stack frame.", "C. Points to the return address.", "D. Points to the next stack frame.", "B"
"Stacks", "What does it mean for an algorithm to be 'tail-recursive'?", "A. It uses a queue instead of a stack.", "B. Its recursive call is the last operation, allowing optimization to iterative code.", "C. It avoids using the call stack.", "D. It has a very long recursion depth.", "B"
"Stacks", "If you need to process elements in the exact reverse order of their arrival, which data structure is most appropriate?", "A. Queue", "B. Stack", "C. Array", "D. Linked List (general)", "B"
"Stacks", "Which of the following is a direct consequence of the LIFO principle?", "A. The oldest element is processed first.", "B. The element added last is the first one to be removed.", "C. Elements are always sorted.", "D. Random access is efficient.", "B"
"Queues", "Which principle does a Queue data structure follow?", "A. LIFO (Last In, First Out)", "B. FIFO (First In, First Out)", "C. LILO (Last In, Last Out)", "D. FILO (First In, Last Out)", "B"
"Queues", "What is the operation to add an element to the rear of a queue called?", "A. Dequeue", "B. Peek", "C. Enqueue", "D. Pop", "C"
"Queues", "What is the operation to remove an element from the front of a queue called?", "A. Enqueue", "B. Dequeue", "C. Front", "D. Push", "B"
"Queues", "Which of the following is true about a queue?", "A. Elements can be accessed randomly.", "B. Elements are added and removed from opposite ends.", "C. Elements are stored in contiguous memory locations only.", "D. It is a non-linear data structure.", "B"
"Queues", "What is the time complexity of the Enqueue operation in a queue implemented using a circular array (assuming not full)?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Queues", "What is the time complexity of the Dequeue operation in a queue implemented using a linked list?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Queues", "When does a 'Queue Overflow' error occur?", "A. When trying to dequeue from an empty queue.", "B. When trying to enqueue an element onto a full queue.", "C. When the queue is created.", "D. When the queue has only one element.", "B"
"Queues", "When does a 'Queue Underflow' error occur?", "A. When trying to dequeue from an empty queue.", "B. When trying to enqueue an element onto a full queue.", "C. When the queue is created.", "D. When the queue has only one element.", "A"
"Queues", "Which of these is a common application of queues?", "A. Function call management (recursion)", "B. CPU scheduling", "C. Checking balanced parentheses", "D. Undo/Redo operations", "B"
"Queues", "What is the 'front' or 'peek' operation in a queue?", "A. Removes the front element.", "B. Adds an element to the rear.", "C. Returns the front element without removing it.", "D. Checks if the queue is empty.", "C"
"Queues", "What is the space complexity of a queue containing 'n' elements?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)", "C"
"Queues", "If a queue is implemented using a fixed-size array, what is a major issue to address after several enqueue and dequeue operations?", "A. Queue becomes full instantly.", "B. Underflow errors.", "C. Wasted space at the beginning of the array (front pointer moves).", "D. Data corruption.", "C"
"Queues", "How is the issue of wasted space in an array-based queue typically resolved?", "A. By using a stack.", "B. By using a circular array (circular queue).", "C. By always shifting elements to the front.", "D. By making the array larger.", "B"
"Queues", "What is a 'circular queue'?", "A. A queue that stores only numbers.", "B. A queue where the rear wraps around to the front of the array when needed.", "C. A queue that processes elements in a random order.", "D. A queue with a fixed capacity.", "B"
"Queues", "Which type of queue is suitable for implementing priority-based tasks?", "A. Simple Queue", "B. Circular Queue", "C. Priority Queue", "D. Deque (Double-ended Queue)", "C"
"Queues", "What is the time complexity for inserting an element into a Priority Queue (typically implemented with a heap)?", "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n log n)", "B"
"Queues", "What is a 'Deque' (Double-ended Queue)?", "A. A queue that only allows insertions from the front.", "B. A queue that only allows deletions from the rear.", "C. A queue that allows insertions and deletions from both ends.", "D. A queue that stores two types of data.", "C"
"Queues", "Which of the following data structures is essential for implementing BFS (Breadth-First Search)?", "A. Stack", "B. Queue", "C. Linked List (general)", "D. Hash Table", "B"
"Queues", "How many pointers are typically needed for a linked list implementation of a queue?", "A. One (front pointer)", "B. Two (front and rear pointers)", "C. Zero", "D. Three", "B"
"Queues", "What is the time complexity of checking if a queue is empty?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Queues", "If a queue is empty, what should a `Dequeue` operation typically return or do?", "A. Return 0.", "B. Return null or throw an exception.", "C. Return the last enqueued value.", "D. Remain idle.", "B"
"Queues", "Which of these real-world scenarios exemplifies a queue?", "A. A stack of books.", "B. Cars waiting at a traffic light.", "C. A browser's back history.", "D. A pile of clean laundry.", "B"
"Queues", "What is the primary advantage of a linked list implementation of a queue over an array implementation?", "A. Better cache performance.", "B. Fixed size, so no overflow.", "C. Dynamic size, no need for resizing or overflow issues (until memory runs out).", "D. Faster access to middle elements.", "C"
"Queues", "In a simple array-based queue, if the `front` pointer is at index `i` and `rear` pointer is at index `j`, how do you check if the queue is full?", "A. `front == rear`", "B. `front == (rear + 1) % capacity` (for circular)", "C. `rear == capacity - 1`", "D. `front == 0 && rear == capacity - 1`", "D"
"Queues", "What is the state of a queue after `Enqueue(A)`, `Enqueue(B)`, `Dequeue()`, `Enqueue(C)`?", "A. B, C", "B. A, B, C", "C. C, B", "D. A, C", "A"
"Queues", "Which of the following is true about a Priority Queue?", "A. Elements are retrieved in the order they were inserted.", "B. Elements are retrieved based on their priority.", "C. It is always implemented using a linked list.", "D. It only stores integers.", "B"
"Queues", "What data structure is commonly used to implement a Priority Queue efficiently?", "A. Stack", "B. Simple Array", "C. Heap", "D. Hash Table", "C"
"Queues", "Which search algorithm uses a queue to explore nodes level by level?", "A. Depth-First Search (DFS)", "B. Breadth-First Search (BFS)", "C. Linear Search", "D. Binary Search", "B"
"Queues", "In a circular array-based queue, what is the condition for an empty queue?", "A. `front == (rear + 1) % capacity`", "B. `front == rear`", "C. `front == 0`", "D. `rear == capacity - 1`", "B"
"Queues", "If a queue is used to process tasks in a printer spooler, what happens when a new print job arrives?", "A. It goes to the front of the queue.", "B. It is added to the rear of the queue.", "C. It is discarded if the queue is full.", "D. It is sorted based on document size.", "B"
"Queues", "Which of the following is NOT a typical operation associated with a queue?", "A. isFull()", "B. isEmpty()", "C. Pop()", "D. size()", "C"
"Queues", "What is the difference between a queue and a stack?", "A. Stacks are FIFO, queues are LIFO.", "B. Stacks operate on one end, queues operate on two ends.", "C. Stacks are linear, queues are non-linear.", "D. Stacks are used for recursion, queues are not.", "B"
"Queues", "Which queue variant would you use if you need to add and remove elements from both ends?", "A. Simple Queue", "B. Circular Queue", "C. Priority Queue", "D. Deque", "D"
"Queues", "What is the disadvantage of implementing a queue using two stacks?", "A. Enqueue/Dequeue operations become O(1).", "B. Enqueue/Dequeue operations can become O(n) in worst case for specific operations.", "C. It uses less memory.", "D. It is simpler to implement.", "B"
"Queues", "In a queue implemented with a linked list, which node represents the `front` of the queue?", "A. The head node.", "B. The tail node.", "C. The middle node.", "D. Any node.", "A"
"Queues", "In a queue implemented with a linked list, which node represents the `rear` of the queue?", "A. The head node.", "B. The tail node.", "C. The middle node.", "D. Any node.", "B"
"Queues", "What is a 'message queue' in operating systems?", "A. A queue for sorting messages.", "B. A queue used for inter-process communication.", "C. A queue for network packets only.", "D. A queue for managing system errors.", "B"
"Queues", "Which data structure is best suited for buffering data streams?", "A. Stack", "B. Queue", "C. Array", "D. Tree", "B"
"Queues", "If a queue is used to manage print jobs, and a high-priority job arrives, how would a standard queue handle it?", "A. It would process it immediately.", "B. It would place it at the front of the queue.", "C. It would place it at the rear, processing it in FIFO order.", "D. It would discard it.", "C"
"Queues", "What is a 'job queue' in an operating system context?", "A. A queue of jobs waiting for user input.", "B. A queue of programs waiting to be executed by the CPU.", "C. A queue of completed jobs.", "D. A queue for network connections.", "B"
"Queues", "What is the typical time complexity of getting the `front` element without removing it in a queue?", "A. O(n)", "B. O(log n)", "C. O(1)", "D. O(n^2)", "C"
"Queues", "Which type of queue is typically used for a task scheduler in a multi-threaded environment where tasks have different priorities?", "A. Simple Queue", "B. Circular Queue", "C. Priority Queue", "D. Deque", "C"
"Queues", "Can a queue store elements of different data types?", "A. Yes, always.", "B. No, only homogeneous types.", "C. Depends on the programming language and implementation.", "D. Only if it's a dynamic queue.", "C"
"Queues", "What is the purpose of a 'buffer' when using a queue?", "A. To sort incoming data.", "B. To temporarily store data between a producer and consumer, smoothing out rate differences.", "C. To encrypt the data.", "D. To compress the data.", "B"
"Queues", "In an array-based implementation of a queue, how is the `rear` pointer (index) updated after an `Enqueue` operation?", "A. `rear = rear - 1`", "B. `rear = (rear + 1) % capacity` (for circular)", "C. `rear = 0`", "D. `rear = front`", "B"
"Queues", "What is the main benefit of a circular queue over a linear array-based queue?", "A. It's simpler to implement.", "B. It avoids wasted memory space by reusing array slots.", "C. It is inherently dynamic.", "D. It provides O(1) time complexity for search.", "B"
"Queues", "If a queue implementation uses a dynamic array (like `ArrayList`), what happens if an `Enqueue` operation is attempted on a full underlying array?", "A. A queue overflow error occurs.", "B. The array's capacity is increased (e.g., doubled), and elements are copied.", "C. The element is discarded.", "D. The queue becomes a linked list.", "B"
"Queues", "Which of the following data structures can be used to implement both a stack and a queue?", "A. Array", "B. Linked List", "C. Both A and B", "D. Neither", "C"
"Queues", "What is the concept of 'throughput' related to queues in systems?", "A. The number of elements currently in the queue.", "B. The rate at which elements are processed and leave the queue.", "C. The maximum capacity of the queue.", "D. The time an element waits in the queue.", "B"
"Queues", "Which type of queue is most suitable for handling input from devices where the order of arrival is critical?", "A. Priority Queue", "B. Deque", "C. Simple (FIFO) Queue", "D. Circular Queue (if capacity is fixed)", "C"
"Recursion", "What is recursion in programming?", "A. A loop that iterates infinitely.", "B. A function that calls itself directly or indirectly.", "C. A function that calls another function.", "D. A technique to avoid loops.", "B"
"Recursion", "What are the two main components of a recursive function?", "A. Input and output.", "B. Base case and recursive step.", "C. Loop and conditional statement.", "D. Global and local variables.", "B"
"Recursion", "What is the 'base case' in a recursive function?", "A. The first recursive call.", "B. The condition that terminates the recursion.", "C. The part that performs the main computation.", "D. The last line of the function.", "B"
"Recursion", "What happens if a recursive function does not have a base case?", "A. It runs infinitely, leading to a stack overflow.", "B. It returns an error at compile time.", "C. It performs faster.", "D. It automatically stops after a few calls.", "A"
"Recursion", "Which data structure is implicitly used by the system to manage recursive function calls?", "A. Queue", "B. Heap", "C. Stack (Call Stack)", "D. Linked List", "C"
"Recursion", "What is the time complexity of a recursive factorial function for a number N?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N^2)", "C"
"Recursion", "What is the space complexity of a recursive factorial function for a number N?", "A. O(1)", "B. O(log N)", "C. O(N) due to call stack", "D. O(N^2)", "C"
"Recursion", "Which of the following problems is naturally suited for a recursive solution?", "A. Finding an element in an unsorted array.", "B. Traversing a tree.", "C. Sorting a large array using Bubble Sort.", "D. Implementing a queue.", "B"
"Recursion", "What is 'tail recursion'?", "A. A recursive call that is the first operation in the function.", "B. A recursive call that is the last operation in the function.", "C. A recursive call that is not optimized.", "D. A recursion without a base case.", "B"
"Recursion", "Why is tail recursion important in some programming languages?", "A. It makes the code more complex.", "B. It cannot be optimized by compilers.", "C. It can be optimized to iterative code, reducing stack space.", "D. It always runs faster.", "C"
"Recursion", "What is the output of the following pseudocode: `function func(n): if n <= 0 then return 0 else return n + func(n-1)` for `func(3)`?", "A. 0", "B. 3", "C. 6", "D. 9", "C"
"Recursion", "What is the common issue that can arise from excessive recursion?", "A. Heap overflow.", "B. Stack overflow.", "C. Compilation error.", "D. Memory underflow.", "B"
"Recursion", "Which of the following is an iterative solution for a problem that can also be solved recursively?", "A. Loop", "B. Memoization", "C. Dynamic Programming", "D. All of the above (often used for optimization/alternative)", "A"
"Recursion", "Can every recursive function be rewritten iteratively?", "A. No, some problems are inherently recursive.", "B. Yes, with explicit stack management.", "C. Only if it's tail-recursive.", "D. Only if it's a simple recursion.", "B"
"Recursion", "What is 'memoization' in the context of recursion?", "A. A technique to make recursion run infinitely.", "B. A technique to store results of expensive function calls and return the cached result when the same inputs occur again.", "C. A method to convert recursion to iteration.", "D. A debugging technique for recursion.", "B"
"Recursion", "For which type of problems is memoization particularly useful with recursion?", "A. Problems with no overlapping subproblems.", "B. Problems with optimal substructure and overlapping subproblems (Dynamic Programming).", "C. Problems with large inputs but no repetitive calculations.", "D. Simple recursive problems like factorial.", "B"
"Recursion", "What is the Fibonacci sequence defined by `F(n) = F(n-1) + F(n-2)` with base cases `F(0)=0, F(1)=1`? What is `F(4)`?", "A. 2", "B. 3", "C. 4", "D. 5", "B"
"Recursion", "What is the disadvantage of a naive recursive implementation of Fibonacci (without memoization)?", "A. It uses too much memory.", "B. It performs redundant calculations of overlapping subproblems.", "C. It has a high constant factor.", "D. It is not possible to implement.", "B"
"Recursion", "Which of the following sorting algorithms is typically implemented using recursion (divide and conquer)?", "A. Bubble Sort", "B. Insertion Sort", "C. Merge Sort", "D. Selection Sort", "C"
"Recursion", "When performing a Depth-First Search (DFS) on a graph, what data structure can be used to explicitly manage the traversal if not using recursion?", "A. Queue", "B. Stack", "C. Hash Table", "D. Priority Queue", "B"
"Recursion", "What is 'direct recursion'?", "A. A function that calls another function.", "B. A function that calls itself directly.", "C. A function that avoids calling itself.", "D. A function that leads to infinite recursion.", "B"
"Recursion", "What is 'indirect recursion'?", "A. A function that calls itself directly.", "B. A function that calls another function, which in turn calls the first function.", "C. A recursive function with no base case.", "D. A recursive function that uses a global variable.", "B"
"Recursion", "Which of the following problems can be solved using recursion, demonstrating backtracking?", "A. Tower of Hanoi", "B. N-Queens Problem", "C. Sudoku Solver", "D. All of the above", "D"
"Recursion", "What is the typical return value of a recursive function when it hits its base case?", "A. A recursive call.", "B. A value that directly contributes to the final solution without further recursion.", "C. An error message.", "D. Nothing (void).", "B"
"Recursion", "What is 'mutual recursion'?", "A. When two functions call each other.", "B. When a function calls itself twice.", "C. When a function uses multiple base cases.", "D. When recursion is avoided.", "A"
"Recursion", "In the Tower of Hanoi problem with 'n' disks, what is the minimum number of moves required?", "A. n^2", "B. 2n - 1", "C. 2^n - 1", "D. n!", "C"
"Recursion", "When analyzing the time complexity of recursion, what does the 'recurrence relation' describe?", "A. The memory usage of the function.", "B. How the running time of a problem of size 'n' relates to the running time of smaller subproblems.", "C. The number of base cases.", "D. The number of iterations in a loop.", "B"
"Recursion", "What is the time complexity of generating all permutations of a string of length N?", "A. O(N)", "B. O(N log N)", "C. O(N!)", "D. O(2^N)", "C"
"Recursion", "Which of the following is true about recursion?", "A. It always consumes less memory than iteration.", "B. It can lead to more elegant and readable code for certain problems.", "C. It is generally faster than iteration for all problems.", "D. It is only used for mathematical calculations.", "B"
"Recursion", "What is the 'maximum recursion depth'?", "A. The number of times a function calls itself.", "B. The maximum number of frames allowed on the call stack before a stack overflow.", "C. The maximum input size for a recursive function.", "D. The number of base cases in a function.", "B"
"Recursion", "How can you debug a recursive function?", "A. Only by checking the final output.", "B. By setting breakpoints and inspecting the call stack.", "C. Recursion cannot be debugged.", "D. By converting it to an iterative function first.", "B"
"Recursion", "What is the relationship between recursion and mathematical induction?", "A. They are unrelated.", "B. Recursion is similar to the inductive step, and the base case is similar to the base case in induction.", "C. Mathematical induction proves iterative functions.", "D. Recursion is always less efficient than induction.", "B"
"Recursion", "Consider the pseudocode: `function power(base, exp): if exp == 0 then return 1 else return base * power(base, exp-1)`. What is `power(2, 3)`?", "A. 2", "B. 4", "C. 6", "D. 8", "D"
"Recursion", "What is the time complexity of the `power(base, exp)` function (naive recursive) for `exp`?", "A. O(1)", "B. O(log exp)", "C. O(exp)", "D. O(exp^2)", "C"
"Recursion", "Which problem demonstrates the principle of 'divide and conquer' inherently through recursion?", "A. Linear Search", "B. Bubble Sort", "C. QuickSort", "D. All of the above", "C"
"Recursion", "What is the space complexity of a recursive implementation of binary search?", "A. O(1)", "B. O(log n) due to recursion stack.", "C. O(n)", "D. O(n log n)", "B"
"Recursion", "What is 'backtracking' in the context of recursion?", "A. Going back to the previous state to explore other possibilities when a path doesn't lead to a solution.", "B. Reversing the order of recursive calls.", "C. An optimization for tail recursion.", "D. A method to avoid infinite loops.", "A"
"Recursion", "Which of the following is a classic example of a problem solved with backtracking recursion?", "A. Factorial calculation.", "B. Finding the shortest path in a graph (e.g., Dijkstra).", "C. Generating subsets of a set.", "D. Sorting an array.", "C"
"Recursion", "When converting a recursive function to an iterative one, what explicit data structure might you need to use?", "A. Queue", "B. Hash Table", "C. Stack", "D. Tree", "C"
"Recursion", "What is the main conceptual benefit of writing a recursive solution over an iterative one for certain problems?", "A. Always faster execution.", "B. Less memory consumption.", "C. More closely mirrors the mathematical definition or problem structure, leading to cleaner code.", "D. Easier to debug.", "C"
"Recursion", "What does it mean for a recursive function to have 'overlapping subproblems'?", "A. The subproblems are completely independent.", "B. The same subproblems are solved multiple times during the recursion.", "C. The subproblems are solved in parallel.", "D. The subproblems are always sorted.", "B"
"Recursion", "What is the recursive definition of greatest common divisor (GCD) using the Euclidean algorithm?", "A. `GCD(a, b) = GCD(b, a % b)` with base `GCD(a, 0) = a`.", "B. `GCD(a, b) = GCD(a-b, b)`.", "C. `GCD(a, b) = a * b`.", "D. `GCD(a, b) = a + b`.", "A"
"Recursion", "What is the output of `func(5)` in the following pseudocode: `function func(n): if n == 1 then return 1 else return n + func(n-2)`?", "A. 15", "B. 9", "C. 10", "D. Infinite loop", "B"
"Recursion", "Can recursion be used to implement infinite loops?", "A. No, only iterative loops can be infinite.", "B. Yes, if there is no proper base case or the base case is never reached.", "C. Only in specific programming languages.", "D. Only for positive numbers.", "B"
"Recursion", "What is the relationship between 'divide and conquer' and recursion?", "A. They are unrelated concepts.", "B. Divide and conquer is a problem-solving paradigm, and recursion is a common technique to implement it.", "C. Recursion is a type of divide and conquer algorithm.", "D. Divide and conquer avoids recursion.", "B"
"Recursion", "Which of the following is an example of a problem where an iterative solution might be preferred over a recursive one due to stack limitations?", "A. Factorial of a very large number.", "B. Traversing a small binary tree.", "C. Fibonacci sequence for small n.", "D. Tower of Hanoi for small disks.", "A"
"Recursion", "What is the recursion depth for finding an element in a binary search tree of height `h`?", "A. O(1)", "B. O(log h)", "C. O(h)", "D. O(n)", "C"
"Recursion", "What happens to local variables of a recursive function when it calls itself?", "A. They are shared across all calls.", "B. A new set of local variables is created for each call on the stack.", "C. They are deleted.", "D. They become global variables.", "B"
"Recursion", "What is the output of `func(0)` for: `function func(n): if n > 0 then return n * func(n-1) else return 1`?", "A. 0", "B. 1", "C. Error", "D. Infinite loop", "B"
"Recursion", "When converting a recursive solution to dynamic programming, what is the 'bottom-up' approach called?", "A. Memoization", "B. Tabulation", "C. Backtracking", "D. Divide and Conquer", "B"
"Backtracking", "Which of the following best describes backtracking?", "A. A technique to sort elements in reverse order.", "B. A brute-force algorithmic paradigm that finds all (or some) solutions by systematically searching through a solution space.", "C. A method to always find the optimal solution.", "D. A technique to avoid recursion.", "B"
"Backtracking", "What is the core idea of backtracking?", "A. To eliminate possibilities one by one.", "B. To build a solution step-by-step, and if a partial solution cannot be completed, undo the last step and try another path.", "C. To always choose the best immediate option.", "D. To use a queue to manage states.", "B"
"Backtracking", "Which data structure is implicitly or explicitly used in backtracking to keep track of the current path and enable undoing steps?", "A. Queue", "B. Stack", "C. Hash Table", "D. Linked List", "B"
"Backtracking", "When does backtracking 'prune' the search space?", "A. When a solution is found.", "B. When a partial solution is determined to be invalid or cannot lead to a valid solution.", "C. When all possible solutions are explored.", "D. When the input is too large.", "B"
"Backtracking", "Which of the following problems is a classic example solved using backtracking?", "A. Finding the factorial of a number.", "B. Sorting an array.", "C. N-Queens Problem.", "D. Calculating Fibonacci numbers iteratively.", "C"
"Backtracking", "In the N-Queens problem, what does backtracking primarily help to avoid?", "A. Placing queens on the same row.", "B. Placing queens on the same column.", "C. Placing queens on the same diagonal.", "D. Exploring invalid board configurations that won't lead to a solution.", "D"
"Backtracking", "What is the purpose of the 'explore' step in a backtracking algorithm?", "A. To check if a solution is found.", "B. To add an element to the current partial solution and recursively call the function.", "C. To remove an element from the current partial solution.", "D. To print the final solution.", "B"
"Backtracking", "What is the purpose of the 'undo' or 'backtrack' step?", "A. To confirm a solution.", "B. To remove the last added element from the partial solution, effectively trying a different branch.", "C. To restart the algorithm from scratch.", "D. To clean up memory.", "B"
"Backtracking", "What is the time complexity of a backtracking algorithm for solving a problem with `N` choices at each step and `M` steps (worst case, without pruning)?", "A. O(N * M)", "B. O(N + M)", "C. O(N^M)", "D. O(M^N)", "C"
"Backtracking", "Is backtracking guaranteed to find an optimal solution?", "A. Yes, always.", "B. No, it finds *all* (or some) valid solutions, optimality depends on additional logic.", "C. Only if the problem has unique solutions.", "D. Only for small inputs.", "B"
"Backtracking", "Which of the following is a common application of backtracking?", "A. Compiling source code.", "B. Solving Sudoku puzzles.", "C. Implementing a web server.", "D. Optimizing database queries.", "B"
"Backtracking", "What is the primary difference between recursion and backtracking?", "A. Recursion is always for sorting; backtracking is for searching.", "B. Backtracking is a specific algorithmic technique built on recursion that explores paths and reverts.", "C. Recursion avoids stacks; backtracking requires them.", "D. They are completely unrelated.", "B"
"Backtracking", "In generating all permutations of a string, when does backtracking occur?", "A. After printing a full permutation.", "B. When a character has been placed, and all possibilities for the remaining positions are explored, then that character is 'unplaced' to try another.", "C. When the string is empty.", "D. At the beginning of the function.", "B"
"Backtracking", "What is a 'state space tree' in the context of backtracking?", "A. A tree that stores all variables.", "B. A tree that represents all possible partial solutions and their extensions.", "C. A tree that is always sorted.", "D. A tree used for network routing.", "B"
"Backtracking", "What is 'pruning' in backtracking?", "A. Adding more branches to the search tree.", "B. Eliminating branches of the state space tree that cannot lead to a valid solution.", "C. Rearranging the order of branches.", "D. Merging multiple solutions.", "B"
"Backtracking", "Which problem involves finding a path in a grid from start to end, visiting each cell exactly once?", "A. N-Queens", "B. Hamiltonian Cycle (or Path)", "C. Subset Sum", "D. Traveling Salesperson Problem (TSP)", "B"
"Backtracking", "When solving the Subset Sum problem using backtracking, what is the 'choice' at each step?", "A. To include the current element in the subset or not.", "B. To sort the elements or not.", "C. To find the largest element.", "D. To find the smallest element.", "A"
"Backtracking", "What is the difference between backtracking and brute force?", "A. Backtracking is always faster than brute force.", "B. Backtracking is a type of brute force, but it systematically prunes the search space.", "C. Brute force uses recursion, backtracking uses iteration.", "D. Brute force doesn't explore all options.", "B"
"Backtracking", "What type of problems are most suitable for backtracking?", "A. Optimization problems (finding the best solution).", "B. Decision problems (yes/no answer).", "C. Enumeration/Search problems (finding all or some solutions satisfying constraints).", "D. Sorting problems.", "C"
"Backtracking", "Is the Traveling Salesperson Problem (TSP) typically solved exactly with backtracking for large inputs?", "A. Yes, it's very efficient.", "B. No, it's NP-hard, so backtracking is too slow for large inputs; heuristics are used.", "C. Only if the graph is small.", "D. TSP is not a backtracking problem.", "B"
"Backtracking", "What does it mean for a backtracking solution to be 'optimal'?", "A. It runs in O(1) time.", "B. It uses the least amount of memory.", "C. It finds the best possible solution among all valid ones, if specifically designed to do so.", "D. It finds a solution quickly, even if not the best.", "C"
"Backtracking", "Which of the following is an example of a constraint satisfaction problem typically solved with backtracking?", "A. Finding the minimum element in an array.", "B. Cryptarithmetic puzzles (e.g., SEND + MORE = MONEY).", "C. Calculating the sum of an array.", "D. Searching for a string.", "B"
"Backtracking", "When solving the Rat in a Maze problem with backtracking, if a path leads to a dead end, what does the algorithm do?", "A. Continues forward.", "B. Marks the path as visited and backtracks to try another direction.", "C. Resets the entire maze.", "D. Randomly chooses a new direction.", "B"
"Backtracking", "What is the typical return value of a recursive backtracking function if a solution is found?", "A. True/False (for existence) or the solution itself.", "B. An error message.", "C. The number of steps taken.", "D. The input array.", "A"
"Backtracking", "Can backtracking be implemented iteratively?", "A. No, it's purely recursive.", "B. Yes, by explicitly managing a stack.", "C. Only for simple problems.", "D. Only in certain programming languages.", "B"
"Backtracking", "In the context of backtracking, what is a 'partial candidate'?", "A. An incomplete solution that might be extended to a full solution.", "B. A solution that is known to be incorrect.", "C. A specific input value.", "D. A function parameter.", "A"
"Backtracking", "When generating all subsets of a set using backtracking, what choices are made at each step?", "A. To include the current element or not.", "B. To sort the subset.", "C. To remove elements.", "D. To add elements until the set is empty.", "A"
"Backtracking", "What is the primary benefit of pruning in backtracking?", "A. It ensures a solution is found faster.", "B. It reduces the number of unnecessary computations by cutting off branches.", "C. It simplifies the code.", "D. It converts the problem to a dynamic programming one.", "B"
"Backtracking", "Which of the following is typically NOT considered a backtracking problem?", "A. Permutations generation.", "B. Combination sum.", "C. Fibonacci sequence calculation.", "D. Graph coloring.", "C"
"Backtracking", "In the N-Queens problem, how do you check if placing a queen at `(row, col)` is valid?", "A. Check only the row.", "B. Check only the column.", "C. Check the row, column, and both diagonals for conflicts with previously placed queens.", "D. Check all 8 directions from `(row, col)`.", "C"
"Backtracking", "What is a 'decision tree' often associated with in backtracking?", "A. A tree of if-else statements.", "B. A conceptual tree representing the choices made at each step in the search for a solution.", "C. A data structure used for sorting.", "D. A tree that stores only valid solutions.", "B"
"Backtracking", "When solving the M-Coloring Problem using backtracking, what decision is made for each vertex?", "A. To remove it or not.", "B. To assign it one of the M available colors.", "C. To check if it's connected to other vertices.", "D. To change its position.", "B"
"Backtracking", "If a backtracking algorithm is searching for *any* valid solution, how does it typically behave once one is found?", "A. It continues searching for all others.", "B. It stops and returns the found solution.", "C. It prints an error.", "D. It backtracks and then continues searching.", "B"
"Backtracking", "What is the main challenge when implementing backtracking solutions?", "A. They are always very simple.", "B. Defining the state, choices, constraints, and base case correctly, and managing the state changes.", "C. Lack of suitable programming languages.", "D. Limited memory availability.", "B"
"Backtracking", "Which approach does backtracking fall under?", "A. Greedy approach", "B. Dynamic Programming", "C. Brute-force with pruning", "D. Divide and Conquer", "C"
"Backtracking", "What happens to the state (e.g., board configuration, set of chosen elements) when backtracking from a recursive call?", "A. It remains unchanged.", "B. It is automatically reset by the system.", "C. It is reverted to its state *before* the last decision was made.", "D. It is completely cleared.", "C"
"Backtracking", "For solving the Sudoku problem, how does backtracking work?", "A. It tries numbers 1-9 in empty cells, and if a number leads to an invalid state, it backtracks.", "B. It guesses all numbers at once.", "C. It uses a sorting algorithm.", "D. It only works on partially filled grids.", "A"
"Backtracking", "What is the difference in goal between backtracking and dynamic programming?", "A. Backtracking finds *all* solutions, DP finds *optimal* solutions (or count them).", "B. Backtracking is always faster.", "C. DP uses recursion, backtracking uses iteration.", "D. Backtracking is only for small problems.", "A"
"Backtracking", "Which algorithm for generating all permutations of a string utilizes backtracking?", "A. Lexicographical order generation.", "B. Heap's algorithm.", "C. Iterative permutation generation.", "D. All of the above (some variants are recursive with backtracking).", "B"
"Backtracking", "When should you NOT use backtracking?", "A. When finding all possible solutions is required.", "B. When the problem has strict constraints that eliminate many paths early.", "C. When the search space is astronomically large and only an approximate solution is acceptable.", "D. When solving combinatorial problems.", "C"
"Backtracking", "What is 'branch and bound'?", "A. A synonym for backtracking.", "B. A technique similar to backtracking but specifically for optimization problems, using bounds to prune branches.", "C. A technique for parallel processing.", "D. A method for traversing binary trees.", "B"
"Backtracking", "Which common graph traversal algorithm is essentially a backtracking process?", "A. Breadth-First Search (BFS)", "B. Depth-First Search (DFS)", "C. Dijkstra's Algorithm", "D. Prim's Algorithm", "B"
"Backtracking", "What type of problems does backtracking most commonly solve?", "A. Problems where you need to compute a value.", "B. Problems where you need to find a sequence of choices that satisfies some constraints.", "C. Problems where you need to sort data.", "D. Problems where you need to store data efficiently.", "B"
"Backtracking", "What is the recursive approach typically called in a backtracking algorithm?", "A. The 'solve' function.", "B. The 'findPath' or 'generate' function.", "C. The 'backtrack' function.", "D. All of the above, depending on context.", "D"
"Backtracking", "Consider a simple `solve(index, current_solution)` function in backtracking. What does `index` usually represent?", "A. The number of solutions found so far.", "B. The current element being considered or the depth in the decision tree.", "C. The total size of the problem.", "D. The best solution found.", "B"
"Backtracking", "When designing a backtracking algorithm, what are the 'constraints'?", "A. The limitations of the programming language.", "B. Rules that a partial or complete solution must satisfy to be valid.", "C. The number of recursive calls.", "D. The size of the input data.", "B"
"Backtracking", "What is the typical base case for a backtracking algorithm that generates all permutations of a set?", "A. When the set is empty.", "B. When the current permutation has reached the desired length.", "C. When a conflict is found.", "D. When the algorithm runs out of memory.", "B"
"Backtracking", "Does backtracking inherently produce unique solutions if duplicates are possible in input?", "A. Yes, always.", "B. No, extra logic is required to handle duplicates if unique solutions are desired.", "C. Only if the input is sorted.", "D. It depends on the problem, but often requires extra checks.", "B"
"Backtracking", "What is the primary advantage of backtracking over a pure brute-force approach (without pruning)?", "A. It's simpler to implement.", "B. It's guaranteed to find an optimal solution.", "C. It can significantly reduce the search space and improve performance by avoiding dead ends.", "D. It uses less memory.", "C"
"Backtracking", "In a recursive backtracking function, why do we often pass a copy of the current state or revert changes after the recursive call?", "A. To avoid infinite loops.", "B. To ensure that the state for sibling branches is correct and unpolluted.", "C. To save memory.", "D. To speed up the algorithm.", "B"
"Greedy", "Which of the following best describes a greedy algorithm?", "A. Always finds the globally optimal solution.", "B. Makes the locally optimal choice at each step with the hope of finding a global optimum.", "C. Explores all possible solutions systematically.", "D. Uses recursion to solve problems.", "B"
"Greedy", "What is the main characteristic of a greedy choice?", "A. It depends on future choices.", "B. It is made without considering future consequences.", "C. It is chosen randomly.", "D. It is always the most complex choice.", "B"
"Greedy", "For a greedy algorithm to work correctly, what two properties are usually required in the problem?", "A. Overlapping Subproblems and Optimal Substructure.", "B. Greedy Choice Property and Optimal Substructure.", "C. No Overlapping Subproblems and No Optimal Substructure.", "D. NP-Completeness and Polynomial Time.", "B"
"Greedy", "What is 'Greedy Choice Property'?", "A. A globally optimal solution can be arrived at by making a sequence of locally optimal choices.", "B. The problem can be divided into smaller subproblems.", "C. The problem has multiple solutions.", "D. The solution depends on random choices.", "A"
"Greedy", "What is 'Optimal Substructure' in the context of greedy algorithms?", "A. The optimal solution to the problem contains optimal solutions to subproblems.", "B. The problem has a unique optimal solution.", "C. The problem can be solved in linear time.", "D. The problem is easy to implement.", "A"
"Greedy", "Which of the following problems can be solved using a greedy approach?", "A. Traveling Salesperson Problem (TSP)", "B. N-Queens Problem", "C. Coin Change Problem (for standard denominations)", "D. Longest Common Subsequence", "C"
"Greedy", "For the Activity Selection Problem, what is the greedy choice?", "A. Always select the activity with the longest duration.", "B. Always select the activity that starts earliest.", "C. Always select the activity that finishes earliest.", "D. Always select the activity that uses the most resources.", "C"
"Greedy", "Which algorithm is used to find the Minimum Spanning Tree (MST) using a greedy approach?", "A. Dijkstra's Algorithm", "B. Bellman-Ford Algorithm", "C. Prim's Algorithm and Kruskal's Algorithm", "D. Floyd-Warshall Algorithm", "C"
"Greedy", "In Prim's Algorithm for MST, what is the greedy choice?", "A. Add the vertex closest to the starting vertex.", "B. Add the edge with the minimum weight that connects a vertex in the MST to a vertex outside the MST.", "C. Add any edge that does not form a cycle.", "D. Add the edge with the maximum weight.", "B"
"Greedy", "In Kruskal's Algorithm for MST, what is the greedy choice?", "A. Add the vertex closest to the starting vertex.", "B. Add the edge with the minimum weight that does not form a cycle with previously added edges.", "C. Add any edge that connects two disjoint sets.", "D. Add the edge with the maximum weight that does not form a cycle.", "B"
"Greedy", "What is the time complexity of Kruskal's algorithm (using a disjoint set union for cycle detection)?", "A. O(V log V)", "B. O(E log E) or O(E log V)", "C. O(V^2)", "D. O(E + V)", "B"
"Greedy", "What is the time complexity of Prim's algorithm (using a min-priority queue)?", "A. O(V log V)", "B. O(E log V)", "C. O(E + V log V)", "D. O(E + V log E)", "C"
"Greedy", "Which of the following is an example of a greedy approach for the Coin Change problem (making change with minimum coins)?", "A. Always picking the largest denomination coin first (if valid).", "B. Trying all combinations of coins.", "C. Using dynamic programming.", "D. Using recursion with memoization.", "A"
"Greedy", "When does the greedy approach for the Coin Change problem fail to find the optimal solution?", "A. For all denominations.", "B. For standard denominations (e.g., USD, EUR).", "C. For non-standard denominations where a smaller coin might be part of an optimal solution (e.g., coins {1, 3, 4}, target 6).", "D. It never fails.", "C"
"Greedy", "Which algorithm solves the Single-Source Shortest Path problem for graphs with non-negative edge weights using a greedy strategy?", "A. Bellman-Ford Algorithm", "B. Floyd-Warshall Algorithm", "C. Dijkstra's Algorithm", "D. Prim's Algorithm", "C"
"Greedy", "What is the greedy choice in Dijkstra's Algorithm?", "A. Always choose the edge with the minimum weight.", "B. Always choose the vertex with the currently smallest known distance from the source.", "C. Always choose the vertex that has the most outgoing edges.", "D. Always choose the path with the fewest edges.", "B"
"Greedy", "What is the time complexity of Dijkstra's algorithm using a min-priority queue?", "A. O(V^2)", "B. O(E + V log V)", "C. O(E log V)", "D. O(V log E)", "B"
"Greedy", "Which of the following scenarios is NOT suitable for a greedy approach?", "A. Finding the shortest path in a graph with negative edge weights.", "B. Huffman Coding for data compression.", "C. Activity Selection Problem.", "D. Fractional Knapsack Problem.", "A"
"Greedy", "What is the Fractional Knapsack Problem?", "A. You can only take whole items.", "B. You can take fractions of items.", "C. You must take all items.", "D. You can only take items with even weights.", "B"
"Greedy", "What is the greedy choice for the Fractional Knapsack Problem?", "A. Always pick items with the largest weight first.", "B. Always pick items with the smallest weight first.", "C. Always pick items with the highest value-to-weight ratio first.", "D. Always pick items with the highest value first.", "C"
"Greedy", "Does the greedy approach always yield an optimal solution for the 0/1 Knapsack Problem?", "A. Yes, always.", "B. No, because the optimal choice for fractional might not be optimal for whole items.", "C. Only if all items have the same weight.", "D. Only if all items have the same value.", "B"
"Greedy", "Which algorithm is used for Huffman Coding?", "A. A greedy algorithm.", "B. A dynamic programming algorithm.", "C. A divide and conquer algorithm.", "D. A brute force algorithm.", "A"
"Greedy", "In Huffman Coding, what is the greedy choice?", "A. Always combine the two most frequent characters.", "B. Always combine the two least frequent characters/trees.", "C. Always combine the first two characters encountered.", "D. Always combine the two longest codes.", "B"
"Greedy", "What is the outcome of Huffman Coding?", "A. A sorted list of characters.", "B. A balanced binary search tree.", "C. A prefix code that minimizes total encoded length.", "D. A hash table for character lookup.", "C"
"Greedy", "When is a greedy approach considered feasible?", "A. When it's easy to implement.", "B. When it's proven to find the global optimum for the specific problem.", "C. When it's the only available algorithm.", "D. When the input size is small.", "B"
"Greedy", "Which of the following statements is true about greedy algorithms?", "A. They are always more complex to implement than dynamic programming.", "B. They are often simpler to design and implement than dynamic programming or brute-force, but less powerful.", "C. They require exponential time complexity.", "D. They use significantly more memory than other approaches.", "B"
"Greedy", "What is a 'local optimum' in the context of greedy algorithms?", "A. The best possible solution for the entire problem.", "B. The best choice at the current step, without regard for future steps.", "C. A solution that is close to the global optimum but not exactly it.", "D. An error in the algorithm.", "B"
"Greedy", "If a greedy algorithm yields a solution, is it guaranteed to be optimal?", "A. Yes, by definition.", "B. No, it only finds a locally optimal solution, which may or may not be globally optimal.", "C. Only if the problem is NP-hard.", "D. Only if the input data is sorted.", "B"
"Greedy", "Which of these is a common greedy approach for finding the shortest path in an unweighted graph?", "A. Dijkstra's Algorithm", "B. Bellman-Ford Algorithm", "C. Breadth-First Search (BFS)", "D. Floyd-Warshall Algorithm", "C"
"Greedy", "Is building a spanning tree always a greedy process?", "A. Yes, both Prim's and Kruskal's are greedy.", "B. No, only Prim's is greedy.", "C. No, only Kruskal's is greedy.", "D. No, spanning trees are always found by dynamic programming.", "A"
"Greedy", "In what type of problems are greedy algorithms generally effective?", "A. Problems requiring precise global optimization where every subproblem interaction is critical.", "B. Problems where a sequence of locally optimal choices can accumulate into a globally optimal solution.", "C. Problems with negative cycles.", "D. Problems with very complex constraints.", "B"
"Greedy", "Consider the scenario: You have tasks with start and end times, and you want to schedule the maximum number of tasks that don't overlap. This is the Activity Selection Problem, typically solved by which method?", "A. Dynamic Programming", "B. Greedy", "C. Backtracking", "D. Divide and Conquer", "B"
"Greedy", "What is a major limitation of greedy algorithms?", "A. High time complexity.", "B. Difficulty in implementation.", "C. They do not always find the globally optimal solution.", "D. High space complexity.", "C"
"Greedy", "Can a greedy algorithm be used to solve the Longest Common Subsequence problem?", "A. Yes, efficiently.", "B. No, it requires dynamic programming.", "C. Only if the sequences are very short.", "D. Only if the sequences are sorted.", "B"
"Greedy", "Which of the following is true about a greedy approach to the Set Cover problem?", "A. It always finds the minimum set cover.", "B. It's a heuristic that often finds a good approximation, but not necessarily the optimal solution.", "C. It is a polynomial-time exact algorithm.", "D. It only works for small sets.", "B"
"Greedy", "In scheduling jobs with deadlines and profits, which greedy strategy is often used?", "A. Sort by deadline, then by profit.", "B. Sort by profit, then by deadline.", "C. Sort by profit per unit time.", "D. Sort by deadline in increasing order, then select the job with max profit that fits.", "D"
"Greedy", "If a problem has optimal substructure, does it necessarily mean a greedy algorithm will work?", "A. Yes, always.", "B. No, it also needs the greedy choice property.", "C. Only if it also has overlapping subproblems.", "D. Only if it is a simple problem.", "B"
"Greedy", "Which approach is generally faster, greedy or dynamic programming, if both can solve the problem?", "A. Dynamic Programming (due to memoization).", "B. Greedy (due to simpler choices and typically fewer computations).", "C. They are always equally fast.", "D. Depends on the problem's input size.", "B"
"Greedy", "What does 'change-making problem' refer to?", "A. How to change the currency type.", "B. How to make exact change for a given amount using the fewest possible coins.", "C. How to store coins efficiently.", "D. How to count the number of available coins.", "B"
"Greedy", "Which real-world application often uses greedy heuristics?", "A. Exact shortest path calculation in complex networks with negative weights.", "B. Network routing protocols (e.g., OSPF, RIP sometimes use greedy-like metrics).", "C. Cryptography.", "D. Parsing programming languages.", "B"
"Greedy", "Consider the problem of assigning rooms to classes to maximize room utilization. A greedy approach might involve: 'Assign the next class to the room that becomes free earliest'. Is this always optimal?", "A. Yes, always.", "B. No, because an earlier choice might block a more optimal future arrangement.", "C. Only if all classes have the same duration.", "D. Only if there are unlimited rooms.", "B"
"Greedy", "What is a 'matroid' in the context of greedy algorithms?", "A. A specific type of graph.", "B. A mathematical structure that formally proves when a greedy algorithm will work for a set system.", "C. A data structure used by greedy algorithms.", "D. A type of problem that cannot be solved greedily.", "B"
"Greedy", "If a greedy algorithm provides an approximate solution to an NP-hard problem, what does that imply?", "A. It means it's the best possible solution.", "B. It means it's a solution found in polynomial time, but not necessarily the optimal one.", "C. It means the algorithm will eventually find the optimal solution.", "D. It means the problem is actually P-complete.", "B"
"Greedy", "Does the greedy algorithm for finding the maximum number of non-overlapping activities work if activities can have negative durations?", "A. Yes, it works fine.", "B. No, durations must be positive.", "C. It depends on the sorting order.", "D. The problem does not allow negative durations.", "D"
"Greedy", "Which of the following is true about a greedy approach to the Task Scheduling problem (minimizing maximum lateness)?", "A. It sorts tasks by shortest processing time.", "B. It sorts tasks by latest deadline.", "C. It processes tasks in order of increasing earliest start time.", "D. It assigns tasks randomly.", "B"
"Greedy", "What is the primary difference between Dijkstra's and Bellman-Ford algorithms regarding graph properties?", "A. Dijkstra's is greedy and works on non-negative weights; Bellman-Ford handles negative weights.", "B. Dijkstra's is dynamic programming; Bellman-Ford is greedy.", "C. Dijkstra's is for acyclic graphs; Bellman-Ford is for cyclic graphs.", "D. Dijkstra's finds all-pairs shortest paths; Bellman-Ford finds single-source.", "A"
"Greedy", "What is the typical output of a greedy algorithm?", "A. All possible solutions.", "B. A single solution, which is hoped to be optimal.", "C. A set of probabilities for each choice.", "D. An exact count of operations.", "B"
"Greedy", "Consider a scenario where you have to select maximum items from a list with given weights and values to fit into a knapsack of limited capacity. If you can take *fractions* of items, which algorithm is suitable?", "A. 0/1 Knapsack (DP)", "B. Fractional Knapsack (Greedy)", "C. Subset Sum (Backtracking)", "D. Traveling Salesperson Problem (TSP)", "B"
"Greedy", "What is the core distinction between the problems that fit a greedy approach vs. those that need dynamic programming?", "A. Greedy problems don't have optimal substructure.", "B. Greedy problems always have overlapping subproblems, DP problems do not.", "C. In greedy, local optimal choices directly lead to global optimum; in DP, choices depend on optimal solutions to subproblems which might not be locally obvious.", "D. Greedy problems are always simpler.", "C"
"Greedy", "Which scheduling problem is known to be solvable by a greedy algorithm?", "A. Job scheduling with deadlines and profits (max profit).", "B. Job scheduling to minimize maximum lateness.", "C. Both A and B.", "D. Neither A nor B.", "C"
"Greedy", "When solving the Minimum Spanning Tree problem, why does the greedy choice work?", "A. Because the MST is always unique.", "B. Because adding the smallest edge (Kruskal) or smallest connecting edge (Prim) ensures we are building the MST incrementally.", "C. Because it is a simple problem.", "D. Because it involves recursion.", "B"
"DP", "Which of the following best describes DP?", "A. A technique to solve problems by breaking them into smaller, independent subproblems.", "B. An algorithmic paradigm that solves problems by breaking them into overlapping subproblems and storing the results of subproblems.", "C. A method that always makes the locally optimal choice.", "D. A technique used exclusively for sorting.", "B"
"DP", "What are the two key properties a problem must have to be solvable by DP?", "A. Greedy Choice Property and Optimal Substructure.", "B. Overlapping Subproblems and Optimal Substructure.", "C. NP-Completeness and Polynomial Time.", "D. No Overlapping Subproblems and No Optimal Substructure.", "B"
"DP", "What is 'Overlapping Subproblems' in DP?", "A. Subproblems that are solved independently.", "B. Subproblems that share common sub-subproblems, which are solved repeatedly by a naive recursive approach.", "C. Subproblems that are of the same size.", "D. Subproblems that are completely different.", "B"
"DP", "What is 'Optimal Substructure' in DP?", "A. The problem has a unique optimal solution.", "B. The optimal solution to the problem can be constructed from optimal solutions to its subproblems.", "C. The problem can be solved in linear time.", "D. The problem is easy to implement.", "B"
"DP", "What are the two main approaches to implement DP?", "A. Recursion and Iteration.", "B. Top-down (Memoization) and Bottom-up (Tabulation).", "C. Greedy and Divide-and-Conquer.", "D. Brute-force and Backtracking.", "B"
"DP", "What is 'Memoization' in DP?", "A. A bottom-up approach that fills a table iteratively.", "B. A top-down recursive approach that stores the results of function calls to avoid recomputing them.", "C. A technique to sort the input data.", "D. A method to handle hash collisions.", "B"
"DP", "What is 'Tabulation' in DP?", "A. A top-down recursive approach with caching.", "B. A bottom-up iterative approach that fills a table (usually from smaller subproblems to larger ones).", "C. A method for organizing data in a database.", "D. A technique for optimizing memory usage.", "B"
"DP", "Which of the following problems is a classic example solvable by DP?", "A. Linear Search", "B. Factorial calculation", "C. Longest Common Subsequence (LCS)", "D. Prim's Algorithm for MST", "C"
"DP", "What is the time complexity of calculating the Nth Fibonacci number using a naive recursive approach?", "A. O(N)", "B. O(log N)", "C. O(2^N)", "D. O(N^2)", "C"
"DP", "What is the time complexity of calculating the Nth Fibonacci number using DP (either memoization or tabulation)?", "A. O(N)", "B. O(log N)", "C. O(2^N)", "D. O(N^2)", "A"
"DP", "What is the space complexity of calculating the Nth Fibonacci number using DP (tabulation)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N^2)", "C"
"DP", "Which problem involves finding the maximum value of items that can be put into a knapsack of limited capacity, where items cannot be broken (0/1 choice)?", "A. Fractional Knapsack", "B. Coin Change Problem", "C. 0/1 Knapsack Problem", "D. Activity Selection Problem", "C"
"DP", "What is the typical state definition for the 0/1 Knapsack Problem using DP?", "A. `dp[i]` represents the max value for weight `i`.", "B. `dp[i][w]` represents the max value using first `i` items with capacity `w`.", "C. `dp[i][j]` represents the max profit if `i` items are chosen and `j` items are left.", "D. `dp[i]` represents the weight of item `i`.", "B"
"DP", "What is the time complexity of the 0/1 Knapsack problem using DP with `n` items and knapsack capacity `W`?", "A. O(n)", "B. O(W)", "C. O(n * W)", "D. O(n + W)", "C"
"DP", "For the Coin Change problem (finding minimum number of coins to make a sum), what is the DP approach?", "A. Iteratively build up solutions for smaller sums using available coins.", "B. Recursively try all combinations.", "C. Always pick the largest coin first.", "D. Sort the coins and pick the smallest.", "A"
"DP", "What is the base case for the minimum coin change problem (DP) for `dp[0]`?", "A. 1", "B. -1 (or infinity)", "C. 0", "D. The smallest coin value", "C"
"DP", "What is the time complexity of the Coin Change problem (minimum coins) using DP with `amount` A and `num_coins` C?", "A. O(A)", "B. O(C)", "C. O(A * C)", "D. O(A + C)", "C"
"DP", "Which of the following problems can be solved by DP, where overlapping subproblems are evident?", "A. Factorial", "B. Tower of Hanoi", "C. Matrix Chain Multiplication", "D. All of the above", "C"
"DP", "What is the Longest Common Subsequence (LCS) problem?", "A. Finding the longest string that is a subsequence of all given strings.", "B. Finding the longest common substring.", "C. Finding the longest common prefix.", "D. Finding the shortest common supersequence.", "A"
"DP", "What is the state definition `dp[i][j]` typically represent in LCS for two strings `s1` (length `m`) and `s2` (length `n`)?", "A. Length of LCS of `s1[0...i]` and `s2[0...j]`.", "B. Length of LCS of `s1[i...m]` and `s2[j...n]`.", "C. Length of LCS of `s1` and `s2`.", "D. Number of common characters.", "A"
"DP", "What is the time complexity of LCS using DP for strings of length `m` and `n`?", "A. O(m + n)", "B. O(min(m, n))", "C. O(m * n)", "D. O(2^(m+n))", "C"
"DP", "Which of the following problems is also known as the 'Bellman-Ford' algorithm when applied to finding shortest paths in graphs with negative edge weights?", "A. All-Pairs Shortest Path", "B. Single-Source Shortest Path (with negative weights)", "C. Minimum Spanning Tree", "D. Traveling Salesperson Problem", "B"
"DP", "What is the time complexity of the Bellman-Ford algorithm for a graph with V vertices and E edges?", "A. O(E log V)", "B. O(V^3)", "C. O(V * E)", "D. O(E + V log V)", "C"
"DP", "Which problem is solved by the Floyd-Warshall algorithm?", "A. Single-Source Shortest Path.", "B. All-Pairs Shortest Path.", "C. Minimum Spanning Tree.", "D. Longest Path.", "B"
"DP", "What is the time complexity of the Floyd-Warshall algorithm for a graph with V vertices?", "A. O(V^2)", "B. O(V^3)", "C. O(E log V)", "D. O(V * E)", "B"
"DP", "Can the Floyd-Warshall algorithm detect negative cycles?", "A. No, it only works for positive weights.", "B. Yes, by checking if `dist[i][i]` becomes negative.", "C. Only if the cycle involves the source vertex.", "D. Only if it's explicitly programmed to do so.", "B"
"DP", "Which of the following is true about DP compared to greedy algorithms?", "A. DP always finds the optimal solution, greedy does not always.", "B. Greedy is always more complex to implement.", "C. DP always runs faster than greedy.", "D. DP uses less memory than greedy.", "A"
"DP", "What is the key idea behind 'memoization'?", "A. Sorting the input to speed up computation.", "B. Storing the results of already computed subproblems to avoid redundant calculations.", "C. Using recursion to break down problems.", "D. Converting recursion to iteration.", "B"
"DP", "When designing a DP solution, what is the crucial first step?", "A. Writing the base cases directly.", "B. Identifying the recursive relation (or recurrence) and the optimal substructure.", "C. Choosing between memoization and tabulation.", "D. Coding the solution without prior thought.", "B"
"DP", "What is 'space optimization' in DP?", "A. Reducing the time complexity of the algorithm.", "B. Reducing the memory usage of the DP table, often from O(N*M) to O(N) or O(M).", "C. Using less data in the input.", "D. Employing a recursive solution over an iterative one.", "B"
"DP", "For the 'Minimum Path Sum' in a grid, what is the DP state `dp[i][j]` usually represent?", "A. The total sum of elements in the grid.", "B. The minimum path sum from `(0,0)` to `(i,j)`.", "C. The maximum path sum from `(0,0)` to `(i,j)`.", "D. The number of paths from `(0,0)` to `(i,j)`.", "B"
"DP", "Which problem deals with finding the number of distinct ways to reach a top of a staircase, taking 1 or 2 steps at a time?", "A. Fibonacci sequence (similar structure)", "B. Longest Common Subsequence", "C. 0/1 Knapsack", "D. Tower of Hanoi", "A"
"DP", "What is the relationship between 'Divide and Conquer' and 'DP'?", "A. They are identical concepts.", "B. Divide and Conquer solves independent subproblems; DP solves overlapping subproblems by storing results.", "C. DP is a type of Divide and Conquer.", "D. Divide and Conquer is always faster.", "B"
"DP", "When would you prefer a top-down (memoization) approach over a bottom-up (tabulation) approach?", "A. When the state transitions are complex and difficult to iterate.", "B. When all subproblems need to be computed anyway.", "C. When the recursion tree is very shallow.", "D. When space optimization is the top priority.", "A"
"DP", "When would you prefer a bottom-up (tabulation) approach over a top-down (memoization) approach?", "A. When only a few subproblems are needed.", "B. When the recursion depth is very high (avoid stack overflow).", "C. When debugging recursive calls is easier.", "D. When the problem structure is inherently recursive.", "B"
"DP", "Which of the following is true about DP for the Rod Cutting Problem?", "A. It uses a greedy approach to find the optimal solution.", "B. It calculates the maximum revenue for cutting a rod of length `n` into pieces.", "C. It only works for specific rod lengths.", "D. It finds the minimum number of cuts.", "B"
"DP", "What is the state for the 'Partition Problem' (dividing a set into two subsets with equal sums)?", "A. `dp[i]` is true if sum `i` is achievable.", "B. `dp[i][j]` is true if item `i` can be included for sum `j`.", "C. `dp[i]` is the minimum difference.", "D. `dp[i][j]` is the number of partitions.", "A"
"DP", "What is the time complexity of the 'Boolean Parenthesization' problem using DP?", "A. O(N)", "B. O(N log N)", "C. O(N^3)", "D. O(2^N)", "C"
"DP", "Which problem finds the minimum number of jumps to reach the end of an array?", "A. Longest Increasing Subsequence", "B. Jump Game (DP or Greedy)", "C. Coin Change", "D. Edit Distance", "B"
"DP", "What is the primary difference between `sum of subset` problem and `partition problem`?", "A. Sum of subset finds if a sum is achievable, partition checks if a total sum can be halved.", "B. Sum of subset is DP, partition is greedy.", "C. Partition is for arrays, sum of subset for sets.", "D. They are the same problem.", "A"
"DP", "What is 'knapsack capacity' in the 0/1 Knapsack Problem?", "A. The number of items available.", "B. The maximum weight the knapsack can hold.", "C. The maximum value the knapsack can hold.", "D. The number of possible subproblems.", "B"
"DP", "In the 'Longest Palindromic Subsequence' problem, what is the typical DP state `dp[i][j]`?", "A. Length of the longest palindromic subsequence of the substring `s[0...i]`.", "B. Length of the longest palindromic subsequence of the substring `s[i...j]`.", "C. Length of the longest palindromic subsequence of the entire string.", "D. Number of palindromic subsequences.", "B"
"DP", "What is the time complexity for 'Longest Palindromic Subsequence' for a string of length `N`?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(2^N)", "C"
"DP", "Which problem seeks to find the minimum number of deletions to make a string a palindrome?", "A. Longest Palindromic Subsequence (related)", "B. Edit Distance", "C. Longest Common Substring", "D. Word Break", "A"
"DP", "What is the 'Maximum Sum Subarray' problem (Kadane's Algorithm) an example of?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Divide and Conquer", "D. All of the above (often solved with greedy/DP)", "D"
"DP", "What is the typical DP state for Kadane's algorithm?", "A. `dp[i]` is the maximum sum ending at index `i`.", "B. `dp[i]` is the maximum sum in the entire array up to index `i`.", "C. `dp[i][j]` is the maximum sum between `i` and `j`.", "D. `dp[i]` is the element at index `i`.", "A"
"DP", "Which of the following problems can be solved by DP and is related to grid traversal?", "A. Unique Paths", "B. N-Queens", "C. Subset Sum", "D. Permutations", "A"
"DP", "In 'Unique Paths' problem, if `dp[i][j]` represents the number of unique paths to cell `(i,j)`, what is its recurrence relation?", "A. `dp[i][j] = dp[i-1][j] + dp[i][j-1]`", "B. `dp[i][j] = dp[i-1][j] * dp[i][j-1]`", "C. `dp[i][j] = dp[i-1][j]`", "D. `dp[i][j] = dp[i][j-1]`", "A"
"DP", "What is the time complexity of the 'Unique Paths' problem for an `m x n` grid?", "A. O(m + n)", "B. O(m * n)", "C. O(m^2)", "D. O(n^2)", "B"
"DP", "What is the concept of 'State Representation' in DP?", "A. How the problem's solution is stored.", "B. How to define the subproblems and their relationship to the original problem.", "C. How to visualize the DP table.", "D. How to choose the base cases.", "B"
"DP", "Which of the following is true about the order of filling the DP table in 'Tabulation'?", "A. From largest subproblems to smallest.", "B. From smallest subproblems to largest.", "C. Randomly.", "D. It doesn't matter.", "B"
"Trees", "Which of the following best describes a 'Tree' data structure?", "A. A linear data structure.", "B. A hierarchical data structure.", "C. A collection of unordered elements.", "D. A structure where elements are linked sequentially.", "B"
"Trees", "In a tree, what is the node at the topmost level called?", "A. Leaf node", "B. Parent node", "C. Root node", "D. Child node", "C"
"Trees", "Which of the following is true about a 'Leaf Node'?", "A. It has at least one child.", "B. It has no children.", "C. It is always the root node.", "D. It has multiple parents.", "B"
"Trees", "What is the 'Depth' of a node in a tree?", "A. The number of nodes in its subtree.", "B. The length of the path from the root to that node.", "C. The number of children it has.", "D. The maximum depth of any node in the tree.", "B"
"Trees", "What is the 'Height' of a tree?", "A. The total number of nodes in the tree.", "B. The maximum depth of any node in the tree.", "C. The number of levels in the tree.", "D. The depth of the root node.", "B"
"Trees", "What is a 'Binary Tree'?", "A. A tree where each node has at most two children.", "B. A tree where each node has exactly two children.", "C. A tree where each node has at most one child.", "D. A tree where nodes are sorted.", "A"
"Trees", "In a Binary Tree, if a node has only one child, where can that child be?", "A. Only left child.", "B. Only right child.", "C. Either a left or a right child.", "D. It must have two children.", "C"
"Trees", "What is a 'Full Binary Tree'?", "A. A binary tree where every node has either zero or two children.", "B. A binary tree where all leaf nodes are at the same level.", "C. A binary tree where every level is completely filled.", "D. A binary tree with N nodes and N-1 edges.", "A"
"Trees", "What is a 'Complete Binary Tree'?", "A. A binary tree where every node has either zero or two children.", "B. A binary tree where all leaf nodes are at the same level.", "C. A binary tree in which all levels are completely filled, except possibly the last level, which is filled from left to right.", "D. A binary tree where values are sorted.", "C"
"Trees", "What is a 'Perfect Binary Tree'?", "A. A binary tree where all internal nodes have two children and all leaf nodes are at the same level.", "B. A binary tree where every node has at most two children.", "C. A binary tree where the left subtree is always larger than the right.", "D. A binary tree with N nodes.", "A"
"Trees", "What is the maximum number of nodes in a binary tree of height `h`?", "A. 2^h", "B. 2^h - 1", "C. 2^(h+1) - 1", "D. h + 1", "C"
"Trees", "What is the minimum number of nodes in a binary tree of height `h`?", "A. h + 1", "B. 2^h - 1", "C. h", "D. 2^(h-1)", "A"
"Trees", "Which traversal visits the left subtree, then the root, then the right subtree?", "A. Pre-order", "B. In-order", "C. Post-order", "D. Level-order", "B"
"Trees", "Which traversal visits the root, then the left subtree, then the right subtree?", "A. Pre-order", "B. In-order", "C. Post-order", "D. Level-order", "A"
"Trees", "Which traversal visits the left subtree, then the right subtree, then the root?", "A. Pre-order", "B. In-order", "C. Post-order", "D. Level-order", "C"
"Trees", "Which traversal visits nodes level by level?", "A. Pre-order", "B. In-order", "C. Post-order", "D. Level-order (Breadth-First Search)", "D"
"Trees", "In a Binary Search Tree (BST), what is the property of the left child of a node?", "A. Its value is greater than the parent's value.", "B. Its value is less than or equal to the parent's value.", "C. Its value is equal to the parent's value.", "D. Its value is random.", "B"
"Trees", "In a BST, what is the property of the right child of a node?", "A. Its value is less than or equal to the parent's value.", "B. Its value is greater than the parent's value.", "C. Its value is equal to the parent's value.", "D. Its value is random.", "B"
"Trees", "What is the time complexity to search for an element in a balanced BST?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"Trees", "What is the worst-case time complexity to search for an element in a skewed BST?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"Trees", "Which traversal of a BST yields elements in sorted order?", "A. Pre-order", "B. In-order", "C. Post-order", "D. Level-order", "B"
"Trees", "What is the purpose of an 'AVL Tree'?", "A. To ensure all nodes have two children.", "B. To make sure the tree is always skewed.", "C. To maintain balance (height balance) after insertions/deletions for O(log N) operations.", "D. To store only unique values.", "C"
"Trees", "What is the 'balance factor' of a node in an AVL tree?", "A. The difference between the number of nodes in the left and right subtrees.", "B. The difference between the heights of its left and right subtrees.", "C. The total number of nodes in its subtree.", "D. The number of its children.", "B"
"Trees", "For an AVL tree, what is the allowed range for the balance factor of any node?", "A. {-1, 0, 1}", "B. {-2, -1, 0, 1, 2}", "C. {0, 1}", "D. Any integer value.", "A"
"Trees", "What is a 'Red-Black Tree'?", "A. A type of Binary Search Tree that is self-balancing.", "B. A tree where nodes are colored red or black, but no other properties.", "C. A tree used exclusively for graphics rendering.", "D. A tree that only stores colors.", "A"
"Trees", "What is a 'Heap' data structure?", "A. A general tree structure.", "B. A complete binary tree that satisfies the heap property (min-heap or max-heap).", "C. A linked list with special properties.", "D. A tree that stores elements in sorted order.", "B"
"Trees", "In a 'Max-Heap', what is the property of the root node?", "A. It contains the smallest element.", "B. It contains the largest element.", "C. It contains the median element.", "D. Its value is always 0.", "B"
"Trees", "In a 'Min-Heap', what is the property of the root node?", "A. It contains the smallest element.", "B. It contains the largest element.", "C. It contains the median element.", "D. Its value is always positive.", "A"
"Trees", "What is the time complexity to insert an element into a heap?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"Trees", "What is the time complexity to extract the maximum element from a max-heap?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"Trees", "Which sorting algorithm uses a heap?", "A. Merge Sort", "B. Quick Sort", "C. Heap Sort", "D. Bubble Sort", "C"
"Trees", "What is a 'Trie' (Prefix Tree) primarily used for?", "A. Sorting numbers.", "B. Efficient retrieval of words and checking for prefixes in a dictionary.", "C. Finding the shortest path in a graph.", "D. Representing mathematical expressions.", "B"
"Trees", "In a Trie, where do words typically end?", "A. Only at leaf nodes.", "B. Only at internal nodes.", "C. At any node, marked with a special flag.", "D. Only at the root node.", "C"
"Trees", "What is the advantage of a Trie over a hash table for string lookups?", "A. Faster average-case lookup.", "B. Supports prefix search and lexicographical sorting of keys.", "C. Less memory usage.", "D. Simpler implementation.", "B"
"Trees", "What is a 'B-Tree' primarily used for?", "A. In-memory data storage.", "B. Indexing large amounts of data in databases and file systems.", "C. Solving mathematical equations.", "D. Real-time data processing.", "B"
"Trees", "Why are B-Trees preferred over Binary Search Trees for disk-based data storage?", "A. They are simpler to implement.", "B. They have a higher branching factor, reducing disk I/O operations.", "C. They always remain perfectly balanced.", "D. They store data only on leaf nodes.", "B"
"Trees", "In a B-Tree of order `m`, what is the maximum number of children a node can have?", "A. m-1", "B. m", "C. 2m-1", "D. 2m", "B"
"Trees", "What is a 'Binary Expression Tree'?", "A. A binary tree used to store numbers only.", "B. A binary tree where internal nodes are operators and leaf nodes are operands.", "C. A tree for storing network addresses.", "D. A tree for organizing files.", "B"
"Trees", "Which traversal of an expression tree would yield the postfix expression?", "A. In-order", "B. Pre-order", "C. Post-order", "D. Level-order", "C"
"Trees", "What is the maximum number of children a node can have in a general tree (non-binary)?", "A. 0", "B. 1", "C. 2", "D. Any number", "D"
"Trees", "What is the relationship between a graph and a tree?", "A. A tree is a specific type of graph (connected, acyclic).", "B. A graph is a specific type of tree.", "C. They are completely unrelated.", "D. Trees are always directed graphs.", "A"
"Trees", "What is the time complexity to delete a node from a BST (worst case for skewed tree)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"Trees", "What is 'Tree Traversal'?", "A. Adding new nodes to the tree.", "B. Visiting each node in the tree exactly once in a systematic way.", "C. Deleting nodes from the tree.", "D. Balancing the tree.", "B"
"Trees", "Can a tree have cycles?", "A. Yes, always.", "B. No, by definition, a tree is an acyclic graph.", "C. Only if it's a directed tree.", "D. Only if it has more than one root.", "B"
"Trees", "What is the 'root' of a tree?", "A. A node with no children.", "B. A node with no parent.", "C. A node with the smallest value.", "D. The center node of the tree.", "B"
"Trees", "If a tree has N nodes, how many edges does it have?", "A. N", "B. N-1", "C. N+1", "D. 2N", "B"
"Trees", "What is a 'Forest' in the context of trees?", "A. A single tree with many nodes.", "B. A collection of disjoint trees.", "C. A tree with cycles.", "D. A special type of binary tree.", "B"
"Trees", "What is 'Tree Pruning'?", "A. Removing unwanted branches or subtrees, often in decision trees to avoid overfitting.", "B. Adding new branches to a tree.", "C. Balancing a tree.", "D. Sorting nodes within a tree.", "A"
"Trees", "Which of the following is an application of trees?", "A. File system directories.", "B. Representing hierarchical data.", "C. Parsing syntax (e.g., ASTs in compilers).", "D. All of the above.", "D"
"Trees", "What is the 'degree' of a node in a tree?", "A. The number of nodes in its subtree.", "B. The number of children it has.", "C. The depth of the node.", "D. The height of the node.", "B"
"Trees", "What is the difference between a 'Binary Tree' and a 'Binary Search Tree'?", "A. Binary trees can have any values, BSTs have a specific ordering property.", "B. Binary trees are balanced, BSTs are not.", "C. Binary trees have 2 children, BSTs can have any number.", "D. Binary trees are always complete, BSTs are not.", "A"
"BinaryTree", "In a BinaryTree, what is the maximum number of children any node can have?", "A. 0", "B. 1", "C. 2", "D. Any number", "C"
"BinaryTree", "Which property defines a 'Strict BinaryTree' (or Proper BinaryTree)?", "A. Every node has at most two children.", "B. Every internal node has exactly two children, and every leaf node has zero children.", "C. All leaf nodes are at the same level.", "D. It is always a complete binary tree.", "B"
"BinaryTree", "What is the relationship between the number of nodes (N) and levels (L) in a full binary tree?", "A. N = 2^L - 1", "B. N = 2L", "C. N = L + 1", "D. N = 2^L", "A"
"BinaryTree", "Which traversal is implicitly used to build a binary tree from a given array in a level-order fashion?", "A. Pre-order", "B. In-order", "C. Post-order", "D. Level-order (BFS)", "D"
"BinaryTree", "Given a pre-order traversal `A, B, D, E, C, F` and in-order traversal `D, B, E, A, F, C` for a binary tree, what is the root node?", "A. A", "B. B", "C. D", "D. E", "A"
"BinaryTree", "Given an in-order traversal `D, B, E, A, F, C` and post-order traversal `D, E, B, F, C, A` for a binary tree, what is the root node?", "A. A", "B. B", "C. D", "D. E", "A"
"BinaryTree", "If a binary tree has `N` nodes, what is its minimum possible height (root at height 0)?", "A. N", "B. log2(N) (approximately)", "C. N-1", "D. 2^N", "B"
"BinaryTree", "If a binary tree has `N` nodes, what is its maximum possible height (root at height 0)?", "A. N", "B. N-1", "C. log2(N)", "D. 2^N", "B"
"BinaryTree", "What does it mean for a binary tree to be 'skewed'?", "A. All nodes have two children.", "B. All nodes have zero children.", "C. All nodes have only left children OR only right children (forming a linked list-like structure).", "D. All leaf nodes are at the same level.", "C"
"BinaryTree", "When converting a general tree to a binary tree, what common representation is used?", "A. Left-child, right-sibling representation.", "B. Adjacency matrix.", "C. Adjacency list.", "D. Array representation only.", "A"
"BinaryTree", "Which of the following traversals of a binary tree is typically implemented using a Queue?", "A. Pre-order (recursive)", "B. In-order (recursive)", "C. Post-order (recursive)", "D. Level-order", "D"
"BinaryTree", "Which of the following traversals of a binary tree is typically implemented using a Stack (iteratively)?", "A. Level-order", "B. In-order", "C. Only Post-order", "D. None of the above", "B"
"BinaryTree", "In a binary tree, what is a 'sibling' node?", "A. A node at the same level as another node.", "B. A node that shares the same parent as another node.", "C. A node that is an ancestor.", "D. A node that is a descendant.", "B"
"BinaryTree", "What is the 'height of a node' in a binary tree (length of longest path from node to a leaf)?", "A. The length of the path from the root to that node.", "B. The number of children the node has.", "C. The length of the longest path from that node to a leaf in its subtree.", "D. The height of the entire tree.", "C"
"BinaryTree", "What is the primary use case for a Binary Search Tree (BST) – a specialized binary tree?", "A. Fast insertion of elements at the front.", "B. Efficient searching, insertion, and deletion of elements while maintaining sorted order.", "C. Storing elements for Breadth-First Search.", "D. Managing function calls.", "B"
"BinaryTree", "When inserting a new node into a BST (a type of binary tree), where is it always inserted?", "A. At the root.", "B. As a leaf node.", "C. At the deepest level possible.", "D. Randomly.", "B"
"BinaryTree", "To delete a node with two children from a BST, which node replaces it?", "A. Its parent.", "B. Its left child.", "C. Its in-order predecessor or in-order successor.", "D. Its right child.", "C"
"BinaryTree", "What property does a 'Degenerate BinaryTree' have?", "A. It is a complete binary tree.", "B. It has only one node.", "C. Each node has only one child, forming a linked list-like structure.", "D. It is a full binary tree.", "C"
"BinaryTree", "What is the time complexity to insert into a perfectly balanced binary tree?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"BinaryTree", "What is the space complexity of storing a binary tree with `N` nodes?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N^2)", "C"
"BinaryTree", "Which of the following is NOT a type of balanced binary search tree?", "A. AVLTree", "B. Red-Black Tree", "C. Splay Tree", "D. Skewed Tree", "D"
"BinaryTree", "What is the main reason for using balanced BSTs (like AVL or Red-Black trees)?", "A. To simplify the implementation of insertion.", "B. To guarantee O(log N) worst-case time complexity for operations.", "C. To reduce the memory footprint.", "D. To ensure unique element storage.", "B"
"BinaryTree", "Which property is maintained in a Max-Heap (a type of complete binary tree)?", "A. Parent node value is less than or equal to its children's values.", "B. Parent node value is greater than or equal to its children's values.", "C. All leaf nodes are at the same level.", "D. The tree is always perfectly balanced.", "B"
"BinaryTree", "Which property is maintained in a Min-Heap (a type of complete binary tree)?", "A. Parent node value is less than or equal to its children's values.", "B. Parent node value is greater than or equal to its children's values.", "C. All leaf nodes are at the same level.", "D. The tree is always perfectly balanced.", "A"
"BinaryTree", "Heaps are typically implemented using which underlying data structure?", "A. Linked List", "B. Array", "C. Stack", "D. Queue", "B"
"BinaryTree", "What is 'Heapify' operation used for (in the context of building a heap)?", "A. Inserting an element into a heap.", "B. Deleting an element from a heap.", "C. Maintaining the heap property in a subtree after an insertion or deletion.", "D. Building a heap from an unsorted array.", "D"
"BinaryTree", "What is the time complexity of building a heap from `N` elements?", "A. O(N log N)", "B. O(N)", "C. O(log N)", "D. O(N^2)", "B"
"BinaryTree", "What does a 'BinaryTree Node' typically contain?", "A. A data value.", "B. A pointer to its left child.", "C. A pointer to its right child.", "D. All of the above.", "D"
"BinaryTree", "Can a binary tree have multiple root nodes?", "A. Yes, any number.", "B. No, a binary tree must have exactly one root node.", "C. Only if it's a skewed tree.", "D. Only if it's a complete binary tree.", "B"
"BinaryTree", "What is the maximum number of nodes at level `i` (root at level 0) in a perfect binary tree?", "A. 2^i", "B. 2i", "C. i+1", "D. i^2", "A"
"BinaryTree", "If a binary tree is represented using an array, and a node is at index `i`, what are the indices of its left and right children (0-indexed)?", "A. Left: `2*i`, Right: `2*i+1`", "B. Left: `2*i+1`, Right: `2*i+2`", "C. Left: `i-1`, Right: `i+1`", "D. Left: `i/2`, Right: `i/2 + 1`", "B"
"BinaryTree", "What is the time complexity of searching for an element in a general (unbalanced) binary tree?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"BinaryTree", "Which algorithm is commonly used for constructing an optimal prefix code (like Huffman codes) and uses a min-priority queue (often a min-heap)?", "A. Kruskal's Algorithm", "B. Prim's Algorithm", "C. Huffman Coding Algorithm", "D. Dijkstra's Algorithm", "C"
"BinaryTree", "What is the purpose of 'Threaded BinaryTree'?", "A. To simplify tree traversal.", "B. To avoid the need for recursion in traversals by using null pointers to point to in-order predecessor/successor.", "C. To store additional data in nodes.", "D. To make the tree balanced.", "B"
"BinaryTree", "What kind of binary tree guarantees the fastest average search time if elements are inserted randomly?", "A. Skewed BinaryTree", "B. Perfectly Balanced BinaryTree (like AVL/Red-Black)", "C. Degenerate BinaryTree", "D. Any binary tree will have the same average search time.", "B"
"BinaryTree", "What is a 'BinaryTree Iterator' typically based on for an in-order traversal?", "A. A Queue", "B. A Stack", "C. A Hash Map", "D. An Array", "B"
"BinaryTree", "If a binary tree is represented using pointers, how do you indicate a child that does not exist?", "A. Assign it a value of -1.", "B. Assign it a null pointer.", "C. Delete the node.", "D. Do nothing.", "B"
"BinaryTree", "What is the time complexity of deleting the root from a Min-Heap?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"BinaryTree", "Which property is specific to a Binary Search Tree but not a general BinaryTree?", "A. Each node has at most two children.", "B. There is a specific ordering of values in the left and right subtrees relative to the parent.", "C. It can be implemented with pointers.", "D. It has a root node.", "B"
"BinaryTree", "What is a 'Segment Tree' primarily used for?", "A. Storing strings efficiently.", "B. Performing range queries (e.g., sum, min, max) on an array efficiently.", "C. Representing hierarchical file systems.", "D. Solving shortest path problems.", "B"
"BinaryTree", "What is the time complexity of a range query on a Segment Tree with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"BinaryTree", "What is a 'Fenwick Tree' (Binary Indexed Tree) primarily used for?", "A. Sorting algorithms.", "B. Efficiently calculating prefix sums and updating elements in an array.", "C. Managing network routing tables.", "D. Data compression.", "B"
"BinaryTree", "What is the time complexity of updating an element in a Fenwick Tree with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"BinaryTree", "What is the purpose of using a 'dummy node' in some binary tree implementations?", "A. To simplify handling edge cases (e.g., empty tree, single node).", "B. To increase memory usage.", "C. To mark the end of a tree.", "D. To store temporary values.", "A"
"BinaryTree", "What is a 'Mirror' of a binary tree?", "A. A copy of the tree.", "B. A tree where left and right children are swapped recursively for all nodes.", "C. A tree with reversed order of elements.", "D. A tree with the same values but different structure.", "B"
"BinaryTree", "How do you check if two binary trees are identical?", "A. Compare their root nodes only.", "B. Perform a traversal and compare elements and structure recursively.", "C. Check if they have the same number of nodes.", "D. Compare their heights.", "B"
"BinaryTree", "What is the time complexity to find the Lowest Common Ancestor (LCA) in a binary tree (naive approach traversing from root)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"BinaryTree", "Which property ensures that a complete binary tree can be efficiently stored in an array?", "A. Its nodes are sorted.", "B. Its levels are filled from left to right, with no gaps.", "C. It is always a full binary tree.", "D. It has a fixed height.", "B"
"BinaryTree", "What is the primary role of a 'Binary Expression Tree' in a compiler?", "A. To store variables.", "B. To represent the structure of an arithmetic expression for evaluation.", "C. To manage memory allocation.", "D. To optimize loops.", "B"
"BinaryTree", "What is the time complexity of converting a binary tree to its mirror image?", "A. O(1)", "B. O(log N)", "C. O(N) (visiting each node once)", "D. O(N log N)", "C"
"BST", "Which of the following is a fundamental property of a Binary Search Tree (BST)?", "A. Every node has at most two children.", "B. The value of any node is greater than or equal to the values in its left subtree and less than the values in its right subtree.", "C. All leaf nodes are at the same level.", "D. It is always a complete binary tree.", "B"
"BST", "What is the time complexity to search for an element in a balanced BST?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"BST", "What is the worst-case time complexity to search for an element in a skewed BST?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"BST", "Where are new nodes always inserted in a BST?", "A. At the root.", "B. At the deepest level possible, as a leaf node.", "C. At the parent of the node being inserted.", "D. Randomly to maintain balance.", "B"
"BST", "Which traversal of a BST visits elements in non-decreasing (sorted) order?", "A. Pre-order", "B. In-order", "C. Post-order", "D. Level-order", "B"
"BST", "To find the minimum element in a BST, which path should you follow from the root?", "A. Always go right.", "B. Always go left.", "C. Follow the path with larger values.", "D. Follow the path with smaller values until a leaf is reached.", "B"
"BST", "To find the maximum element in a BST, which path should you follow from the root?", "A. Always go right.", "B. Always go left.", "C. Follow the path with smaller values.", "D. Follow the path with larger values until a leaf is reached.", "A"
"BST", "When deleting a node with two children from a BST, which node typically replaces it?", "A. Its parent.", "B. Its left child.", "C. Its in-order predecessor or in-order successor.", "D. Its right child.", "C"
"BST", "If the in-order successor is used to replace a deleted node with two children, where is it found?", "A. The rightmost node in the left subtree.", "B. The leftmost node in the right subtree.", "C. The parent of the deleted node.", "D. The root of the tree.", "B"
"BST", "What is the primary disadvantage of an unbalanced BST?", "A. It uses too much memory.", "B. Its performance degrades to O(N) in the worst-case, similar to a linked list.", "C. It cannot store duplicate values.", "D. It is difficult to implement.", "B"
"BST", "Which of the following is NOT a self-balancing BST?", "A. AVL Tree", "B. Red-Black Tree", "C. Splay Tree", "D. Regular Binary Search Tree", "D"
"BST", "What is the purpose of self-balancing BSTs?", "A. To simplify insertion operations.", "B. To guarantee O(log N) worst-case time complexity for search, insert, and delete operations.", "C. To reduce the memory footprint of the tree.", "D. To allow duplicate values in the tree.", "B"
"BST", "Given a set of `N` distinct values, how many different BSTs can be formed?", "A. N!", "B. 2^N", "C. Catalan number C_N", "D. N log N", "C"
"BST", "What happens if you insert elements into a BST in strictly increasing or strictly decreasing order?", "A. The tree remains balanced.", "B. The tree becomes skewed, resembling a linked list.", "C. The tree automatically balances itself.", "D. It becomes a complete binary tree.", "B"
"BST", "Is it possible for a BST to have duplicate values?", "A. No, BSTs fundamentally require unique values.", "B. Yes, depending on the implementation (e.g., allow duplicates in left or right subtree, or store count).", "C. Only in balanced BSTs.", "D. Only if the duplicates are at the leaf nodes.", "B"
"BST", "What is the time complexity to insert an element into a BST (worst case for skewed tree)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"BST", "What is the time complexity to delete an element from a BST (worst case for skewed tree)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"BST", "To check if a binary tree is a valid BST, what is the most common approach?", "A. Check if the left child is smaller and right child is larger for every node (local check only).", "B. Perform an in-order traversal and check if the elements are sorted.", "C. Check if the tree is balanced.", "D. Check if all nodes have unique values.", "B"
"BST", "What is the 'predecessor' of a node in a BST (in-order)?", "A. The node immediately before it in an in-order traversal.", "B. The node immediately after it in an in-order traversal.", "C. Its parent node.", "D. Its left child.", "A"
"BST", "What is the 'successor' of a node in a BST (in-order)?", "A. The node immediately before it in an in-order traversal.", "B. The node immediately after it in an in-order traversal.", "C. Its parent node.", "D. Its right child.", "B"
"BST", "If you want to find the Kth smallest element in a BST, which traversal is most directly useful?", "A. Pre-order", "B. In-order", "C. Post-order", "D. Level-order", "B"
"BST", "Which of the following operations on a BST is NOT generally O(log N) in a balanced BST?", "A. Search", "B. Insert", "C. Delete", "D. Finding all nodes at a specific depth (requires traversal, potentially O(N))", "D"
"BST", "What is the structure of a node in a typical BST implementation?", "A. Data, pointer to left child, pointer to right child.", "B. Data only.", "C. Data, pointer to parent.", "D. Data, pointer to next node.", "A"
"BST", "Can a BST be empty?", "A. No, it must have at least one node.", "B. Yes, it can be represented by a null root pointer.", "C. Only if it's a degenerate tree.", "D. Only if it's a perfect binary tree.", "B"
"BST", "What is the main advantage of BSTs over sorted arrays?", "A. Faster search operations.", "B. Easier implementation.", "C. More efficient insertion and deletion of elements without shifting.", "D. Less memory consumption.", "C"
"BST", "What is the main advantage of sorted arrays over BSTs?", "A. Faster insertion.", "B. Better space efficiency for sequential access (cache locality).", "C. Easier to implement deletion.", "D. Faster search in all cases.", "B"
"BST", "How can you find the Lowest Common Ancestor (LCA) of two nodes in a BST?", "A. Traverse from the root; the last node visited that is between both target values (or is one of them) is the LCA.", "B. Find the parents of both nodes and compare them.", "C. Always the root of the tree.", "D. Perform a level-order traversal.", "A"
"BST", "If a BST node is deleted and it has only one child, what replaces it?", "A. Its in-order predecessor.", "B. Its in-order successor.", "C. Its only child.", "D. Null.", "C"
"BST", "What is the time complexity of building a BST from `N` unsorted elements in the worst case?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(log N)", "C"
"BST", "What is the time complexity of building a BST from `N` unsorted elements in the average case?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(log N)", "B"
"BST", "Which of the following is true regarding a BST and its height?", "A. The height is always log N.", "B. The height can be up to N-1 in the worst case.", "C. The height is independent of the insertion order.", "D. Only balanced BSTs have a defined height.", "B"
"BST", "How is memory typically allocated for BST nodes?", "A. On the stack.", "B. Dynamically on the heap.", "C. Statically.", "D. In registers.", "B"
"BST", "If you perform a pre-order traversal of a BST and then an in-order traversal, can you uniquely reconstruct the BST?", "A. Yes, always.", "B. No, two traversals are generally not enough to uniquely identify a BST.", "C. Only if the BST is perfectly balanced.", "D. Only if the BST is skewed.", "A"
"BST", "If you perform an in-order traversal of a BST and then a post-order traversal, can you uniquely reconstruct the BST?", "A. Yes, always.", "B. No, two traversals are generally not enough to uniquely identify a BST.", "C. Only if the BST is perfectly balanced.", "D. Only if the BST is skewed.", "A"
"BST", "Why are rotations used in self-balancing BSTs like AVL trees?", "A. To simplify deletion of nodes.", "B. To improve cache performance.", "C. To maintain the height balance property after insertion or deletion.", "D. To convert the tree into a linked list.", "C"
"BST", "What is the purpose of the 'balance factor' in an AVL tree?", "A. To determine if a node has children.", "B. To measure the height difference between left and right subtrees and detect imbalance.", "C. To count the number of nodes in a subtree.", "D. To calculate the average value of nodes.", "B"
"BST", "In a Red-Black Tree, what is the maximum path from the root to any leaf compared to the minimum path?", "A. It is at most twice as long.", "B. It is always equal.", "C. It can be infinitely long.", "D. It is at most 1.5 times as long.", "A"
"BST", "What is the disadvantage of using a Splay Tree over an AVL or Red-Black Tree?", "A. Worse average-case performance.", "B. Worst-case operations can be O(N).", "C. More complex to implement.", "D. Does not support searching.", "B"
"BST", "What is the average-case time complexity of operations (search, insert, delete) in a Splay Tree?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"BST", "Can a BST be built from a sorted array in O(N) time while maintaining balance?", "A. No, it always takes O(N log N).", "B. Yes, by picking the middle element as root and recursively building left/right subtrees.", "C. Only if the array contains duplicates.", "D. Only using a hash map.", "B"
"BST", "What is the output if you perform a pre-order traversal on a BST with elements 50, 30, 70, 20, 40, 60, 80?", "A. 20, 30, 40, 50, 60, 70, 80", "B. 50, 30, 20, 40, 70, 60, 80", "C. 20, 40, 30, 60, 80, 70, 50", "D. 50, 70, 80, 60, 30, 40, 20", "B"
"BST", "What is the output if you perform a post-order traversal on a BST with elements 50, 30, 70, 20, 40, 60, 80?", "A. 20, 30, 40, 50, 60, 70, 80", "B. 50, 30, 20, 40, 70, 60, 80", "C. 20, 40, 30, 60, 80, 70, 50", "D. 50, 70, 80, 60, 30, 40, 20", "C"
"BST", "In a BST, if a node's left child is null, what is its in-order predecessor?", "A. Its parent.", "B. The largest value in its right subtree.", "C. It doesn't have one.", "D. The root node.", "A"
"BST", "In a BST, if a node's right child is null, what is its in-order successor?", "A. Its parent (if it's a left child).", "B. The smallest value in its left subtree.", "C. It doesn't have one.", "D. The root node.", "A"
"BST", "What is the primary application of BSTs in real-world scenarios?", "A. Graph traversal.", "B. Implementing dictionaries, sets, and symbol tables where sorted order and efficient lookups are needed.", "C. Image processing.", "D. Network routing.", "B"
"BST", "When implementing a BST, why might you use recursion?", "A. It's always more efficient than iteration.", "B. The recursive definition of a tree (node, left subtree, right subtree) naturally maps to recursive functions.", "C. To avoid using a stack.", "D. To achieve better cache performance.", "B"
"BST", "What is a 'Treap'?", "A. A type of balanced BST that combines properties of a binary search tree and a heap.", "B. A tree used for network routing.", "C. A specific type of skewed BST.", "D. A tree that only stores character data.", "A"
"BST", "What is the role of 'priorities' in a Treap?", "A. They determine the search order.", "B. They maintain the heap property (usually max-heap) on nodes, helping maintain balance.", "C. They indicate the depth of the node.", "D. They store actual data values.", "B"
"BST", "Is a BST guaranteed to be balanced if elements are inserted in a random order?", "A. Yes, always.", "B. No, but it tends to be reasonably balanced on average.", "C. Only if the number of elements is small.", "D. Only if it's a perfectly random order.", "B"
"BST", "What is the output of an in-order traversal on an empty BST?", "A. Error", "B. Null", "C. An empty list/sequence.", "D. The root node.", "C"
"AVLTree", "What does 'AVL' in AVLTree stand for?", "A. Advanced Vertical Lattices", "B. Adelson-Velsky and Landis", "C. Automated Virtual Libraries", "D. Accelerated Vector Logic", "B"
"AVLTree", "What is the primary characteristic that distinguishes an AVLTree from a regular Binary Search Tree (BST)?", "A. It can store duplicate values.", "B. It is always a complete binary tree.", "C. It is self-balancing, maintaining a height-balance property.", "D. Its nodes are sorted in a specific order.", "C"
"AVLTree", "What is the 'balance factor' of a node in an AVLTree?", "A. The number of children it has.", "B. The difference between the heights of its left and right subtrees.", "C. The total number of nodes in its subtree.", "D. The sum of values in its children.", "B"
"AVLTree", "For an AVLTree to remain balanced, what is the allowed range for the balance factor of any node?", "A. {-2, -1, 0, 1, 2}", "B. {-1, 0, 1}", "C. {0, 1}", "D. Any integer value.", "B"
"AVLTree", "When an insertion or deletion causes a node to violate the AVL balance property (balance factor outside {-1, 0, 1}), what operations are performed to restore balance?", "A. Swapping nodes.", "B. Rotations (single or double).", "C. Rebuilding the entire tree.", "D. Deleting the unbalanced node.", "B"
"AVLTree", "How many types of rotations are primarily used in AVLTree?", "A. One (Single Rotation)", "B. Two (Single Rotation and Double Rotation)", "C. Three (Left, Right, and Double)", "D. Four (LL, RR, LR, RL)", "D"
"AVLTree", "Which rotation handles an imbalance where a node's left child's left subtree caused the imbalance (Left-Left case)?", "A. Left Rotation", "B. Right Rotation", "C. Left-Right Rotation", "D. Right-Left Rotation", "B"
"AVLTree", "Which rotation handles an imbalance where a node's right child's right subtree caused the imbalance (Right-Right case)?", "A. Left Rotation", "B. Right Rotation", "C. Left-Right Rotation", "D. Right-Left Rotation", "A"
"AVLTree", "Which rotation handles an imbalance where a node's left child's right subtree caused the imbalance (Left-Right case)?", "A. Single Right Rotation", "B. Single Left Rotation", "C. Left-Right Rotation (Left then Right)", "D. Right-Left Rotation (Right then Left)", "C"
"AVLTree", "Which rotation handles an imbalance where a node's right child's left subtree caused the imbalance (Right-Left case)?", "A. Single Right Rotation", "B. Single Left Rotation", "C. Left-Right Rotation (Left then Right)", "D. Right-Left Rotation (Right then Left)", "D"
"AVLTree", "What is the time complexity for search, insertion, and deletion operations in an AVLTree?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"AVLTree", "What is the worst-case height of an AVLTree with `N` nodes?", "A. O(N)", "B. O(log N)", "C. O(sqrt(N))", "D. O(N log N)", "B"
"AVLTree", "Compared to a Red-Black Tree, what is generally true about an AVLTree?", "A. It performs fewer rotations.", "B. It is more strictly balanced (taller but wider).", "C. It is typically faster for search operations.", "D. It is easier to implement.", "C"
"AVLTree", "Compared to a Red-Black Tree, what is generally true about an AVLTree regarding insertions/deletions?", "A. It tends to perform more rotations.", "B. It is typically faster for insertion and deletion operations.", "C. It uses less memory.", "D. It is less complex to implement.", "A"
"AVLTree", "What is the primary motivation for using an AVLTree over a regular BST?", "A. To simplify implementation.", "B. To prevent the tree from becoming skewed and degrading performance to O(N).", "C. To store unique elements only.", "D. To reduce memory usage.", "B"
"AVLTree", "When an insertion happens in an AVLTree, which nodes' balance factors might be affected and need re-evaluation?", "A. Only the newly inserted node.", "B. Only the root node.", "C. Only parent nodes of the path from the inserted node up to the root.", "D. All nodes in the tree.", "C"
"AVLTree", "What is the maximum number of rotations needed after a single insertion in an AVLTree to restore balance?", "A. One single rotation or one double rotation.", "B. Two single rotations.", "C. Three rotations.", "D. Log N rotations.", "A"
"AVLTree", "What is the maximum number of rotations needed after a single deletion in an AVLTree to restore balance?", "A. One single rotation or one double rotation.", "B. Log N rotations (propagating up from the deletion point).", "C. Two single rotations.", "D. Three rotations.", "B"
"AVLTree", "If a node's balance factor becomes 2, it indicates a:", "A. Left-heavy imbalance.", "B. Right-heavy imbalance.", "C. Perfectly balanced node.", "D. Valid state.", "B"
"AVLTree", "If a node's balance factor becomes -2, it indicates a:", "A. Left-heavy imbalance.", "B. Right-heavy imbalance.", "C. Perfectly balanced node.", "D. Valid state.", "A"
"AVLTree", "Which property of a BST does an AVLTree maintain strictly?", "A. The sorted order of elements.", "B. The complete binary tree property.", "C. The full binary tree property.", "D. The maximum number of nodes at each level.", "A"
"AVLTree", "Is an AVLTree always a complete binary tree?", "A. Yes, always.", "B. No, it is a height-balanced tree, not necessarily complete.", "C. Only if the number of nodes is a power of 2.", "D. Only for small trees.", "B"
"AVLTree", "What is the space complexity of an AVLTree with `N` nodes?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"AVLTree", "What information is typically stored in an AVLTree node in addition to the data and child pointers?", "A. Color (Red/Black)", "B. Balance factor or height.", "C. Parent pointer only.", "D. Number of nodes in subtree.", "B"
"AVLTree", "When performing an LL rotation, which node moves to the root of the affected subtree?", "A. The original unbalanced node.", "B. The original unbalanced node's left child.", "C. The original unbalanced node's right child.", "D. A new node is created.", "B"
"AVLTree", "When performing an RR rotation, which node moves to the root of the affected subtree?", "A. The original unbalanced node.", "B. The original unbalanced node's left child.", "C. The original unbalanced node's right child.", "D. A new node is created.", "C"
"AVLTree", "An LR rotation involves which sequence of single rotations?", "A. Left rotation on parent, then Right rotation on child.", "B. Right rotation on child, then Left rotation on parent.", "C. Left rotation on child, then Right rotation on parent.", "D. Right rotation on parent, then Left rotation on child.", "C"
"AVLTree", "An RL rotation involves which sequence of single rotations?", "A. Left rotation on parent, then Right rotation on child.", "B. Right rotation on child, then Left rotation on parent.", "C. Left rotation on child, then Right rotation on parent.", "D. Right rotation on parent, then Left rotation on child.", "B"
"AVLTree", "What happens to the balance factors of nodes involved in a single rotation (LL or RR)?", "A. They all become 0.", "B. They are recomputed based on the new subtree heights.", "C. They remain unchanged.", "D. They all become 1 or -1.", "B"
"AVLTree", "Which of the following is true about the values within an AVLTree?", "A. They are unique and sorted.", "B. They must be non-negative.", "C. They can be unsorted.", "D. They follow no specific order beyond the balance.", "A"
"AVLTree", "Is the root of an AVLTree always the median element of all values in the tree?", "A. Yes, always.", "B. No, but its value is generally close to the median in a balanced tree.", "C. Only if the tree is perfectly balanced.", "D. Only if elements are inserted in a sorted order.", "B"
"AVLTree", "What is the typical use case for AVLTree?", "A. When quick search times are critical and insertions/deletions are frequent, but not overwhelmingly so.", "B. For storing very large amounts of data on disk.", "C. For problems requiring exact median finding.", "D. For unweighted graph traversals.", "A"
"AVLTree", "What is the main disadvantage of AVLTree compared to simpler BSTs?", "A. Slower search operations.", "B. More complex implementation due to rotation logic.", "C. Higher memory consumption.", "D. Inability to handle duplicate keys.", "B"
"AVLTree", "When is an AVLTree considered 'degenerate'?", "A. When it becomes completely skewed, losing its balance property (not an AVLTree then).", "B. When it has only one node.", "C. When all nodes have two children.", "D. When all leaf nodes are at the same level.", "A"
"AVLTree", "If an AVLTree node has a balance factor of 0, what does it imply?", "A. Its left subtree is taller than its right subtree.", "B. Its right subtree is taller than its left subtree.", "C. Its left and right subtrees have the same height.", "D. The node is a leaf node.", "C"
"AVLTree", "Consider an AVLTree. If an insertion leads to a balance factor of -2 at node X, and X's left child Y has a balance factor of -1. What rotation is needed?", "A. LL rotation (Right rotation at X)", "B. RR rotation (Left rotation at X)", "C. LR rotation (Left at Y, then Right at X)", "D. RL rotation (Right at Y, then Left at X)", "A"
"AVLTree", "Consider an AVLTree. If an insertion leads to a balance factor of -2 at node X, and X's left child Y has a balance factor of 1. What rotation is needed?", "A. LL rotation (Right rotation at X)", "B. RR rotation (Left rotation at X)", "C. LR rotation (Left at Y, then Right at X)", "D. RL rotation (Right at Y, then Left at X)", "C"
"AVLTree", "Consider an AVLTree. If an insertion leads to a balance factor of 2 at node X, and X's right child Y has a balance factor of 1. What rotation is needed?", "A. LL rotation (Right rotation at X)", "B. RR rotation (Left rotation at X)", "C. LR rotation (Left at Y, then Right at X)", "D. RL rotation (Right at Y, then Left at X)", "B"
"AVLTree", "Consider an AVLTree. If an insertion leads to a balance factor of 2 at node X, and X's right child Y has a balance factor of -1. What rotation is needed?", "A. LL rotation (Right rotation at X)", "B. RR rotation (Left rotation at X)", "C. LR rotation (Left at Y, then Right at X)", "D. RL rotation (Right at Y, then Left at X)", "D"
"AVLTree", "What is the maximum number of comparisons for a search operation in an AVLTree with `N` nodes?", "A. N", "B. log2(N)", "C. Approximately 1.44 * log2(N)", "D. N/2", "C"
"AVLTree", "Are AVLTree typically implemented with recursion or iteration?", "A. Primarily iteration, to avoid stack overflow.", "B. Primarily recursion, due to the natural recursive definition of tree operations and rotations.", "C. Only iteration is possible.", "D. Only recursion is possible.", "B"
"AVLTree", "When a rotation occurs in an AVLTree, how many nodes actually change their data values?", "A. All nodes in the tree.", "B. The two (or three) nodes directly involved in the rotation.", "C. Only the root of the affected subtree.", "D. None, only pointers are rearranged.", "D"
"AVLTree", "Does an AVLTree provide better worst-case performance than a Red-Black tree for all operations?", "A. Yes, always.", "B. No, Red-Black trees offer slightly better worst-case guarantees for insertions/deletions due to simpler rebalancing rules.", "C. Only for search operations.", "D. Only for small trees.", "B"
"AVLTree", "What is the height of an empty AVLTree?", "A. 0", "B. -1", "C. 1", "D. Undefined", "B"
"AVLTree", "What is the height of an AVLTree with a single node?", "A. 0", "B. -1", "C. 1", "D. Undefined", "A"
"AVLTree", "If a node `X` has height `h`, and its balance factor is `0`, what are the heights of its left and right children?", "A. Left: `h-1`, Right: `h-1`", "B. Left: `h`, Right: `h`", "C. Left: `h-1`, Right: `h`", "D. Left: `h`, Right: `h-1`", "A"
"AVLTree", "What is the primary role of the 'height' attribute stored in each node of an AVLTree?", "A. To determine the number of children.", "B. To calculate the balance factor quickly without traversing subtrees.", "C. To identify the root node.", "D. To store the value of the node.", "B"
"AVLTree", "Can a sequence of insertions to an AVLTree cause a height increase of more than 1 at the root?", "A. Yes, multiple times during a single insertion.", "B. No, a single insertion can increase the height of the entire tree by at most 1.", "C. Only if the tree is very large.", "D. Only if multiple rotations are performed.", "B"
"AVLTree", "When an AVLTree is deleted, how is its balance factor updated?", "A. It stays the same.", "B. It is always set to 0.", "C. It is recomputed based on its children's heights after any rotations.", "D. It is set to -1 or 1 randomly.", "C"
"AVLTree", "Which concept is common to both AVLTree and Red-Black trees?", "A. Fixed number of nodes.", "B. Self-balancing properties to maintain logarithmic time complexity.", "C. Only supporting unique keys.", "D. Storing color attributes in nodes.", "B"
"RedBlackTree", "What is the primary characteristic that distinguishes a Red-Black Tree from a regular Binary Search Tree (BST)?", "A. It can store duplicate values.", "B. It is always a complete binary tree.", "C. It is self-balancing, maintaining specific properties to ensure logarithmic time complexity.", "D. Its nodes are sorted in a specific order.", "C"
"RedBlackTree", "How many specific properties must a Red-Black Tree satisfy?", "A. 3", "B. 4", "C. 5", "D. 6", "C"
"RedBlackTree", "Which of the following is NOT a property of a Red-Black Tree?", "A. Every node is either Red or Black.", "B. The root is always Black.", "C. Every path from a given node to any of its descendant NULL nodes contains the same number of Black nodes.", "D. Every Red node must have at least one Black child.", "D"
"RedBlackTree", "Which of the following is a correct property of a Red-Black Tree?", "A. All leaf nodes are Red.", "B. If a node is Red, then both its children are Black.", "C. Every path from the root to a leaf has the same number of Red nodes.", "D. The parent of a Red node must be Red.", "B"
"RedBlackTree", "What color are all leaf (NULL) nodes in a Red-Black Tree considered to be?", "A. Red", "B. Black", "C. White", "D. Depends on the implementation", "B"
"RedBlackTree", "What is the time complexity for search, insertion, and deletion operations in a Red-Black Tree?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"RedBlackTree", "What is the worst-case height of a Red-Black Tree with `N` nodes?", "A. O(N)", "B. O(log N)", "C. O(sqrt(N))", "D. O(N log N)", "B"
"RedBlackTree", "Compared to an AVL Tree, what is generally true about a Red-Black Tree?", "A. It is more strictly balanced (taller but wider).", "B. It is typically faster for search operations.", "C. It tends to perform fewer rotations (on average) during insertions/deletions.", "D. It is easier to implement.", "C"
"RedBlackTree", "What is the primary motivation for using a Red-Black Tree over a regular BST?", "A. To simplify implementation.", "B. To prevent the tree from becoming skewed and degrading performance to O(N).", "C. To store unique elements only.", "D. To reduce memory usage.", "B"
"RedBlackTree", "When an insertion or deletion violates Red-Black Tree properties, what operations are primarily used to restore them?", "A. Swapping nodes and recoloring.", "B. Rotations and recoloring.", "C. Rebuilding the entire tree.", "D. Deleting the unbalanced node.", "B"
"RedBlackTree", "What is the maximum number of rotations needed after a single insertion in a Red-Black Tree to restore balance?", "A. One (at most)", "B. Two", "C. Three", "D. Log N", "A"
"RedBlackTree", "What is the maximum number of rotations needed after a single deletion in a Red-Black Tree to restore balance?", "A. One (at most)", "B. Two", "C. Three", "D. Log N (propagating up from the deletion point)", "D"
"RedBlackTree", "The property that 'Every path from a given node to any of its descendant NULL nodes contains the same number of Black nodes' is called:", "A. Black-height property.", "B. Color consistency property.", "C. Node balance property.", "D. Path length property.", "A"
"RedBlackTree", "If a newly inserted node is Red, and its parent is also Red, which property is violated?", "A. Root property.", "B. Black-height property.", "C. Red-node property (no two adjacent Red nodes).", "D. Leaf property.", "C"
"RedBlackTree", "What happens to the color of the root node if a Red-Black Tree becomes empty?", "A. It remains Black.", "B. It becomes Red.", "C. It becomes NULL (which is considered Black).", "D. It is undefined.", "C"
"RedBlackTree", "Is a Red-Black Tree always a complete binary tree?", "A. Yes, always.", "B. No, it is a balanced tree, but not necessarily complete.", "C. Only if the number of nodes is a power of 2.", "D. Only for small trees.", "B"
"RedBlackTree", "What is the space complexity of a Red-Black Tree with `N` nodes?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"RedBlackTree", "What information is typically stored in a Red-Black Tree node in addition to the data and child pointers?", "A. Balance factor or height.", "B. Color (Red/Black).", "C. Parent pointer only.", "D. Number of nodes in subtree.", "B"
"RedBlackTree", "Which rotation operation involves three nodes: grandparent, parent, and child, and is used when a double rotation would be needed in an AVL Tree equivalent scenario?", "A. Single Right Rotation", "B. Single Left Rotation", "C. A specific sequence of two single rotations (e.g., Left-Right)", "D. A single rotation is always sufficient for any violation.", "C"
"RedBlackTree", "In a Red-Black Tree, if a node `X` is Red, what color must its children be?", "A. Both Red.", "B. Both Black.", "C. One Red, one Black.", "D. Can be any color.", "B"
"RedBlackTree", "What is the maximum height difference between the left and right subtrees of any node in a Red-Black Tree (in terms of black-height)?", "A. 0", "B. 1", "C. 2", "D. log N", "B"
"RedBlackTree", "Which is generally easier to implement, an AVL Tree or a Red-Black Tree?", "A. AVL Tree (due to simpler balance factor checks).", "B. Red-Black Tree (due to fixed color properties).", "C. Both are equally complex.", "D. Depends on the programming language.", "A"
"RedBlackTree", "What is the typical use case for Red-Black Trees?", "A. When quick search times are critical and insertions/deletions are frequent (e.g., standard library sets/maps).", "B. For storing very large amounts of data on disk.", "C. For problems requiring exact median finding.", "D. For unweighted graph traversals.", "A"
"RedBlackTree", "When an insertion occurs, a newly inserted node in a Red-Black Tree is initially colored:", "A. Black", "B. Red", "C. Grey", "D. Blue", "B"
"RedBlackTree", "Why is a newly inserted node initially colored Red?", "A. To immediately satisfy the Red-node property.", "B. To simplify the rebalancing logic by potentially violating only one property.", "C. To ensure the black-height property is always satisfied.", "D. It is a convention with no specific reason.", "B"
"RedBlackTree", "What is a 'sibling' node in the context of Red-Black Tree rebalancing?", "A. Any node at the same depth.", "B. A node that shares the same parent.", "C. A node in the opposite subtree of the root.", "D. An uncle node.", "B"
"RedBlackTree", "In Red-Black Tree insertion, what is an 'uncle' node?", "A. The parent's sibling.", "B. The node's grandparent.", "C. The node's sibling.", "D. The node's child.", "A"
"RedBlackTree", "If an inserted Red node has a Red parent and its uncle is also Red (Case 1), what is the typical rebalancing action?", "A. Rotation only.", "B. Recolor parent, uncle, and grandparent (grandparent becomes Red, parent and uncle Black).", "C. Deletion and re-insertion.", "D. Nothing, it's already balanced.", "B"
"RedBlackTree", "If an inserted Red node has a Red parent and its uncle is Black (Case 2 or 3), what rebalancing operations might be involved?", "A. Recolor only.", "B. Rotations and recoloring.", "C. Rebuilding from scratch.", "D. Swapping nodes.", "B"
"RedBlackTree", "The black-height property implies that the longest path from the root to any leaf is at most how many times the length of the shortest path?", "A. 1.5 times", "B. 2 times", "C. 3 times", "D. Equal", "B"
"RedBlackTree", "Which standard library data structures are commonly implemented using Red-Black Trees?", "A. `std::vector` (C++), `ArrayList` (Java)", "B. `std::map`/`std::set` (C++), `TreeMap`/`TreeSet` (Java)", "C. `std::list` (C++), `LinkedList` (Java)", "D. `std::queue` (C++), `ArrayDeque` (Java)", "B"
"RedBlackTree", "Is it possible for a Red-Black Tree to have duplicate values?", "A. No, Red-Black Trees fundamentally require unique values.", "B. Yes, by convention they can be placed in either left or right subtrees, or a count can be stored.", "C. Only if it's explicitly allowed by disabling rebalancing.", "D. Only if the duplicates are at the leaf nodes.", "B"
"RedBlackTree", "What happens to the color of the root node after any rebalancing operation (insertion or deletion)?", "A. It might become Red.", "B. It always remains Black.", "C. It is always recolored to Red.", "D. It is undefined.", "B"
"RedBlackTree", "The number of Black nodes from the root to any leaf node is constant. This guarantees:", "A. Perfect balance.", "B. That the tree will not become too unbalanced.", "C. All paths have the same number of total nodes.", "D. No Red nodes exist.", "B"
"RedBlackTree", "In a Red-Black Tree, if a node is Black, can its child be Black?", "A. No, never.", "B. Yes, always.", "C. Yes, but not if the child's parent is also Black.", "D. Yes, as long as Red-node property is not violated elsewhere.", "D"
"RedBlackTree", "What is the primary advantage of Red-Black Trees over AVL Trees in practice for typical library implementations?", "A. Simpler search algorithm.", "B. Fewer rotations/rebalancing steps on average, leading to faster updates.", "C. Less memory overhead per node.", "D. Guaranteed perfect balance.", "B"
"RedBlackTree", "When performing a deletion in a Red-Black Tree, if the deleted node is Black, what often happens?", "A. The tree automatically balances itself with no changes.", "B. A 'double black' situation or similar imbalance arises, requiring rebalancing.", "C. The tree becomes permanently skewed.", "D. The root changes color.", "B"
"RedBlackTree", "If a Red-Black Tree is formed by inserting elements in strictly increasing order, what will its structure be like?", "A. It will be a perfectly balanced tree.", "B. It will still be a valid Red-Black Tree, albeit potentially less efficient than if inserted randomly, but never skewed like a simple BST.", "C. It will become a linked list of Red nodes.", "D. It will become a linked list of Black nodes.", "B"
"RedBlackTree", "Which type of rotation in a Red-Black Tree involves moving the parent node down and the child node up, while preserving the BST property?", "A. Zig Rotation", "B. Zag Rotation", "C. Tree Rotation", "D. Both A and B (Left/Right rotations)", "D"
"RedBlackTree", "Can a Red-Black Tree have a Red root?", "A. Yes, if it's a single node tree.", "B. No, the root must always be Black.", "C. Only after an insertion.", "D. Only after a deletion.", "B"
"RedBlackTree", "What is the minimum number of nodes required to form a Red-Black Tree where rebalancing operations are clearly demonstrated?", "A. 1", "B. 2", "C. 3", "D. 4", "C"
"RedBlackTree", "Which data structure is most similar in purpose and performance guarantees to a Red-Black Tree?", "A. Hash Table", "B. B-Tree", "C. Heap", "D. AVL Tree", "D"
"RedBlackTree", "In the deletion process, if a Black node is replaced by a Red child, what is often the immediate action?", "A. Color the child Black.", "B. Perform a rotation.", "C. Do nothing, it's balanced.", "D. Recolor the root.", "A"
"RedBlackTree", "What is the main goal of the recoloring and rotation operations in a Red-Black Tree?", "A. To simplify the tree structure.", "B. To maintain the 5 Red-Black Tree properties.", "C. To make all nodes Black.", "D. To minimize memory usage.", "B"
"RedBlackTree", "Are Red-Black Trees easier or harder to implement than B-Trees?", "A. Easier, as B-Trees are generally more complex for disk-based operations.", "B. Harder, due to intricate color rules.", "C. They are about the same difficulty.", "D. B-Trees are a subset of Red-Black Trees.", "A"
"RedBlackTree", "What is the role of NULL (sentinel) nodes in a Red-Black Tree implementation?", "A. To act as actual data nodes.", "B. To simplify boundary conditions and property checks (they are always Black).", "C. To represent missing children and save memory.", "D. To mark the end of the tree.", "B"
"RedBlackTree", "Consider a Red-Black Tree. If you find a path from the root to a leaf with a different number of black nodes than another path, what does this indicate?", "A. The tree is a valid Red-Black Tree.", "B. The tree is an AVL Tree.", "C. The tree is not a valid Red-Black Tree (violates black-height property).", "D. The tree is perfectly balanced.", "C"
"RedBlackTree", "If a Red-Black Tree has a Black root, can it be a single node tree?", "A. Yes, if the node is Black.", "B. No, it must have at least two nodes.", "C. Only if the node is Red.", "D. Only if it's a leaf node.", "A"
"RedBlackTree", "What is the purpose of the 'double black' node concept in Red-Black Tree deletion?", "A. It indicates a completely balanced state.", "B. It's a temporary state representing a black-height violation that needs to be fixed.", "C. It means the node has two black children.", "D. It is a special type of leaf node.", "B"
"RedBlackTree", "When using a Red-Black Tree as a map, what part of the node structure corresponds to the key?", "A. The color attribute.", "B. The data value used for ordering (typically part of the data field).", "C. The parent pointer.", "D. The child pointers.", "B"
"BTree", "What is the primary application area for B-Trees?", "A. In-memory sorting algorithms.", "B. Indexing large amounts of data in databases and file systems.", "C. Network routing protocols.", "D. Real-time graphics rendering.", "B"
"BTree", "Why are B-Trees preferred over Binary Search Trees (BSTs) for disk-based data storage?", "A. They are simpler to implement.", "B. They have a higher branching factor, which minimizes disk I/O operations by keeping the tree shallow.", "C. They always remain perfectly balanced.", "D. They store data only on leaf nodes.", "B"
"BTree", "In a B-Tree of order `m` (or minimum degree `t`), what is the maximum number of children a node can have?", "A. m-1", "B. m", "C. 2m-1", "D. 2m", "B"
"BTree", "In a B-Tree of order `m` (or minimum degree `t`), what is the minimum number of children a non-root node can have?", "A. 1", "B. ceil(m/2)", "C. m-1", "D. 2", "B"
"BTree", "What is the minimum number of keys a non-root node in a B-Tree of order `m` (or minimum degree `t`) must contain?", "A. 1", "B. ceil(m/2) - 1", "C. m-1", "D. 2t - 1", "B"
"BTree", "What is the maximum number of keys a node in a B-Tree of order `m` (or minimum degree `t`) can contain?", "A. m", "B. m-1", "C. 2m-1", "D. 2t-1", "B"
"BTree", "What is always true about the root node of a B-Tree?", "A. It can have only one child.", "B. It must have at least `m` children.", "C. It can have anywhere from 2 to `m` children (or 0 if it's the only node).", "D. It has `m-1` keys.", "C"
"BTree", "Are all leaf nodes in a B-Tree required to be at the same level?", "A. No, only in specific types like B+ Trees.", "B. Yes, always.", "C. Only if the tree is perfectly balanced.", "D. It depends on the insertion order.", "B"
"BTree", "What is the height of a B-Tree with `N` keys and minimum degree `t`?", "A. O(N)", "B. O(log_t N)", "C. O(t * log N)", "D. O(N^2)", "B"
"BTree", "When a B-Tree node becomes full during an insertion, what operation is performed?", "A. Rotation.", "B. Splitting the node into two, promoting a median key to the parent.", "C. Rebalancing the entire tree.", "D. Deleting the oldest key.", "B"
"BTree", "When a key is deleted from a B-Tree, and a node underflows, what operations might be performed?", "A. Rotations and recoloring.", "B. Merging with a sibling or borrowing from a sibling.", "C. Rebuilding the entire tree.", "D. Moving the key to a leaf node.", "B"
"BTree", "What is the primary difference between a B-Tree and a B+ Tree?", "A. B-Trees store data only at leaf nodes.", "B. B+ Trees store all data at leaf nodes and have linked leaves for range queries.", "C. B-Trees are not balanced.", "D. B+ Trees have a smaller branching factor.", "B"
"BTree", "Which type of tree is typically used for file systems and database indexes?", "A. Binary Search Tree", "B. AVL Tree", "C. Red-Black Tree", "D. B-Tree (or B+ Tree)", "D"
"BTree", "What is the time complexity for search, insertion, and deletion operations in a B-Tree with `N` keys and minimum degree `t`?", "A. O(log N)", "B. O(log_t N)", "C. O(t * log_t N)", "D. O(N)", "C"
"BTree", "In a B-Tree, keys within a node are kept in what order?", "A. Unsorted.", "B. Random order.", "C. Sorted order.", "D. Reverse sorted order.", "C"
"BTree", "What is the role of the pointers (children) in a B-Tree node?", "A. They point to sibling nodes.", "B. They point to parent nodes.", "C. They point to subtrees containing keys less than, between, or greater than the keys in the current node.", "D. They store actual data values.", "C"
"BTree", "When splitting a B-Tree node with `2t-1` keys, how many new nodes are created?", "A. 1", "B. 2", "C. 3", "D. m", "B"
"BTree", "In a B-Tree split operation, where does the median key go?", "A. It remains in the original node.", "B. It is moved to the new sibling node.", "C. It is promoted up to the parent node.", "D. It is discarded.", "C"
"BTree", "If a root node splits in a B-Tree, what happens to the height of the tree?", "A. It decreases by one.", "B. It remains the same.", "C. It increases by one.", "D. It becomes zero.", "C"
"BTree", "What is the minimum degree `t` of a B-Tree?", "A. The maximum number of children a node can have.", "B. The minimum number of children a node must have (except root).", "C. The height of the tree.", "D. The number of keys in the root.", "B"
"BTree", "A B-Tree of order 3 means a node can have a maximum of how many children?", "A. 2", "B. 3", "C. 4", "D. 5", "B"
"BTree", "A B-Tree of order 3 means a non-root node must have a minimum of how many children?", "A. 1", "B. 2", "C. 3", "D. 4", "B"
"BTree", "What is the primary advantage of B-Trees for disk-based databases?", "A. They are simpler to program.", "B. They minimize the number of disk I/O operations due to their shallow height.", "C. They guarantee faster updates than queries.", "D. They consume less memory than other trees.", "B"
"BTree", "Are all keys in a B-Tree unique?", "A. Yes, always.", "B. No, duplicate keys are explicitly handled by design.", "C. It depends on the implementation; some allow duplicates, some don't.", "D. Only at the leaf nodes.", "C"
"BTree", "When performing a search in a B-Tree, what strategy is typically used within a node?", "A. Linear search.", "B. Binary search.", "C. Hash lookup.", "D. Random access.", "B"
"BTree", "What is the role of 'borrowing' in B-Tree deletion?", "A. It's used when a node becomes full.", "B. It's used when a node underflows, trying to redistribute keys from a rich sibling.", "C. It's a method to merge nodes.", "D. It refers to copying data to memory.", "B"
"BTree", "What is the role of 'merging' in B-Tree deletion?", "A. It's used when a node becomes full.", "B. It's used when a node and its sibling both underflow, combining them into one node.", "C. It's a method to split nodes.", "D. It refers to sorting keys within a node.", "B"
"BTree", "Which of the following is true about B-Tree deletion?", "A. It always results in a height decrease.", "B. It can propagate changes up to the root, potentially decreasing tree height.", "C. It only affects leaf nodes.", "D. It's simpler than insertion.", "B"
"BTree", "What is a 'pointer' in a B-Tree node typically representing?", "A. A memory address of the next key.", "B. A reference to a child node (subtree).", "C. An index into an array.", "D. A connection to a sibling node.", "B"
"BTree", "How many keys does a B-Tree node with `k` children contain?", "A. k", "B. k-1", "C. k+1", "D. 2k", "B"
"BTree", "In a B-Tree, what does 'degree' refer to?", "A. The number of keys in a node.", "B. The maximum number of children a node can have.", "C. The height of the tree.", "D. The number of nodes at the lowest level.", "B"
"BTree", "What is the maximum height of a B-Tree in terms of page I/O (disk accesses)?", "A. Proportional to N (number of keys).", "B. Proportional to log_m(N) where `m` is the branching factor.", "C. Proportional to the number of nodes.", "D. Proportional to the square root of N.", "B"
"BTree", "What is 'internal fragmentation' in the context of B-Trees?", "A. Disk space lost because nodes are not entirely full.", "B. Data spread across multiple disk blocks.", "C. Unused memory within a node's structure.", "D. The process of splitting a node.", "A"
"BTree", "Can a B-Tree be used for in-memory data structures?", "A. No, they are exclusively for disk-based storage.", "B. Yes, but they are generally less efficient than Red-Black or AVL trees for purely in-memory use.", "C. Only for very small datasets.", "D. Only if the memory is structured like a disk.", "B"
"BTree", "What is the 'order' of a B-Tree usually defined as?", "A. The minimum number of keys in a node.", "B. The maximum number of keys in a node.", "C. The minimum number of children a non-root node can have.", "D. The maximum number of children a node can have.", "D"
"BTree", "If a B-Tree has a minimum degree of `t=2` (meaning max children is 4, max keys is 3), what is the minimum number of keys for a non-root node?", "A. 1", "B. 2", "C. 3", "D. 4", "A"
"BTree", "Why is the branching factor `m` so important for B-Trees?", "A. It determines the number of rotations.", "B. A higher `m` leads to a shorter tree, reducing disk I/O.", "C. It makes the implementation simpler.", "D. It defines the number of unique keys.", "B"
"BTree", "What happens to the structure of a B-Tree if all insertions happen in sorted order?", "A. It becomes skewed like a linked list.", "B. It remains balanced, performing splits as needed to maintain properties.", "C. It will only have one level.", "D. It will only have a root and leaf nodes.", "B"
"BTree", "Which property ensures that a B-Tree remains balanced during insertions and deletions?", "A. All internal nodes must have two children.", "B. All leaf nodes are at the same depth.", "C. Keys are always sorted.", "D. Node sizes are fixed.", "B"
"BTree", "What is the term for a B-Tree where all leaf nodes are linked together to facilitate range queries?", "A. B-Tree", "B. B+ Tree", "C. B* Tree", "D. AVL Tree", "B"
"BTree", "In a B+ Tree, where is the actual data (records) stored?", "A. In all nodes.", "B. Only in internal nodes.", "C. Only in leaf nodes.", "D. In a separate hash table.", "C"
"BTree", "What is the advantage of a B+ Tree's linked leaf nodes?", "A. Faster individual key lookups.", "B. Efficient range queries and sequential access.", "C. Reduced memory usage.", "D. Simpler deletion process.", "B"
"BTree", "How does a B-Tree handle large keys (e.g., long strings)?", "A. It stores them entirely within the node structure.", "B. It stores pointers to the keys, which are stored elsewhere, to keep node size manageable.", "C. It breaks them into smaller pieces.", "D. It doesn't support large keys.", "B"
"BTree", "Is it possible for a B-Tree to have a single node (the root) that is also a leaf?", "A. No, a root must always have children.", "B. Yes, if the tree is empty or contains only a few keys.", "C. Only if it's a B+ Tree.", "D. Only if `m` is 2.", "B"
"BTree", "What is the primary role of an 'index' in a database, often implemented with B-Trees?", "A. To store all data records directly.", "B. To speed up data retrieval by allowing quick lookup of record locations.", "C. To encrypt sensitive data.", "D. To perform mathematical calculations.", "B"
"BTree", "In a B-Tree, the number of keys in a non-root node is `k`. What is the number of children for that node?", "A. k", "B. k+1", "C. k-1", "D. 2k", "B"
"BTree", "What is the common term for a B-Tree used in a file system?", "A. Directory tree.", "B. Index tree.", "C. File allocation table (FAT).", "D. Inode structure.", "B"
"BTree", "Which data structure is best suited for scenarios where data is stored on secondary storage (like hard drives) and minimizing disk I/O is crucial?", "A. AVL Tree", "B. Red-Black Tree", "C. B-Tree", "D. Hash Map", "C"
"BTree", "What is the main difference in terms of key storage between a B-Tree and a B+ Tree's internal nodes?", "A. B-Trees store all keys in internal nodes; B+ Trees store only copies of keys.", "B. B-Trees store keys and data in internal nodes; B+ Trees store only keys (for navigation).", "C. B-Trees store only data; B+ Trees store only keys.", "D. There is no difference.", "B"
"BTree", "Are B-Trees typically implemented using recursion or iteration?", "A. Primarily recursion due to the tree structure.", "B. Primarily iteration to avoid stack overflow for large trees, especially for disk operations.", "C. Only recursion is possible.", "D. Only iteration is possible.", "B"
"BPlusTree", "What is the primary difference between a BPlusTree and a BTree?", "A. BPlusTrees store all keys and data in all nodes.", "B. BPlusTrees store all data records only at the leaf nodes, while internal nodes store only keys for navigation.", "C. BPlusTrees are not balanced.", "D. BPlusTrees have a smaller branching factor.", "B"
"BPlusTree", "Where are all the actual data records (pointers to data records) stored in a BPlusTree?", "A. In all nodes (internal and leaf).", "B. Only in the internal nodes.", "C. Only in the leaf nodes.", "D. In a separate hash table.", "C"
"BPlusTree", "What is the primary advantage of the linked list structure among the leaf nodes in a BPlusTree?", "A. Faster individual key lookups.", "B. Efficient range queries and sequential access (e.g., iterating through all records in a range).", "C. Reduced memory usage.", "D. Simpler deletion process.", "B"
"BPlusTree", "In a BPlusTree, what do the internal (non-leaf) nodes contain?", "A. Keys and pointers to data records.", "B. Only keys (acting as separators/indices) and child pointers.", "C. Only data records.", "D. Pointers to siblings.", "B"
"BPlusTree", "Why is a BPlusTree preferred over a BTree for database indexing with range queries?", "A. BTree cannot handle range queries.", "B. BPlusTree's linked leaf nodes make range queries more efficient as data is sequential.", "C. BPlusTree uses less memory.", "D. BPlusTree is always perfectly balanced.", "B"
"BPlusTree", "In a BPlusTree of order `m` (or minimum degree `t`), what is the maximum number of keys a leaf node can contain?", "A. m-1", "B. m", "C. 2m-1", "D. 2t-1", "A"
"BPlusTree", "In a BPlusTree of order `m` (or minimum degree `t`), what is the maximum number of keys an internal node can contain?", "A. m-1", "B. m", "C. 2m-1", "D. 2t-1", "A"
"BPlusTree", "What is the minimum number of keys a non-root, non-leaf node in a BPlusTree of order `m` (or minimum degree `t`) must contain?", "A. 1", "B. ceil(m/2) - 1", "C. m-1", "D. 2t - 1", "B"
"BPlusTree", "What is the minimum number of keys a leaf node in a BPlusTree of order `m` (or minimum degree `t`) must contain?", "A. 1", "B. ceil(m/2) - 1", "C. m-1", "D. 2t - 1", "B"
"BPlusTree", "When an internal node in a BPlusTree becomes full during insertion, what operation is performed?", "A. Rotation.", "B. Splitting the node into two, promoting a copy of the median key to the parent.", "C. Rebalancing the entire tree.", "D. Deleting the oldest key.", "B"
"BPlusTree", "When a leaf node in a BPlusTree becomes full during insertion, what operation is performed?", "A. Rotation.", "B. Splitting the node into two, promoting a copy of the median key to the parent.", "C. Rebalancing the entire tree.", "D. Deleting the oldest key.", "B"
"BPlusTree", "What happens to the promoted key during an internal node split in a BPlusTree?", "A. It stays in the original node and is copied to the parent.", "B. It is moved to the new sibling node.", "C. It is promoted to the parent, but also copied into the new sibling node.", "D. It is discarded.", "A"
"BPlusTree", "What happens to the promoted key during a leaf node split in a BPlusTree?", "A. It stays in the original node.", "B. It is moved to the new sibling node.", "C. It is copied to the parent, and the median value is also part of the new sibling node.", "D. It is discarded.", "C"
"BPlusTree", "Are all leaf nodes in a BPlusTree required to be at the same level?", "A. No, only in specific types.", "B. Yes, always.", "C. Only if the tree is perfectly balanced.", "D. It depends on the insertion order.", "B"
"BPlusTree", "What is the time complexity for search, insertion, and deletion operations in a BPlusTree with `N` keys and minimum degree `t`?", "A. O(log N)", "B. O(log_t N)", "C. O(t * log_t N)", "D. O(N)", "C"
"BPlusTree", "In a BPlusTree, keys within a node (both internal and leaf) are kept in what order?", "A. Unsorted.", "B. Random order.", "C. Sorted order.", "D. Reverse sorted order.", "C"
"BPlusTree", "What is the role of the pointers (children) in an internal node of a BPlusTree?", "A. They point to sibling nodes.", "B. They point to data records.", "C. They point to subtrees (child nodes).", "D. They store actual data values.", "C"
"BPlusTree", "What is the role of the pointers in a leaf node of a BPlusTree?", "A. They point to child nodes.", "B. They point to other leaf nodes in a sequential manner (sibling pointers).", "C. They point to parent nodes.", "D. They store actual data values.", "B"
"BPlusTree", "When a key is deleted from a BPlusTree and a node underflows, what operations might be performed?", "A. Rotations and recoloring.", "B. Merging with a sibling or borrowing from a sibling.", "C. Rebuilding the entire tree.", "D. Moving the key to a leaf node.", "B"
"BPlusTree", "What is the primary advantage of BPlusTrees over hash tables for database indexing?", "A. Faster average-case lookup.", "B. Efficient range queries and sorted traversal.", "C. Less memory usage.", "D. Simpler implementation.", "B"
"BPlusTree", "Can a BPlusTree store duplicate keys?", "A. No, BPlusTrees fundamentally require unique keys.", "B. Yes, they are typically handled by storing duplicate keys or pointers to multiple data records at leaf nodes.", "C. Only if it's a very small tree.", "D. Only if the duplicates are in internal nodes.", "B"
"BPlusTree", "What happens to the height of a BPlusTree if the root node splits?", "A. It decreases by one.", "B. It remains the same.", "C. It increases by one.", "D. It becomes zero.", "C"
"BPlusTree", "What is the main reason for BPlusTrees' efficiency in disk-based systems?", "A. They keep all data in memory.", "B. Their shallow height due to high fan-out minimizes disk I/O operations.", "C. They use a hashing mechanism.", "D. They perform constant-time operations.", "B"
"BPlusTree", "In a BPlusTree, if you search for a key, where will you eventually find the data record associated with it?", "A. In the root node.", "B. In any internal node.", "C. Always in a leaf node.", "D. It depends on the key value.", "C"
"BPlusTree", "What is the typical 'order' of a BPlusTree in a practical database system?", "A. Very small (e.g., 2-4).", "B. Very large (e.g., hundreds or thousands).", "C. Depends on the number of records.", "D. Fixed at 10.", "B"
"BPlusTree", "When a leaf node underflows in a BPlusTree, and it cannot borrow from a sibling, what operation is performed?", "A. Rotation.", "B. Splitting.", "C. Merging with a sibling.", "D. Deletion of the underflowed node.", "C"
"BPlusTree", "When an internal node underflows in a BPlusTree, and it cannot borrow from a sibling, what operation is performed?", "A. Rotation.", "B. Splitting.", "C. Merging with a sibling (and potentially adjusting parent's key).", "D. Deletion of the underflowed node.", "C"
"BPlusTree", "What is the common term for a BPlusTree index where keys are stored in the same order as the physical data records on disk?", "A. Secondary index.", "B. Clustered index.", "C. Non-clustered index.", "D. Hash index.", "B"
"BPlusTree", "What is the common term for a BPlusTree index where keys store pointers to the physical data records, which might be in a different order?", "A. Secondary index.", "B. Clustered index.", "C. Non-clustered index.", "D. Hash index.", "C"
"BPlusTree", "If a BPlusTree has `N` records, and block size allows `B` keys per node, what is its height approximately?", "A. O(N)", "B. O(log_B N)", "C. O(B * log N)", "D. O(N^2)", "B"
"BPlusTree", "How does a BPlusTree ensure that all search operations involve traversing from the root to a leaf?", "A. Only leaf nodes contain data pointers, forcing traversal to the lowest level.", "B. Internal nodes contain pointers to siblings.", "C. The root is always a leaf node.", "D. Search is only done on leaf nodes.", "A"
"BPlusTree", "What happens to the key values in internal nodes during an insertion into a BPlusTree?", "A. They are copied to leaf nodes.", "B. They serve as separators, guiding search to the correct child branch.", "C. They are deleted after guiding the search.", "D. They store actual data.", "B"
"BPlusTree", "What is the minimum degree `t` of a BPlusTree?", "A. The maximum number of children a node can have.", "B. The minimum number of children a non-root internal node must have.", "C. The height of the tree.", "D. The number of keys in the root.", "B"
"BPlusTree", "In a BPlusTree of minimum degree `t`, an internal node with `k` keys will have how many children?", "A. k", "B. k+1", "C. k-1", "D. 2k", "B"
"BPlusTree", "What is a 'sequence set' in a BPlusTree?", "A. The set of all internal nodes.", "B. The linked list of leaf nodes, containing all data records.", "C. A sorted list of all keys in the tree.", "D. The set of all root nodes.", "B"
"BPlusTree", "What is an 'index set' in a BPlusTree?", "A. The set of all leaf nodes.", "B. The collection of internal nodes that form the search path structure.", "C. A sorted list of all data records.", "D. The set of all keys in the tree.", "B"
"BPlusTree", "Is the root of a BPlusTree ever a leaf node?", "A. No, never.", "B. Yes, if the tree contains only a few keys (less than the max keys of a leaf node).", "C. Only if it's a BTree.", "D. Only if `m` is 2.", "B"
"BPlusTree", "When searching for a key not present in a BPlusTree, where does the search terminate?", "A. At the root node.", "B. At an internal node.", "C. At a leaf node, indicating the key is not found.", "D. It crashes.", "C"
"BPlusTree", "What is the primary disadvantage of BPlusTrees compared to hash tables?", "A. Slower range queries.", "B. Slower average-case single key lookups.", "C. Greater memory usage.", "D. More complex implementation.", "B"
"BPlusTree", "What is the advantage of BPlusTrees over simple sorted arrays?", "A. Faster sequential access.", "B. Efficient insertion and deletion of elements without massive shifting.", "C. Less memory usage.", "D. Simpler implementation.", "B"
"BPlusTree", "Which database operations benefit most from BPlusTrees?", "A. Full table scans.", "B. Insertions, deletions, and especially range-based queries (e.g., WHERE price BETWEEN X AND Y).", "C. Aggregation (SUM, AVG).", "D. Join operations between large tables.", "B"
"BPlusTree", "When is the height of a BPlusTree guaranteed to increase?", "A. Every time a new record is inserted.", "B. Only when the root node splits.", "C. When any internal node splits.", "D. When any leaf node splits.", "B"
"BPlusTree", "What kind of data are BPlusTrees typically used to index?", "A. Only integer data.", "B. Only string data.", "C. Data that needs to be accessed efficiently by key, and often in ranges.", "D. Small, volatile datasets.", "C"
"BPlusTree", "What is the implication of all data records being in the leaf nodes of a BPlusTree?", "A. Internal nodes can be smaller, fitting more keys per block.", "B. Search operations require fewer disk I/Os.", "C. Deletion is always simpler.", "D. Range queries are slower.", "A"
"BPlusTree", "How do BPlusTrees handle duplicate keys (if allowed)?", "A. By placing all duplicate data records directly in the internal nodes.", "B. By storing multiple data pointers for the same key in a leaf node, or by chaining duplicate records.", "C. They strictly forbid duplicates.", "D. By always assigning duplicates to the rightmost child.", "B"
"BPlusTree", "What is the 'fan-out' of a BPlusTree node?", "A. The number of keys in the node.", "B. The number of child pointers (or children).", "C. The height of the node.", "D. The depth of the node.", "B"
"BPlusTree", "In a BPlusTree, what does the term 'order' often refer to?", "A. The minimum number of keys in a node.", "B. The maximum number of keys (or pointers) that can be stored in a node.", "C. The height of the tree.", "D. The number of leaf nodes.", "B"
"BPlusTree", "What is a major concern when designing BPlusTrees for a database?", "A. The choice of colors for nodes.", "B. The size of the disk blocks, which dictates the node size and fan-out.", "C. The number of CPUs available.", "D. The type of sorting algorithm used.", "B"
"BPlusTree", "What ensures that a BPlusTree remains balanced?", "A. Random insertions and deletions.", "B. The split and merge operations that maintain minimum and maximum key/child constraints for nodes.", "C. Periodic full tree rebuilds.", "D. Only balanced data input.", "B"
"BPlusTree", "Which operation is generally considered to be the most complex in a BPlusTree?", "A. Search.", "B. Insertion (due to potential splits and propagation).", "C. Deletion (due to potential merges/borrows and propagation).", "D. Traversing the leaf nodes.", "C"
"SegmentTree", "What is a SegmentTree primarily used for?", "A. Storing strings efficiently.", "B. Performing range queries (e.g., sum, min, max, XOR) and point/range updates on an array efficiently.", "C. Representing hierarchical file systems.", "D. Solving shortest path problems.", "B"
"SegmentTree", "What is the time complexity of building a SegmentTree from an array of `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"SegmentTree", "What is the time complexity of performing a range query (e.g., sum) on a SegmentTree with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"SegmentTree", "What is the time complexity of performing a point update on a SegmentTree with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"SegmentTree", "What is the space complexity of a SegmentTree built on an array of `N` elements?", "A. O(N)", "B. O(log N)", "C. O(N log N)", "D. O(N^2)", "A"
"SegmentTree", "How many nodes does a SegmentTree typically have for an array of size `N`?", "A. Exactly N nodes.", "B. Approximately 2N to 4N nodes.", "C. Approximately N log N nodes.", "D. Exactly log N nodes.", "B"
"SegmentTree", "What kind of operation does each node in a SegmentTree represent?", "A. A single element from the original array.", "B. A range or segment of the original array.", "C. The entire original array.", "D. A pointer to another node.", "B"
"SegmentTree", "Which of the following problems can be efficiently solved using a SegmentTree?", "A. Finding the shortest path in a graph.", "B. Searching for a specific element in an unsorted list.", "C. Finding the sum of elements in a given range [L, R] and updating an element.", "D. Sorting an array.", "C"
"SegmentTree", "SegmentTrees are typically implemented using which underlying data structure?", "A. Linked List", "B. Adjacency List", "C. Array (implicit tree representation)", "D. Hash Map", "C"
"SegmentTree", "If a SegmentTree node covers the range [L, R], what ranges do its children typically cover?", "A. [L, L+1] and [R-1, R]", "B. [L, M] and [M+1, R], where M is (L+R)/2", "C. [L, R/2] and [R/2+1, R]", "D. [0, L] and [R, N-1]", "B"
"SegmentTree", "In a SegmentTree, the leaf nodes correspond to what?", "A. The entire array range.", "B. Individual elements of the original array.", "C. Half of the original array.", "D. Ranges that cannot be further divided.", "B"
"SegmentTree", "Why is `log N` complexity achieved for queries and updates in a SegmentTree?", "A. Because the tree is always perfectly balanced.", "B. Because at each step, the search/update range is halved.", "C. Due to constant time operations at each node.", "D. Because it uses hashing.", "B"
"SegmentTree", "Can a SegmentTree handle point updates (changing a single element's value)?", "A. No, only range updates.", "B. Yes, by traversing down to the leaf and updating ancestors.", "C. Only if the array is sorted.", "D. Only for the root element.", "B"
"SegmentTree", "Can a SegmentTree handle range updates (changing all elements in a range)?", "A. No, only point updates.", "B. Yes, typically with a technique called 'lazy propagation'.", "C. Only if the range is small.", "D. Only by rebuilding the entire tree.", "B"
"SegmentTree", "What is 'lazy propagation' in the context of SegmentTrees used for?", "A. To speed up point queries.", "B. To optimize range updates by deferring updates to child nodes.", "C. To balance the tree.", "D. To reduce memory usage.", "B"
"SegmentTree", "When performing a range query in a SegmentTree, if a node's range is completely contained within the query range, what happens?", "A. The function recursively calls its children.", "B. The value stored in that node is directly returned (and combined).", "C. The node is skipped.", "D. The tree is rebuilt.", "B"
"SegmentTree", "When performing a range query in a SegmentTree, if a node's range is outside the query range, what happens?", "A. Its value is returned.", "B. It is skipped (often by returning an identity element).", "C. It causes an error.", "D. It is fully traversed.", "B"
"SegmentTree", "What is the identity element for a sum query in a SegmentTree?", "A. 0", "B. 1", "C. -1", "D. Infinity", "A"
"SegmentTree", "What is the identity element for a minimum query in a SegmentTree?", "A. 0", "B. 1", "C. Negative infinity", "D. Positive infinity", "D"
"SegmentTree", "What is the identity element for a maximum query in a SegmentTree?", "A. 0", "B. 1", "C. Negative infinity", "D. Positive infinity", "C"
"SegmentTree", "When building a SegmentTree, why is it often padded to the next power of two?", "A. To ensure the tree is always a complete binary tree for simpler array mapping.", "B. To reduce memory usage.", "C. To make it a balanced binary search tree.", "D. It's not necessary.", "A"
"SegmentTree", "What type of tree structure does a SegmentTree naturally form?", "A. A skewed tree.", "B. A complete binary tree (conceptually, when padded).", "C. A perfect binary tree.", "D. A balanced search tree (like AVL).", "B"
"SegmentTree", "Can a SegmentTree handle operations other than sum, min, max (e.g., XOR, GCD)?", "A. No, it's limited to these basic operations.", "B. Yes, as long as the operation is associative and has an identity element.", "C. Only if the array contains specific data types.", "D. Only with significant modifications.", "B"
"SegmentTree", "Is a SegmentTree a Binary Search Tree?", "A. Yes, always.", "B. No, it's a binary tree that represents array segments, not ordered elements for search by value.", "C. Only if it's perfectly balanced.", "D. Only for specific types of data.", "B"
"SegmentTree", "What happens during a push-down operation in lazy propagation?", "A. The pending update is applied to the current node.", "B. The pending update is pushed from the current node to its children.", "C. The array is updated.", "D. The query result is returned.", "B"
"SegmentTree", "When is a push-down operation typically performed in lazy propagation?", "A. After every query.", "B. Before querying or updating a node's children.", "C. Only when the tree is built.", "D. Only when a leaf node is reached.", "B"
"SegmentTree", "What is the depth of a SegmentTree (root at depth 0) for an array of size `N`?", "A. O(N)", "B. O(log N)", "C. O(N log N)", "D. O(sqrt(N))", "B"
"SegmentTree", "If a SegmentTree is implemented using an array, what is the parent of node at index `i` (0-indexed, root at 0)?", "A. `(i-1)/2`", "B. `i/2`", "C. `2*i+1`", "D. `2*i+2`", "A"
"SegmentTree", "If a SegmentTree is implemented using an array, what are the children of node at index `i` (0-indexed, root at 0)?", "A. `(i-1)/2, i/2`", "B. `i/2, i/2 + 1`", "C. `2*i+1, 2*i+2`", "D. `i-1, i+1`", "C"
"SegmentTree", "For an array `[1, 2, 3, 4]`, what range would the root of a SegmentTree typically cover?", "A. `[1, 1]`", "B. `[1, 4]`", "C. `[2, 3]`", "D. `[0, 3]` (if 0-indexed)", "D"
"SegmentTree", "If a range query is for `[L, R]`, and a node covers `[nodeL, nodeR]`. If `nodeR < L` or `nodeL > R`, what does this imply?", "A. The node's range is completely outside the query range.", "B. The node's range is completely inside the query range.", "C. The node's range partially overlaps the query range.", "D. An error has occurred.", "A"
"SegmentTree", "If a SegmentTree is used for point updates and range sums, and an element at index `i` is updated, which nodes need to be updated?", "A. Only the leaf node corresponding to `i`.", "B. Only the root node.", "C. The leaf node for `i` and all its ancestor nodes up to the root.", "D. All nodes in the tree.", "C"
"SegmentTree", "What is a 'persistent SegmentTree' used for?", "A. Storing data permanently on disk.", "B. Allowing queries on past versions of the array without rebuilding the tree.", "C. Making the tree more robust to failures.", "D. Optimizing memory usage.", "B"
"SegmentTree", "How does a persistent SegmentTree achieve its functionality?", "A. By copying the entire tree for each update.", "B. By creating new nodes only for the modified path and sharing untouched parts.", "C. By storing diffs between versions.", "D. By hashing each version.", "B"
"SegmentTree", "What is a 'Fenwick Tree' (Binary Indexed Tree) related to a SegmentTree?", "A. It's a type of SegmentTree.", "B. It's an alternative data structure for similar problems, often simpler for point updates and prefix sums.", "C. It's a precursor to SegmentTrees.", "D. It's a completely unrelated data structure.", "B"
"SegmentTree", "When would you prefer a SegmentTree over a Fenwick Tree?", "A. For simple point updates and prefix sums.", "B. When dealing with range updates and/or operations that are not easily invertible (like min/max).", "C. When memory is extremely limited.", "D. When the array is very small.", "B"
"SegmentTree", "Which of the following operations would be challenging to implement with a simple SegmentTree without lazy propagation?", "A. Point sum query.", "B. Point update.", "C. Range sum query.", "D. Range update (e.g., add X to all elements in [L,R]).", "D"
"SegmentTree", "What is the primary advantage of a SegmentTree over a simple array for range queries and updates?", "A. It always uses less memory.", "B. It offers logarithmic time complexity for these operations, whereas a simple array would be linear.", "C. It is simpler to implement.", "D. It can store more data.", "B"
"SegmentTree", "If a SegmentTree stores maximum values, and a node has value `V`, what does `V` represent?", "A. The maximum value in the original array.", "B. The maximum value in the range covered by that node.", "C. The maximum value of its children.", "D. The maximum value of the entire tree.", "B"
"SegmentTree", "Can a SegmentTree be used on a dynamic array (where elements are added/removed from ends)?", "A. Yes, with specific modifications like implicit segment trees or dynamic segment trees.", "B. No, it requires a fixed-size array.", "C. Only if the array size doubles/halves.", "D. Only for very small arrays.", "A"
"SegmentTree", "What is the base case for the recursive build function of a SegmentTree?", "A. When the range becomes empty.", "B. When the range contains a single element (a leaf node).", "C. When the range is the entire array.", "D. When the tree reaches a certain depth.", "B"
"SegmentTree", "In a standard SegmentTree, does each node explicitly store its left and right child pointers?", "A. Yes, always.", "B. No, they are implicitly determined by array indices.", "C. Only the root node.", "D. Only leaf nodes.", "B"
"SegmentTree", "What is the typical value initialized to a SegmentTree node if the operation is a sum and the range is invalid/empty?", "A. -1", "B. 0", "C. Infinity", "D. The last element.", "B"
"SegmentTree", "What is the typical value initialized to a SegmentTree node if the operation is a minimum and the range is invalid/empty?", "A. -1", "B. 0", "C. Positive Infinity", "D. The first element.", "C"
"SegmentTree", "Can a SegmentTree be used to find the number of elements less than X in a given range?", "A. Yes, with additional data in nodes or by building a specialized SegmentTree (e.g., on counts).", "B. No, it only supports sum, min, max.", "C. Only if the array is sorted.", "D. Only for point queries.", "A"
"SegmentTree", "What is the disadvantage of using a SegmentTree for very sparse arrays?", "A. It performs too slowly.", "B. It consumes a lot of memory for empty/unused ranges.", "C. It cannot handle sparse data.", "D. Updates become too complex.", "B"
"SegmentTree", "How does a SegmentTree compare to a square root decomposition approach for range queries/updates?", "A. SegmentTree is generally faster (O(log N) vs O(sqrt N)).", "B. Square root decomposition is always faster.", "C. They have similar complexity.", "D. Square root decomposition uses less memory.", "A"
"SegmentTree", "What is the conceptual 'root' of a SegmentTree?", "A. The first element of the array.", "B. A node representing the entire range of the original array.", "C. The smallest element in the array.", "D. A placeholder node.", "B"
"SegmentTree", "If a range query is [ql, qr] and a node covers [nl, nr]. What happens if there's a partial overlap (e.g., nl < ql < nr)?", "A. The node's value is returned directly.", "B. The node is skipped.", "C. The query recurses into both children, and their results are combined.", "D. The query stops.", "C"
"SegmentTree", "What is the fundamental principle that allows SegmentTrees to work efficiently for range operations?", "A. Data compression.", "B. Divide and Conquer.", "C. Hashing.", "D. Graph traversal.", "B"
"FenwickTree", "What is another common name for a Fenwick Tree?", "A. Segment Tree", "B. AVL Tree", "C. Binary Indexed Tree (BIT)", "D. Red-Black Tree", "C"
"FenwickTree", "What are the primary operations that a Fenwick Tree efficiently supports?", "A. Range queries (sum, min, max) and range updates.", "B. Point updates and prefix sum queries.", "C. Insertion and deletion of arbitrary elements.", "D. Finding shortest paths in a graph.", "B"
"FenwickTree", "What is the time complexity of building a Fenwick Tree from an array of `N` elements (initializing to zero then N point updates)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "D"
"FenwickTree", "What is the time complexity of performing a prefix sum query (sum from index 1 to `i`) on a Fenwick Tree with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"FenwickTree", "What is the time complexity of performing a point update (changing a single element's value) on a Fenwick Tree with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"FenwickTree", "What is the space complexity of a Fenwick Tree built on an array of `N` elements?", "A. O(N)", "B. O(log N)", "C. O(N log N)", "D. O(N^2)", "A"
"FenwickTree", "How does a Fenwick Tree represent the array it operates on?", "A. As a complete binary tree where each node stores a range sum.", "B. As an array where each index stores the sum of a specific range, based on binary representation.", "C. As a linked list.", "D. As a hash table.", "B"
"FenwickTree", "Which binary operation is crucial to navigating a Fenwick Tree?", "A. Bitwise AND (&)", "B. Bitwise OR (|)", "C. Bitwise XOR (^)", "D. Bitwise NOT (~)", "A"
"FenwickTree", "To find the next parent node for an update operation in a Fenwick Tree, you add `val & (-val)` to the current index. What does `val & (-val)` compute?", "A. The next power of 2.", "B. The smallest set bit (LSB) of `val`.", "C. The largest set bit of `val`.", "D. The index of the parent.", "B"
"FenwickTree", "To find the parent for a prefix sum query in a Fenwick Tree, you subtract `val & (-val)` from the current index. What does this operation achieve?", "A. It moves to the next greater index.", "B. It effectively removes the LSB, moving to an ancestor node that covers a smaller range.", "C. It moves to a sibling node.", "D. It moves to a child node.", "B"
"FenwickTree", "Can a Fenwick Tree directly find the sum of an arbitrary range `[L, R]`?", "A. No, it only supports prefix sums.", "B. Yes, by computing `prefix_sum(R) - prefix_sum(L-1)`.", "C. Yes, but it requires O(N) time.", "D. Only if L is 1.", "B"
"FenwickTree", "When would you prefer a Fenwick Tree over a Segment Tree?", "A. When dealing with complex range updates and queries (e.g., range min/max).", "B. For simple point updates and prefix sum (or similar associative) queries, due to simpler implementation and smaller constant factors.", "C. When the array is dynamic.", "D. When memory is extremely limited (Fenwick Tree uses more).", "B"
"FenwickTree", "Can a Fenwick Tree be used for range updates and point queries?", "A. No, not directly.", "B. Yes, by using a difference array and performing two Fenwick Tree updates for a range update.", "C. Only if the array is sorted.", "D. Only for positive values.", "B"
"FenwickTree", "What is the range that an element at index `i` (1-indexed) in a Fenwick Tree array represents?", "A. `[1, i]`", "B. `[i - (i & -i) + 1, i]`", "C. `[i, N]`", "D. `[i, i + (i & -i) - 1]`", "B"
"FenwickTree", "Why is Fenwick Tree typically 1-indexed?", "A. To simplify the bitwise operations (`i & -i`).", "B. It's an arbitrary convention.", "C. To save memory.", "D. To align with 0-indexed arrays.", "A"
"FenwickTree", "Can a Fenwick Tree directly handle operations like finding the minimum or maximum in a range?", "A. Yes, all associative operations work directly.", "B. No, `min` and `max` operations are not easily invertible, making them unsuitable for the standard Fenwick Tree structure.", "C. Only if the values are positive.", "D. Only with lazy propagation.", "B"
"FenwickTree", "What is the core idea behind how a Fenwick Tree efficiently computes sums?", "A. It stores every possible range sum.", "B. Each element stores the sum of its immediate children.", "C. Each element stores the sum of a power-of-2 sized contiguous block ending at that index.", "D. It uses a hash map for sums.", "C"
"FenwickTree", "How does a Fenwick Tree handle negative numbers in the array?", "A. It cannot handle negative numbers.", "B. It handles them correctly, as sum operations are additive.", "C. It requires a transformation.", "D. It converts them to positive values.", "B"
"FenwickTree", "What is the primary disadvantage of a Fenwick Tree compared to a Segment Tree for certain problems?", "A. Slower point updates.", "B. Less flexibility for complex range queries (e.g., range min/max, or operations not easily invertible).", "C. Higher memory usage.", "D. More complex implementation.", "B"
"FenwickTree", "Is a Fenwick Tree a Binary Search Tree?", "A. Yes, always.", "B. No, it's an array-based data structure that leverages bitwise operations.", "C. Only if the array is sorted.", "D. Only for specific data types.", "B"
"FenwickTree", "What is the total number of nodes (array elements) required for a Fenwick Tree on an array of size `N`?", "A. `N`", "B. `N+1` (for 1-indexing)", "C. `2N`", "D. `N log N`", "B"
"FenwickTree", "If you want to support range updates and range queries with a Fenwick Tree, how many BITs would you typically use?", "A. One.", "B. Two (one for original values, one for differences).", "C. Three.", "D. It's not possible.", "B"
"FenwickTree", "Which bitwise operation is used to find the parent for a `get_sum` operation by `i -= i & -i`?", "A. AND", "B. OR", "C. XOR", "D. NOT", "A"
"FenwickTree", "Which bitwise operation is used to find the next element to update for an `update` operation by `i += i & -i`?", "A. AND", "B. OR", "C. XOR", "D. NOT", "A"
"FenwickTree", "Can a Fenwick Tree be used for 2D arrays?", "A. No, only 1D arrays.", "B. Yes, by using a 2D Fenwick Tree where each element represents a 2D range.", "C. Only for square matrices.", "D. Only if the matrix is sparse.", "B"
"FenwickTree", "What is `i & -i` equivalent to in decimal?", "A. `i % 2`", "B. `i / 2`", "C. The lowest set bit (LSB) of `i`.", "D. The highest set bit of `i`.", "C"
"FenwickTree", "For an index `i=12` (binary `1100`), what is `i & -i`?", "A. 0 (binary `0000`)", "B. 4 (binary `0100`)", "C. 8 (binary `1000`)", "D. 12 (binary `1100`)", "B"
"FenwickTree", "What does a `get_sum(idx)` function typically do in a Fenwick Tree?", "A. Returns the value at `idx`.", "B. Returns the sum of elements from index 1 to `idx`.", "C. Returns the sum of all elements in the tree.", "D. Returns the value of the root.", "B"
"FenwickTree", "What does an `update(idx, delta)` function typically do in a Fenwick Tree?", "A. Sets the value at `idx` to `delta`.", "B. Adds `delta` to the value at `idx` and updates relevant ancestor sums.", "C. Subtracts `delta` from `idx`.", "D. Rebuilds the tree.", "B"
"FenwickTree", "If we need to perform range updates (add X to `[L, R]`) and point queries (get value at `i`), how can a Fenwick Tree be adapted?", "A. It cannot be done.", "B. By using two Fenwick Trees and a difference array approach.", "C. By changing the bitwise operations.", "D. By adding lazy propagation.", "B"
"FenwickTree", "What is the minimum index (typically) used in a Fenwick Tree array?", "A. 0", "B. 1", "C. -1", "D. Any non-negative integer.", "B"
"FenwickTree", "Consider a Fenwick Tree for sums. If `tree[i]` stores the sum of elements in `[i - (i & -i) + 1, i]`. For `i=8` (binary `1000`), what range does `tree[8]` cover?", "A. `[1, 8]`", "B. `[8, 8]`", "C. `[1, 7]`", "D. `[5, 8]`", "A"
"FenwickTree", "Consider a Fenwick Tree for sums. For `i=6` (binary `0110`), what range does `tree[6]` cover?", "A. `[1, 6]`", "B. `[5, 6]`", "C. `[6, 6]`", "D. `[1, 5]`", "B"
"FenwickTree", "The maximum value an index can take in a Fenwick Tree is `N`. What is the maximum height of the implicit tree for queries/updates?", "A. `N`", "B. `log2(N)`", "C. `N * log N`", "D. `sqrt(N)`", "B"
"FenwickTree", "If a Fenwick Tree is built on an array where all elements are positive, can `get_sum(i)` ever return a negative value?", "A. Yes, if there are underflows.", "B. No, the sum of positive numbers is always positive.", "C. Only if updates are negative.", "D. Only if the array is very large.", "B"
"FenwickTree", "Is Fenwick Tree generally easier to implement than Segment Tree?", "A. Yes, due to simpler recurrence relations and bitwise operations.", "B. No, Segment Tree is simpler.", "C. They are equally complex.", "D. Depends on the programming language.", "A"
"FenwickTree", "Which problem can be solved efficiently by a Fenwick Tree by converting it into a prefix sum problem?", "A. Finding the product of elements in a range.", "B. Finding the XOR sum of elements in a range.", "C. Finding the number of inversions in an array.", "D. Finding the median of an array.", "C"
"FenwickTree", "What is the main characteristic that makes a Fenwick Tree suitable for range sum queries?", "A. Its ability to store elements in sorted order.", "B. Its hierarchical decomposition of ranges based on binary representation.", "C. Its use of hashing.", "D. Its fixed height.", "B"
"FenwickTree", "If an array has `N` elements, what is the size of the Fenwick Tree array required for 1-indexing?", "A. N", "B. N-1", "C. N+1", "D. 2N", "C"
"FenwickTree", "Does a Fenwick Tree implicitly store the original array values?", "A. Yes, directly.", "B. No, it stores sums of ranges; the original values can be derived but are not explicitly stored.", "C. Only at leaf nodes.", "D. Only at the root node.", "B"
"FenwickTree", "To find the value of a single element `arr[i]` from a Fenwick Tree (that only supports prefix sums), how can it be calculated?", "A. `get_sum(i)`", "B. `get_sum(i) - get_sum(i-1)`", "C. `get_sum(i) + get_sum(i-1)`", "D. It cannot be calculated.", "B"
"FenwickTree", "For what kind of values can Fenwick Trees be used?", "A. Only positive integers.", "B. Only non-negative integers.", "C. Any numerical values (integers, floats) as long as the operation is associative and has an identity.", "D. Only binary values.", "C"
"FenwickTree", "What is the key insight behind using `i & -i` for Fenwick Tree navigation?", "A. It provides a random access to any element.", "B. It isolates the lowest set bit, which corresponds to the size of the range the node represents.", "C. It quickly computes the sum of the entire array.", "D. It helps in balancing the tree.", "B"
"FenwickTree", "Can a Fenwick Tree be used to count frequencies of elements in a range?", "A. No, it's only for sums.", "B. Yes, by treating element values as indices and incrementing counts at those indices.", "C. Only if the elements are sorted.", "D. Only for binary elements.", "B"
"FenwickTree", "If `N` is a power of 2, does it simplify Fenwick Tree operations significantly?", "A. Yes, operations become O(1).", "B. No, the O(log N) complexity remains due to the nature of bitwise operations.", "C. Only for updates.", "D. Only for queries.", "B"
"FenwickTree", "What is the typical starting point for implementing a Fenwick Tree (index-wise)?", "A. A 0-indexed array.", "B. A 1-indexed array.", "C. A 2-indexed array.", "D. A hash table.", "B"
"FenwickTree", "What is a 'persistent Fenwick Tree'?", "A. A Fenwick Tree stored on disk.", "B. A Fenwick Tree that allows querying previous states of the array efficiently.", "C. A Fenwick Tree that never gets cleared.", "D. A Fenwick Tree that is always balanced.", "B"
"FenwickTree", "How does a persistent Fenwick Tree work conceptually?", "A. It clones the entire tree for each update.", "B. It makes new nodes only for the modified path and reuses unchanged parts.", "C. It uses a difference array to store changes.", "D. It builds a new tree from scratch for each query.", "B"
"FenwickTree", "When dealing with range updates and point queries using a difference array with Fenwick Trees, how many Fenwick Tree lookups are needed for a point query?", "A. One.", "B. Two.", "C. Three.", "D. Depends on the range.", "B"
"Heaps", "What is the primary characteristic of a Heap data structure?", "A. It is always a sorted list.", "B. It is a complete binary tree that satisfies the heap property.", "C. It is a general tree with no specific order.", "D. It is a graph with weighted edges.", "B"
"Heaps", "What are the two main types of Heaps?", "A. AVL Heap and Red-Black Heap", "B. Min-Heap and Max-Heap", "C. Binary Heap and Ternary Heap", "D. Fixed Heap and Dynamic Heap", "B"
"Heaps", "In a Max-Heap, what is the relationship between a parent node and its children?", "A. Parent is less than or equal to its children.", "B. Parent is greater than or equal to its children.", "C. Parent is always equal to its children.", "D. There is no specific relationship.", "B"
"Heaps", "In a Min-Heap, what is the relationship between a parent node and its children?", "A. Parent is less than or equal to its children.", "B. Parent is greater than or equal to its children.", "C. Parent is always equal to its children.", "D. There is no specific relationship.", "A"
"Heaps", "Where is the largest element always located in a Max-Heap?", "A. At any leaf node.", "B. At the root node.", "C. At the leftmost child.", "D. At the rightmost child.", "B"
"Heaps", "Where is the smallest element always located in a Min-Heap?", "A. At any leaf node.", "B. At the root node.", "C. At the leftmost child.", "D. At the rightmost child.", "B"
"Heaps", "What kind of binary tree is a Heap guaranteed to be?", "A. Full Binary Tree", "B. Perfect Binary Tree", "C. Complete Binary Tree", "D. Skewed Binary Tree", "C"
"Heaps", "Heaps are typically implemented using which underlying data structure?", "A. Linked List", "B. Array", "C. Stack", "D. Queue", "B"
"Heaps", "If a Heap is implemented using a 1-indexed array, and a node is at index `i`, what are the indices of its left and right children?", "A. Left: `2*i`, Right: `2*i+1`", "B. Left: `2*i+1`, Right: `2*i+2`", "C. Left: `i-1`, Right: `i+1`", "D. Left: `i/2`, Right: `i/2 + 1`", "A"
"Heaps", "If a Heap is implemented using a 1-indexed array, and a node is at index `i`, what is the index of its parent?", "A. `2*i`", "B. `(i-1)/2`", "C. `i/2` (integer division)", "D. `i-1`", "C"
"Heaps", "What is the time complexity to insert an element into a Heap with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"Heaps", "What is the time complexity to delete the maximum/minimum element from a Heap with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"Heaps", "What is the time complexity to build a Heap from an unsorted array of `N` elements?", "A. O(N log N)", "B. O(N)", "C. O(log N)", "D. O(N^2)", "B"
"Heaps", "What operation is performed after inserting a new element at the end of a Heap array to restore the heap property?", "A. Heapify-down (or sink)", "B. Heapify-up (or swim/bubble-up)", "C. Rebuild the entire heap", "D. Rotate", "B"
"Heaps", "What operation is performed after deleting the root element and replacing it with the last element in a Heap array to restore the heap property?", "A. Heapify-down (or sink)", "B. Heapify-up (or swim/bubble-up)", "C. Rebuild the entire heap", "D. Rotate", "A"
"Heaps", "What is the space complexity of a Heap with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"Heaps", "What is 'Heap Sort' primarily based on?", "A. Merge Sort", "B. Quick Sort", "C. The properties of a Heap data structure for efficient sorting.", "D. Bubble Sort", "C"
"Heaps", "What is the time complexity of Heap Sort for `N` elements in the worst case?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(log N)", "B"
"Heaps", "Is Heap Sort an in-place sorting algorithm?", "A. No, it requires O(N) auxiliary space.", "B. Yes, it sorts the array without significant extra space.", "C. Only for small arrays.", "D. Depends on the implementation.", "B"
"Heaps", "Which data structure is best suited for implementing a 'Priority Queue'?", "A. Stack", "B. Queue", "C. Hash Table", "D. Heap", "D"
"Heaps", "In a Priority Queue implemented with a Max-Heap, which element has the highest priority?", "A. The smallest element.", "B. The largest element.", "C. The element inserted first.", "D. The element inserted last.", "B"
"Heaps", "In a Priority Queue implemented with a Min-Heap, which element has the highest priority?", "A. The smallest element.", "B. The largest element.", "C. The element inserted first.", "D. The element inserted last.", "A"
"Heaps", "What is the primary operation of a Priority Queue that corresponds to deleting the root of a Heap?", "A. `enqueue()`", "B. `dequeue()` (or `extract_min/max`)", "C. `peek()`", "D. `isEmpty()`", "B"
"Heaps", "What is the primary operation of a Priority Queue that corresponds to inserting an element into a Heap?", "A. `enqueue()` (or `insert`)", "B. `dequeue()`", "C. `peek()`", "D. `isEmpty()`", "A"
"Heaps", "Can a Heap be used to find an arbitrary element (not min/max) efficiently?", "A. Yes, in O(log N) time.", "B. No, searching for an arbitrary element is O(N) in a heap.", "C. Only if the heap is sorted.", "D. Only if the element is at a leaf node.", "B"
"Heaps", "Is a Heap a Binary Search Tree (BST)?", "A. Yes, always.", "B. No, a Heap only guarantees the heap property, not sorted order across subtrees (left < parent < right).", "C. Only if it's a Min-Heap.", "D. Only if it's a Max-Heap.", "B"
"Heaps", "What is the height of a Heap with `N` elements?", "A. O(N)", "B. O(log N)", "C. O(N log N)", "D. O(1)", "B"
"Heaps", "When performing Heap Sort, after the heap is built, what happens in the second phase?", "A. Elements are inserted one by one into a new array.", "B. The maximum (or minimum) element is repeatedly extracted and placed at the end (or beginning) of the array, shrinking the heap.", "C. The heap is recursively split into two halves.", "D. Elements are swapped randomly.", "B"
"Heaps", "What is the use of `heapify` (or `sift-down`) function in building a heap from an array?", "A. To insert a single element.", "B. To restore the heap property from a given node downwards.", "C. To extract the root element.", "D. To sort the array.", "B"
"Heaps", "Which algorithm is used for finding the `k` largest (or smallest) elements from a large dataset, efficiently using a Heap?", "A. Quickselect", "B. Median-of-Medians", "C. Heap-based selection algorithm (e.g., using a min-heap for largest K, or max-heap for smallest K).", "D. Radix Sort", "C"
"Heaps", "What property ensures that a heap can be efficiently stored in an array without wasting space?", "A. The heap property.", "B. Its complete binary tree property.", "C. All nodes have two children.", "D. It is always sorted.", "B"
"Heaps", "What is the time complexity to peek at the maximum/minimum element of a Heap?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "A"
"Heaps", "Can a heap contain duplicate values?", "A. No, all values must be unique.", "B. Yes, heaps can typically handle duplicate values.", "C. Only in a Max-Heap.", "D. Only in a Min-Heap.", "B"
"Heaps", "What happens to the elements after Heap Sort is completed (if sorting in ascending order using a Max-Heap)?", "A. The largest elements are at the beginning of the array.", "B. The array is sorted in ascending order.", "C. The array is sorted in descending order.", "D. The array remains unsorted.", "B"
"Heaps", "What happens to the elements after Heap Sort is completed (if sorting in descending order using a Min-Heap)?", "A. The smallest elements are at the beginning of the array.", "B. The array is sorted in ascending order.", "C. The array is sorted in descending order.", "D. The array remains unsorted.", "C"
"Heaps", "When would you prefer a Heap over a Binary Search Tree for representing a priority queue?", "A. When searching for arbitrary elements frequently.", "B. When insertions and deletions are primarily at the highest/lowest priority, and order of other elements doesn't matter.", "C. When all elements must be kept sorted at all times.", "D. When memory is very limited (Heap uses more).", "B"
"Heaps", "What is a 'Fibonacci Heap'?", "A. A more relaxed type of heap, optimized for specific graph algorithms, with better asymptotic worst-case performance for some operations than binary heaps.", "B. A heap where elements are Fibonacci numbers.", "C. A heap that is always perfectly balanced.", "D. A heap for very small N.", "A"
"Heaps", "What is the main advantage of a Binary Heap over a Red-Black Tree for a pure priority queue?", "A. Faster build time (O(N) vs O(N log N)).", "B. Faster arbitrary element deletion.", "C. Guaranteed O(log N) worst-case time for all operations.", "D. Easier implementation for complex operations.", "A"
"Heaps", "What is the primary disadvantage of using a simple array as a heap implementation (compared to a linked node structure for a binary tree)?", "A. More complex index calculations.", "B. Fixed size, making dynamic resizing challenging or inefficient.", "C. Faster access times.", "D. Cannot handle duplicate elements.", "B"
"Heaps", "What is the largest possible number of children a node can have in a standard Binary Heap?", "A. 0", "B. 1", "C. 2", "D. Any number", "C"
"Heaps", "If a node `i` has a value `X` in a Max-Heap, and its parent is `P`, what can be said about `P`'s value?", "A. `P < X`", "B. `P > X`", "C. `P >= X`", "D. `P <= X`", "C"
"Heaps", "What is the first step in the `heapify` (building a heap) process from an unsorted array?", "A. Start from the root and go downwards.", "B. Start from the first non-leaf node and go upwards to the root.", "C. Start from the last leaf node and go upwards.", "D. Sort the array first.", "B"
"Heaps", "When does a 'min-heapify' operation stop?", "A. When the element is larger than both its children.", "B. When the element is smaller than its smallest child or it becomes a leaf.", "C. When the root is reached.", "D. When all elements are sorted.", "B"
"Heaps", "What is the fundamental difference between `heapify-up` and `heapify-down`?", "A. `heapify-up` moves an element towards the root; `heapify-down` moves it towards a leaf.", "B. `heapify-up` is for insertion; `heapify-down` is for deletion.", "C. They are the same operation, just called differently.", "D. `heapify-up` works with max-heaps; `heapify-down` with min-heaps.", "A"
"Heaps", "Which graph algorithm commonly uses a Min-Priority Queue (implemented with a Heap)?", "A. Breadth-First Search (BFS)", "B. Depth-First Search (DFS)", "C. Dijkstra's Shortest Path Algorithm or Prim's Minimum Spanning Tree Algorithm.", "D. Topological Sort", "C"
"Heaps", "If you have a Max-Heap and you want to implement `decrease-key` operation, how would you typically do it?", "A. Decrease the key, then perform `heapify-down`.", "B. Decrease the key, then perform `heapify-up`.", "C. Remove the element, then re-insert it.", "D. It's not supported.", "A"
"Heaps", "If you have a Min-Heap and you want to implement `increase-key` operation, how would you typically do it?", "A. Increase the key, then perform `heapify-down`.", "B. Increase the key, then perform `heapify-up`.", "C. Remove the element, then re-insert it.", "D. It's not supported.", "A"
"Heaps", "The elements in a Heap are partially ordered. What does 'partially ordered' mean in this context?", "A. All elements are sorted.", "B. Only the root is ordered relative to its children.", "C. There is a specific relationship between parent and child, but no specific order between siblings or elements at different branches (other than ancestors/descendants).", "D. Elements are ordered randomly.", "C"
"Heaps", "What is the time complexity of building a heap from an array by repeatedly inserting elements (using `insert` operation)?", "A. O(N)", "B. O(N log N)", "C. O(log N)", "D. O(N^2)", "B"
"Heaps", "What is the maximum number of nodes at level `k` (root at level 0) in a complete binary tree of height `h`?", "A. 2^k", "B. 2^h", "C. 2k", "D. k+1", "A"
"MinHeap", "What is the fundamental property of a MinHeap?", "A. Every node's value is greater than or equal to its children's values.", "B. Every node's value is less than or equal to its children's values.", "C. All leaf nodes are at the same level.", "D. It is always a perfectly balanced tree.", "B"
"MinHeap", "Where is the smallest element always located in a MinHeap?", "A. At any leaf node.", "B. At the root node.", "C. At the leftmost child.", "D. At the rightmost child.", "B"
"MinHeap", "What kind of binary tree structure does a MinHeap maintain?", "A. Full Binary Tree", "B. Perfect Binary Tree", "C. Complete Binary Tree", "D. Skewed Binary Tree", "C"
"MinHeap", "MinHeaps are typically implemented using which underlying data structure?", "A. Linked List", "B. Array", "C. Stack", "D. Queue", "B"
"MinHeap", "If a MinHeap is implemented using a 1-indexed array, and a node is at index `i`, what is the index of its parent?", "A. `2*i`", "B. `(i-1)/2`", "C. `i/2` (integer division)", "D. `i-1`", "C"
"MinHeap", "What is the time complexity to insert an element into a MinHeap with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"MinHeap", "What is the time complexity to delete the minimum element (root) from a MinHeap with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"MinHeap", "What operation is performed after inserting a new element at the end of a MinHeap array to restore the heap property?", "A. `min-heapify-down` (or sink)", "B. `min-heapify-up` (or swim/bubble-up)", "C. Rebuild the entire heap", "D. Rotate", "B"
"MinHeap", "What operation is performed after deleting the root element (minimum) and replacing it with the last element in a MinHeap array to restore the heap property?", "A. `min-heapify-down` (or sink)", "B. `min-heapify-up` (or swim/bubble-up)", "C. Rebuild the entire heap", "D. Rotate", "A"
"MinHeap", "What is the time complexity to build a MinHeap from an unsorted array of `N` elements?", "A. O(N log N)", "B. O(N)", "C. O(log N)", "D. O(N^2)", "B"
"MinHeap", "Which common data structure is often implemented using a MinHeap?", "A. Stack", "B. Queue", "C. Priority Queue", "D. Hash Map", "C"
"MinHeap", "In a Priority Queue implemented with a MinHeap, which element has the highest priority?", "A. The smallest element.", "B. The largest element.", "C. The element inserted first.", "D. The element inserted last.", "A"
"MinHeap", "Can a MinHeap be used to find an arbitrary element (not minimum) efficiently?", "A. Yes, in O(log N) time.", "B. No, searching for an arbitrary element is O(N) in a heap.", "C. Only if the heap is sorted.", "D. Only if the element is at a leaf node.", "B"
"MinHeap", "Is a MinHeap a Binary Search Tree (BST)?", "A. Yes, always.", "B. No, a MinHeap only guarantees the heap property (parent <= children), not sorted order across subtrees (left < parent < right).", "C. Only if it's perfectly balanced.", "D. Only for specific data types.", "B"
"MinHeap", "What is the height of a MinHeap with `N` elements?", "A. O(N)", "B. O(log N)", "C. O(N log N)", "D. O(1)", "B"
"MinHeap", "What is the time complexity to peek at the minimum element of a MinHeap?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "A"
"MinHeap", "Can a MinHeap contain duplicate values?", "A. No, all values must be unique.", "B. Yes, MinHeaps can typically handle duplicate values.", "C. Only for specific integer types.", "D. Only at the root.", "B"
"MinHeap", "When performing `min-heapify-down`, an element is compared with which of its children?", "A. Only its left child.", "B. Only its right child.", "C. Its smaller child.", "D. Its larger child.", "C"
"MinHeap", "Which graph algorithm commonly uses a Min-Priority Queue (implemented with a MinHeap) for finding shortest paths?", "A. Breadth-First Search (BFS)", "B. Depth-First Search (DFS)", "C. Dijkstra's Shortest Path Algorithm", "D. Kruskal's Algorithm", "C"
"MinHeap", "Which algorithm for finding Minimum Spanning Tree commonly uses a Min-Priority Queue (implemented with a MinHeap)?", "A. Prim's Algorithm", "B. Kruskal's Algorithm", "C. Bellman-Ford Algorithm", "D. Floyd-Warshall Algorithm", "A"
"MinHeap", "What is the role of `decrease-key` operation (making a key smaller) in a MinHeap, and how is it typically handled?", "A. Decrease key, then `min-heapify-down`.", "B. Decrease key, then `min-heapify-up`.", "C. Remove element, then re-insert.", "D. Not supported efficiently.", "B"
"MinHeap", "What is the role of `increase-key` operation (making a key larger) in a MinHeap, and how is it typically handled?", "A. Increase key, then `min-heapify-down`.", "B. Increase key, then `min-heapify-up`.", "C. Remove element, then re-insert.", "D. Not supported efficiently.", "A"
"MinHeap", "In an array-based MinHeap, what is the smallest index a child node can have for a parent at index `i` (1-indexed)?", "A. `i+1`", "B. `2*i`", "C. `i/2`", "D. `2*i+1`", "B"
"MinHeap", "If a MinHeap has `N` elements, and is stored in a 0-indexed array, what are the children of node at index `i`?", "A. Left: `2*i`, Right: `2*i+1`", "B. Left: `2*i+1`, Right: `2*i+2`", "C. Left: `(i-1)/2`, Right: `(i+1)/2`", "D. Left: `i-1`, Right: `i+1`", "B"
"MinHeap", "The MinHeap property `Parent <= Children` implies that the smallest element is at the root. What does this mean for other elements?", "A. They are completely unsorted.", "B. Elements are sorted within each level.", "C. There is a partial ordering, but not a full sorted order.", "D. All elements are larger than their children.", "C"
"MinHeap", "What happens to the structure of a MinHeap if elements are inserted in strictly increasing order?", "A. It becomes a perfectly balanced tree.", "B. It effectively forms a linked list-like structure (degenerate tree).", "C. It remains a valid MinHeap, but the `heapify-up` operations will be minimal.", "D. It becomes a MaxHeap.", "C"
"MinHeap", "What is the primary advantage of a MinHeap over a sorted array for a priority queue that frequently adds/removes minimum elements?", "A. Faster access to arbitrary elements.", "B. Logarithmic time for insertions and deletions vs. linear time for a sorted array.", "C. Less memory usage.", "D. Simpler implementation.", "B"
"MinHeap", "When extracting the minimum element from a MinHeap, what is the first step?", "A. Recursively search for the smallest element.", "B. Swap the root with the last element in the heap array.", "C. Delete the root directly.", "D. Rebuild the entire heap.", "B"
"MinHeap", "After swapping the root with the last element during extraction, what is the next step?", "A. Re-insert the new root at the end.", "B. Remove the old root (which is now at the end).", "C. Perform `min-heapify-up` on the new root.", "D. Perform `min-heapify-down` on the new root.", "D"
"MinHeap", "Which common algorithm uses a MinHeap to efficiently connect all vertices in a graph with the minimum total edge weight?", "A. Dijkstra's Algorithm", "B. Prim's Algorithm (for MST)", "C. Kruskal's Algorithm (uses a Union-Find structure, but edges are often processed from a MinHeap/priority queue)", "D. Bellman-Ford Algorithm", "B"
"MinHeap", "If a node `i` in a MinHeap has a value `X`, and its child is `C`, what can be said about `C`'s value?", "A. `C < X`", "B. `C > X`", "C. `C >= X`", "D. `C <= X`", "C"
"MinHeap", "Can a MinHeap be used to implement a max-priority queue (where largest elements have highest priority)?", "A. Yes, by negating all values.", "B. No, a MinHeap can only manage minimums.", "C. Only with significant modifications.", "D. Only for specific data types.", "A"
"MinHeap", "What is the maximum number of children any node can have in a standard MinHeap?", "A. 0", "B. 1", "C. 2", "D. Any number", "C"
"MinHeap", "When does a `min-heapify-down` operation stop?", "A. When the element is larger than both its children.", "B. When the element is smaller than its smallest child or it becomes a leaf node.", "C. When the root is reached.", "D. When all elements are sorted.", "B"
"MinHeap", "What is the primary difference between `min-heapify-up` and `min-heapify-down`?", "A. `min-heapify-up` moves an element towards the root; `min-heapify-down` moves it towards a leaf.", "B. `min-heapify-up` is for deletion; `min-heapify-down` is for insertion.", "C. They are the same operation, just called differently.", "D. `min-heapify-up` works with max-heaps; `min-heapify-down` with min-heaps.", "A"
"MinHeap", "Which sorting algorithm leverages the MinHeap property?", "A. Quick Sort (if smallest elements are extracted repeatedly and placed at the end for descending sort)", "B. Merge Sort", "C. Bubble Sort", "D. Insertion Sort", "A"
"MinHeap", "Consider a MinHeap stored in an array: `[10, 20, 30, 40, 50, 60]`. If `15` is inserted, where would it initially be placed before `heapify-up`?", "A. Index 1 (root)", "B. Index 7 (end of array)", "C. Index 3", "D. Index 0", "B"
"MinHeap", "After inserting `15` into `[10, 20, 30, 40, 50, 60]` and performing `heapify-up`, what would the new MinHeap root be?", "A. 10", "B. 15", "C. 20", "D. 30", "A"
"MinHeap", "If a MinHeap's array is `[5, 10, 15, 20, 25]`, and the minimum (5) is extracted, what is the *first* array state after swapping the root with the last element?", "A. `[25, 10, 15, 20]` (5 is removed)", "B. `[10, 5, 15, 20, 25]`", "C. `[5, 25, 10, 15, 20]`", "D. `[10, 15, 20, 25]`", "A"
"MinHeap", "After extracting the minimum (5) from `[5, 10, 15, 20, 25]` and performing `min-heapify-down`, what would the new MinHeap root be?", "A. 10", "B. 15", "C. 20", "D. 25", "A"
"MinHeap", "What is the typical use case for a MinHeap in operating systems?", "A. Scheduling CPU processes based on shortest remaining time.", "B. Managing memory allocation.", "C. Handling file system access.", "D. Network routing.", "A"
"MinHeap", "Does a MinHeap support finding the `k`-th smallest element efficiently (without rebuilding the heap)?", "A. Yes, in O(log N) time.", "B. No, finding the k-th smallest typically requires O(K log N) or O(N) using other techniques.", "C. Only if k=1.", "D. Only if k=N.", "B"
"MinHeap", "What is the role of 'sentinel' or 'dummy' nodes in some MinHeap implementations?", "A. To store additional data.", "B. To simplify array indexing and avoid out-of-bounds checks for children/parents.", "C. To mark the end of the heap.", "D. To indicate an empty heap.", "B"
"MinHeap", "When constructing a MinHeap by repeated insertions, what is the overall time complexity?", "A. O(N)", "B. O(N log N)", "C. O(log N)", "D. O(N^2)", "B"
"MinHeap", "If a MinHeap has 7 nodes, what is its maximum height (root at height 0)?", "A. 1", "B. 2", "C. 3", "D. 7", "B"
"MinHeap", "If a MinHeap has 8 nodes, what is its maximum height (root at height 0)?", "A. 1", "B. 2", "C. 3", "D. 8", "C"
"MinHeap", "Which property is crucial for the efficient array representation of a MinHeap?", "A. The values are sorted.", "B. It is a complete binary tree.", "C. All nodes have two children.", "D. The root is always the smallest.", "B"
"MinHeap", "For a MinHeap stored in a 0-indexed array, what is the parent of a node at index `i` (excluding the root)?", "A. `2*i+1`", "B. `(i-1)/2` (integer division)", "C. `i/2`", "D. `i-1`", "B"
"MinHeap", "What is the standard approach for initializing a MinHeap with existing elements in linear time?", "A. Insert elements one by one using `heapify-up`.", "B. Call `min-heapify-down` on nodes from the last non-leaf node up to the root.", "C. Sort the array first.", "D. Use a recursive build function from the root.", "B"
"MaxHeap", "What is the fundamental property of a MaxHeap?", "A. Every node's value is less than or equal to its children's values.", "B. Every node's value is greater than or equal to its children's values.", "C. All leaf nodes are at the same level.", "D. It is always a perfectly balanced tree.", "B"
"MaxHeap", "Where is the largest element always located in a MaxHeap?", "A. At any leaf node.", "B. At the root node.", "C. At the leftmost child.", "D. At the rightmost child.", "B"
"MaxHeap", "What kind of binary tree structure does a MaxHeap maintain?", "A. Full Binary Tree", "B. Perfect Binary Tree", "C. Complete Binary Tree", "D. Skewed Binary Tree", "C"
"MaxHeap", "MaxHeaps are typically implemented using which underlying data structure?", "A. Linked List", "B. Array", "C. Stack", "D. Queue", "B"
"MaxHeap", "If a MaxHeap is implemented using a 1-indexed array, and a node is at index `i`, what is the index of its parent?", "A. `2*i`", "B. `(i-1)/2`", "C. `i/2` (integer division)", "D. `i-1`", "C"
"MaxHeap", "What is the time complexity to insert an element into a MaxHeap with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"MaxHeap", "What is the time complexity to delete the maximum element (root) from a MaxHeap with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"MaxHeap", "What operation is performed after inserting a new element at the end of a MaxHeap array to restore the heap property?", "A. `max-heapify-down` (or sink)", "B. `max-heapify-up` (or swim/bubble-up)", "C. Rebuild the entire heap", "D. Rotate", "B"
"MaxHeap", "What operation is performed after deleting the root element (maximum) and replacing it with the last element in a MaxHeap array to restore the heap property?", "A. `max-heapify-down` (or sink)", "B. `max-heapify-up` (or swim/bubble-up)", "C. Rebuild the entire heap", "D. Rotate", "A"
"MaxHeap", "What is the time complexity to build a MaxHeap from an unsorted array of `N` elements?", "A. O(N log N)", "B. O(N)", "C. O(log N)", "D. O(N^2)", "B"
"MaxHeap", "Which common data structure is often implemented using a MaxHeap?", "A. Stack", "B. Queue", "C. Priority Queue", "D. Hash Map", "C"
"MaxHeap", "In a Priority Queue implemented with a MaxHeap, which element has the highest priority?", "A. The smallest element.", "B. The largest element.", "C. The element inserted first.", "D. The element inserted last.", "B"
"MaxHeap", "Can a MaxHeap be used to find an arbitrary element (not maximum) efficiently?", "A. Yes, in O(log N) time.", "B. No, searching for an arbitrary element is O(N) in a heap.", "C. Only if the heap is sorted.", "D. Only if the element is at a leaf node.", "B"
"MaxHeap", "Is a MaxHeap a Binary Search Tree (BST)?", "A. Yes, always.", "B. No, a MaxHeap only guarantees the heap property (parent >= children), not sorted order across subtrees (left < parent < right).", "C. Only if it's perfectly balanced.", "D. Only for specific data types.", "B"
"MaxHeap", "What is the height of a MaxHeap with `N` elements?", "A. O(N)", "B. O(log N)", "C. O(N log N)", "D. O(1)", "B"
"MaxHeap", "What is the time complexity to peek at the maximum element of a MaxHeap?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "A"
"MaxHeap", "Can a MaxHeap contain duplicate values?", "A. No, all values must be unique.", "B. Yes, MaxHeaps can typically handle duplicate values.", "C. Only for specific integer types.", "D. Only at the root.", "B"
"MaxHeap", "When performing `max-heapify-down`, an element is compared with which of its children?", "A. Only its left child.", "B. Only its right child.", "C. Its smaller child.", "D. Its larger child.", "D"
"MaxHeap", "Which sorting algorithm's in-place version primarily uses a MaxHeap?", "A. Merge Sort", "B. Quick Sort", "C. Heap Sort", "D. Bubble Sort", "C"
"MaxHeap", "What is the role of `increase-key` operation (making a key larger) in a MaxHeap, and how is it typically handled?", "A. Increase key, then `max-heapify-down`.", "B. Increase key, then `max-heapify-up`.", "C. Remove element, then re-insert.", "D. Not supported efficiently.", "B"
"MaxHeap", "What is the role of `decrease-key` operation (making a key smaller) in a MaxHeap, and how is it typically handled?", "A. Decrease key, then `max-heapify-down`.", "B. Decrease key, then `max-heapify-up`.", "C. Remove element, then re-insert.", "D. Not supported efficiently.", "A"
"MaxHeap", "In an array-based MaxHeap, what is the largest index a child node can have for a parent at index `i` (1-indexed)?", "A. `i+1`", "B. `2*i`", "C. `i/2`", "D. `2*i+1`", "D"
"MaxHeap", "If a MaxHeap has `N` elements, and is stored in a 0-indexed array, what are the children of node at index `i`?", "A. Left: `2*i`, Right: `2*i+1`", "B. Left: `2*i+1`, Right: `2*i+2`", "C. Left: `(i-1)/2`, Right: `(i+1)/2`", "D. Left: `i-1`, Right: `i+1`", "B"
"MaxHeap", "The MaxHeap property `Parent >= Children` implies that the largest element is at the root. What does this mean for other elements?", "A. They are completely unsorted.", "B. Elements are sorted within each level.", "C. There is a partial ordering, but not a full sorted order.", "D. All elements are smaller than their children.", "C"
"MaxHeap", "What happens to the structure of a MaxHeap if elements are inserted in strictly decreasing order?", "A. It becomes a perfectly balanced tree.", "B. It remains a valid MaxHeap, but the `heapify-up` operations will be minimal.", "C. It effectively forms a linked list-like structure (degenerate tree).", "D. It becomes a MinHeap.", "B"
"MaxHeap", "When extracting the maximum element from a MaxHeap, what is the first step?", "A. Recursively search for the largest element.", "B. Swap the root with the last element in the heap array.", "C. Delete the root directly.", "D. Rebuild the entire heap.", "B"
"MaxHeap", "After swapping the root with the last element during extraction, what is the next step?", "A. Re-insert the new root at the end.", "B. Remove the old root (which is now at the end).", "C. Perform `max-heapify-up` on the new root.", "D. Perform `max-heapify-down` on the new root.", "D"
"MaxHeap", "Which common algorithm uses a MaxHeap to find the `k` largest elements in a stream of data?", "A. Quickselect", "B. Building a min-heap of size K, or a max-heap of size K and extracting the root.", "C. Merge sort", "D. Bubble sort", "B"
"MaxHeap", "What is the typical use case for a MaxHeap in operating systems?", "A. Scheduling tasks based on highest priority.", "B. Managing disk space.", "C. Handling network packets.", "D. Searching for files.", "A"
"MaxHeap", "Can a MaxHeap be used to implement a min-priority queue (where smallest elements have highest priority)?", "A. Yes, by negating all values.", "B. No, a MaxHeap can only manage maximums.", "C. Only with significant modifications.", "D. Only for specific data types.", "A"
"MaxHeap", "What is the maximum number of children any node can have in a standard MaxHeap?", "A. 0", "B. 1", "C. 2", "D. Any number", "C"
"MaxHeap", "When does a `max-heapify-down` operation stop?", "A. When the element is smaller than both its children.", "B. When the element is larger than its largest child or it becomes a leaf node.", "C. When the root is reached.", "D. When all elements are sorted.", "B"
"MaxHeap", "What is the primary difference between `max-heapify-up` and `max-heapify-down`?", "A. `max-heapify-up` moves an element towards the root; `max-heapify-down` moves it towards a leaf.", "B. `max-heapify-up` is for deletion; `max-heapify-down` is for insertion.", "C. They are the same operation, just called differently.", "D. `max-heapify-up` works with min-heaps; `max-heapify-down` with max-heaps.", "A"
"MaxHeap", "Which sorting algorithm, when implemented in-place, places the largest elements at the end of the array after each extraction?", "A. Merge Sort", "B. Quick Sort", "C. Heap Sort (using MaxHeap for ascending sort)", "D. Insertion Sort", "C"
"MaxHeap", "Consider a MaxHeap stored in an array: `[60, 50, 40, 30, 20, 10]`. If `55` is inserted, where would it initially be placed before `heapify-up`?", "A. Index 1 (root)", "B. Index 7 (end of array)", "C. Index 3", "D. Index 0", "B"
"MaxHeap", "After inserting `55` into `[60, 50, 40, 30, 20, 10]` and performing `heapify-up`, what would the new MaxHeap look like (conceptual array view)?", "A. `[60, 50, 55, 30, 20, 10, 40]`", "B. `[60, 55, 40, 30, 20, 10, 50]`", "C. `[60, 50, 40, 55, 20, 10, 30]`", "D. `[60, 50, 40, 30, 20, 10, 55]` (no changes)", "B"
"MaxHeap", "If a MaxHeap's array is `[100, 80, 90, 70, 60]`, and the maximum (100) is extracted, what is the *first* array state after swapping the root with the last element?", "A. `[60, 80, 90, 70]` (100 is removed)", "B. `[80, 100, 90, 70, 60]`", "C. `[100, 60, 80, 90, 70]`", "D. `[80, 90, 70, 60]`", "A"
"MaxHeap", "After extracting the maximum (100) from `[100, 80, 90, 70, 60]` and performing `max-heapify-down`, what would the new MaxHeap root be?", "A. 60", "B. 70", "C. 80", "D. 90", "D"
"MaxHeap", "Which data structure is typically used for implementing a 'median-of-stream' algorithm efficiently?", "A. Single MaxHeap.", "B. Single MinHeap.", "C. A combination of a MaxHeap and a MinHeap.", "D. A hash table.", "C"
"MaxHeap", "Does a MaxHeap support finding the `k`-th largest element efficiently (without rebuilding the heap)?", "A. Yes, in O(log N) time.", "B. No, finding the k-th largest typically requires O(K log N) or O(N) using other techniques.", "C. Only if k=1.", "D. Only if k=N.", "B"
"MaxHeap", "What is the role of 'sentinel' or 'dummy' nodes in some MaxHeap implementations?", "A. To store additional data.", "B. To simplify array indexing and avoid out-of-bounds checks for children/parents.", "C. To mark the end of the heap.", "D. To indicate an empty heap.", "B"
"MaxHeap", "When constructing a MaxHeap by repeated insertions, what is the overall time complexity?", "A. O(N)", "B. O(N log N)", "C. O(log N)", "D. O(N^2)", "B"
"MaxHeap", "If a MaxHeap has 7 nodes, what is its maximum height (root at height 0)?", "A. 1", "B. 2", "C. 3", "D. 7", "B"
"MaxHeap", "If a MaxHeap has 8 nodes, what is its maximum height (root at height 0)?", "A. 1", "B. 2", "C. 3", "D. 8", "C"
"MaxHeap", "Which property is crucial for the efficient array representation of a MaxHeap?", "A. The values are sorted.", "B. It is a complete binary tree.", "C. All nodes have two children.", "D. The root is always the largest.", "B"
"MaxHeap", "For a MaxHeap stored in a 0-indexed array, what is the parent of a node at index `i` (excluding the root)?", "A. `2*i+1`", "B. `(i-1)/2` (integer division)", "C. `i/2`", "D. `i-1`", "B"
"MaxHeap", "What is the standard approach for initializing a MaxHeap with existing elements in linear time?", "A. Insert elements one by one using `heapify-up`.", "B. Call `max-heapify-down` on nodes from the last non-leaf node up to the root.", "C. Sort the array first.", "D. Use a recursive build function from the root.", "B"
"Graphs", "Which of the following is NOT a common way to represent a graph?", "A. Adjacency Matrix", "B. Adjacency List", "C. Edge List", "D. Hash Table", "D"
"Graphs", "In an undirected graph with `V` vertices and `E` edges, what is the maximum number of edges?", "A. V-1", "B. V^2", "C. E-1", "D. V * (V-1) / 2", "D"
"Graphs", "In an adjacency matrix representation of a graph with `V` vertices, what is the size of the matrix?", "A. V x 1", "B. V x V", "C. V x E", "D. E x E", "B"
"Graphs", "What is the space complexity of an adjacency matrix for a graph with `V` vertices?", "A. O(V)", "B. O(V^2)", "C. O(E)", "D. O(V+E)", "B"
"Graphs", "What is the space complexity of an adjacency list for a graph with `V` vertices and `E` edges?", "A. O(V)", "B. O(V^2)", "C. O(E)", "D. O(V+E)", "D"
"Graphs", "When is an adjacency matrix a good choice for graph representation?", "A. For sparse graphs (few edges).", "B. For dense graphs (many edges).", "C. When memory is very limited.", "D. When only finding neighbors is required.", "B"
"Graphs", "When is an adjacency list a good choice for graph representation?", "A. For dense graphs (many edges).", "B. When checking for edge existence is a frequent operation.", "C. For sparse graphs (few edges).", "D. When the graph is complete.", "C"
"Graphs", "What does 'degree of a vertex' mean in an undirected graph?", "A. The number of edges connected to it.", "B. The number of vertices connected to it.", "C. Its position in the graph.", "D. Its weight.", "A"
"Graphs", "In a directed graph, what is the difference between 'in-degree' and 'out-degree'?", "A. In-degree is edges leaving, out-degree is edges entering.", "B. In-degree is edges entering, out-degree is edges leaving.", "C. They are always equal.", "D. In-degree is for sources, out-degree for sinks.", "B"
"Graphs", "Which graph traversal algorithm explores as far as possible along each branch before backtracking?", "A. Breadth-First Search (BFS)", "B. Depth-First Search (DFS)", "C. Dijkstra's Algorithm", "D. Prim's Algorithm", "B"
"Graphs", "Which graph traversal algorithm explores all the neighbor nodes at the present depth level before moving on to nodes at the next depth level?", "A. Breadth-First Search (BFS)", "B. Depth-First Search (DFS)", "C. Dijkstra's Algorithm", "D. Prim's Algorithm", "A"
"Graphs", "What data structure is typically used to implement Breadth-First Search (BFS)?", "A. Stack", "B. Queue", "C. Priority Queue", "D. Hash Map", "B"
"Graphs", "What data structure is typically used to implement Depth-First Search (DFS)?", "A. Stack (or recursion, which uses the call stack)", "B. Queue", "C. Priority Queue", "D. Hash Map", "A"
"Graphs", "What is the time complexity of BFS or DFS on a graph represented by an adjacency list?", "A. O(V)", "B. O(E)", "C. O(V+E)", "D. O(V*E)", "C"
"Graphs", "What is the time complexity of BFS or DFS on a graph represented by an adjacency matrix?", "A. O(V)", "B. O(E)", "C. O(V+E)", "D. O(V^2)", "D"
"Graphs", "A graph without cycles is called a:", "A. Complete Graph", "B. Connected Graph", "C. Acyclic Graph", "D. Directed Graph", "C"
"Graphs", "A graph where every pair of distinct vertices is connected by a unique edge is called a:", "A. Sparse Graph", "B. Dense Graph", "C. Complete Graph", "D. Disconnected Graph", "C"
"Graphs", "A graph is said to be 'connected' if:", "A. It has at least one edge.", "B. All vertices have the same degree.", "C. There is a path between every pair of distinct vertices.", "D. It has no cycles.", "C"
"Graphs", "What is a 'weighted graph'?", "A. A graph where edges have associated numerical values (weights).", "B. A graph with very few edges.", "C. A graph where vertices have weights.", "D. A graph used for balancing loads.", "A"
"Graphs", "What is a 'tree' in graph theory?", "A. A connected graph with cycles.", "B. A disconnected graph without cycles.", "C. A connected, acyclic graph.", "D. Any graph with a root node.", "C"
"Graphs", "The sum of degrees of all vertices in an undirected graph is equal to:", "A. The number of vertices (V).", "B. The number of edges (E).", "C. Twice the number of edges (2E).", "D. V * (V-1) / 2", "C"
"Graphs", "What is a 'cycle' in a graph?", "A. A path that starts and ends at different vertices.", "B. A path that visits every vertex exactly once.", "C. A path that starts and ends at the same vertex and visits at least one other vertex.", "D. A path that visits only two vertices.", "C"
"Graphs", "Which of these is NOT a type of graph?", "A. Undirected Graph", "B. Directed Graph", "C. Flow Graph", "D. Circular Graph", "D"
"Graphs", "What is a 'subgraph'?", "A. A smaller, disconnected graph.", "B. A graph formed by a subset of vertices and edges of a larger graph.", "C. A graph with only one vertex.", "D. A graph with no edges.", "B"
"Graphs", "What is a 'self-loop' in a graph?", "A. An edge connecting a vertex to another vertex.", "B. An edge connecting a vertex to itself.", "C. A path that forms a cycle.", "D. An edge with no weight.", "B"
"Graphs", "Multiple edges between the same pair of vertices are called:", "A. Self-loops", "B. Parallel edges", "C. Bridge edges", "D. Disconnected edges", "B"
"Graphs", "A graph that has no parallel edges and no self-loops is called a:", "A. Simple Graph", "B. Complex Graph", "C. Multi-Graph", "D. Pseudo-Graph", "A"
"Graphs", "Which graph algorithm is used to find the shortest path from a single source vertex to all other vertices in a non-negative weighted graph?", "A. Bellman-Ford Algorithm", "B. Floyd-Warshall Algorithm", "C. Dijkstra's Algorithm", "D. Kruskal's Algorithm", "C"
"Graphs", "Which graph algorithm can find the shortest path from a single source vertex to all other vertices in a graph with negative edge weights (but no negative cycles)?", "A. Dijkstra's Algorithm", "B. Prim's Algorithm", "C. Bellman-Ford Algorithm", "D. A* Search Algorithm", "C"
"Graphs", "Which graph algorithm finds the minimum spanning tree of an undirected, weighted graph?", "A. Dijkstra's Algorithm", "B. Kruskal's Algorithm", "C. Bellman-Ford Algorithm", "D. BFS", "B"
"Graphs", "What is a 'strongly connected component' in a directed graph?", "A. A subgraph where every vertex is connected to every other vertex.", "B. A maximal subgraph where every vertex is reachable from every other vertex within the component.", "C. A subgraph with no cycles.", "D. A component with the highest degree.", "B"
"Graphs", "What is a 'topological sort' applicable to?", "A. Any undirected graph.", "B. Any directed graph.", "C. Directed Acyclic Graphs (DAGs).", "D. Weighted graphs only.", "C"
"Graphs", "The result of a topological sort is:", "A. A unique path.", "B. A linear ordering of vertices such that for every directed edge (u, v), u comes before v in the ordering.", "C. The shortest path.", "D. The longest path.", "B"
"Graphs", "What does it mean for a graph to be 'bipartite'?", "A. Its vertices can be divided into two disjoint sets such that edges only connect vertices from different sets.", "B. It has exactly two connected components.", "C. It has only two vertices.", "D. It has exactly two cycles.", "A"
"Graphs", "An 'articulation point' (or cut vertex) in a connected graph is a vertex whose removal:", "A. Increases the number of edges.", "B. Disconnects the graph (increases the number of connected components).", "C. Reduces the number of vertices.", "D. Changes the graph to a tree.", "B"
"Graphs", "A 'bridge' (or cut edge) in a connected graph is an edge whose removal:", "A. Increases the number of vertices.", "B. Disconnects the graph (increases the number of connected components).", "C. Reduces the number of edges.", "D. Creates a cycle.", "B"
"Graphs", "What is a 'tree edge' in DFS?", "A. An edge that connects a node to its ancestor.", "B. An edge that connects a node to its child in the DFS tree.", "C. An edge that connects two nodes in different subtrees.", "D. An edge that completes a cycle.", "B"
"Graphs", "What is a 'back edge' in DFS?", "A. An edge that connects a node to its ancestor in the DFS tree.", "B. An edge that connects a node to its child.", "C. An edge that connects two nodes in different subtrees.", "D. An edge that has been visited twice.", "A"
"Graphs", "What is a 'cross edge' in DFS (for a directed graph)?", "A. An edge that connects a node to an ancestor.", "B. An edge that connects two nodes in different subtrees, where one is not an ancestor of the other.", "C. An edge connecting parent to child.", "D. An edge that is part of a cycle.", "B"
"Graphs", "What is a 'forward edge' in DFS (for a directed graph)?", "A. An edge (u, v) where v is a descendant of u in the DFS tree, but not a direct child.", "B. An edge from child to parent.", "C. An edge between two unrelated subtrees.", "D. An edge that creates a cycle.", "A"
"Graphs", "What does it mean for a graph to be 'dense'?", "A. It has very few edges compared to the maximum possible.", "B. It has many edges, approaching the maximum possible for its number of vertices.", "C. It has many vertices but few edges.", "D. It has a high degree of connectivity for its size.", "B"
"Graphs", "What does it mean for a graph to be 'sparse'?", "A. It has very few edges compared to the maximum possible.", "B. It has many edges, approaching the maximum possible for its number of vertices.", "C. It has many vertices but few edges.", "D. It has a high degree of connectivity for its size.", "A"
"Graphs", "What is a 'path' in a graph?", "A. A sequence of distinct vertices.", "B. A sequence of alternating vertices and edges, starting and ending with vertices.", "C. A sequence of edges only.", "D. A cycle in the graph.", "B"
"Graphs", "What is the 'length' of a path in an unweighted graph?", "A. The sum of weights of edges.", "B. The number of vertices in the path.", "C. The number of edges in the path.", "D. The maximum degree of any vertex in the path.", "C"
"Graphs", "What is the 'length' of a path in a weighted graph?", "A. The number of edges in the path.", "B. The sum of weights of edges in the path.", "C. The number of vertices in the path.", "D. The product of weights of edges in the path.", "B"
"Graphs", "A 'directed acyclic graph' (DAG) is used in which of the following applications?", "A. Social network analysis (general).", "B. Representing tasks with dependencies (e.g., project scheduling).", "C. Road networks with two-way streets.", "D. Fully connected neural networks.", "B"
"Graphs", "If a graph has `V` vertices and `E` edges. For a sparse graph, which representation is more memory efficient?", "A. Adjacency Matrix", "B. Adjacency List", "C. Edge List (if only edges needed)", "D. Both are equally efficient", "B"
"Graphs", "If a graph has `V` vertices and `E` edges. For a dense graph, which representation is more efficient for checking if an edge `(u,v)` exists?", "A. Adjacency Matrix (O(1))", "B. Adjacency List (O(degree(u)))", "C. Edge List (O(E))", "D. Hash Table", "A"
"Graphs", "What is the result of a BFS traversal from a source node in an unweighted graph?", "A. A minimum spanning tree.", "B. A shortest path tree from the source to all reachable nodes.", "C. A topological sort.", "D. A list of all cycles.", "B"
"Graphs", "What is the result of a DFS traversal from a source node in a graph?", "A. A shortest path tree.", "B. A DFS tree, which can reveal cycles and connected components.", "C. A minimum spanning tree.", "D. A topological sort.", "B"
"Graphs", "In an undirected graph, an edge `(u, v)` is a `bridge` if:", "A. It forms a cycle with other edges.", "B. Its removal increases the number of connected components.", "C. It connects two vertices with the same degree.", "D. It's the only edge between `u` and `v`.", "B"
"DFS", "What data structure is primarily used to implement Depth-First Search (DFS) iteratively?", "A. Queue", "B. Stack", "C. Priority Queue", "D. Hash Table", "B"
"DFS", "Which approach does DFS primarily follow for graph traversal?", "A. Breadth-first exploration", "B. Exploring as far as possible along each branch before backtracking", "C. Prioritizing shortest paths", "D. Visiting all neighbors at the current level first", "B"
"DFS", "What is the time complexity of DFS on a graph represented by an adjacency list with `V` vertices and `E` edges?", "A. O(V)", "B. O(E)", "C. O(V+E)", "D. O(V*E)", "C"
"DFS", "What is the time complexity of DFS on a graph represented by an adjacency matrix with `V` vertices?", "A. O(V)", "B. O(E)", "C. O(V+E)", "D. O(V^2)", "D"
"DFS", "What data structure is used implicitly when DFS is implemented recursively?", "A. Heap", "B. Queue", "C. Call Stack", "D. Linked List", "C"
"DFS", "Which of the following is a common application of DFS?", "A. Finding the shortest path in an unweighted graph.", "B. Finding connected components in a graph.", "C. Finding the minimum spanning tree.", "D. Calculating all-pairs shortest paths.", "B"
"DFS", "When performing DFS, what does a 'visited' array or set help prevent?", "A. Infinite loops in graphs with cycles.", "B. Visiting isolated vertices.", "C. Incorrect path calculations.", "D. Memory overflow.", "A"
"DFS", "What is the order of nodes visited in a DFS traversal starting from node A in a graph A->B, A->C, B->D, C->E (assuming alphabetical neighbor order)?", "A. A, B, D, C, E", "B. A, C, E, B, D", "C. A, B, C, D, E", "D. A, C, B, E, D", "A"
"DFS", "In a directed graph, what type of edge indicates a cycle during a DFS traversal (when detecting cycles)?", "A. Tree edge", "B. Forward edge", "C. Back edge", "D. Cross edge", "C"
"DFS", "What is a 'tree edge' in DFS?", "A. An edge connecting a node to its ancestor in the DFS tree.", "B. An edge that connects a node to its child in the DFS tree.", "C. An edge that connects two nodes in different subtrees.", "D. An edge that completes a cycle.", "B"
"DFS", "What is a 'back edge' in DFS?", "A. An edge that connects a node to its ancestor (or itself) in the DFS tree.", "B. An edge that connects a node to its child.", "C. An edge that connects two nodes in different subtrees.", "D. An edge that has been visited twice.", "A"
"DFS", "What is a 'cross edge' in DFS (for a directed graph)?", "A. An edge that connects a node to an ancestor.", "B. An edge that connects two nodes in different subtrees, where one is not an ancestor of the other.", "C. An edge connecting parent to child.", "D. An edge that creates a cycle.", "B"
"DFS", "What is a 'forward edge' in DFS (for a directed graph)?", "A. An edge (u, v) where v is a descendant of u in the DFS tree, but not a direct child.", "B. An edge from child to parent.", "C. An edge between two unrelated subtrees.", "D. An edge that creates a cycle.", "A"
"DFS", "Which graph property can DFS be used to find?", "A. Shortest path in weighted graph.", "B. Longest path in any graph.", "C. Strongly Connected Components (SCCs) in a directed graph.", "D. Minimum Spanning Tree.", "C"
"DFS", "What kind of graphs can topological sort be applied to?", "A. Any undirected graph.", "B. Any directed graph.", "C. Directed Acyclic Graphs (DAGs).", "D. Weighted graphs only.", "C"
"DFS", "Which traversal order does DFS naturally produce for topological sort?", "A. Pre-order", "B. Post-order (reverse of DFS finishing times)", "C. In-order", "D. Level-order", "B"
"DFS", "What does it mean if a DFS traversal visits all vertices starting from a single source vertex?", "A. The graph is cyclic.", "B. The graph is disconnected.", "C. The graph is connected (or the source can reach all other vertices).", "D. The graph is bipartite.", "C"
"DFS", "DFS is particularly useful for problems involving:", "A. Finding the shortest distance.", "B. Exploring all reachable nodes from a source.", "C. Pathfinding and cycle detection.", "D. Load balancing.", "C"
"DFS", "Does DFS find the shortest path in an unweighted graph?", "A. Yes, always.", "B. No, BFS finds the shortest path in unweighted graphs.", "C. Only if the graph is a tree.", "D. Only if the graph has no cycles.", "B"
"DFS", "What happens if a DFS encounters an already visited node that is currently in the recursion stack (grey/active state)?", "A. It indicates the presence of a cycle.", "B. It indicates the graph is acyclic.", "C. It means the search is complete.", "D. It is ignored.", "A"
"DFS", "What is the maximum recursion depth for a recursive DFS on a graph with `V` vertices?", "A. O(1)", "B. O(log V)", "C. O(V)", "D. O(V^2)", "C"
"DFS", "Can DFS be used to detect cycles in an undirected graph?", "A. No, only in directed graphs.", "B. Yes, if a DFS encounters a visited node that is not its immediate parent.", "C. Only if the graph is small.", "D. Only for self-loops.", "B"
"DFS", "When performing DFS, what state does a node typically enter when it's first visited?", "A. Unvisited", "B. Visiting (or Grey)", "C. Visited (or Black)", "D. Finished", "B"
"DFS", "When performing DFS, what state does a node typically enter after all its descendants have been visited and it's popped from the stack?", "A. Unvisited", "B. Visiting (or Grey)", "C. Visited (or Black)", "D. Finished (or fully processed)", "C"
"DFS", "What is an 'articulation point' (or cut vertex) in a graph, and how can DFS help find it?", "A. A vertex whose removal makes the graph denser; DFS does not help.", "B. A vertex whose removal disconnects the graph; DFS can find it using discovery and low-link times.", "C. A vertex with the highest degree; DFS finds it by counting edges.", "D. A leaf node; DFS finds it by checking if it has no children.", "B"
"DFS", "What is a 'bridge' (or cut edge) in a graph, and how can DFS help find it?", "A. An edge that forms a cycle; DFS does not help.", "B. An edge whose removal disconnects the graph; DFS can find it using discovery and low-link times.", "C. An edge with the highest weight; DFS finds it by summing weights.", "D. An edge that connects to the root; DFS finds it by checking parent pointers.", "B"
"DFS", "In a DFS traversal, what defines the 'discovery time' of a vertex?", "A. The time it takes to finish processing the vertex.", "B. The time when the vertex is first visited.", "C. The time when all its neighbors are visited.", "D. The total time spent in its subtree.", "B"
"DFS", "In a DFS traversal, what defines the 'finishing time' of a vertex?", "A. The time when the vertex is first visited.", "B. The time when all its adjacent vertices have been explored and its DFS call completes.", "C. The total time spent in its subtree.", "D. The time it takes to reach the root from this vertex.", "B"
"DFS", "Which graph algorithm can be used as a subroutine for finding Strongly Connected Components?", "A. BFS", "B. DFS (two times, on original graph and reversed graph)", "C. Dijkstra's", "D. Prim's", "B"
"DFS", "Can DFS be used to check if a graph is bipartite?", "A. No, it's not applicable.", "B. Yes, by attempting to 2-color the graph during traversal and checking for conflicts.", "C. Only if the graph is a tree.", "D. Only for directed graphs.", "B"
"DFS", "What is the space complexity of DFS (recursive) in the worst case for a graph with `V` vertices and `E` edges?", "A. O(1)", "B. O(V) due to recursion stack depth.", "C. O(E)", "D. O(V+E)", "B"
"DFS", "Which of the following is true regarding DFS traversal order?", "A. It always visits nodes in increasing order of their values.", "B. The order depends heavily on the adjacency list/matrix representation and starting node.", "C. It always visits nodes level by level.", "D. It always visits leaf nodes first.", "B"
"DFS", "When DFS is applied to a tree, what does it essentially become?", "A. A level-order traversal.", "B. A pre-order, in-order, or post-order traversal depending on when actions are taken.", "C. A shortest path algorithm.", "D. A minimum spanning tree algorithm.", "B"
"DFS", "What is the primary difference in behavior between BFS and DFS in exploring a graph?", "A. BFS explores deeply first; DFS explores broadly first.", "B. BFS uses a queue; DFS uses a stack/recursion.", "C. BFS finds all paths; DFS finds only one path.", "D. BFS works only for unweighted graphs; DFS works for weighted graphs.", "B"
"DFS", "If a graph has multiple connected components, how would a standard DFS algorithm explore them?", "A. It would only explore the component of the starting node.", "B. It would automatically find all components.", "C. It requires calling DFS multiple times, once for each unvisited node in different components.", "D. It would get stuck.", "C"
"DFS", "Consider a disconnected graph. If DFS is called only once from an arbitrary start node, what part of the graph will it visit?", "A. The entire graph.", "B. Only the first node.", "C. Only the connected component containing the start node.", "D. It will visit no nodes.", "C"
"DFS", "Which technique is a direct application of DFS?", "A. Prim's Algorithm", "B. Kruskal's Algorithm", "C. Kosaraju's Algorithm (for SCCs)", "D. Dijkstra's Algorithm", "C"
"DFS", "What is the purpose of the 'finish time' (or post-order number) in DFS?", "A. To determine the order of nodes in the shortest path.", "B. To order nodes for topological sort or to identify strongly connected components.", "C. To check if a node has been visited.", "D. To count the number of edges.", "B"
"DFS", "If a graph has `V` vertices, how many times will each edge be traversed (in total) during a DFS traversal using an adjacency list?", "A. Once.", "B. Twice (once from each direction for undirected graphs).", "C. V times.", "D. E times.", "B"
"DFS", "What happens when DFS encounters a node that is 'visited' but 'not processed' (still in the recursion stack / grey state)?", "A. It means the graph is acyclic.", "B. It's a forward edge.", "C. It's a back edge, indicating a cycle.", "D. It's a cross edge.", "C"
"DFS", "When is DFS generally preferred over BFS?", "A. For finding the shortest path in unweighted graphs.", "B. For finding minimum spanning trees.", "C. For problems requiring path exploration, cycle detection, or topological sorting where depth matters more than minimum distance.", "D. For finding all connected components simultaneously.", "C"
"DFS", "In a DFS traversal, what is the 'discovery time' (or pre-order number) of the root node?", "A. 0", "B. 1", "C. Infinity", "D. The number of nodes.", "B"
"DFS", "How can DFS be used to find all paths between two nodes?", "A. By simply running a single DFS.", "B. By modifying DFS to not mark nodes as fully 'visited' until all paths through them are explored (or explicitly track paths).", "C. By using an additional queue.", "D. It cannot be used for this purpose.", "B"
"DFS", "Is DFS guaranteed to find the shortest path in a weighted graph?", "A. Yes, always.", "B. No, it doesn't consider edge weights for path optimization.", "C. Only if all weights are positive.", "D. Only if the graph is a tree.", "B"
"DFS", "What is the typical output of a DFS traversal (if not explicitly modified for a specific problem)?", "A. A list of visited nodes in discovery order.", "B. A shortest path tree.", "C. A minimum spanning tree.", "D. A bipartite coloring.", "A"
"DFS", "Can DFS handle graphs with disconnected components without specific modification to the algorithm itself?", "A. Yes, it will visit all components automatically.", "B. No, it only visits the component reachable from the start node.", "C. It will only visit the component with the most nodes.", "D. It will crash.", "B"
"DFS", "What is the main advantage of iterative DFS over recursive DFS for very large graphs?", "A. Simpler to write.", "B. Avoids potential stack overflow issues.", "C. Faster execution time.", "D. Uses less memory.", "B"
"DFS", "Consider a graph. If DFS is used for a cycle detection in an undirected graph, what kind of edge indicates a cycle?", "A. A tree edge.", "B. A back edge (to an already visited, non-parent node).", "C. A forward edge.", "D. A cross edge.", "B"
"DFS", "How does DFS explore compared to BFS when visualizing their search frontier?", "A. BFS expands uniformly; DFS expands in a zig-zag, going deep on one path first.", "B. BFS goes deep; DFS goes wide.", "C. BFS is random; DFS is systematic.", "D. Both are identical.", "A"
"BFS", "What data structure is primarily used to implement Breadth-First Search (BFS)?", "A. Stack", "B. Queue", "C. Priority Queue", "D. Hash Table", "B"
"BFS", "Which approach does BFS primarily follow for graph traversal?", "A. Exploring as far as possible along each branch before backtracking", "B. Depth-first exploration", "C. Visiting all the neighbor nodes at the present depth level before moving on to nodes at the next depth level", "D. Prioritizing shortest paths in weighted graphs", "C"
"BFS", "What is the time complexity of BFS on a graph represented by an adjacency list with `V` vertices and `E` edges?", "A. O(V)", "B. O(E)", "C. O(V+E)", "D. O(V*E)", "C"
"BFS", "What is the time complexity of BFS on a graph represented by an adjacency matrix with `V` vertices?", "A. O(V)", "B. O(E)", "C. O(V+E)", "D. O(V^2)", "D"
"BFS", "Which of the following is a common application of BFS?", "A. Detecting cycles in a directed graph.", "B. Finding the shortest path in an unweighted graph.", "C. Finding strongly connected components.", "D. Topological sorting.", "B"
"BFS", "When performing BFS, what does a 'visited' array or set help prevent?", "A. Incorrect path calculations.", "B. Infinite loops in graphs with cycles and redundant processing.", "C. Visiting isolated vertices.", "D. Memory overflow from queue.", "B"
"BFS", "What is the order of nodes visited in a BFS traversal starting from node A in a graph A->B, A->C, B->D, C->E (assuming alphabetical neighbor order)?", "A. A, B, D, C, E", "B. A, C, E, B, D", "C. A, B, C, D, E", "D. A, C, B, E, D", "C"
"BFS", "Does BFS guarantee finding the shortest path in an unweighted graph?", "A. No, only DFS does.", "B. Yes, always.", "C. Only if the graph is a tree.", "D. Only if there are no cycles.", "B"
"BFS", "What is the shortest path length from a source `S` to a target `T` in an unweighted graph found by BFS?", "A. The number of vertices in the path.", "B. The number of edges in the path.", "C. The sum of weights of edges.", "D. The maximum degree along the path.", "B"
"BFS", "What happens if a BFS encounters an already visited node?", "A. It means a cycle is detected.", "B. It means the graph is disconnected.", "C. It is simply ignored, as it has already been processed or is in the queue.", "D. It causes the algorithm to terminate.", "C"
"BFS", "What is the maximum space complexity of BFS for a graph with `V` vertices and `E` edges?", "A. O(1)", "B. O(V) for the queue and visited array.", "C. O(E)", "D. O(V+E)", "B"
"BFS", "Can BFS be used to detect cycles in an undirected graph?", "A. No, it's not applicable.", "B. Yes, by checking if an already visited node is encountered that is not the parent of the current node.", "C. Only if the graph is small.", "D. Only for self-loops.", "B"
"BFS", "What does it mean if a BFS traversal visits all vertices starting from a single source vertex?", "A. The graph is cyclic.", "B. The graph is disconnected.", "C. The graph is connected (or the source can reach all other vertices).", "D. The graph is bipartite.", "C"
"BFS", "Which problem is BFS particularly well-suited for?", "A. Finding the longest path.", "B. Finding all cycles.", "C. Finding all nodes reachable from a source, and their shortest distances in terms of number of edges.", "D. Topological sorting on arbitrary graphs.", "C"
"BFS", "If a graph has multiple connected components, how would a standard BFS algorithm explore them?", "A. It would only explore the component of the starting node.", "B. It would automatically find all components.", "C. It requires calling BFS multiple times, once for each unvisited node in different components.", "D. It would get stuck.", "A"
"BFS", "Which type of graph does BFS work best for when finding shortest paths?", "A. Weighted graphs with negative weights.", "B. Unweighted graphs.", "C. Graphs with self-loops.", "D. Directed acyclic graphs (DAGs).", "B"
"BFS", "When performing BFS, a node is marked as 'visited' when?", "A. When it's added to the queue.", "B. When it's dequeued and its neighbors are being explored.", "C. After all its neighbors have been visited.", "D. When the BFS completes.", "A"
"BFS", "What is the 'level' of a node in BFS?", "A. Its alphabetical order.", "B. Its distance (number of edges) from the source node.", "C. The number of neighbors it has.", "D. Its position in the adjacency list.", "B"
"BFS", "Which of these algorithms/applications typically uses BFS as a core component?", "A. Kruskal's algorithm for MST.", "B. Prim's algorithm for MST.", "C. Ford-Fulkerson algorithm for max flow (finding augmenting paths).", "D. Bellman-Ford for shortest paths with negative weights.", "C"
"BFS", "Can BFS be used to check if a graph is bipartite?", "A. No, it's not applicable.", "B. Yes, by attempting to 2-color the graph during traversal and checking for conflicts.", "C. Only if the graph is a tree.", "D. Only for directed graphs.", "B"
"BFS", "Consider a graph. If BFS is used to check for connectivity between two nodes `S` and `T`, what happens if `T` is found?", "A. The algorithm stops, as a path is found.", "B. The algorithm continues to visit all reachable nodes.", "C. The algorithm restarts from `T`.", "D. It indicates no path exists.", "A"
"BFS", "How does BFS explore compared to DFS when visualizing their search frontier?", "A. BFS expands uniformly (level by level); DFS goes deep on one path first.", "B. BFS goes deep; DFS goes wide.", "C. BFS is random; DFS is systematic.", "D. Both are identical.", "A"
"BFS", "What is the primary output of a standard BFS traversal (if not explicitly modified for a specific problem)?", "A. A list of visited nodes in discovery order, and optionally distances from source.", "B. A topological sort.", "C. A minimum spanning tree.", "D. A list of all cycles.", "A"
"BFS", "If a graph has `V` vertices, how many times will each vertex be enqueued during a BFS traversal?", "A. Once.", "B. Twice.", "C. V times.", "D. E times.", "A"
"BFS", "What is the advantage of BFS over DFS for finding the shortest path in an unweighted graph?", "A. BFS is simpler to implement.", "B. BFS naturally explores in layers, guaranteeing the first time a node is reached is via the shortest path.", "C. BFS uses less memory.", "D. BFS handles negative weights better.", "B"
"BFS", "Is BFS suitable for finding cycles in a directed graph?", "A. Yes, always.", "B. No, DFS is generally better suited for cycle detection in directed graphs.", "C. Only if the graph is a tree.", "D. Only for small graphs.", "B"
"BFS", "In BFS, what happens if the queue becomes empty before all vertices are visited?", "A. An error occurs.", "B. The graph contains disconnected components, and all reachable nodes from the starting source have been visited.", "C. The graph has no cycles.", "D. The algorithm has found the shortest path.", "B"
"BFS", "Which of the following is NOT a direct application of BFS?", "A. Finding connected components.", "B. Finding the diameter of a tree.", "C. Finding a Hamiltonian cycle.", "D. Web crawlers.", "C"
"BFS", "When is BFS generally preferred over DFS?", "A. For problems requiring deep exploration or cycle detection.", "B. For problems where the shortest path (in terms of number of edges) is needed, or exploring nodes level by level.", "C. For topological sorting.", "D. When stack overflow is a concern.", "B"
"BFS", "Consider a graph with `N` vertices. If all vertices are reachable from the source, how many vertices will be added to the queue in total during BFS?", "A. At most `N`.", "B. Exactly `N`.", "C. At most `2N`.", "D. Depends on the number of edges.", "A"
"BFS", "What is the order in which nodes are added to and removed from the queue in BFS?", "A. LIFO (Last-In, First-Out)", "B. FIFO (First-In, First-Out)", "C. Random Order", "D. Priority Order", "B"
"BFS", "In BFS, what can be stored along with a node in the queue to reconstruct the shortest path later?", "A. Its color.", "B. Its parent node.", "C. Its degree.", "D. Its value.", "B"
"BFS", "What is the primary difference in how BFS handles cycles compared to DFS?", "A. BFS explicitly detects cycles and reports them.", "B. BFS naturally avoids getting stuck in cycles because it visits nodes level by level and marks them visited upon enqueueing.", "C. BFS requires special backtracking for cycles.", "D. BFS cannot handle cycles.", "B"
"BFS", "If a graph has no edges, what is the time complexity of BFS starting from a single node?", "A. O(1)", "B. O(V)", "C. O(E)", "D. O(V+E) which simplifies to O(V) since E=0.", "D"
"BFS", "What is the maximum value of the shortest path from a source `S` to any other reachable vertex `V` in an unweighted graph with `N` vertices?", "A. 1", "B. `N`", "C. `N-1`", "D. `2N`", "C"
"BFS", "Can BFS be used to find all paths between two nodes?", "A. Yes, always.", "B. No, it typically finds only one shortest path, not all possible paths.", "C. Only if the graph is a tree.", "D. Only for very small graphs.", "B"
"BFS", "What type of edges does BFS identify in a graph?", "A. Tree edges and back edges.", "B. Tree edges and cross edges.", "C. Forward edges and back edges.", "D. Only tree edges.", "B"
"BFS", "In BFS, a 'tree edge' is an edge that:", "A. Connects a node to an ancestor.", "B. Connects a node to a newly discovered (unvisited) node.", "C. Connects two nodes in different subtrees.", "D. Forms a cycle.", "B"
"BFS", "In BFS, a 'cross edge' is an edge that (in a directed graph):", "A. Connects a node to an ancestor.", "B. Connects two nodes such that neither is an ancestor or descendant of the other.", "C. Connects a node to a newly discovered node.", "D. Forms a self-loop.", "B"
"BFS", "What is a 'Level-Order Traversal' when applied to a tree?", "A. It's equivalent to DFS on the tree.", "B. It's equivalent to BFS on the tree.", "C. It's a random traversal.", "D. It's a pre-order traversal.", "B"
"BFS", "Which of these is a typical real-world application of BFS?", "A. Finding the fastest route with traffic.", "B. Social networking (finding friends of friends).", "C. Detecting deadlocks in operating systems.", "D. DNA sequencing.", "B"
"BFS", "If a BFS traversal completes and there are still unvisited nodes, what does that imply?", "A. The graph is cyclic.", "B. The graph is disconnected.", "C. The starting node cannot reach those unvisited nodes.", "D. Both B and C are correct.", "D"
"BFS", "What is the concept of 'parent pointers' used for in BFS?", "A. To identify the root of the graph.", "B. To reconstruct the shortest path from the source to any reachable node.", "C. To check for cycles.", "D. To count the number of edges.", "B"
"BFS", "When using BFS to find connected components, what happens after one component is fully explored?", "A. The algorithm stops.", "B. Another starting node (unvisited) is chosen, and BFS is run again.", "C. The queue is reset, and the algorithm waits for user input.", "D. It automatically jumps to the next component.", "B"
"BFS", "Which of the following problems is generally NOT solved efficiently by a standard BFS?", "A. Finding the shortest path in a graph with varying positive edge weights.", "B. Finding all nodes within K steps from a source.", "C. Checking if a graph is connected.", "D. Finding the minimum number of moves in a puzzle (state space as graph).", "A"
"BFS", "What happens to the elements in the queue during a BFS traversal?", "A. Elements are added to the front and removed from the front.", "B. Elements are added to the rear and removed from the front.", "C. Elements are added to the rear and removed from the rear.", "D. Elements are added to the front and removed from the rear.", "B"
"BFS", "If BFS is used to count connected components in an undirected graph, how many times will BFS be invoked (in a full algorithm)?", "A. Once, it finds all components automatically.", "B. `V` times, once for each vertex.", "C. Equal to the number of connected components.", "D. Equal to the number of edges.", "C"
"BFS", "What is the relationship between the level of a node and its distance from the source in an unweighted graph?", "A. They are always different.", "B. The level of a node is equal to its shortest distance from the source.", "C. The level is twice the distance.", "D. There is no direct relationship.", "B"
"BFS", "Which of these is a disadvantage of BFS compared to DFS?", "A. It can get stuck in infinite loops in graphs with cycles.", "B. It typically requires more memory for the queue, especially in graphs with high branching factors.", "C. It is slower for finding a deep target node in a sparsely connected graph.", "D. It cannot handle disconnected graphs.", "B"
"BFS", "In BFS, what does the 'discovery time' (or first visit time) of a vertex represent?", "A. Its distance from the root in the BFS tree.", "B. The order in which it's dequeued.", "C. The total time spent processing its neighbors.", "D. Its degree.", "A"
"Dijkstra", "What is the primary purpose of Dijkstra?", "A. To find all-pairs shortest paths in any graph.", "B. To find the shortest path from a single source vertex to all other vertices in a graph with non-negative edge weights.", "C. To find the longest path in a graph.", "D. To detect cycles in a graph.", "B"
"Dijkstra", "Which type of edge weights can Dijkstra handle?", "A. Only positive weights.", "B. Only non-negative weights (positive or zero).", "C. Negative weights are also allowed.", "D. Any real number weights.", "B"
"Dijkstra", "What data structure is commonly used to implement Dijkstra efficiently?", "A. Queue", "B. Stack", "C. Priority Queue (Min-Heap)", "D. Hash Table", "C"
"Dijkstra", "What is the time complexity of Dijkstra using a simple array (linear scan) for extracting minimum distance?", "A. O(V + E)", "B. O(V^2)", "C. O(E log V)", "D. O(V log V)", "B"
"Dijkstra", "What is the time complexity of Dijkstra using a Binary Min-Heap based Priority Queue for extraction?", "A. O(V + E)", "B. O(V^2)", "C. O(E log V)", "D. O(V log E)", "C"
"Dijkstra", "Why does Dijkstra fail with negative edge weights?", "A. It gets stuck in an infinite loop.", "B. It may not find the correct shortest path because it assumes that once a vertex is finalized, its shortest path won't change, which can be violated by negative weights.", "C. It uses a greedy approach that doesn't work with negative values.", "D. It crashes the program.", "B"
"Dijkstra", "What is the key principle Dijkstra follows?", "A. Dynamic Programming", "B. Divide and Conquer", "C. Greedy approach", "D. Backtracking", "C"
"Dijkstra", "In Dijkstra, what does `dist[v]` typically represent?", "A. The final shortest distance from the source to vertex `v`.", "B. The current shortest distance found so far from the source to vertex `v`.", "C. The degree of vertex `v`.", "D. The weight of the edge to `v`.", "B"
"Dijkstra", "When is a vertex 'finalized' or 'settled' in Dijkstra?", "A. When all its neighbors have been visited.", "B. When it is extracted from the priority queue (meaning its shortest path from source has been found).", "C. When all vertices are visited.", "D. After relaxation of all its outgoing edges.", "B"
"Dijkstra", "What is 'relaxation' in the context of Dijkstra?", "A. Adding a new vertex to the graph.", "B. Updating the distance to a neighbor if a shorter path is found through the current vertex.", "C. Removing an half-edge from the graph.", "D. Resetting all distances to infinity.", "B"
"Dijkstra", "Dijkstra works on which type of graphs?", "A. Undirected and Directed graphs.", "B. Only Undirected graphs.", "C. Only Directed graphs.", "D. Only Acyclic graphs.", "A"
"Dijkstra", "What is the initial distance assigned to the source vertex in Dijkstra?", "A. Infinity", "B. 1", "C. 0", "D. -1", "C"
"Dijkstra", "What is the initial distance assigned to all other non-source vertices in Dijkstra?", "A. 0", "B. 1", "C. Infinity", "D. -1", "C"
"Dijkstra", "How many times is each vertex extracted from the priority queue in Dijkstra (in a correctly implemented version)?", "A. Zero times.", "B. Exactly once.", "C. Multiple times, if its distance is updated.", "D. V times.", "B"
"Dijkstra", "If a graph has `V` vertices and `E` edges, what is the maximum number of `decrease-key` operations on the priority queue during Dijkstra?", "A. V", "B. E", "C. V+E", "D. E log V", "B"
"Dijkstra", "Can Dijkstra be used to detect negative cycles?", "A. Yes, always.", "B. No, it's not designed for negative cycles and may produce incorrect results or loop infinitely if one exists and is reachable.", "C. Only if the cycle is short.", "D. Only in directed graphs.", "B"
"Dijkstra", "What is the typical output of Dijkstra?", "A. A list of all edges in the graph.", "B. The shortest path tree from the source vertex.", "C. A list of all cycles.", "D. The maximum flow.", "B"
"Dijkstra", "If a graph is disconnected, and the source vertex is in one component, what will Dijkstra find?", "A. Shortest paths to all vertices in the graph.", "B. Shortest paths only to vertices reachable from the source in its connected component.", "C. It will get stuck.", "D. It will find no paths.", "B"
"Dijkstra", "Which of these algorithms would be a better choice for finding shortest paths if negative edge weights are present?", "A. Prim's Algorithm", "B. Kruskal's Algorithm", "C. Bellman-Ford Algorithm", "D. BFS", "C"
"Dijkstra", "What is the total number of vertices in the final shortest path tree produced by Dijkstra (assuming all vertices are reachable)?", "A. `V`", "B. `V-1`", "C. `E`", "D. `E-1`", "A"
"Dijkstra", "What is the total number of edges in the final shortest path tree produced by Dijkstra (assuming all vertices are reachable)?", "A. `V`", "B. `V-1`", "C. `E`", "D. `E-1`", "B"
"Dijkstra", "For a graph with `V` vertices and `E` edges, which implementation of Dijkstra is most efficient for dense graphs (E ≈ V^2)?", "A. Adjacency Matrix + Simple Array (O(V^2))", "B. Adjacency List + Binary Heap (O(E log V))", "C. Adjacency List + Fibonacci Heap (O(E + V log V))", "D. Adjacency List + AVL Tree", "A"
"Dijkstra", "For a graph with `V` vertices and `E` edges, which implementation of Dijkstra is most efficient for sparse graphs (E ≈ V)?", "A. Adjacency Matrix + Simple Array (O(V^2))", "B. Adjacency List + Binary Heap (O(E log V))", "C. Adjacency List + Fibonacci Heap (O(E + V log V))", "D. Adjacency List + Array (O(V^2))", "B"
"Dijkstra", "Dijkstra maintains a set of 'settled' or 'finalized' vertices. What does this set represent?", "A. Vertices whose shortest paths from the source have been definitively found.", "B. Vertices that have been visited at least once.", "C. Vertices that are still in the priority queue.", "D. Vertices that have no outgoing edges.", "A"
"Dijkstra", "What happens if an edge with weight 0 is encountered in Dijkstra?", "A. It causes an error.", "B. It is treated like any other non-negative edge weight.", "C. It is ignored.", "D. It immediately leads to a shortest path.", "B"
"Dijkstra", "Can Dijkstra be used for finding the longest path?", "A. Yes, by negating edge weights.", "B. No, negating weights would introduce negative cycles, which Dijkstra cannot handle. Longest path is generally NP-hard.", "C. Only in DAGs.", "D. Only if all weights are 1.", "B"
"Dijkstra", "In the initial step of Dijkstra, the source vertex is usually added to the priority queue with what distance?", "A. Infinity", "B. 0", "C. 1", "D. -1", "B"
"Dijkstra", "What is the fundamental difference between Dijkstra and BFS for shortest paths?", "A. Dijkstra handles weighted graphs; BFS handles unweighted graphs.", "B. Dijkstra uses a queue; BFS uses a stack.", "C. Dijkstra finds all paths; BFS finds only one.", "D. Dijkstra works on directed only; BFS works on undirected only.", "A"
"Dijkstra", "Does Dijkstra guarantee finding the shortest path if there are negative cycles?", "A. Yes, it can detect them.", "B. No, it will likely loop infinitely or give incorrect results.", "C. Yes, it will just take longer.", "D. It depends on the starting node.", "B"
"Dijkstra", "Consider a graph. If Dijkstra is running, and it extracts vertex `U` from the priority queue, what does this signify?", "A. `U` is the last vertex to be visited.", "B. The shortest path from the source to `U` has been found.", "C. `U` has no more unvisited neighbors.", "D. `U` is a dead end.", "B"
"Dijkstra", "What role do `predecessor` (or `parent`) pointers play in Dijkstra?", "A. To detect cycles.", "B. To reconstruct the shortest path from the source to any vertex.", "C. To count the number of edges.", "D. To store edge weights.", "B"
"Dijkstra", "Can Dijkstra be adapted to find the shortest path from all vertices to a single target vertex?", "A. No, it's strictly single source.", "B. Yes, by reversing all edge directions and running the algorithm from the target vertex as the new source.", "C. Only by running it V times.", "D. Only if the graph is undirected.", "B"
"Dijkstra", "What is a 'Fibonacci Heap' and how does it relate to Dijkstra?", "A. A type of graph that optimizes Dijkstra.", "B. A specialized priority queue that provides the asymptotically fastest known worst-case running time for Dijkstra (O(E + V log V)).", "C. An alternative algorithm to Dijkstra.", "D. A data structure for storing negative weights.", "B"
"Dijkstra", "What is the primary difference between Dijkstra and Prim's algorithm?", "A. Dijkstra finds shortest paths, Prim's finds minimum spanning trees.", "B. Dijkstra works on unweighted graphs, Prim's on weighted.", "C. Dijkstra uses a queue, Prim's uses a stack.", "D. Dijkstra is greedy, Prim's is dynamic programming.", "A"
"Dijkstra", "When is Dijkstra preferred over Bellman-Ford?", "A. When the graph has negative edge weights.", "B. When the graph is very dense.", "C. When the graph has no negative edge weights and is sparse (E log V < V^2).", "D. When detecting negative cycles is required.", "C"
"Dijkstra", "What is the process of extracting the minimum element from the priority queue in Dijkstra analogous to?", "A. Relaxing an edge.", "B. Marking a vertex as finalized.", "C. Adding a vertex to the graph.", "D. Checking for cycles.", "B"
"Dijkstra", "How does Dijkstra handle isolated vertices (vertices with no incoming or outgoing edges)?", "A. It processes them first.", "B. It ignores them unless they are the source.", "C. Their distance remains infinity (unless they are the source, which is 0).", "D. It causes an error.", "C"
"Dijkstra", "If a graph contains a zero-weight cycle, will Dijkstra find the correct shortest path?", "A. No, it will loop infinitely.", "B. Yes, as long as there are no negative weights, zero-weight cycles are generally fine.", "C. Only if the cycle is unreachable from the source.", "D. Only if the cycle is very long.", "B"
"Dijkstra", "What is the time complexity to initialize distances to infinity for `V` vertices?", "A. O(1)", "B. O(log V)", "C. O(V)", "D. O(V^2)", "C"
"Dijkstra", "Which of the following is a common application of Dijkstra?", "A. Network routing protocols (e.g., OSPF).", "B. Building minimum spanning trees.", "C. Finding maximum flow.", "D. Topological sorting.", "A"
"Dijkstra", "If `relax(u, v)` is called, what condition must be true for `dist[v]` to be updated?", "A. `dist[v] > dist[u]`", "B. `dist[v] < dist[u] + weight(u,v)`", "C. `dist[v] > dist[u] + weight(u,v)`", "D. `dist[u] == infinity`", "C"
"Dijkstra", "What is the largest possible value for an edge weight that Dijkstra can handle?", "A. Any positive integer.", "B. Any non-negative real number.", "C. Max_Int.", "D. Infinity (but not negative infinity).", "B"
"Dijkstra", "The set of vertices extracted from the priority queue and added to the 'settled' set forms what kind of structure?", "A. A cycle.", "B. A path.", "C. A tree (specifically, the shortest path tree).", "D. A forest.", "C"
"Dijkstra", "What is a 'decrease-key' operation in a priority queue essential for when implementing Dijkstra efficiently?", "A. To add new vertices.", "B. To reduce the priority of a vertex (update its distance) already in the priority queue if a shorter path is found.", "C. To remove vertices from the priority queue.", "D. To increase the priority of a vertex.", "B"
"Dijkstra", "If all edge weights are 1, what does Dijkstra effectively become?", "A. DFS", "B. BFS", "C. Prim's Algorithm", "D. Bellman-Ford", "B"
"Dijkstra", "When `dist[v]` is finalized (vertex `v` is extracted from the priority queue), what is guaranteed about `dist[v]`?", "A. It's the longest path from source to `v`.", "B. It's the shortest path from source to `v`.", "C. It's the distance to its parent.", "D. It's `0`.", "B"
"Dijkstra", "What is the typical representation of `infinity` for distances in Dijkstra?", "A. -1", "B. 0", "C. A very large integer (e.g., `Integer.MAX_VALUE` or `Long.MAX_VALUE`) or actual `Double.POSITIVE_INFINITY`.", "D. Null", "C"
"Dijkstra", "What happens to the priority of a vertex in the priority queue if a shorter path to it is found during relaxation?", "A. Its priority decreases (becomes higher in a min-heap).", "B. Its priority increases (becomes lower in a min-heap).", "C. Its priority remains the same.", "D. It is removed from the queue.", "A"
"Dijkstra", "What type of graph problem does Dijkstra NOT directly solve?", "A. Single-source shortest path.", "B. All-pairs shortest path (without running V times).", "C. Shortest path with non-negative weights.", "D. Shortest path in a connected graph.", "B"
"Kruskal", "What is the primary purpose of Kruskal?", "A. To find the shortest path between two specific vertices.", "B. To find a Minimum Spanning Tree (MST) in a connected, undirected, weighted graph.", "C. To detect cycles in a graph.", "D. To find all-pairs shortest paths.", "B"
"Kruskal", "Kruskal belongs to which category of algorithms?", "A. Dynamic Programming", "B. Greedy algorithm", "C. Divide and Conquer", "D. Backtracking", "B"
"Kruskal", "What data structure is essential for efficiently implementing Kruskal to manage disjoint sets of vertices?", "A. Priority Queue", "B. Adjacency List", "C. Disjoint Set Union (DSU) / Union-Find data structure", "D. Stack", "C"
"Kruskal", "What is the first step in Kruskal?", "A. Start with an arbitrary vertex.", "B. Sort all edges of the graph in non-decreasing order of their weights.", "C. Create a graph with all vertices and no edges.", "D. Find the shortest path to all vertices.", "B"
"Kruskal", "After sorting the edges, what does Kruskal do iteratively?", "A. Adds vertices to the MST.", "B. Adds edges that connect two distinct components and do not form a cycle.", "C. Removes edges that form cycles.", "D. Selects edges randomly.", "B"
"Kruskal", "What is the condition for an edge `(u, v)` to be added to the MST in Kruskal?", "A. The edge must have the smallest weight among all edges.", "B. Vertices `u` and `v` must already be in the same component.", "C. Adding the edge `(u, v)` must not form a cycle with already chosen edges, and `u` and `v` must be in different components.", "D. The edge must connect to the source vertex.", "C"
"Kruskal", "What is the time complexity of sorting edges in Kruskal if there are `E` edges?", "A. O(E)", "B. O(V)", "C. O(E log E) or O(E log V) since E can be at most V^2, so log E approx 2 log V", "D. O(V^2)", "C"
"Kruskal", "What is the time complexity of the Union-Find operations (Find and Union) in Kruskal over `E` edge processing steps?", "A. O(E)", "B. O(E log V)", "C. Nearly O(E) amortized time (using path compression and union by rank/size).", "D. O(V^2)", "C"
"Kruskal", "What is the overall time complexity of Kruskal with `V` vertices and `E` edges, assuming an efficient Union-Find implementation?", "A. O(V + E)", "B. O(V^2)", "C. O(E log E) or O(E log V)", "D. O(V log V)", "C"
"Kruskal", "Does Kruskal work on disconnected graphs?", "A. Yes, it finds an MST for each connected component (a Minimum Spanning Forest).", "B. No, it requires a connected graph to work correctly.", "C. Only if all components have the same number of vertices.", "D. It crashes on disconnected graphs.", "A"
"Kruskal", "Can Kruskal handle negative edge weights?", "A. No, it requires all weights to be positive.", "B. Yes, it works correctly with negative edge weights as long as there are no negative cycles (which are not relevant for MSTs anyway).", "C. Only if all weights are negative.", "D. It loops infinitely with negative weights.", "B"
"Kruskal", "What is the number of edges in a Minimum Spanning Tree of a connected graph with `V` vertices?", "A. V", "B. V-1", "C. E", "D. E-1", "B"
"Kruskal", "If there are multiple edges with the same minimum weight, how does Kruskal typically handle ties?", "A. It picks all of them.", "B. It picks the first one encountered after sorting, but any choice would lead to a valid MST.", "C. It picks none of them.", "D. It asks the user to decide.", "B"
"Kruskal", "What property does an MST have regarding cycles?", "A. It contains at least one cycle.", "B. It contains no cycles.", "C. It contains exactly one cycle.", "D. It contains only self-loops.", "B"
"Kruskal", "What is the primary difference between Kruskal and Prim's algorithm for MST?", "A. Kruskal adds vertices, Prim's adds edges.", "B. Kruskal is edge-centric, Prim's is vertex-centric.", "C. Kruskal uses a priority queue, Prim's uses Union-Find.", "D. Kruskal works on directed graphs, Prim's on undirected.", "B"
"Kruskal", "Which property of MSTs is directly exploited by Kruskal?", "A. Cut Property (or Bridge Property)", "B. Cycle Property", "C. Shortest Path Property", "D. Connectivity Property", "B"
"Kruskal", "In the Disjoint Set Union (Union-Find) data structure, what does the `Find` operation do?", "A. Joins two sets.", "B. Returns the representative (root) of the set containing a given element.", "C. Inserts an element into a set.", "D. Deletes an element from a set.", "B"
"Kruskal", "In the Disjoint Set Union (Union-Find) data structure, what does the `Union` operation do?", "A. Checks if two elements are in the same set.", "B. Merges two sets into one.", "C. Creates a new set for an element.", "D. Finds the parent of an element.", "B"
"Kruskal", "Consider a graph with `V` vertices and `E` edges. If `E` is very small (sparse graph), which algorithm is generally faster for MST?", "A. Prim's Algorithm (with Binary Heap)", "B. Kruskal", "C. Both are equally fast.", "D. Neither works efficiently.", "B"
"Kruskal", "Consider a graph with `V` vertices and `E` edges. If `E` is very large (dense graph), which algorithm is generally faster for MST?", "A. Prim's Algorithm (with Adjacency Matrix / simple array)", "B. Kruskal", "C. Both are equally fast.", "D. Neither works efficiently.", "A"
"Kruskal", "If a graph has multiple MSTs due to equal edge weights, does Kruskal guarantee finding all of them?", "A. Yes, always.", "B. No, it finds one specific MST depending on the tie-breaking rule during sorting.", "C. Only if the graph is a tree.", "D. Only if all edge weights are unique.", "B"
"Kruskal", "What does it mean for an undirected graph to be 'connected'?", "A. It has no cycles.", "B. There is a path between every pair of distinct vertices.", "C. All vertices have the same degree.", "D. It has at least one edge.", "B"
"Kruskal", "What is a 'forest' in graph theory?", "A. A connected graph with cycles.", "B. A collection of disjoint trees.", "C. A graph with no vertices.", "D. A graph with all vertices connected to a central node.", "B"
"Kruskal", "When implementing Kruskal, how do you initially represent each vertex for the Union-Find structure?", "A. All vertices in one large set.", "B. Each vertex in its own individual set.", "C. Vertices are not part of any set initially.", "D. Vertices are grouped by their degrees.", "B"
"Kruskal", "What is the primary benefit of path compression in Union-Find?", "A. Reduces memory usage.", "B. Makes `Union` operations faster.", "C. Flattens the tree structure, speeding up future `Find` operations.", "D. Detects cycles more accurately.", "C"
"Kruskal", "What is the primary benefit of union by rank (or size) in Union-Find?", "A. Reduces memory usage.", "B. Ensures the trees remain relatively balanced, speeding up future `Union` operations.", "C. Detects cycles more accurately.", "D. Makes `Find` operations faster.", "B"
"Kruskal", "If `Find(u)` and `Find(v)` return the same representative during Kruskal, what does it mean?", "A. `u` and `v` are isolated vertices.", "B. `u` and `v` are already in the same connected component.", "C. `u` and `v` are directly connected by an edge.", "D. The graph has no cycles.", "B"
"Kruskal", "The edges selected by Kruskal are guaranteed to be:", "A. The heaviest edges that don't form a cycle.", "B. The edges that form the shortest path.", "C. The lightest edges that don't form a cycle.", "D. Any random edges.", "C"
"Kruskal", "When Kruskal terminates, what condition is met?", "A. All vertices are visited.", "B. All edges have been processed.", "C. An MST containing V-1 edges (for connected graph) has been formed, or a spanning forest for disconnected graph.", "D. No more cycles can be formed.", "C"
"Kruskal", "Is Kruskal suitable for graphs with directed edges?", "A. Yes, it works for directed graphs to find an MST.", "B. No, the concept of MST is typically for undirected graphs. Kruskal relies on properties of undirected edges.", "C. Only if the directed graph is a DAG.", "D. Only if all edges have the same weight.", "B"
"Kruskal", "What is a 'spanning tree'?", "A. A tree that includes some of the vertices of a graph.", "B. A subgraph that is a tree and connects all the vertices of the graph.", "C. Any tree within a graph.", "D. A path that visits all vertices.", "B"
"Kruskal", "What happens if Kruskal is applied to a disconnected graph?", "A. It crashes.", "B. It finds a Minimum Spanning Forest (MST for each component).", "C. It only finds an MST for the largest connected component.", "D. It finds a single path.", "B"
"Kruskal", "In the context of Kruskal, what does 'cutting an edge' mean?", "A. Removing it from consideration permanently.", "B. Breaking a cycle.", "C. Selecting it for the MST.", "D. Decreasing its weight.", "C"
"Kruskal", "Why is sorting edges crucial for Kruskal's correctness?", "A. It ensures that the smallest edges are considered first, supporting the greedy choice property.", "B. It helps detect cycles faster.", "C. It simplifies the Union-Find operations.", "D. It reduces memory usage.", "A"
"Kruskal", "Which of these graph problems is NOT directly solved by Kruskal?", "A. Minimum Spanning Tree.", "B. Shortest path between two specific nodes.", "C. Finding connected components (as a byproduct of Union-Find).", "D. Network design optimization.", "B"
"Kruskal", "If a graph has `V=4` vertices and `E=6` edges with weights: (A,B,1), (A,C,2), (B,C,3), (B,D,4), (C,D,5), (A,D,6). What is the first edge chosen by Kruskal?", "A. (A,B,1)", "B. (A,C,2)", "C. (B,C,3)", "D. (A,D,6)", "A"
"Kruskal", "Following the previous question's graph and selected edge (A,B,1), what would be the next edge chosen by Kruskal?", "A. (B,C,3)", "B. (A,C,2)", "C. (B,D,4)", "D. (A,D,6)", "B"
"Kruskal", "Consider a graph. After (A,B,1) and (A,C,2) are selected. Next edge is (B,C,3). Should it be selected?", "A. Yes, always.", "B. No, because it forms a cycle (A-B-C-A) with already selected edges.", "C. Only if it's the smallest remaining.", "D. Only if it connects to a new component.", "B"
"Kruskal", "What is the maximum number of times the `Union` operation is performed in Kruskal for a connected graph with `V` vertices?", "A. V", "B. V-1", "C. E", "D. E-1", "B"
"Kruskal", "Why is Kruskal often preferred for very sparse graphs?", "A. Its sorting step dominates, and for sparse graphs, E log E is often less than V^2.", "B. Its Union-Find operations are faster for sparse graphs.", "C. It uses less memory for sparse graphs.", "D. It is simpler to implement.", "A"
"Kruskal", "What is the smallest possible weight of an edge in a graph that Kruskal can handle?", "A. 1", "B. 0", "C. Any real number (positive, negative, or zero).", "D. Only positive integers.", "C"
"Kruskal", "If a graph has `V` vertices and `E` edges, what is the maximum number of edges Kruskal will attempt to consider for inclusion?", "A. V-1", "B. V", "C. E", "D. E+V", "C"
"Kruskal", "What is the output of Kruskal for a connected graph?", "A. A list of shortest paths.", "B. A set of edges forming a Minimum Spanning Tree.", "C. A set of disjoint components.", "D. A sorted list of all edges.", "B"
"Kruskal", "Kruskal operates by maintaining a set of disjoint sets of vertices. Initially, each vertex is in its own set. This represents:", "A. All vertices are connected.", "B. No edges have been added yet, and each vertex is a separate component.", "C. The graph is fully connected.", "D. The graph has cycles.", "B"
"Kruskal", "If a graph has distinct edge weights, how many Minimum Spanning Trees can it have?", "A. Zero", "B. One", "C. Multiple", "D. Depends on the number of vertices.", "B"
"Kruskal", "What is the best case time complexity for Kruskal?", "A. O(V)", "B. O(E log E)", "C. O(V + E)", "D. O(1)", "B"
"Kruskal", "Does Kruskal require the graph to be represented in a specific way (e.g., Adjacency List/Matrix)?", "A. Yes, only Adjacency Matrix.", "B. Yes, only Adjacency List.", "C. No, an Edge List representation is most natural and efficient for sorting.", "D. Yes, only an implicit representation.", "C"
"Kruskal", "When using the Union-Find structure in Kruskal, what is the value stored in the `parent` array for a root of a set?", "A. Its own index.", "B. -1 (or some other indicator).", "C. The index of its first child.", "D. The weight of an edge.", "B"
"Kruskal", "What is the maximum rank (or height) of a tree in a Union-Find structure with `V` elements, when using union by rank and path compression?", "A. O(1)", "B. O(log V)", "C. O(V)", "D. O(alpha(V)) (inverse Ackermann function)", "B"
"Kruskal", "The efficiency of Kruskal is heavily reliant on the performance of which two operations?", "A. BFS and DFS.", "B. Sorting and Union-Find operations.", "C. Matrix multiplication and inversion.", "D. Hashing and searching.", "B"
"Prim", "What is the primary purpose of Prim?", "A. To find the shortest path between two specific vertices.", "B. To find a Minimum Spanning Tree (MST) in a connected, undirected, weighted graph.", "C. To detect cycles in a graph.", "D. To find all-pairs shortest paths.", "B"
"Prim", "Prim belongs to which category of algorithms?", "A. Dynamic Programming", "B. Greedy algorithm", "C. Divide and Conquer", "D. Backtracking", "B"
"Prim", "What data structure is essential for efficiently implementing Prim to select the next vertex to add to the MST?", "A. Stack", "B. Queue", "C. Priority Queue (Min-Heap)", "D. Hash Table", "C"
"Prim", "What is the starting point for Prim?", "A. Any arbitrary edge in the graph.", "B. Any arbitrary vertex in the graph.", "C. The vertex with the highest degree.", "D. The vertex with the smallest ID.", "B"
"Prim", "Prim grows the MST by iteratively adding which element?", "A. The vertex with the minimum distance from the source.", "B. The edge with the smallest weight that connects a vertex in the MST to a vertex outside the MST.", "C. Any edge that doesn't form a cycle.", "D. The vertex with the most unvisited neighbors.", "B"
"Prim", "What is the time complexity of Prim using a simple array (linear scan) to find the minimum edge?", "A. O(V + E)", "B. O(V^2)", "C. O(E log V)", "D. O(V log V)", "B"
"Prim", "What is the time complexity of Prim using a Binary Min-Heap based Priority Queue for selection?", "A. O(V + E)", "B. O(V^2)", "C. O(E log V)", "D. O(V log E)", "C"
"Prim", "Can Prim handle negative edge weights?", "A. No, it requires all weights to be non-negative (positive or zero).", "B. Yes, it works correctly with negative edge weights.", "C. Only if all weights are negative.", "D. It loops infinitely with negative weights.", "A"
"Prim", "What is the number of edges in a Minimum Spanning Tree of a connected graph with `V` vertices?", "A. V", "B. V-1", "C. E", "D. E-1", "B"
"Prim", "Prim's correctness relies on which property of MSTs?", "A. Cycle Property", "B. Cut Property (or Bridge Property)", "C. Shortest Path Property", "D. Connectivity Property", "B"
"Prim", "In Prim, what does `key[v]` typically represent?", "A. The final weight of the edge connecting `v` to the MST.", "B. The minimum weight of an edge connecting `v` to any vertex already in the MST.", "C. The distance from the source to `v`.", "D. The degree of vertex `v`.", "B"
"Prim", "What does `parent[v]` typically store in Prim?", "A. The previous vertex in the shortest path.", "B. The vertex in the MST to which `v` is connected by the minimum weight edge.", "C. The root of the component `v` belongs to.", "D. Its own index.", "B"
"Prim", "What is the initial `key` value for the starting vertex in Prim?", "A. Infinity", "B. 1", "C. 0", "D. -1", "C"
"Prim", "What is the initial `key` value for all other non-starting vertices in Prim?", "A. 0", "B. 1", "C. Infinity", "D. -1", "C"
"Prim", "How many times is each vertex extracted from the priority queue in Prim (in a correctly implemented version)?", "A. Zero times.", "B. Exactly once.", "C. Multiple times, if its key value is updated.", "D. V times.", "B"
"Prim", "If a graph has `V` vertices and `E` edges, what is the maximum number of `decrease-key` operations on the priority queue during Prim?", "A. V", "B. E", "C. V+E", "D. E log V", "B"
"Prim", "What is 'relaxation' in the context of Prim?", "A. Adding a new vertex to the graph.", "B. Updating the `key` value of a neighbor if a lighter edge is found connecting it to the growing MST.", "C. Removing an edge from the graph.", "D. Resetting all key values to infinity.", "B"
"Prim", "Does Prim work on disconnected graphs?", "A. Yes, it finds an MST for each connected component (a Minimum Spanning Forest).", "B. No, it finds an MST only if the graph is connected. If disconnected, it finds an MST for the component of the starting vertex.", "C. Only if all components have the same number of vertices.", "D. It crashes on disconnected graphs.", "B"
"Prim", "Which type of graph representation is generally more efficient for Prim when using a Binary Heap?", "A. Adjacency Matrix", "B. Adjacency List", "C. Edge List", "D. Hash Table", "B"
"Prim", "Consider a graph with `V` vertices and `E` edges. If `E` is very small (sparse graph), which MST algorithm is generally faster?", "A. Prim (with Fibonacci Heap)", "B. Kruskal", "C. Both are equally fast.", "D. Neither works efficiently.", "B"
"Prim", "Consider a graph with `V` vertices and `E` edges. If `E` is very large (dense graph), which MST algorithm is generally faster?", "A. Prim (with Adjacency Matrix / simple array)", "B. Kruskal", "C. Both are equally fast.", "D. Neither works efficiently.", "A"
"Prim", "What is the primary difference between Prim and Kruskal for MST?", "A. Prim builds the MST by adding edges in increasing order of weight; Kruskal builds it by extending a single component.", "B. Prim extends a single growing component; Kruskal builds the MST by adding edges that connect two distinct components.", "C. Prim uses Union-Find; Kruskal uses a Priority Queue.", "D. Prim works on directed graphs; Kruskal on undirected.", "B"
"Prim", "Prim's Algorithm maintains a set of vertices already included in the MST. What does this set ensure?", "A. All vertices will be connected.", "B. That no cycles are formed.", "C. Only the shortest paths are chosen.", "D. The algorithm terminates quickly.", "B"
"Prim", "If there are multiple edges with the same minimum weight that could be added, how does Prim typically handle ties?", "A. It picks all of them.", "B. It picks one of them, but any choice would lead to a valid MST.", "C. It picks none of them.", "D. It asks the user to decide.", "B"
"Prim", "Is Prim suitable for graphs with directed edges?", "A. Yes, it works for directed graphs to find an MST.", "B. No, the concept of MST is typically for undirected graphs. Prim relies on symmetric connections.", "C. Only if the directed graph is a DAG.", "D. Only if all edges have the same weight.", "B"
"Prim", "What is the final number of edges in the MST constructed by Prim for a connected graph with `V` vertices?", "A. V", "B. V-1", "C. E", "D. E-1", "B"
"Prim", "When Prim terminates for a connected graph, what condition is met?", "A. All edges have been processed.", "B. An MST containing V-1 edges has been formed, and all vertices are included.", "C. No more cycles can be formed.", "D. The priority queue is empty and all edges have been relaxed.", "B"
"Prim", "If all edge weights are identical (e.g., all 1s), what does Prim effectively become?", "A. DFS", "B. BFS", "C. Dijkstra's Algorithm", "D. Kruskal's Algorithm", "B"
"Prim", "Which of these is a typical real-world application of MST algorithms like Prim?", "A. Finding the shortest driving route.", "B. Designing a network to connect several locations with minimum cable length.", "C. Sorting a list of items.", "D. Searching for an item in a database.", "B"
"Prim", "What is a 'Fibonacci Heap' and how does it relate to Prim?", "A. A type of graph that optimizes Prim.", "B. A specialized priority queue that provides the asymptotically fastest known worst-case running time for Prim (O(E + V log V)).", "C. An alternative algorithm to Prim.", "D. A data structure for storing negative weights.", "B"
"Prim", "When `key[v]` is finalized (vertex `v` is extracted from the priority queue), what is guaranteed about `key[v]`?", "A. It's the longest edge connecting `v` to the MST.", "B. It's the minimum weight edge connecting `v` to the MST built so far.", "C. It's the distance from `v` to the starting vertex.", "D. It's `0`.", "B"
"Prim", "What is the typical representation of `infinity` for `key` values in Prim?", "A. -1", "B. 0", "C. A very large integer (e.g., `Integer.MAX_VALUE` or `Long.MAX_VALUE`).", "D. Null", "C"
"Prim", "What happens to the priority of a vertex in the priority queue if a lighter edge connecting it to the MST is found during relaxation?", "A. Its priority decreases (becomes higher in a min-heap).", "B. Its priority increases (becomes lower in a min-heap).", "C. Its priority remains the same.", "D. It is removed from the queue.", "A"
"Prim", "Prim's Algorithm is analogous to which shortest path algorithm in its structure?", "A. Bellman-Ford Algorithm", "B. Floyd-Warshall Algorithm", "C. Dijkstra's Algorithm (both use a greedy approach with a priority queue)", "D. A* Search Algorithm", "C"
"Prim", "What is the crucial 'cut property' that MST algorithms leverage?", "A. If you cut the graph into two parts, the lightest edge crossing the cut must be in the MST.", "B. If you remove an edge, the graph becomes disconnected.", "C. All edges in an MST must have distinct weights.", "D. Any cycle must contain an edge not in the MST.", "A"
"Prim", "Can Prim find more than one MST if they exist for a given graph?", "A. Yes, it will list all of them.", "B. No, it finds one specific MST depending on arbitrary tie-breaking.", "C. Only if the graph is very small.", "D. Only if all edge weights are equal.", "B"
"Prim", "What is the purpose of the `inMST` (or `visited`) boolean array in Prim?", "A. To track which vertices have been explored by DFS.", "B. To track which vertices are currently in the priority queue.", "C. To mark vertices that have been included in the Minimum Spanning Tree.", "D. To indicate if a vertex is disconnected.", "C"
"Prim", "If a graph has `V` vertices and `E` edges. For a sparse graph, which representation is more memory efficient for Prim?", "A. Adjacency Matrix", "B. Adjacency List", "C. Edge List", "D. Both are equally efficient", "B"
"Prim", "If a graph has `V` vertices and `E` edges. For a dense graph, which representation is more efficient for Prim when using a simple array (O(V^2))?", "A. Adjacency Matrix", "B. Adjacency List", "C. Edge List", "D. Hash Table", "A"
"Prim", "Which operation is performed repeatedly in Prim to update `key` values of neighboring vertices?", "A. `Find` operation.", "B. `Union` operation.", "C. `Decrease-key` operation on the priority queue.", "D. `Enqueue` operation.", "C"
"Prim", "What is the time complexity to initialize `key` values to infinity for `V` vertices and set `parent` pointers?", "A. O(1)", "B. O(log V)", "C. O(V)", "D. O(V^2)", "C"
"Prim", "The set of edges added to the MST by Prim forms what kind of structure?", "A. A cycle.", "B. A path.", "C. A tree.", "D. A forest.", "C"
"Prim", "How does Prim handle isolated vertices (vertices not connected to the starting component)?", "A. It processes them first.", "B. It ignores them; their `key` values will remain infinity, and they won't be part of the MST.", "C. Their `key` values become 0.", "D. It causes an error.", "B"
"Prim", "What is the maximum number of edges considered by Prim for selection (not including edges in relaxation)?", "A. V-1", "B. V", "C. E", "D. E+V", "A"
"Prim", "What is the advantage of Prim over Kruskal for dense graphs?", "A. Prim's O(V^2) or O(E + V log V) can be better than Kruskal's O(E log E) when E is large.", "B. Prim uses less memory.", "C. Prim is simpler to implement.", "D. Prim handles negative weights.", "A"
"Prim", "Which version of Prim uses an Adjacency Matrix and a simple array to achieve O(V^2) complexity?", "A. Prim with Binary Heap.", "B. Prim without a priority queue.", "C. Prim with Fibonacci Heap.", "D. Prim with Union-Find.", "B"
"Prim", "If a graph has `V` vertices and the edge weights are all positive, will Prim find the correct MST?", "A. No, only if all weights are 1.", "B. Yes, always.", "C. Only if the graph is small.", "D. Only if the graph has no cycles.", "B"
"Prim", "What is the overall space complexity of Prim using a Binary Min-Heap?", "A. O(1)", "B. O(V) for `key`, `parent`, `inMST` arrays, and O(V) for the heap.", "C. O(E)", "D. O(V+E) for adjacency list.", "D"
"Prim", "Does Prim sort edges explicitly at the beginning?", "A. Yes, it sorts all edges.", "B. No, it picks the minimum edge greedily from candidate edges.", "C. Only if there are many edges.", "D. Only if weights are negative.", "B"
"Prim", "When implementing Prim, why is `delete-min` operation crucial for the priority queue?", "A. To remove a random vertex.", "B. To get the vertex with the currently smallest `key` value to add to the MST.", "C. To add a new edge.", "D. To decrease the key of a vertex.", "B"
"PriorityQueue", "What is the fundamental property of a PriorityQueue?", "A. Elements are retrieved in FIFO order.", "B. Elements are retrieved based on their priority, with the highest (or lowest) priority element retrieved first.", "C. Elements are retrieved in LIFO order.", "D. Elements are retrieved in insertion order.", "B"
"PriorityQueue", "Which of the following data structures is most commonly used to implement a PriorityQueue efficiently?", "A. Linked List", "B. Array", "C. Heap (Binary Heap is common)", "D. Hash Table", "C"
"PriorityQueue", "In a Max-PriorityQueue, which element has the highest priority?", "A. The smallest element.", "B. The largest element.", "C. The element inserted first.", "D. The element inserted last.", "B"
"PriorityQueue", "In a Min-PriorityQueue, which element has the highest priority?", "A. The smallest element.", "B. The largest element.", "C. The element inserted first.", "D. The element inserted last.", "A"
"PriorityQueue", "What is the time complexity to insert an element into a Binary Heap-based PriorityQueue with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"PriorityQueue", "What is the time complexity to extract the minimum/maximum element from a Binary Heap-based PriorityQueue with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"PriorityQueue", "What is the time complexity to peek (look at, but not remove) the minimum/maximum element from a Binary Heap-based PriorityQueue?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "A"
"PriorityQueue", "Which of the following algorithms uses a PriorityQueue (specifically a Min-PriorityQueue)?", "A. BFS (Breadth-First Search)", "B. DFS (Depth-First Search)", "C. Dijkstra's Algorithm", "D. Topological Sort", "C"
"PriorityQueue", "Which of the following algorithms uses a PriorityQueue (specifically a Min-PriorityQueue)?", "A. Kruskal's Algorithm (for sorting edges first, but not dynamically using PQ for components)", "B. Prim's Algorithm", "C. Bellman-Ford Algorithm", "D. Floyd-Warshall Algorithm", "B"
"PriorityQueue", "A 'decrease-key' operation on a PriorityQueue is crucial for which algorithm?", "A. BFS", "B. DFS", "C. Dijkstra's and Prim's Algorithms", "D. QuickSort", "C"
"PriorityQueue", "If a PriorityQueue is implemented using an unsorted array, what would be the time complexity for `extract-min` (or `extract-max`)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"PriorityQueue", "If a PriorityQueue is implemented using a sorted array, what would be the time complexity for `insert`?", "A. O(1)", "B. O(log N) (binary search for position)", "C. O(N) (for shifting elements)", "D. O(N log N)", "C"
"PriorityQueue", "What is the space complexity of a Binary Heap-based PriorityQueue with `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"PriorityQueue", "Can a PriorityQueue store duplicate elements?", "A. No, never.", "B. Yes, if their priorities are the same, their relative order is usually undefined or depends on implementation.", "C. Only if their priorities are different.", "D. Only if they are primitive types.", "B"
"PriorityQueue", "What is a 'Fibonacci Heap' commonly used for?", "A. To implement a faster Hash Table.", "B. To achieve asymptotically better worst-case time complexity for Dijkstra's and Prim's algorithms, especially for dense graphs.", "C. To sort elements in linear time.", "D. To implement a simple queue.", "B"
"PriorityQueue", "In a Binary Heap, where is the element with the highest priority always located?", "A. At the root of the heap.", "B. At the last leaf node.", "C. In the middle of the heap.", "D. It varies depending on the element's value.", "A"
"PriorityQueue", "The `heapify` operation in a Binary Heap takes what time complexity?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"PriorityQueue", "Building a heap from `N` unsorted elements using `heapify` operations takes what time complexity?", "A. O(log N)", "B. O(N)", "C. O(N log N)", "D. O(N^2)", "B"
"PriorityQueue", "Which of these is NOT a common operation on a PriorityQueue?", "A. `Insert` (add element)", "B. `Extract-Min` / `Extract-Max` (remove highest priority element)", "C. `Delete` (remove specific element by value/key)", "D. `Search` (find element by value)", "D"
"PriorityQueue", "If you need to implement a PriorityQueue where `decrease-key` is a frequent operation, which heap type is theoretically best?", "A. Binary Heap", "B. D-ary Heap", "C. Fibonacci Heap", "D. Skew Heap", "C"
"PriorityQueue", "What does it mean for a heap to satisfy the 'heap property'?", "A. All elements are sorted.", "B. The value of a parent node is always greater than (or less than, for min-heap) the values of its children.", "C. The tree is always a complete binary tree.", "D. All leaf nodes have the same depth.", "B"
"PriorityQueue", "Is a Binary Search Tree (BST) a good choice for implementing a PriorityQueue?", "A. Yes, always.", "B. No, `extract-min`/`max` could be O(N) in worst case (skewed tree), and `decrease-key` is not natural.", "C. Only if the BST is perfectly balanced.", "D. Only for small number of elements.", "B"
"PriorityQueue", "Which real-world scenario is a good fit for using a PriorityQueue?", "A. Managing tasks in a print queue (FIFO).", "B. Scheduling processes in an operating system based on their urgency.", "C. Storing user login information.", "D. Storing historical stock prices in chronological order.", "B"
"PriorityQueue", "If you implement a PriorityQueue using a simple sorted linked list, what is the insertion time complexity?", "A. O(1)", "B. O(log N)", "C. O(N) (to find correct insertion spot)", "D. O(N log N)", "C"
"PriorityQueue", "What is a 'binomial heap'?", "A. A type of queue where elements are removed randomly.", "B. A collection of binomial trees that forms a heap, offering better theoretical performance than binary heaps for some operations.", "C. A heap where elements are sorted alphabetically.", "D. A heap for boolean values only.", "B"
"PriorityQueue", "A Min-PriorityQueue can be used to simulate a Max-PriorityQueue by:", "A. Multiplying all priorities by -1.", "B. Adding a large constant to all priorities.", "C. Using a different internal data structure.", "D. It's not possible.", "A"
"PriorityQueue", "Which of the following sorting algorithms implicitly uses a heap (and thus a PriorityQueue concept)?", "A. Merge Sort", "B. Quick Sort", "C. Heap Sort", "D. Bubble Sort", "C"
"PriorityQueue", "If the elements in a PriorityQueue have numerical priorities, does a smaller number always mean higher priority?", "A. Yes, in a Max-PriorityQueue.", "B. Yes, in a Min-PriorityQueue.", "C. No, it depends on whether it's a Min-PQ (smaller = higher) or Max-PQ (larger = higher).", "D. Only if all priorities are positive.", "C"
"PriorityQueue", "What is the advantage of using a PriorityQueue over a regular Queue or Stack for certain algorithms?", "A. It guarantees constant time operations.", "B. It allows processing elements in an order determined by their importance, not just arrival time.", "C. It uses less memory.", "D. It's simpler to implement.", "B"
"PriorityQueue", "Consider a scenario where you always need to access the element that arrived earliest, but only among those elements with the highest priority. Which variant of PriorityQueue would this describe?", "A. A standard PriorityQueue with FIFO tie-breaking.", "B. A standard PriorityQueue with LIFO tie-breaking.", "C. A regular Queue.", "D. A Stack.", "A"
"PriorityQueue", "What is the primary operation that distinguishes a PriorityQueue from a simple queue or stack?", "A. `enqueue`", "B. `dequeue`", "C. `peek`", "D. `priority-based retrieval/extraction`", "D"
"PriorityQueue", "Can you efficiently find an arbitrary element by its value in a Binary Heap-based PriorityQueue?", "A. Yes, in O(1) time.", "B. Yes, in O(log N) time.", "C. No, it typically requires O(N) time as it's not designed for arbitrary search.", "D. Only if the heap is sorted.", "C"
"PriorityQueue", "What is the space complexity of Prim's Algorithm, largely due to the PriorityQueue?", "A. O(1)", "B. O(log V)", "C. O(V) for storing vertices in the PQ.", "D. O(E)", "C"
"PriorityQueue", "What is the space complexity of Dijkstra's Algorithm, largely due to the PriorityQueue?", "A. O(1)", "B. O(log V)", "C. O(V) for storing vertices in the PQ.", "D. O(E)", "C"
"PriorityQueue", "If you need to merge two PriorityQueues, which heap structure offers an efficient `meld`/`union` operation?", "A. Binary Heap (requires rebuilding or merging element by element).", "B. Fibonacci Heap or Skew Heap.", "C. Sorted Array.", "D. Unsorted Linked List.", "B"
"PriorityQueue", "A 'D-ary heap' is a generalization of a binary heap. What is `D`?", "A. The number of levels in the heap.", "B. The number of children each node can have (degree).", "C. The maximum priority value.", "D. The depth of the heap.", "B"
"PriorityQueue", "What is the benefit of a D-ary heap over a Binary Heap for certain operations?", "A. Faster `insert` and `extract-min` for very small D.", "B. Faster `decrease-key` if `D` is large (reducing depth to traverse up).", "C. Slower overall but uses less memory.", "D. It's always faster for all operations.", "B"
"PriorityQueue", "Which PriorityQueue operation directly impacts the total time complexity of Dijkstra's/Prim's if implemented with a simple array instead of a heap?", "A. `Insert`", "B. `Peek`", "C. `Extract-Min` (becomes O(V) instead of O(log V))", "D. `Delete`", "C"
"PriorityQueue", "If a PriorityQueue is used to implement a sorting algorithm, what is the initial step?", "A. Sort the elements directly.", "B. Insert all elements into the PriorityQueue.", "C. Create an empty PriorityQueue.", "D. Search for the smallest element.", "B"
"PriorityQueue", "After inserting all elements into a PriorityQueue for sorting, what is the next step?", "A. Continue inserting more elements.", "B. Repeatedly extract the min/max element until the PriorityQueue is empty, placing them into a sorted array/list.", "C. Perform a search operation.", "D. Build a new PriorityQueue.", "B"
"PriorityQueue", "Is a PriorityQueue typically used for graph traversal algorithms like BFS or DFS?", "A. Yes, always.", "B. No, BFS uses a standard queue and DFS uses a stack (or recursion stack).", "C. Only for weighted graphs.", "D. Only for directed graphs.", "B"
"PriorityQueue", "What is the primary role of the 'priority' assigned to an element in a PriorityQueue?", "A. To determine its alphabetical order.", "B. To determine its storage location in memory.", "C. To determine its retrieval order relative to other elements.", "D. To count its frequency.", "C"
"PriorityQueue", "If a PriorityQueue is empty, what should happen on an `extract-min` operation?", "A. It returns `0`.", "B. It returns `null` or throws an `EmptyQueueException`.", "C. It waits for an element to be inserted.", "D. It returns the smallest possible integer.", "B"
"PriorityQueue", "What is the difference between a PriorityQueue and a sorted list?", "A. A sorted list maintains all elements in sorted order; a PriorityQueue only guarantees that the highest priority element is easily accessible.", "B. A PriorityQueue is always faster.", "C. A sorted list cannot handle duplicates.", "D. A PriorityQueue can only store integers.", "A"
"PriorityQueue", "In a Binary Heap represented by an array, if a node is at index `i`, where are its children located?", "A. `2i+1` and `2i+2` (0-indexed).", "B. `i/2` and `i/2 + 1`.", "C. `i-1` and `i+1`.", "D. `2i` and `2i+1` (1-indexed).", "A"
"PriorityQueue", "In a Binary Heap represented by an array, if a node is at index `i`, where is its parent located?", "A. `2i+1`.", "B. `(i-1)/2` (integer division, 0-indexed).", "C. `i+1`.", "D. `i/2` (integer division, 1-indexed).", "B"
"PriorityQueue", "What is the 'heap property' for a Max-Heap?", "A. Parent is smaller than children.", "B. Parent is larger than or equal to children.", "C. All elements are unique.", "D. The heap is always full.", "B"
"PriorityQueue", "What is the 'heap property' for a Min-Heap?", "A. Parent is larger than children.", "B. Parent is smaller than or equal to children.", "C. All elements are unique.", "D. The heap is always full.", "B"
"PriorityQueue", "When is a `decrease-key` operation typically used in graph algorithms?", "A. When a node is added to the graph.", "B. When a shorter path (or lighter edge) is found to a vertex already in the PriorityQueue.", "C. When a cycle is detected.", "D. When the algorithm needs to terminate.", "B"
"PriorityQueue", "Could a balanced Binary Search Tree (like AVL or Red-Black Tree) be used to implement a PriorityQueue?", "A. No, never.", "B. Yes, with O(log N) for most operations, but potentially more complex than a heap.", "C. Only if it's a min-heap.", "D. Only if it's a max-heap.", "B"
"Trie", "What is a Trie (pronounced 'try') primarily used for?", "A. Storing data in a sorted order.", "B. Efficient retrieval of a key's value in a hash table.", "C. Efficient storage and retrieval of strings based on their prefixes.", "D. Representing graphs for shortest path algorithms.", "C"
"Trie", "A Trie is also known by what other name?", "A. Hash Map", "B. Prefix Tree", "C. Suffix Array", "D. Binary Search Tree", "B"
"Trie", "What is a node in a Trie typically composed of?", "A. A value and pointers to left and right children.", "B. An array or map of pointers (children) to other Trie nodes, indexed by characters, and often a flag indicating if it marks the end of a word.", "C. A single character and a pointer to the next character.", "D. A hash value and a linked list of collisions.", "B"
"Trie", "How is a word typically represented in a Trie?", "A. By a single node.", "B. By a path from the root to a node, with the last node in the path marked as the end of a word.", "C. By a hash of the word.", "D. By a linked list of characters.", "B"
"Trie", "What is the time complexity to insert a string of length `L` into a Trie?", "A. O(1)", "B. O(log N) where N is number of words.", "C. O(L) (proportional to the length of the string).", "D. O(L * alphabet_size)", "C"
"Trie", "What is the time complexity to search for a string of length `L` in a Trie?", "A. O(1)", "B. O(log N) where N is number of words.", "C. O(L) (proportional to the length of the string).", "D. O(L * alphabet_size)", "C"
"Trie", "What is the space complexity of a Trie containing `N` words with average length `L` and alphabet size `A` (worst case)?", "A. O(N)", "B. O(N * L)", "C. O(N * L * A)", "D. O(Total number of characters in all words * A)", "D"
"Trie", "What is the main advantage of a Trie over a hash table for string storage and retrieval?", "A. Faster average-case lookup.", "B. Supports prefix-based searching, auto-completion, and spell checking efficiently.", "C. Requires less memory.", "D. Easier to implement.", "B"
"Trie", "What is the main advantage of a Trie over a Binary Search Tree (BST) for string storage?", "A. Easier balancing.", "B. Faster average-case lookup.", "C. Faster worst-case lookup for strings (O(L) vs O(L*log N) or O(L*depth)).", "D. Uses less memory.", "C"
"Trie", "What is the purpose of the 'end of word' flag (or similar mechanism) in a Trie node?", "A. To mark the root of the Trie.", "B. To indicate that a path from the root to this node represents a complete word in the dictionary.", "C. To indicate that this node is a leaf node.", "D. To store the frequency of the word.", "B"
"Trie", "If two words share a common prefix, how are they stored in a Trie?", "A. They are stored in separate branches from the root.", "B. They share common nodes for their shared prefix, and then branch off.", "C. They are linked together in a list.", "D. One word is a child of the other.", "B"
"Trie", "Which of the following operations is a Trie particularly well-suited for?", "A. Finding the smallest element.", "B. Checking if a given prefix exists in a dictionary.", "C. Deleting a random element efficiently.", "D. Calculating the sum of all elements.", "B"
"Trie", "What happens to a Trie node if it has no children and is not marked as the end of a word, during a deletion process?", "A. It must be kept.", "B. It can be safely deleted.", "C. It can only be deleted if it's the root.", "D. Its parent must be deleted too.", "B"
"Trie", "How does a Trie handle varying lengths of strings?", "A. It can only store strings of the same length.", "B. It naturally accommodates varying lengths, with paths ending at different depths.", "C. It pads shorter strings with null characters.", "D. It converts all strings to the same length.", "B"
"Trie", "What is the maximum number of children a node in a standard Trie can have?", "A. 2 (binary tree).", "B. The size of the alphabet (e.g., 26 for English lowercase letters).", "C. Unlimited.", "D. Varies based on string length.", "B"
"Trie", "Can a Trie be used to store numbers instead of strings?", "A. No, only strings.", "B. Yes, by representing numbers as sequences of digits (e.g., in binary or decimal form).", "C. Only floating-point numbers.", "D. Only positive integers.", "B"
"Trie", "What is the main disadvantage of a Trie in terms of space complexity?", "A. It is always more space-efficient than hash tables.", "B. It can consume a lot of memory, especially if the alphabet is large or there are many short, distinct prefixes.", "C. It consumes constant space regardless of input.", "D. It requires external storage.", "B"
"Trie", "What is a 'compressed Trie' or 'Radix Tree'?", "A. A Trie that only stores numbers.", "B. A Trie optimized to reduce space by compressing paths that contain no branching nodes (single-child nodes).", "C. A Trie that only stores unique words.", "D. A Trie implemented using hashing.", "B"
"Trie", "Which of these is NOT a typical application of Tries?", "A. Auto-completion and spell-checking.", "B. IP routing (longest prefix matching).", "C. Storing and querying phone numbers.", "D. Finding the shortest path in a weighted graph.", "D"
"Trie", "What is the root node of a Trie?", "A. It represents the first character of the first word.", "B. It is an empty node that serves as the starting point for all words.", "C. It stores the longest word.", "D. It stores the number of words in the Trie.", "B"
"Trie", "If you search for a prefix `P` in a Trie, and it exists, how do you find all words starting with `P`?", "A. By performing a BFS or DFS starting from the node representing the end of prefix `P`.", "B. You cannot; a Trie only supports exact word lookup.", "C. By iterating through all words in the Trie.", "D. By rebuilding the Trie for that prefix.", "A"
"Trie", "Consider an empty Trie. When the first word 'cat' is inserted, how many nodes are typically created (excluding the root)?", "A. 1", "B. 2", "C. 3", "D. 4", "C"
"Trie", "Following the previous question, if 'car' is then inserted, how many *new* nodes are created (excluding the root and existing 'c' and 'a' nodes)?", "A. 1", "B. 2", "C. 3", "D. 4", "A"
"Trie", "What happens if you try to insert a word that already exists in a Trie?", "A. An error occurs.", "B. The word is re-inserted, creating duplicates.", "C. The 'end of word' flag of the existing node (if not already set) is set, and no new nodes are added for existing path.", "D. The old word is deleted and the new one inserted.", "C"
"Trie", "Can a Trie be used to count the frequency of words?", "A. No, it only stores presence.", "B. Yes, by adding a counter to each node marked as an 'end of word'.", "C. Only if all words have the same length.", "D. Only if the Trie is very small.", "B"
"Trie", "When deleting a word from a Trie, what is the safest approach for deleting nodes?", "A. Delete all nodes corresponding to the word's path.", "B. Only unset the 'end of word' flag. Then, starting from the last node of the word, traverse upwards, deleting nodes that are no longer part of any other word and have no children.", "C. Delete the root node.", "D. Rebuild the entire Trie without the word.", "B"
"Trie", "Is a Trie a tree data structure?", "A. No, it's a type of hash table.", "B. Yes, it's a tree where each node represents a prefix.", "C. It's a graph, not a tree.", "D. It's a linear data structure.", "B"
"Trie", "What determines the depth of a node in a Trie?", "A. Its position in the memory.", "B. The number of characters in the prefix it represents.", "C. The number of words passing through it.", "D. The order of insertion.", "B"
"Trie", "Can a Trie store associated values with words (like a dictionary/map)?", "A. No, only strings.", "B. Yes, by storing the value at the node marked as the 'end of word'.", "C. Only if the value is a string.", "D. Only if the value is an integer.", "B"
"Trie", "In a Trie, is it typically necessary to store the character itself within each node?", "A. Yes, always.", "B. No, the character is implied by the pointer from its parent (e.g., `children['a']` means this child represents 'a').", "C. Only for the root node.", "D. Only for leaf nodes.", "B"
"Trie", "What is a 'suffix tree'?", "A. A Trie that stores suffixes of a string, useful for pattern matching within a text.", "B. A Trie that only stores prefixes.", "C. A tree sorted by suffix.", "D. A Trie for finding shortest paths.", "A"
"Trie", "What is the typical alphabet size for an English dictionary Trie?", "A. 2 (binary).", "B. 10 (digits).", "C. 26 (lowercase letters) or 52 (case-sensitive letters).", "D. 256 (ASCII characters).", "C"
"Trie", "Compared to a balanced Binary Search Tree, when does a Trie perform better for string operations?", "A. When the strings are very long and distinct.", "B. When there are many strings sharing common prefixes.", "C. When searching for arbitrary elements.", "D. When space is extremely limited.", "B"
"Trie", "Compared to a hash table, when does a Trie perform better for string operations?", "A. When exact match lookup is the only requirement.", "B. When there's a need for prefix matching, auto-completion, or lexicographical ordering of keys.", "C. When dealing with very few strings.", "D. When hash collisions are not an issue.", "B"
"Trie", "What is a potential issue if a Trie uses a fixed-size array for children pointers for a large alphabet?", "A. Faster lookup always.", "B. High memory consumption due to many null pointers (sparse arrays).", "C. Reduced functionality.", "D. Difficulty in inserting elements.", "B"
"Trie", "How can the memory consumption of a Trie be optimized for large alphabets?", "A. By using a hash map or balanced tree instead of a fixed-size array for children pointers within each node.", "B. By storing only the last character of each word.", "C. By duplicating nodes.", "D. By storing all words in a single linked list.", "A"
"Trie", "What is the average time complexity for searching for a word in a Trie?", "A. O(1)", "B. O(log N)", "C. O(L) where L is the length of the word.", "D. O(L * alphabet_size)", "C"
"Trie", "Can a Trie directly help in finding the longest common substring between two given strings?", "A. Yes, directly.", "B. No, it's designed for prefixes.", "C. Yes, but it's more complicated and typically involves a suffix tree.", "D. Only if the strings are identical.", "C"
"Trie", "In a standard Trie, what does each edge typically represent?", "A. A complete word.", "B. A character.", "C. A prefix.", "D. A pointer to another Trie.", "B"
"Trie", "Is the order of insertion of words into a Trie significant for its structure?", "A. Yes, it completely changes the structure.", "B. No, the final structure for a given set of words is unique, regardless of insertion order.", "C. Only if words have common prefixes.", "D. Only for deletion operations.", "B"
"Trie", "What kind of traversal can be used to list all words in a Trie in lexicographical (alphabetical) order?", "A. BFS (Breadth-First Search).", "B. DFS (Depth-First Search) combined with iterating through children in alphabetical order.", "C. Random traversal.", "D. Post-order traversal.", "B"
"Trie", "What is the key idea behind 'longest prefix matching' often implemented with Tries in networking?", "A. Finding the shortest common prefix.", "B. Finding the longest prefix in a routing table that matches a destination IP address.", "C. Matching entire IP addresses exactly.", "D. Counting occurrences of prefixes.", "B"
"Trie", "Can a Trie be implemented recursively?", "A. No, only iteratively.", "B. Yes, recursive calls can simplify the insertion and search logic.", "C. Only for very small Tries.", "D. Only for deletion.", "B"
"Trie", "When comparing a Trie to a Hash Table, which is generally better for spell-checking suggestions (finding closest words)?", "A. Hash Table.", "B. Trie, because its structure naturally supports finding words with small edit distances (e.g., using Levenshtein distance with limited depth-first search).", "C. Both are equally good.", "D. Neither is good.", "B"
"Trie", "If you need to store millions of English words for quick prefix-based searching, which data structure is generally most suitable?", "A. Array.", "B. Linked List.", "C. Trie.", "D. Simple Hash Map.", "C"
"Trie", "What happens if a word is inserted into a Trie, and later a longer word that shares the same prefix is inserted?", "A. The first word is overwritten.", "B. The path for the longer word is extended from the common prefix, and the 'end of word' flag for the first word's end node remains set.", "C. An error occurs.", "D. The Trie has to be rebuilt.", "B"
"Trie", "In a Trie, if a node has multiple children, what does that signify?", "A. A single word branches off.", "B. Multiple words share the prefix up to that node and then diverge with different characters.", "C. An error in the Trie structure.", "D. The end of a word.", "B"
"Trie", "What is the `isEndOfWord` flag's type?", "A. Integer to store frequency.", "B. Boolean to indicate if this node completes a valid word.", "C. Character to store the last letter.", "D. Pointer to the next word.", "B"
"Trie", "If a Trie node represents the prefix 'app', and it has children for 'l' and 'e', what words could be formed?", "A. 'apl', 'ape'.", "B. 'appl', 'apple'.", "C. 'ap', 'pl', 'le'.", "D. 'app', 'l', 'e'.", "B"
"Trie", "The memory occupied by a Trie is proportional to the total number of unique prefixes stored. True or False?", "A. True", "B. False", "A"
"Knapsack", "What is the general goal of the Knapsack?", "A. To find the shortest path in a graph.", "B. To select items with given weights and values to maximize total value within a weight capacity.", "C. To sort a list of items efficiently.", "D. To find all possible combinations of items.", "B"
"Knapsack", "What are the two main types of the Knapsack?", "A. Single and Multiple.", "B. Fractional and 0/1.", "C. Bounded and Unbounded.", "D. Static and Dynamic.", "B"
"Knapsack", "Which algorithm design paradigm is commonly used to solve the 0/1 Knapsack?", "A. Greedy Algorithm", "B. Divide and Conquer", "C. Dynamic Programming", "D. Backtracking", "C"
"Knapsack", "Which algorithm design paradigm is commonly used to solve the Fractional Knapsack?", "A. Greedy Algorithm", "B. Divide and Conquer", "C. Dynamic Programming", "D. Backtracking", "A"
"Knapsack", "In the 0/1 Knapsack, what does '0/1' signify?", "A. Items can be taken zero or one time (i.e., entirely or not at all).", "B. The solution has a 0% or 100% chance of being optimal.", "C. There are only two types of items.", "D. The weight capacity is either 0 or 1.", "A"
"Knapsack", "In the Fractional Knapsack, what does 'Fractional' signify?", "A. Items can be broken into fractions.", "B. The weight capacity can be a fraction.", "C. The value of items can be a fraction.", "D. The problem is solved using fractions.", "A"
"Knapsack", "For the Fractional Knapsack, what is the greedy strategy?", "A. Always pick the item with the highest value.", "B. Always pick the item with the smallest weight.", "C. Always pick the item with the highest value-to-weight ratio.", "D. Always pick the item with the lowest value-to-weight ratio.", "C"
"Knapsack", "Why does the greedy approach work for Fractional Knapsack but not always for 0/1 Knapsack?", "A. Because items can be split, maximizing value density locally leads to global optimum.", "B. Because it's simpler to implement.", "C. Because it uses less memory.", "D. Because it has fewer constraints.", "A"
"Knapsack", "What is the time complexity of the greedy approach for Fractional Knapsack with `N` items?", "A. O(1)", "B. O(log N)", "C. O(N) (if items are already sorted by ratio)", "D. O(N log N) (due to sorting items by value-to-weight ratio).", "D"
"Knapsack", "The 0/1 Knapsack is an example of what type of computational problem?", "A. P-problem", "B. NP-complete problem", "C. Polynomial time problem", "D. Logarithmic time problem", "B"
"Knapsack", "What is the typical time complexity for solving the 0/1 Knapsack using dynamic programming with `N` items and a capacity `W`?", "A. O(N)", "B. O(W)", "C. O(N + W)", "D. O(N * W)", "D"
"Knapsack", "What does the `dp[i][w]` entry in a 2D DP table for 0/1 Knapsack typically represent?", "A. The maximum value that can be obtained with first `i` items and weight capacity `w`.", "B. The weight of the `i`-th item with value `w`.", "C. The number of items that can fit into capacity `w`.", "D. The minimum weight to achieve value `w` with `i` items.", "A"
"Knapsack", "What is the base case for the 0/1 Knapsack DP table?", "A. `dp[0][w] = 0` for all `w`, and `dp[i][0] = 0` for all `i`.", "B. `dp[0][0] = 1`.", "C. All `dp` values are initialized to infinity.", "D. The last row and column are 0.", "A"
"Knapsack", "In the 0/1 Knapsack DP recurrence relation, if item `i`'s weight `wi` is greater than current capacity `w`, what is `dp[i][w]` equal to?", "A. `dp[i-1][w]` (exclude item `i`).", "B. `value[i] + dp[i-1][w - wi]` (include item `i`).", "C. `0`.", "D. `infinity`.", "A"
"Knapsack", "In the 0/1 Knapsack DP recurrence relation, if item `i`'s weight `wi` is less than or equal to current capacity `w`, what is `dp[i][w]` equal to?", "A. `value[i] + dp[i-1][w - wi]`", "B. `dp[i-1][w]`", "C. `max(dp[i-1][w], value[i] + dp[i-1][w - wi])`", "D. `min(dp[i-1][w], value[i] + dp[i-1][w - wi])`", "C"
"Knapsack", "What is the space complexity of the 2D DP approach for 0/1 Knapsack?", "A. O(N)", "B. O(W)", "C. O(N * W)", "D. O(1)", "C"
"Knapsack", "Can the space complexity of the 0/1 Knapsack DP be optimized to O(W)?", "A. No, it's impossible.", "B. Yes, by using only two rows (current and previous) or a single 1D array.", "C. Only if N is very small.", "D. Only if W is very small.", "B"
"Knapsack", "When optimizing 0/1 Knapsack DP to O(W) space, which direction should the inner loop iterate for weights to avoid using the current item multiple times?", "A. From 1 to W.", "B. From W down to 1.", "C. It doesn't matter.", "D. Randomly.", "B"
"Knapsack", "What is the main characteristic that makes 0/1 Knapsack suitable for dynamic programming?", "A. Optimal Substructure and Overlapping Subproblems.", "B. Greedy Choice Property.", "C. Divide and Conquer principle.", "D. Backtracking nature.", "A"
"Knapsack", "The Unbounded Knapsack (also known as Complete Knapsack) allows:", "A. Only one of each item.", "B. Any number of each item.", "C. Only fractions of items.", "D. Items to be taken negative times.", "B"
"Knapsack", "What is the difference in the DP recurrence for Unbounded Knapsack compared to 0/1 Knapsack?", "A. In 0/1, we use `dp[i-1]` for both choices; in Unbounded, for including an item, we use `dp[i]` (or `dp[current_item]` in 1D space) instead of `dp[i-1]` for the remaining capacity, allowing reuse.", "B. Unbounded uses a different base case.", "C. Unbounded uses a `min` instead of `max`.", "D. There is no DP solution for Unbounded.", "A"
"Knapsack", "Consider a 0/1 Knapsack with Capacity W=5, Items: (Value=60, Weight=10), (Value=100, Weight=20), (Value=120, Weight=30). What is the maximum value?", "A. 0 (no items fit)", "B. 60", "C. 100", "D. 120", "A"
"Knapsack", "Consider a 0/1 Knapsack with Capacity W=50, Items: (Value=60, Weight=10), (Value=100, Weight=20), (Value=120, Weight=30). What is the maximum value?", "A. 160 (60+100)", "B. 180 (60+120)", "C. 220 (100+120)", "D. 280 (60+100+120)", "C"
"Knapsack", "Which of the following is NOT an application of the Knapsack?", "A. Resource allocation.", "B. Portfolio optimization.", "C. Cutting stock problem.", "D. Finding shortest paths in unweighted graphs.", "D"
"Knapsack", "If all items in a 0/1 Knapsack have the same weight, does the greedy approach (picking highest value first) work?", "A. Yes, always.", "B. No, never.", "C. Only if the weight is 1.", "D. Only if the capacity is very large.", "A"
"Knapsack", "If all items in a 0/1 Knapsack have the same value, does the greedy approach (picking smallest weight first) work?", "A. Yes, always.", "B. No, never.", "C. Only if the value is 1.", "D. Only if the capacity is very small.", "A"
"Knapsack", "What is the state space of the 0/1 Knapsack for N items and capacity W?", "A. N", "B. W", "C. N*W", "D. 2^N", "D"
"Knapsack", "Why is the 0/1 Knapsack considered NP-complete?", "A. Because its time complexity is O(N*W), which is polynomial if W is small.", "B. Because no known polynomial-time algorithm exists for arbitrary inputs (in terms of N and W).", "C. Because it has only two choices for each item.", "D. Because it is a minimization problem.", "B"
"Knapsack", "Can the 0/1 Knapsack be solved with a greedy approach if items are sorted by value-to-weight ratio?", "A. Yes, always.", "B. No, a greedy approach on ratio does not guarantee optimality for 0/1 Knapsack.", "C. Only if all weights are equal.", "D. Only if all values are equal.", "B"
"Knapsack", "What is a 'bounded' knapsack?", "A. Each item can be taken at most once.", "B. Each item can be taken any number of times.", "C. Each item can be taken a specific limited number of times.", "D. Only a specific number of items can be taken in total.", "C"
"Knapsack", "How can the Bounded Knapsack be transformed into a 0/1 Knapsack?", "A. By ignoring the bounds.", "B. By creating multiple copies of each item up to its bound, then treating each copy as a unique 0/1 item.", "C. By changing the values of the items.", "D. It cannot be transformed.", "B"
"Knapsack", "What is the memory required for the optimal O(W) space solution for 0/1 Knapsack?", "A. Proportional to the number of items.", "B. Proportional to the knapsack capacity.", "C. Proportional to the product of items and capacity.", "D. Constant memory.", "B"
"Knapsack", "Which type of recurrence relation is typical for dynamic programming solutions to Knapsack?", "A. Linear recurrence.", "B. Recursive definition with memoization.", "C. Exponential recurrence.", "D. Logarithmic recurrence.", "B"
"Knapsack", "Consider a Knapsack where items have weights but no values. The goal is to fill the knapsack as much as possible. This is a variant of:", "A. Subset Sum Problem.", "B. Change-making problem.", "C. Maximum Flow Problem.", "D. Traveling Salesperson Problem.", "A"
"Knapsack", "What does 'Pseudo-polynomial' time complexity mean for 0/1 Knapsack (O(N*W))?", "A. It's truly polynomial time.", "B. It's polynomial in the numerical value of the input (W), but exponential in the number of bits needed to represent W.", "C. It's always exponential.", "D. It's a non-deterministic polynomial time.", "B"
"Knapsack", "What happens if an item's weight is 0 in the 0/1 Knapsack?", "A. It causes an error.", "B. It can always be included without penalty, potentially leading to infinite value if value > 0 and unlimited items.", "C. It's treated as weight 1.", "D. It is ignored.", "B"
"Knapsack", "In a scenario where you have a list of tasks, each with a deadline and profit, and you want to maximize total profit by doing tasks that finish by their deadline (one task at a time). This is related to:", "A. Knapsack.", "B. Activity Selection Problem.", "C. Job Sequencing with Deadlines.", "D. Minimum Spanning Tree.", "C"
"Knapsack", "What is the primary constraint in a typical Knapsack?", "A. Time constraint.", "B. Weight/Capacity constraint.", "C. Number of items constraint.", "D. Value constraint.", "B"
"Knapsack", "If all item weights are very small (e.g., 1 or 2), does the DP solution for 0/1 Knapsack become faster?", "A. No, it remains O(N*W).", "B. Yes, effectively making W smaller in terms of operations related to item weights.", "C. Only if N is also small.", "D. It becomes O(N).", "A"
"Knapsack", "Which of these is NOT a characteristic of problems solvable by a greedy algorithm?", "A. Optimal Substructure.", "B. Greedy Choice Property.", "C. Overlapping Subproblems.", "D. Can sometimes provide a non-optimal solution (for problems where it's not applicable).", "C"
"Knapsack", "The term 'knapsack' refers to:", "A. A type of mathematical equation.", "B. A bag or backpack with a limited carrying capacity.", "C. A specific type of graph.", "D. A data structure.", "B"
"Knapsack", "For the 0/1 Knapsack, if the maximum capacity `W` is very large, but the number of items `N` is small, what alternative approach might be considered over standard DP?", "A. Brute force (2^N).", "B. Meet-in-the-Middle (dividing N items into two halves).", "C. Greedy approach.", "D. Graph traversal.", "B"
"Knapsack", "What if a 0/1 Knapsack specifies that only a fixed number of items `K` must be chosen?", "A. Standard DP can be adapted with an additional dimension for `k` items chosen.", "B. It becomes a simpler problem.", "C. It becomes impossible to solve.", "D. It can only be solved by a greedy approach.", "A"
"Knapsack", "The concept of 'profit' in Knapsack is equivalent to:", "A. Weight.", "B. Value.", "C. Volume.", "D. Cost.", "B"
"Knapsack", "In the 0/1 Knapsack, if an item's weight `wi` is equal to the current capacity `w`, the DP decision still involves:", "A. Only excluding the item.", "B. Only including the item.", "C. Taking the maximum of (excluding item) and (including item, if it fits).", "D. Summing values.", "C"
"Knapsack", "If you have a set of coins and a target amount, and you want to find the minimum number of coins to make that amount (with unlimited supply of each coin), this is similar to:", "A. 0/1 Knapsack (Coin Change DP - minimizing coins, not maximizing value).", "B. Unbounded Knapsack (Coin Change DP - minimizing coins, not maximizing value).", "C. Fractional Knapsack.", "D. Longest Common Subsequence.", "B"
"Knapsack", "What is the 'subset sum problem'?", "A. Finding a subset of numbers that sums to a specific target value (a decision problem related to 0/1 Knapsack).", "B. Finding the largest sum in an array.", "C. Summing all elements in a set.", "D. Finding subsets with maximum value.", "A"
"Knapsack", "Is the 0/1 Knapsack typically solved using recursion with memoization or iterative DP (bottom-up)?", "A. Only recursion with memoization.", "B. Only iterative DP.", "C. Both are valid and lead to the same complexity, iterative is often preferred for avoiding recursion depth limits.", "D. Neither, it's a greedy problem.", "C"
"Knapsack", "If all item weights and the knapsack capacity are integers, the 0/1 Knapsack DP solution works directly. True or False?", "A. True", "B. False", "A"
"Knapsack", "What is the output of a 0/1 Knapsack dynamic programming algorithm (typically)?", "A. The maximum value that can be put in the knapsack.", "B. A list of the items chosen.", "C. The remaining capacity.", "D. All possible combinations of items.", "A"
"LCS", "What does LCS stand for?", "A. Longest Common String", "B. Longest Connected Sequence", "C. Longest Common Subsequence", "D. Largest Current String", "C"
"LCS", "What is a 'subsequence'?", "A. A contiguous part of a sequence.", "B. A sequence that can be derived from another sequence by deleting some or no elements without changing the order of the remaining elements.", "C. A sequence that is shorter than the original sequence.", "D. A reversed sequence.", "B"
"LCS", "What is the primary goal of the LCS problem?", "A. To find the longest substring common to two sequences.", "B. To find the longest sequence that is a subsequence of two or more sequences.", "C. To check if two sequences are identical.", "D. To find the shortest common sequence.", "B"
"LCS", "Which algorithm design paradigm is typically used to solve the LCS problem?", "A. Greedy Algorithm", "B. Divide and Conquer", "C. Dynamic Programming", "D. Backtracking", "C"
"LCS", "If `X = 'ABCBDAB'` and `Y = 'BDCABA'`, what is the length of their LCS?", "A. 3", "B. 4", "C. 5", "D. 6", "C"
"LCS", "What is the time complexity of the standard dynamic programming solution for LCS with two sequences of lengths `m` and `n`?", "A. O(m + n)", "B. O(min(m, n))", "C. O(m * n)", "D. O(max(m, n))", "C"
"LCS", "What does the `dp[i][j]` entry in the LCS DP table typically represent?", "A. The length of the LCS of `X[0...i-1]` and `Y[0...j-1]`.", "B. The character at `X[i]` and `Y[j]`.", "C. The longest common substring of `X[0...i-1]` and `Y[0...j-1]`.", "D. The minimum cost to transform `X` to `Y`.", "A"
"LCS", "What are the base cases for the LCS DP table?", "A. `dp[0][j] = 0` for all `j`, and `dp[i][0] = 0` for all `i`.", "B. `dp[0][0] = 1`.", "C. All `dp` values initialized to infinity.", "D. The last row and column are 0.", "A"
"LCS", "In the LCS DP recurrence, if `X[i-1]` == `Y[j-1]` (characters match), what is `dp[i][j]` equal to?", "A. `dp[i-1][j]`", "B. `dp[i][j-1]`", "C. `1 + dp[i-1][j-1]`", "D. `0`", "C"
"LCS", "In the LCS DP recurrence, if `X[i-1]` != `Y[j-1]` (characters do not match), what is `dp[i][j]` equal to?", "A. `dp[i-1][j-1]`", "B. `max(dp[i-1][j], dp[i][j-1])`", "C. `1 + max(dp[i-1][j], dp[i][j-1])`", "D. `0`", "B"
"LCS", "What is the space complexity of the standard 2D DP solution for LCS with sequences of lengths `m` and `n`?", "A. O(1)", "B. O(min(m, n))", "C. O(m * n)", "D. O(m + n)", "C"
"LCS", "Can the space complexity of the LCS DP be optimized?", "A. No, it's impossible.", "B. Yes, to O(min(m, n)) by using only two rows (current and previous).", "C. Only if `m` is very small.", "D. Only if `n` is very small.", "B"
"LCS", "To reconstruct the actual LCS sequence, what additional information is often stored or derived?", "A. Only the length of the LCS.", "B. A separate 'path' or 'direction' matrix that indicates which subproblem led to the optimal value at each cell.", "C. The original sequences.", "D. A hash map of common subsequences.", "B"
"LCS", "Is the LCS problem related to the Edit Distance (Levenshtein Distance) problem?", "A. No, they are unrelated.", "B. Yes, both involve transforming one string to another, and their DP solutions share similarities.", "C. Only if the strings are very short.", "D. Only if the strings are identical.", "B"
"LCS", "If two sequences have no common characters, what is the length of their LCS?", "A. 0", "B. 1", "C. -1", "D. Undefined", "A"
"LCS", "The LCS problem is an example of a problem exhibiting which properties?", "A. Greedy Choice Property and Optimal Substructure.", "B. Optimal Substructure and Overlapping Subproblems.", "C. Divide and Conquer and Memoization.", "D. Backtracking and Pruning.", "B"
"LCS", "Given `X = 'AGGTAB'` and `Y = 'GXTXAYB'`, which of the following is an LCS?", "A. `GTAB`", "B. `GTXB`", "C. `GTAGB`", "D. `AGTB`", "C"
"LCS", "What is the length of LCS for `X = 'AAAA'` and `Y = 'AA'`?", "A. 0", "B. 2", "C. 4", "D. 6", "B"
"LCS", "Can the LCS be unique?", "A. Yes, always.", "B. No, there can be multiple LCSs of the same length.", "C. Only if the sequences are identical.", "D. Only if the sequences are very short.", "B"
"LCS", "Which of the following is NOT an application of LCS?", "A. Diff utility (comparing files).", "B. Bioinformatics (comparing DNA/protein sequences).", "C. Version control systems (e.g., Git).", "D. Finding the shortest path in a graph.", "D"
"LCS", "If `X` is a subsequence of `Y`, what is `LCS(X, Y)`?", "A. `Y`", "B. `X`", "C. Empty string", "D. The length of `X` + length of `Y`", "B"
"LCS", "If `X` and `Y` are completely different (no common characters), their LCS length is 0. True or False?", "A. True", "B. False", "A"
"LCS", "Can LCS be solved using a greedy approach?", "A. Yes, always.", "B. No, because a local optimal choice (e.g., matching the first common character) does not guarantee a global optimum.", "C. Only for very short strings.", "D. Only if there are no overlapping characters.", "B"
"LCS", "What is the relationship between LCS and Longest Common Substring?", "A. They are the same problem.", "B. LCS considers non-contiguous characters; Longest Common Substring requires contiguous characters.", "C. Longest Common Substring is always longer than LCS.", "D. LCS is always shorter than Longest Common Substring.", "B"
"LCS", "If `m = 0` (length of first sequence is zero), what is `dp[0][j]`?", "A. 1", "B. j", "C. 0", "D. m", "C"
"LCS", "The memoization table for LCS is usually filled in what manner?", "A. Top-down (recursive with memoization).", "B. Bottom-up (iterative).", "C. Both are valid approaches.", "D. Randomly.", "C"
"LCS", "Which type of problem is LCS?", "A. Decision problem.", "B. Optimization problem.", "C. Counting problem.", "D. Search problem.", "B"
"LCS", "If the LCS algorithm determines a length of `k`, how many characters are in the actual common subsequence?", "A. `k`", "B. `k-1`", "C. `k+1`", "D. `2k`", "A"
"LCS", "What is a major advantage of using dynamic programming for LCS over brute-force enumeration of all subsequences?", "A. It uses less memory.", "B. It is always O(1) time complexity.", "C. Brute-force is exponential (2^m * 2^n), DP is polynomial (m*n).", "D. Brute-force is not possible.", "C"
"LCS", "What is the value of `dp[m][n]` after the DP table is filled?", "A. The maximum common character.", "B. The length of the LCS of the entire `X` and `Y` sequences.", "C. The sum of all characters.", "D. The minimum common character.", "B"
"LCS", "Consider `X = 'ABC'` and `Y = 'ACB'`. What is the length of their LCS?", "A. 1", "B. 2", "C. 3", "D. 0", "B"
"LCS", "For `X = 'ABC'` and `Y = 'ACB'`, which of these is an LCS?", "A. `ABC`", "B. `AB`", "C. `AC`", "D. Both B and C", "D"
"LCS", "Can LCS be used to find the minimum number of insertions and deletions needed to transform one string into another?", "A. No, that's Edit Distance.", "B. Yes, `m + n - 2 * LCS_length` (for deletion and insertion only).", "C. Only if the strings are sorted.", "D. Only if there are no common characters.", "B"
"LCS", "The LCS problem is a classic example of applying which principle of dynamic programming?", "A. Principle of inclusion-exclusion.", "B. Principle of optimality.", "C. Principle of recursion.", "D. Principle of iteration.", "B"
"LCS", "When reconstructing the LCS, if `dp[i][j]` came from `dp[i-1][j-1]` (diagonal move), it implies:", "A. `X[i-1]` and `Y[j-1]` were different.", "B. `X[i-1]` and `Y[j-1]` were the same and form part of the LCS.", "C. The subsequence decreased in length.", "D. A new subsequence started.", "B"
"LCS", "When reconstructing the LCS, if `dp[i][j]` came from `dp[i-1][j]` (move up), it implies:", "A. `X[i-1]` was included in the LCS.", "B. `Y[j-1]` was included in the LCS.", "C. `X[i-1]` was NOT included in the LCS, and we consider the LCS of `X` excluding `X[i-1]` with full `Y`.", "D. A character was inserted.", "C"
"LCS", "When reconstructing the LCS, if `dp[i][j]` came from `dp[i][j-1]` (move left), it implies:", "A. `Y[j-1]` was included in the LCS.", "B. `X[i-1]` was included in the LCS.", "C. `Y[j-1]` was NOT included in the LCS, and we consider the LCS of full `X` with `Y` excluding `Y[j-1]`.", "D. A character was deleted.", "C"
"LCS", "What is the purpose of a `0` row and `0` column in the LCS DP table?", "A. To represent empty prefixes, serving as base cases.", "B. To store the initial values of the sequences.", "C. To indicate errors in the algorithm.", "D. To count the number of common characters.", "A"
"LCS", "Can LCS be applied to more than two sequences?", "A. No, only two.", "B. Yes, but the time complexity increases exponentially with the number of sequences (e.g., O(m*n*p) for three).", "C. Only if all sequences are of the same length.", "D. Only by breaking it down into pairwise LCS problems.", "B"
"LCS", "If `X = 'ABCDEFG'` and `Y = 'ACEG'`, what is the length of their LCS?", "A. 3", "B. 4", "C. 5", "D. 7", "B"
"LCS", "If `X = 'ABRACADABRA'` and `Y = 'ABRAKADABRA'`, what is the length of their LCS?", "A. 11", "B. 10", "C. 9", "D. 12", "B"
"LCS", "What is the typical time complexity for the brute-force approach to LCS?", "A. O(m*n)", "B. O(2^m * 2^n)", "C. O(min(2^m, 2^n))", "D. O(m+n)", "B"
"LCS", "The LCS problem demonstrates that a greedy approach is not always optimal for problems with optimal substructure. True or False?", "A. True", "B. False", "A"
"LCS", "For which type of sequences is LCS most commonly applied?", "A. Numerical sequences.", "B. String/character sequences.", "C. Boolean sequences.", "D. Image pixel sequences.", "B"
"LCS", "When filling the DP table for LCS, each cell `dp[i][j]` depends on at most how many other cells?", "A. 1", "B. 2 (left and up)", "C. 3 (left, up, and diagonal)", "D. 4", "C"
"LCS", "What is the main advantage of the O(min(m, n)) space optimization for LCS?", "A. Faster computation time.", "B. Reduced memory usage, crucial for very long strings.", "C. Simpler implementation.", "D. Better for parallel processing.", "B"
"LCS", "Which of the following problems can be reduced to LCS?", "A. Longest Increasing Subsequence (LIS).", "B. Shortest Common Supersequence (SCS).", "C. String Matching (e.g., KMP).", "D. All of the above.", "B"
"LCS", "If `LCS(A, B) = L`, then `SCS(A, B)` (Shortest Common Supersequence) length is `len(A) + len(B) - L`. True or False?", "A. True", "B. False", "A"
"LCS", "In the context of the LCS DP table, the values generally show what trend as `i` and `j` increase?", "A. Always decreasing.", "B. Always increasing (non-decreasing).", "C. Random fluctuations.", "D. Constant values.", "B"
"LCS", "To perform back-tracking and print one of the LCS, which direction do you typically move from `dp[m][n]`?", "A. Only left.", "B. Only up.", "C. Diagonally if characters match, else up or left.", "D. Randomly choose any valid path.", "C"
"LCS", "What is the maximum length an LCS can have for two sequences of length `m` and `n`?", "A. `m + n`", "B. `max(m, n)`", "C. `min(m, n)`", "D. `m * n`", "C"
"SudokuSolver", "What is the primary goal of a SudokuSolver?", "A. To generate new Sudoku puzzles.", "B. To find a single valid solution for a given Sudoku puzzle.", "C. To check if a Sudoku puzzle has multiple solutions.", "D. To analyze the difficulty of a Sudoku puzzle.", "B"
"SudokuSolver", "Which algorithm design paradigm is most commonly used for a SudokuSolver?", "A. Greedy Algorithm", "B. Divide and Conquer", "C. Dynamic Programming", "D. Backtracking", "D"
"SudokuSolver", "What is the size of a standard Sudoku grid?", "A. 4x4", "B. 6x6", "C. 9x9", "D. 12x12", "C"
"SudokuSolver", "What are the three fundamental rules a Sudoku solution must satisfy?", "A. Each row, column, and 3x3 subgrid must contain digits 1-9 exactly once.", "B. Each row, column, and 3x3 subgrid must contain only unique digits.", "C. Each row, column, and 3x3 subgrid must sum to 45.", "D. A and B.", "D"
"SudokuSolver", "When using a backtracking approach, what is the 'choice' at each step?", "A. Deciding which cell to fill first.", "B. Trying to place a digit (1-9) into an empty cell.", "C. Checking if the puzzle is valid.", "D. Removing a digit from a filled cell.", "B"
"SudokuSolver", "In a backtracking SudokuSolver, what happens if a chosen digit leads to an invalid state or a dead end?", "A. The solver declares the puzzle unsolvable.", "B. The solver backtracks to the previous decision point and tries a different digit.", "C. The solver randomly picks a new cell.", "D. The solver attempts to optimize the current digit.", "B"
"SudokuSolver", "What is the 'base case' or 'termination condition' for a recursive backtracking SudokuSolver?", "A. When all cells are filled.", "B. When a valid digit is placed in the first empty cell.", "C. When the solver runs out of time.", "D. When the puzzle becomes invalid.", "A"
"SudokuSolver", "How is an empty cell typically represented in a Sudoku grid (e.g., in code)?", "A. '0' or '.'", "B. '-1'", "C. 'null'", "D. 'empty'", "A"
"SudokuSolver", "What are the three constraints that need to be checked when placing a digit `d` in cell `(row, col)`?", "A. Row constraint, Column constraint, Diagonal constraint.", "B. Row constraint, Column constraint, 3x3 subgrid constraint.", "C. Row constraint, Column constraint, Sum constraint.", "D. Row constraint, Column constraint, Parity constraint.", "B"
"SudokuSolver", "What is the approach to check the 3x3 subgrid constraint for cell `(row, col)`?", "A. Check all cells in `[0...2][0...2]`.", "B. Check cells from `(row/3)*3` to `(row/3)*3 + 2` for rows, and `(col/3)*3` to `(col/3)*3 + 2` for columns.", "C. Check a fixed 3x3 subgrid.", "D. Sum all values in the subgrid.", "B"
"SudokuSolver", "Is a SudokuSolver guaranteed to find a solution if one exists?", "A. No, not always.", "B. Yes, a correct backtracking implementation systematically explores all possibilities.", "C. Only for easy puzzles.", "D. Only if it uses a greedy approach.", "B"
"SudokuSolver", "What is the worst-case time complexity of a brute-force SudokuSolver?", "A. Polynomial (e.g., N^2).", "B. Exponential (e.g., 9^M where M is the number of empty cells).", "C. Logarithmic.", "D. Linear.", "B"
"SudokuSolver", "How does 'pre-filling' cells (e.g., by checking obvious single-candidate cells) before starting backtracking help optimize a SudokuSolver?", "A. It guarantees a unique solution.", "B. It reduces the number of empty cells, thus reducing the search space for backtracking.", "C. It makes the puzzle harder.", "D. It converts the problem to a non-deterministic one.", "B"
"SudokuSolver", "What is 'Most Constrained Variable' (MCV) heuristic in Sudoku solving?", "A. Choosing the empty cell with the fewest possible valid digits to fill next.", "B. Choosing the empty cell with the most possible valid digits to fill next.", "C. Choosing the empty cell that appears first in row-major order.", "D. Choosing the empty cell that has the highest value filled in its neighbors.", "A"
"SudokuSolver", "What is 'Least Constraining Value' (LCV) heuristic in Sudoku solving?", "A. Trying digits in numerical order (1 to 9).", "B. Trying the digit that rules out the fewest options for neighboring unassigned cells.", "C. Trying the digit that is the smallest value.", "D. Trying the digit that is the largest value.", "B"
"SudokuSolver", "If a Sudoku puzzle has multiple solutions, what will a standard backtracking solver typically find?", "A. All possible solutions.", "B. The first solution it encounters.", "C. Only the easiest solution.", "D. It will loop infinitely.", "B"
"SudokuSolver", "Can a SudokuSolver be used to determine if a given Sudoku puzzle has a unique solution?", "A. No, it only finds one solution.", "B. Yes, by finding one solution, then modifying the puzzle slightly and trying to find a second solution, or by explicitly counting solutions.", "C. Only if the puzzle is small.", "D. Only if the puzzle is already solved.", "B"
"SudokuSolver", "What data structure is often used to represent the Sudoku grid in a solver?", "A. Linked List", "B. Stack", "C. 2D Array (or matrix)", "D. Hash Map", "C"
"SudokuSolver", "Why is it generally more efficient to choose an empty cell to fill rather than a filled one?", "A. Filled cells are irrelevant.", "B. Filling an empty cell directly contributes to solving the puzzle; filled cells already satisfy rules.", "C. To avoid infinite loops.", "D. To make the code simpler.", "B"
"SudokuSolver", "In backtracking, when a digit is tried in a cell, and it leads to a dead end, what is the crucial step before trying the next digit?", "A. Move to the next cell.", "B. 'Un-do' the last placement (set the cell back to empty) before backtracking.", "C. Reset the entire grid.", "D. Start from the beginning.", "B"
"SudokuSolver", "Consider a Sudoku cell `(r, c)`. Its 3x3 subgrid can be identified by its top-left cell `(startRow, startCol)`. What are these values?", "A. `(r % 3, c % 3)`", "B. `(r - (r % 3), c - (c % 3))`", "C. `(r / 3, c / 3)`", "D. `(r + 3, c + 3)`", "B"
"SudokuSolver", "What is the typical range of digits used in a standard Sudoku puzzle?", "A. 0-9", "B. 1-9", "C. A-I", "D. Any integers", "B"
"SudokuSolver", "What is the primary benefit of backtracking over a purely iterative approach for Sudoku?", "A. It's faster for all puzzles.", "B. It's inherently recursive, which is simpler to write.", "C. It systematically explores all valid paths until a solution is found or all paths are exhausted, handling complex dependencies.", "D. It uses less memory.", "C"
"SudokuSolver", "If a Sudoku puzzle has no empty cells, but it violates one or more Sudoku rules, what should a solver typically report?", "A. A solution found.", "B. No solution, or invalid initial puzzle.", "C. Puzzle is too easy.", "D. The solver crashed.", "B"
"SudokuSolver", "What is the concept of 'naked singles' or 'hidden singles' in advanced Sudoku solving techniques?", "A. Cells that can only contain one specific digit based on elimination (naked) or based on that digit only fitting in that cell within a row/col/block (hidden).", "B. Cells that are completely empty.", "C. Cells that have multiple solutions.", "D. Cells that are isolated from others.", "A"
"SudokuSolver", "Does a standard backtracking SudokuSolver inherently perform 'naked single' or 'hidden single' deductions?", "A. Yes, always.", "B. No, these are optimization heuristics or pre-processing steps, not part of basic backtracking's core logic.", "C. Only if specified.", "D. Only for easy puzzles.", "B"
"SudokuSolver", "What is the typical flow of a recursive backtracking SudokuSolver function?", "A. Find empty cell -> Try digits 1-9 -> If digit valid -> Recurse -> If true, return true -> Else, backtrack (un-do) -> Try next digit.", "B. Fill all cells randomly -> Check validity -> If valid, return true.", "C. Iterate all digits 1-9 -> Find empty cell -> Place digit.", "D. Only check pre-filled cells.", "A"
"SudokuSolver", "The 'satisfiability problem' (SAT) in computer science is related to Sudoku solving. What is this relation?", "A. Sudoku can be formulated as a SAT problem, showing its NP-completeness.", "B. SAT is a special case of Sudoku.", "C. They are completely unrelated.", "D. Sudoku solves SAT problems.", "A"
"SudokuSolver", "What is 'constraint propagation' in the context of Sudoku solvers?", "A. Randomly assigning digits to cells.", "B. The process of making deductions based on a digit placement, which further restricts possibilities for other cells.", "C. Copying the grid to a new state.", "D. Only checking row constraints.", "B"
"SudokuSolver", "When a Sudoku puzzle has multiple solutions, which solution does a basic backtracking algorithm find?", "A. The one that requires the fewest steps.", "B. The one with the smallest sum of digits.", "C. The first one encountered based on the cell selection order and digit trial order.", "D. The one with the largest sum of digits.", "C"
"SudokuSolver", "What is the purpose of the `isValid` helper function in a SudokuSolver?", "A. To check if a digit is prime.", "B. To check if placing a specific digit at a given cell violates any Sudoku rules.", "C. To check if the entire grid is solved.", "D. To count the number of empty cells.", "B"
"SudokuSolver", "If `isValid` returns `false` for a particular digit in a cell, what happens next in the backtracking loop?", "A. The solver moves to the next cell.", "B. The solver tries the next digit for the current cell.", "C. The solver immediately returns `false`.", "D. The solver terminates.", "B"
"SudokuSolver", "What is a common strategy for picking the next empty cell in a basic SudokuSolver?", "A. Randomly picking an empty cell.", "B. Iterating through cells from top-left to bottom-right (row by row, column by column).", "C. Picking the cell with the most pre-filled neighbors.", "D. Picking the cell with the largest row index.", "B"
"SudokuSolver", "How does a solver determine if a Sudoku puzzle is unsolvable?", "A. If it runs out of memory.", "B. If the backtracking algorithm explores all possible branches and no solution is found.", "C. If the initial grid has no empty cells.", "D. If the first digit tried is invalid.", "B"
"SudokuSolver", "What is a 'human-level' Sudoku solver?", "A. One that uses brute-force backtracking.", "B. One that implements logical deduction rules commonly used by humans (e.g., naked pairs, hidden quads) to minimize or avoid backtracking.", "C. One that takes input from a human.", "D. One that solves only easy puzzles.", "B"
"SudokuSolver", "When designing a SudokuSolver, what are the primary considerations for performance?", "A. Size of the grid only.", "B. Efficiency of finding the next empty cell, validity checks, and heuristics for pruning the search space.", "C. Number of input values.", "D. Type of programming language.", "B"
"SudokuSolver", "Can a SudokuSolver be parallelized for faster execution?", "A. No, it's inherently sequential.", "B. Yes, different branches of the search tree can be explored in parallel.", "C. Only for very large grids.", "D. Only if the puzzle is trivial.", "B"
"SudokuSolver", "What is the general concept of 'pruning' in backtracking algorithms like SudokuSolver?", "A. Removing valid solutions.", "B. Cutting off branches of the search tree that are determined to not lead to a solution, based on current constraints.", "C. Adding new branches to the search tree.", "D. Rearranging the grid.", "B"
"SudokuSolver", "If the initial Sudoku grid provided to the solver contains contradictory digits (e.g., two '5's in the same row), what should happen?", "A. The solver should find a solution by overwriting one of them.", "B. The `isValid` check on the initial grid should detect this and the solver should report an invalid input puzzle.", "C. The solver will loop infinitely.", "D. The solver will fill the rest of the cells randomly.", "B"
"SudokuSolver", "What are 'Dancing Links' or Algorithm X, and how do they relate to Sudoku?", "A. A type of Sudoku puzzle variant.", "B. An advanced, highly efficient algorithm for solving exact cover problems, which Sudoku can be mapped to.", "C. A technique for generating random Sudoku puzzles.", "D. A method for visualizing Sudoku solutions.", "B"
"SudokuSolver", "Does a SudokuSolver require memory proportional to the size of the grid?", "A. Yes, O(N*N) for the grid itself, plus recursive stack space.", "B. No, it uses constant memory.", "C. Only if the grid is very large.", "D. Only for the initial puzzle.", "A"
"SudokuSolver", "What is the purpose of a 'find_empty_cell' function in a typical solver?", "A. To count empty cells.", "B. To locate the next empty cell to attempt filling, often in row-major order.", "C. To check if the grid is solved.", "D. To initialize empty cells.", "B"
"SudokuSolver", "If a Sudoku puzzle has multiple valid solutions, and you want to find all of them, how would you modify a basic backtracking solver?", "A. Remove the `return true` statement after finding the first solution and continue backtracking until all paths are explored.", "B. Add a random element to the solver.", "C. Use a different algorithm entirely.", "D. Only print the first solution.", "A"
"SudokuSolver", "What is the complexity of checking validity (row, column, block) for a single cell `(r, c)` and a digit `d`?", "A. O(1)", "B. O(N) where N is grid side length (9 for standard Sudoku).", "C. O(N^2)", "D. O(log N)", "B"
"SudokuSolver", "What is the maximum number of recursive calls in a backtracking SudokuSolver in the worst case?", "A. 9", "B. 81", "C. 9 raised to the power of the number of empty cells.", "D. Constant.", "C"
"SudokuSolver", "What is the 'Rule of 9' in Sudoku?", "A. Each row, column, and 3x3 block must sum to 9.", "B. Each row, column, and 3x3 block must contain digits 1-9 without repetition (summing to 45).", "C. You can only place 9s.", "D. The grid must contain exactly 9 empty cells.", "B"
"SudokuSolver", "What is the primary role of recursion in a backtracking SudokuSolver?", "A. To manage loops.", "B. To explore potential solutions by making a choice, solving the subproblem, and undoing if necessary.", "C. To check base cases only.", "D. To handle user input.", "B"
"SudokuSolver", "What kind of problem is Sudoku from a computational perspective?", "A. A simple search problem.", "B. A constraint satisfaction problem (CSP).", "C. A graph traversal problem.", "D. A sorting problem.", "B"
"SudokuSolver", "Can a SudokuSolver be implemented iteratively instead of recursively?", "A. No, recursion is mandatory.", "B. Yes, by explicitly managing a stack to simulate recursive calls.", "C. Only for very easy puzzles.", "D. Only if the grid is small.", "B"
"SudokuSolver", "What is the practical impact of using heuristics like MCV and LCV in a SudokuSolver?", "A. They guarantee an optimal solution.", "B. They significantly reduce the average-case runtime by pruning the search tree more effectively.", "C. They increase the memory usage.", "D. They make the solver harder to implement.", "B"
"TopologicalSort", "What is the primary purpose of a Topological Sort?", "A. To find the shortest path in a graph.", "B. To sort nodes of a directed acyclic graph (DAG) in linear order.", "C. To detect cycles in a graph.", "D. To find connected components in a graph.", "B"
"TopologicalSort", "A Topological Sort is applicable only to which type of graph?", "A. Undirected graphs.", "B. Directed graphs with cycles.", "C. Directed Acyclic Graphs (DAGs).", "D. Weighted graphs.", "C"
"TopologicalSort", "What property must a graph *not* have for a Topological Sort to be possible?", "A. Isolated vertices.", "B. Multiple edges between two vertices.", "C. Cycles.", "D. Disconnected components.", "C"
"TopologicalSort", "If a graph contains a cycle, what is the outcome of attempting a Topological Sort?", "A. It will successfully sort the nodes, but the cycle will be at the end.", "B. It will detect the cycle and report that a topological sort is not possible.", "C. It will enter an infinite loop.", "D. It will sort all nodes except those in the cycle.", "B"
"TopologicalSort", "Which of the following algorithms can be used to perform a Topological Sort?", "A. Breadth-First Search (BFS) based on in-degrees (Kahn's Algorithm).", "B. Depth-First Search (DFS).", "C. Both A and B.", "D. Dijkstra's Algorithm.", "C"
"TopologicalSort", "In Kahn's Algorithm (BFS-based Topological Sort), what is the key concept used?", "A. Out-degrees of vertices.", "B. In-degrees of vertices.", "C. Edge weights.", "D. Paths from a source.", "B"
"TopologicalSort", "What is the initial step in Kahn's Algorithm?", "A. Start a DFS from an arbitrary node.", "B. Identify all vertices with an in-degree of zero.", "C. Initialize all in-degrees to infinity.", "D. Create a min-priority queue.", "B"
"TopologicalSort", "What data structure is used in Kahn's Algorithm to store vertices with an in-degree of zero?", "A. Stack", "B. Queue", "C. Priority Queue", "D. Hash Map", "B"
"TopologicalSort", "What happens to the in-degrees of neighbors when a vertex is removed from the queue in Kahn's Algorithm?", "A. They increase.", "B. They decrease.", "C. They remain unchanged.", "D. They are reset to zero.", "B"
"TopologicalSort", "If, at the end of Kahn's Algorithm, the number of vertices in the topological sort order is less than the total number of vertices in the graph, what does this imply?", "A. The graph is disconnected.", "B. The graph contains a cycle.", "C. The graph has multiple valid topological sorts.", "D. The algorithm failed.", "B"
"TopologicalSort", "What is the time complexity of Kahn's Algorithm for a graph with `V` vertices and `E` edges?", "A. O(V)", "B. O(E)", "C. O(V + E)", "D. O(V * E)", "C"
"TopologicalSort", "In a DFS-based Topological Sort, when is a vertex added to the sorted list (or stack)?", "A. Before its children are visited.", "B. After all its descendants have been visited (i.e., when it's popped from the recursion stack).", "C. When it is first visited.", "D. Randomly.", "B"
"TopologicalSort", "What data structure is often used to store the result of a DFS-based Topological Sort (before reversing if desired)?", "A. Queue", "B. Stack (or a list that is reversed at the end)", "C. Priority Queue", "D. Array", "B"
"TopologicalSort", "What is the time complexity of DFS-based Topological Sort for a graph with `V` vertices and `E` edges?", "A. O(V)", "B. O(E)", "C. O(V + E)", "D. O(V * E)", "C"
"TopologicalSort", "If a DAG has multiple valid topological sorts, which algorithm would typically find one specific version?", "A. Both Kahn's and DFS-based algorithms, depending on tie-breaking/traversal order.", "B. Only Kahn's algorithm.", "C. Only DFS-based algorithm.", "D. Neither.", "A"
"TopologicalSort", "Which of the following is a real-world application of Topological Sort?", "A. Finding the shortest route on a map.", "B. Scheduling tasks with dependencies (e.g., in project management, compiler instruction scheduling).", "C. Network flow analysis.", "D. Image processing.", "B"
"TopologicalSort", "Consider tasks A, B, C, D, E. Dependencies: A -> B, A -> C, B -> D, C -> D. Which of the following is a valid topological sort?", "A. A, B, C, D, E", "B. A, C, B, D, E", "C. E, A, B, C, D", "D. A, E, B, C, D", "B"
"TopologicalSort", "Can a Topological Sort be applied to a graph with weighted edges?", "A. No, edge weights are not considered.", "B. Yes, but only if all weights are positive.", "C. Yes, but only if all weights are negative.", "D. Yes, but weights are ignored by the topological sort algorithm itself.", "D"
"TopologicalSort", "What is the minimum number of sources (vertices with in-degree 0) a non-empty DAG must have?", "A. 0", "B. 1", "C. 2", "D. V/2", "B"
"TopologicalSort", "What is the minimum number of sinks (vertices with out-degree 0) a non-empty DAG must have?", "A. 0", "B. 1", "C. 2", "D. V/2", "B"
"TopologicalSort", "If you have a graph representing course prerequisites, what would a Topological Sort produce?", "A. A schedule of courses you must take in order.", "B. The longest path of courses.", "C. The shortest path to graduation.", "D. All possible course combinations.", "A"
"TopologicalSort", "A graph `G` is a DAG if and only if its DFS traversal does not yield any:", "A. Tree edges.", "B. Back edges.", "C. Forward edges.", "D. Cross edges.", "B"
"TopologicalSort", "When detecting a cycle using DFS for Topological Sort, what condition indicates a cycle?", "A. Encountering an already visited node.", "B. Encountering a node that is currently in the recursion stack (i.e., gray node).", "C. Encountering a node with an in-degree of zero.", "D. Encountering a leaf node.", "B"
"TopologicalSort", "How many different topological sorts can a given DAG have?", "A. Exactly one.", "B. Exactly zero.", "C. At least one, and potentially many (if there are parallel paths or choices for nodes with zero in-degree).", "D. Unlimited.", "C"
"TopologicalSort", "Which data structure is crucial for keeping track of visited nodes and recursion stack status in DFS-based Topological Sort to detect cycles?", "A. Queue.", "B. Adjacency List.", "C. Set/array for visited nodes, and potentially another for recursion stack (gray nodes).", "D. Priority Queue.", "C"
"TopologicalSort", "If a graph has multiple connected components, can a Topological Sort be performed?", "A. No, only for fully connected graphs.", "B. Yes, the topological sort will be valid for each component, effectively sorting the entire graph.", "C. Only if the components are small.", "D. Only if there are no edges between components.", "B"
"TopologicalSort", "Consider the DFS-based topological sort. If `u` is visited before `v`, and there is an edge `(u, v)`, then `u` must appear before `v` in the topological sort order. True or False?", "A. True (if `u` is added to list upon finishing, then reversed, or added to stack and then popped)", "B. False", "A"
"TopologicalSort", "The term 'linear ordering' in Topological Sort implies:", "A. Nodes are ordered alphabetically.", "B. Nodes are ordered such that for every directed edge `(u, v)`, `u` comes before `v` in the ordering.", "C. Nodes are ordered by their depth in the graph.", "D. Nodes are ordered by their out-degree.", "B"
"TopologicalSort", "Which algorithm is generally preferred for finding a topological sort?", "A. Kahn's (BFS-based) if cycle detection is a primary concern, or when you want to easily verify the order directly.", "B. DFS-based if already using DFS for other graph traversals.", "C. Both are equally preferred, depending on context and implementation style.", "D. Neither, there are better algorithms.", "C"
"TopologicalSort", "If you have a set of classes and their prerequisites, a Topological Sort would help you determine:", "A. The total time to complete all classes.", "B. A valid sequence in which to take the classes.", "C. The hardest class to take.", "D. The number of students who failed each class.", "B"
"TopologicalSort", "What is the concept of 'in-degree' of a vertex?", "A. The number of outgoing edges from the vertex.", "B. The number of incoming edges to the vertex.", "C. The total number of edges connected to the vertex.", "D. The number of cycles involving the vertex.", "B"
"TopologicalSort", "What is the concept of 'out-degree' of a vertex?", "A. The number of outgoing edges from the vertex.", "B. The number of incoming edges to the vertex.", "C. The total number of edges connected to the vertex.", "D. The number of cycles involving the vertex.", "A"
"TopologicalSort", "In a dependency graph, an edge from A to B (`A -> B`) means:", "A. A depends on B.", "B. B depends on A (A must happen before B).", "C. A and B are independent.", "D. A and B are interchangeable.", "B"
"TopologicalSort", "Which of the following is a non-valid topological sort of a graph with `A -> B`, `B -> C`, `A -> D`?", "A. A, B, D, C", "B. A, D, B, C", "C. B, A, C, D", "D. A, B, C, D", "C"
"TopologicalSort", "What is the result if a Topological Sort is performed on an empty graph?", "A. Error.", "B. An empty list (a valid topological sort).", "C. A list containing all possible vertices (even if none).", "D. It runs infinitely.", "B"
"TopologicalSort", "When using Kahn's algorithm, if the queue becomes empty and not all vertices have been processed, what does this indicate?", "A. The graph is fully sorted.", "B. The graph is disconnected.", "C. The graph contains a cycle.", "D. The graph has multiple topological sorts.", "C"
"TopologicalSort", "Topological Sort can be used as a preliminary step for which other graph algorithms?", "A. Dijkstra's Algorithm on positive weights.", "B. Bellman-Ford Algorithm on negative weights (can be optimized for DAGs).", "C. Finding critical path in project networks (CPM/PERT).", "D. All of the above (when applied to DAGs).", "D"
"TopologicalSort", "Is a reverse topological sort meaningful?", "A. No, it loses the dependency order.", "B. Yes, it can be used to find tasks that have no dependencies on other tasks (sinks).", "C. Only if the graph is undirected.", "D. Only if the graph is very small.", "B"
"TopologicalSort", "Consider DFS-based topological sort. If `u` finishes before `v` in DFS, and `u` is added to the list before `v`, then `u` comes after `v` in the reversed topological sort. True or False?", "A. True", "B. False", "A"
"TopologicalSort", "What type of edges does DFS-based topological sort rely on for its ordering?", "A. Tree edges and forward edges.", "B. Back edges (to detect cycles).", "C. Tree edges (for traversal order) and the finishing times of nodes.", "D. Cross edges.", "C"
"TopologicalSort", "In Kahn's Algorithm, how do you handle vertices that become sources during the process?", "A. They are ignored.", "B. They are immediately added to the queue.", "C. Their in-degrees are reset.", "D. Their out-degrees are checked.", "B"
"TopologicalSort", "If a graph represents a directed tree (a DAG with a single root and no cycles), how many topological sorts can it have?", "A. One.", "B. Many, if there are multiple children at a node.", "C. Zero.", "D. Only if it's a binary tree.", "B"
"TopologicalSort", "A DFS-based topological sort effectively outputs vertices in decreasing order of their DFS finishing times. True or False?", "A. True", "B. False", "A"
"TopologicalSort", "What is the primary difference between a Topological Sort and a general graph traversal (like BFS or DFS)?", "A. Traversal simply visits nodes; Topological Sort provides a specific linear ordering based on dependencies.", "B. Topological Sort is always faster.", "C. General traversals detect cycles; Topological Sort does not.", "D. Topological Sort works on all graphs; traversals do not.", "A"
"TopologicalSort", "Can a Topological Sort be used to find strongly connected components (SCCs)?", "A. Yes, directly.", "B. No, SCCs are found using algorithms like Tarjan's or Kosaraju's, though topological sort can be applied to the condensation graph of SCCs.", "C. Only if the graph is a DAG.", "D. Only if the graph is undirected.", "B"
"TopologicalSort", "What happens to the adjacency list representation during Kahn's algorithm as nodes are processed?", "A. It remains unchanged.", "B. Edges are logically (or actually) removed from the graph as nodes are processed, effectively reducing in-degrees of neighbors.", "C. New edges are added.", "D. All edges are reversed.", "B"
"TopologicalSort", "For a graph with `V` vertices, what is the maximum possible number of edges if it is a DAG?", "A. V * (V - 1) / 2 (like a complete graph, but directed and no self-loops)", "B. V - 1", "C. V^2", "D. Infinite", "A"
"TopologicalSort", "A course dependency graph has `CS101 -> CS201`, `CS101 -> MA101`, `CS201 -> CS301`. Which is *not* a valid topological sort?", "A. CS101, MA101, CS201, CS301", "B. CS101, CS201, MA101, CS301", "C. MA101, CS101, CS201, CS301", "D. CS101, CS201, CS301, MA101", "C"
"TopologicalSort", "In the DFS-based topological sort, the output list will contain nodes in what order if not explicitly reversed?", "A. Ascending order of finishing times.", "B. Descending order of finishing times.", "C. Arbitrary order.", "D. Alphabetical order.", "A"
"TopologicalSort", "What would happen if you tried to perform a Topological Sort on an undirected graph?", "A. It would work if the graph has no cycles.", "B. It would generally fail or report a cycle immediately because every edge in an undirected graph implies a two-way connection, forming trivial cycles.", "C. It would sort by degree.", "D. It would treat it as a directed graph.", "B"
"BellmanFord", "What is the primary purpose of the Bellman-Ford algorithm?", "A. To find the shortest path in unweighted graphs.", "B. To find the shortest path from a single source vertex to all other vertices in a weighted graph, even with negative edge weights.", "C. To find the minimum spanning tree in a graph.", "D. To detect cycles in an undirected graph.", "B"
"BellmanFord", "Unlike Dijkstra's algorithm, what type of edge weights can Bellman-Ford handle?", "A. Only positive edge weights.", "B. Only zero edge weights.", "C. Negative edge weights.", "D. Only integer edge weights.", "C"
"BellmanFord", "What is the time complexity of the Bellman-Ford algorithm for a graph with `V` vertices and `E` edges?", "A. O(V + E)", "B. O(V log E)", "C. O(V * E)", "D. O(E log V)", "C"
"BellmanFord", "What is the key idea behind the Bellman-Ford algorithm's iterative approach?", "A. Greedy selection of the minimum edge.", "B. Relaxing all edges `V-1` times.", "C. Using a priority queue to select the next vertex.", "D. Recursive calls to explore paths.", "B"
"BellmanFord", "What does 'edge relaxation' in Bellman-Ford mean?", "A. Removing an edge from the graph.", "B. Updating the shortest path estimate to a vertex if a shorter path is found through a specific edge.", "C. Adding new edges to the graph.", "D. Changing the weight of an edge.", "B"
"BellmanFord", "How many times does the Bellman-Ford algorithm iterate through all edges to relax them?", "A. Once.", "B. `V-1` times, where `V` is the number of vertices.", "C. `E-1` times, where `E` is the number of edges.", "D. Until no more relaxations are possible.", "B"
"BellmanFord", "What is the significance of performing an additional `V`-th relaxation pass in Bellman-Ford?", "A. To find a shorter path.", "B. To optimize the algorithm's speed.", "C. To detect the presence of a negative-weight cycle reachable from the source.", "D. To find all shortest paths.", "C"
"BellmanFord", "If, after `V-1` relaxations, an edge `(u, v)` with weight `w` can still be relaxed such that `dist[u] + w < dist[v]`, what does this indicate?", "A. The graph is disconnected.", "B. A shorter path has been found.", "C. There is a negative-weight cycle reachable from the source.", "D. The algorithm has converged.", "C"
"BellmanFord", "What is the space complexity of the Bellman-Ford algorithm?", "A. O(1)", "B. O(V) (for distance array and parent pointers)", "C. O(E)", "D. O(V * E)", "B"
"BellmanFord", "What are the initial values for `dist[source]` and `dist[other_vertices]` before running Bellman-Ford?", "A. `dist[source] = 0`, `dist[other_vertices] = 0`.", "B. `dist[source] = infinity`, `dist[other_vertices] = 0`.", "C. `dist[source] = 0`, `dist[other_vertices] = infinity`.", "D. All `dist` values initialized to a random number.", "C"
"BellmanFord", "Can Bellman-Ford find shortest paths if the graph contains a negative-weight cycle reachable from the source?", "A. Yes, and it will give correct path lengths.", "B. No, it will detect the cycle and report that shortest paths are undefined for vertices on/reachable from the cycle.", "C. Yes, but only if the cycle is very small.", "D. It will find the longest path.", "B"
"BellmanFord", "For what type of graphs is Dijkstra's algorithm generally preferred over Bellman-Ford?", "A. Graphs with negative edge weights.", "B. Graphs with positive edge weights, as Dijkstra's is typically faster (O(E + V log V) with min-priority queue).", "C. Graphs with cycles.", "D. Sparse graphs.", "B"
"BellmanFord", "Which of the following is NOT an application of the Bellman-Ford algorithm?", "A. Routing protocols (e.g., RIP).", "B. Arbitrage detection in financial markets.", "C. Finding the minimum spanning tree.", "D. Detecting negative cycles.", "C"
"BellmanFord", "If all edge weights are positive, will Bellman-Ford still work correctly?", "A. No, it's designed for negative weights only.", "B. Yes, but it will be slower than Dijkstra's.", "C. Only if the graph has no cycles.", "D. It will produce incorrect results.", "B"
"BellmanFord", "The `V-1` iterations in Bellman-Ford correspond to what property of shortest paths?", "A. The maximum number of edges in any simple path in a graph with `V` vertices is `V-1`.", "B. The minimum number of edges in any simple path is `V-1`.", "C. The average path length is `V-1`.", "D. The number of vertices minus one.", "A"
"BellmanFord", "What does it mean for shortest paths to be 'undefined' in the presence of a negative-weight cycle?", "A. The path length can be arbitrarily small (approaching negative infinity) by repeatedly traversing the cycle.", "B. The path is too long to calculate.", "C. There are multiple shortest paths.", "D. The path does not exist.", "A"
"BellmanFord", "Is Bellman-Ford a greedy algorithm?", "A. Yes, it makes locally optimal choices.", "B. No, it is a dynamic programming algorithm, building up solutions for increasing path lengths.", "C. It's a mix of greedy and dynamic programming.", "D. It's a brute-force algorithm.", "B"
"BellmanFord", "What is the Bellman-Ford algorithm's behavior if a negative-weight cycle is *not* reachable from the source?", "A. It will still detect the cycle.", "B. It will find the correct shortest paths for all reachable vertices, and correctly indicate no negative cycle for the relevant paths.", "C. It will enter an infinite loop.", "D. It will return incorrect path lengths.", "B"
"BellmanFord", "Consider a graph with vertices A, B, C, D and edges: A-B (w=1), B-C (w=1), C-A (w=-3). If source is A, what will Bellman-Ford detect?", "A. Shortest paths.", "B. No negative cycle.", "C. A negative-weight cycle (A-B-C-A).", "D. An unreachable vertex.", "C"
"BellmanFord", "Which type of graph representation is most suitable for efficiently iterating through all edges in Bellman-Ford?", "A. Adjacency Matrix.", "B. Adjacency List (because it allows easy iteration over edges).", "C. Implicit Graph.", "D. Array of vertices.", "B"
"BellmanFord", "The Bellman-Ford algorithm relies on the principle of:", "A. Divide and Conquer.", "B. Optimal Substructure (shortest path to `v` from `u` using `k` edges builds on shortest path to `u` using `k-1` edges).", "C. Greedy Choice Property.", "D. Backtracking.", "B"
"BellmanFord", "Compared to Dijkstra's, Bellman-Ford's advantage is its ability to handle negative weights. Its disadvantage is:", "A. Simpler implementation.", "B. Slower execution time.", "C. More memory usage.", "D. Inability to detect cycles.", "B"
"BellmanFord", "If a graph has `V` vertices and no negative cycles, what is the maximum number of edges in a shortest path from source to any other vertex?", "A. `V`", "B. `V-1`", "C. `V/2`", "D. `1`", "B"
"BellmanFord", "Can Bellman-Ford be used to find all-pairs shortest paths?", "A. Yes, by running it `V` times, once for each vertex as source.", "B. No, it's only for single-source.", "C. Only if there are no negative weights.", "D. Only if there are very few vertices.", "A"
"BellmanFord", "When running Bellman-Ford `V` times for all-pairs shortest paths, what is the overall time complexity?", "A. O(V^2 * E)", "B. O(V * E)", "C. O(V^3)", "D. O(V^2)", "A"
"BellmanFord", "What is the `predecessor` array used for in Bellman-Ford?", "A. To store the weight of the previous edge.", "B. To reconstruct the shortest path by tracking the parent of each vertex on its shortest path from the source.", "C. To store the number of edges in the path.", "D. To indicate if a vertex has been visited.", "B"
"BellmanFord", "Is Bellman-Ford suitable for dense graphs (E ≈ V^2) or sparse graphs (E ≈ V)?", "A. More suitable for dense graphs.", "B. More suitable for sparse graphs, as E dominates the complexity.", "C. Equally suitable for both.", "D. Not suitable for either.", "B"
"BellmanFord", "What happens to `dist[v]` in relaxation if `dist[u] + weight(u, v)` is less than current `dist[v]`?", "A. `dist[v]` remains unchanged.", "B. `dist[v]` is updated to `dist[u] + weight(u, v)`. ", "C. `dist[v]` is set to 0.", "D. `dist[v]` is set to infinity.", "B"
"BellmanFord", "The Bellman-Ford algorithm is guaranteed to find shortest paths in a graph if:", "A. It has positive edge weights only.", "B. It has no negative edge weights.", "C. It contains no negative-weight cycles reachable from the source.", "D. It is a directed acyclic graph (DAG).", "C"
"BellmanFord", "If Bellman-Ford is run on a DAG, will it still correctly find shortest paths?", "A. No, it's specifically for cycles.", "B. Yes, and it will be faster than on general graphs due to the absence of cycles, potentially terminating early.", "C. It will produce an error.", "D. It will be much slower.", "B"
"BellmanFord", "What would be the time complexity of Bellman-Ford on a DAG if optimized by a topological sort?", "A. O(V + E) (linear time).", "B. O(V*E).", "C. O(V^2).", "D. O(E log V).", "A"
"BellmanFord", "What is the primary difference between how Bellman-Ford and Dijkstra's handle graph traversal?", "A. Bellman-Ford uses a queue, Dijkstra uses a stack.", "B. Bellman-Ford iterates over all edges repeatedly; Dijkstra uses a priority queue to always pick the closest unvisited vertex.", "C. Bellman-Ford is recursive; Dijkstra is iterative.", "D. Bellman-Ford uses adjacency matrix; Dijkstra uses adjacency list.", "B"
"BellmanFord", "Is the result of Bellman-Ford always unique?", "A. Yes, shortest paths are always unique.", "B. No, there can be multiple shortest paths of the same length.", "C. Only if there are no negative weights.", "D. Only if the graph is a tree.", "B"
"BellmanFord", "Which type of graph representation is generally more efficient for adjacency lists when `V` is large but `E` is small (sparse graph)?", "A. Adjacency Matrix.", "B. Adjacency List.", "C. Both are equally efficient.", "D. Neither.", "B"
"BellmanFord", "The Bellman-Ford algorithm is a common textbook example of which programming technique?", "A. Backtracking.", "B. Divide and Conquer.", "C. Dynamic Programming.", "D. Greedy approach.", "C"
"BellmanFord", "What happens if a vertex is unreachable from the source in Bellman-Ford?", "A. Its `dist` value remains `infinity` (or its initial large value).", "B. Its `dist` value becomes 0.", "C. It causes an error.", "D. It will be part of a negative cycle.", "A"
"BellmanFord", "Consider a graph. If Bellman-Ford reports a negative cycle, does it also provide the path to that cycle?", "A. Yes, always.", "B. Not directly in its basic form, but it can be augmented to do so by tracing predecessor pointers from the vertex involved in the last relaxation.", "C. No, it just reports existence.", "D. Only if the cycle is small.", "B"
"BellmanFord", "If an edge weight is 0, how does Bellman-Ford handle it?", "A. It ignores it.", "B. It treats it as a normal edge, contributing 0 to path length.", "C. It treats it as a negative edge.", "D. It treats it as a positive edge.", "B"
"BellmanFord", "Can Bellman-Ford be used to find the shortest path in an undirected graph with negative weights?", "A. Yes, by converting each undirected edge into two directed edges.", "B. No, undirected graphs inherently create negative cycles if any edge is negative.", "C. Only if the graph is a tree.", "D. Only if all weights are positive.", "A"
"BellmanFord", "What is the condition for `dist[v]` to be updated during relaxation?", "A. `dist[u] < dist[v]`", "B. `dist[u] + weight(u, v) < dist[v]`", "C. `weight(u, v) < dist[v]`", "D. `dist[u] > dist[v]`", "B"
"BellmanFord", "What is the primary difference in how Bellman-Ford and Floyd-Warshall solve shortest paths?", "A. Bellman-Ford is single-source, Floyd-Warshall is all-pairs.", "B. Bellman-Ford handles negative cycles, Floyd-Warshall does not.", "C. Bellman-Ford is faster.", "D. Bellman-Ford uses recursion, Floyd-Warshall uses iteration.", "A"
"BellmanFord", "If an edge `(u, v)` is relaxed `V-1` times, what does `dist[v]` guarantee?", "A. It's the shortest path from source to `v` using exactly `V-1` edges.", "B. It's the shortest path from source to `v` using at most `V-1` edges (assuming no negative cycles).", "C. It's the longest path.", "D. It's just a random value.", "B"
"BellmanFord", "The Bellman-Ford algorithm is a fundamental component of which distance-vector routing protocol?", "A. OSPF", "B. BGP", "C. RIP (Routing Information Protocol)", "D. EIGRP", "C"
"BellmanFord", "Does Bellman-Ford work on graphs with self-loops (edges from a vertex to itself)?", "A. Yes, but self-loops with negative weights could be a problem if allowed repeatedly.", "B. No, it always fails.", "C. Only if the self-loop weight is zero.", "D. Only if the self-loop weight is positive.", "A"
"BellmanFord", "What is the final step of the Bellman-Ford algorithm (after `V-1` relaxations)?", "A. Print the shortest paths.", "B. Perform an additional `V`-th relaxation pass to check for negative cycles.", "C. Reset all distances to infinity.", "D. Terminate immediately.", "B"
"BellmanFord", "If a graph has no cycles at all (a tree or forest), will Bellman-Ford be efficient?", "A. Yes, it will still work correctly, but it's overkill; BFS/DFS is enough for unweighted trees, and Dijkstra for positive weighted trees.", "B. No, it requires cycles.", "C. It will only work for binary trees.", "D. It will crash.", "A"
"BellmanFord", "What is the worst-case number of edges `E` in a graph with `V` vertices?", "A. O(V)", "B. O(V log V)", "C. O(V^2)", "D. O(2^V)", "C"
"BellmanFord", "Given V=4, E=4. Source A. Edges: A->B (1), B->C (1), C->D (1), D->A (-5). What will Bellman-Ford detect?", "A. A negative cycle.", "B. Shortest paths for all vertices.", "C. An unreachable vertex.", "D. An error in input.", "A"
"BellmanFord", "Compared to Dijkstra's, Bellman-Ford is more robust due to its handling of:", "A. Disconnected components.", "B. Negative edge weights.", "C. Directed edges.", "D. Large number of vertices.", "B"
"BellmanFord", "The Bellman-Ford algorithm iteratively improves shortest path estimates. This makes it an example of:", "A. A brute-force search.", "B. An approximation algorithm.", "C. A relaxation-based algorithm.", "D. A divide and conquer algorithm.", "C"
"FloydWarshall", "What is the primary purpose of the Floyd-Warshall algorithm?", "A. To find the shortest path from a single source vertex.", "B. To find the shortest path between all pairs of vertices in a weighted graph.", "C. To detect cycles in a graph.", "D. To find the minimum spanning tree.", "B"
"FloydWarshall", "Which algorithm design paradigm does Floyd-Warshall primarily follow?", "A. Greedy Approach", "B. Divide and Conquer", "C. Dynamic Programming", "D. Backtracking", "C"
"FloydWarshall", "What type of edge weights can Floyd-Warshall handle?", "A. Only positive edge weights.", "B. Only non-negative edge weights.", "C. Both positive and negative edge weights.", "D. Only zero edge weights.", "C"
"FloydWarshall", "What is the time complexity of the Floyd-Warshall algorithm for a graph with `V` vertices?", "A. O(V + E)", "B. O(V log V)", "C. O(V^2)", "D. O(V^3)", "D"
"FloydWarshall", "What is the space complexity of the Floyd-Warshall algorithm?", "A. O(1)", "B. O(V)", "C. O(V^2)", "D. O(V^3)", "C"
"FloydWarshall", "What kind of cycles can the Floyd-Warshall algorithm NOT handle correctly?", "A. Positive-weight cycles.", "B. Zero-weight cycles.", "C. Negative-weight cycles.", "D. Any cycles.", "C"
"FloydWarshall", "How does Floyd-Warshall detect a negative-weight cycle?", "A. If any `dist[i][i]` (distance from a vertex to itself) becomes negative after the algorithm completes.", "B. By checking for infinite loops.", "C. By counting the number of edges.", "D. It cannot detect negative cycles.", "A"
"FloydWarshall", "What does the outer loop variable `k` represent in the Floyd-Warshall algorithm's three nested loops?", "A. The source vertex.", "B. The destination vertex.", "C. The intermediate vertex (or "pivot" vertex).", "D. The edge weight.", "C"
"FloydWarshall", "What are the initial values for `dist[i][j]` in the distance matrix?", "A. 0 if `i == j`, `infinity` if no direct edge, and direct edge weight otherwise.", "B. All zeros.", "C. All ones.", "D. All infinity.", "A"
"FloydWarshall", "The core update rule in Floyd-Warshall is `dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])`. What does this represent?", "A. The shortest path from `i` to `j` is either the current shortest path or a path through `k`.", "B. The longest path from `i` to `j`.", "C. The number of edges between `i` and `j`.", "D. The sum of all paths.", "A"
"FloydWarshall", "What does `dist[i][j]` represent after the `k`-th iteration of the outer loop?", "A. The shortest path from `i` to `j` using only intermediate vertices from `0` to `k-1`.", "B. The shortest path from `i` to `j` using only intermediate vertices from `0` to `k`.", "C. The length of the longest path.", "D. The initial distance from `i` to `j`.", "B"
"FloydWarshall", "For what type of graphs is Floyd-Warshall generally well-suited?", "A. Sparse graphs (few edges).", "B. Dense graphs (many edges).", "C. Unweighted graphs.", "D. Acyclic graphs.", "B"
"FloydWarshall", "How does Floyd-Warshall compare to running Bellman-Ford V times (once for each source) for all-pairs shortest paths?", "A. Floyd-Warshall is always faster.", "B. Floyd-Warshall has the same asymptotic time complexity (O(V^2 * E) vs O(V^3)), but often performs better in practice due to simpler inner loops.", "C. Bellman-Ford is always faster.", "D. They are completely different problems.", "B"
"FloydWarshall", "Which problem is the Floyd-Warshall algorithm designed to solve?", "A. Single-Source Shortest Path.", "B. All-Pairs Shortest Path.", "C. Minimum Spanning Tree.", "D. Maximum Flow.", "B"
"FloydWarshall", "If a graph has no direct edge between vertex `i` and vertex `j`, what value is typically assigned to `dist[i][j]` initially?", "A. 0", "B. 1", "C. A very large number (representing infinity).", "D. -1", "C"
"FloydWarshall", "Can the Floyd-Warshall algorithm reconstruct the actual shortest paths, not just their lengths?", "A. No, it only provides lengths.", "B. Yes, by using an additional `path` or `predecessor` matrix.", "C. Only for unweighted graphs.", "D. Only if there are no negative weights.", "B"
"FloydWarshall", "What is an application of the Floyd-Warshall algorithm in computer science?", "A. GPS navigation for a single route.", "B. Finding transitive closure of a graph (reachability).", "C. Network flow optimization.", "D. Sorting a list of numbers.", "B"
"FloydWarshall", "When considering the `k`-th intermediate vertex, the algorithm builds upon solutions calculated using intermediate vertices from `0` to `k-1`. This is a characteristic of:", "A. Greedy algorithms.", "B. Divide and conquer algorithms.", "C. Dynamic programming algorithms.", "D. Backtracking algorithms.", "C"
"FloydWarshall", "If a graph is undirected, how can it be represented for the Floyd-Warshall algorithm?", "A. It cannot be used with undirected graphs.", "B. Each undirected edge `(u, v)` is represented as two directed edges: `u -> v` and `v -> u` with the same weight.", "C. Only one directed edge is needed.", "D. Weights are ignored for undirected graphs.", "B"
"FloydWarshall", "What is a major advantage of Floyd-Warshall over repeated runs of Dijkstra's algorithm for all-pairs shortest paths?", "A. It is faster for all graph types.", "B. It can handle negative edge weights (as long as there are no negative cycles).", "C. It uses less memory.", "D. It is easier to parallelize.", "B"
"FloydWarshall", "What is a major disadvantage of Floyd-Warshall compared to repeated runs of Dijkstra's for all-pairs shortest paths on graphs with only non-negative weights?", "A. It cannot handle negative weights.", "B. It has higher time complexity (O(V^3) vs V * O(E + V log V) which can be better for sparse graphs).", "C. It uses more memory.", "D. It cannot detect negative cycles.", "B"
"FloydWarshall", "If an edge weight is 0, how does Floyd-Warshall handle it?", "A. It ignores it.", "B. It treats it as a normal edge, contributing 0 to path length.", "C. It treats it as a negative edge.", "D. It treats it as an error.", "B"
"FloydWarshall", "Does the order of the inner `i` and `j` loops matter in Floyd-Warshall?", "A. Yes, strictly `i` then `j`.", "B. Yes, strictly `j` then `i`.", "C. No, their order can be swapped.", "D. Only if `k` is fixed.", "C"
"FloydWarshall", "Does the order of the outer `k` loop matter in Floyd-Warshall?", "A. Yes, `k` must iterate from `0` to `V-1` (or `1` to `V`).", "B. No, `k` can iterate in any order.", "C. Only if there are negative weights.", "D. Only if there are cycles.", "A"
"FloydWarshall", "If a graph is disconnected, how does Floyd-Warshall handle the distance between vertices in different components?", "A. It will report an error.", "B. The distance will remain `infinity` (its initial large value).", "C. The distance will be 0.", "D. It will find a path through a common component.", "B"
"FloydWarshall", "What would `dist[i][i]` represent at the end of the algorithm if there are no negative cycles?", "A. Infinity.", "B. The longest path from `i` to `i`.", "C. 0 (distance from a vertex to itself).", "D. The number of self-loops.", "C"
"FloydWarshall", "Is the Floyd-Warshall algorithm an in-place algorithm (modifies the input graph representation)?", "A. Yes, it directly updates the distance matrix.", "B. No, it requires a separate matrix.", "C. Only if the graph is small.", "D. Depends on the implementation language.", "A"
"FloydWarshall", "The Floyd-Warshall algorithm can be thought of as applying the principle of optimal substructure by building up shortest paths incrementally. True or False?", "A. True", "B. False", "A"
"FloydWarshall", "Consider a graph with vertices 1, 2, 3. Edges: 1->2 (w=1), 2->3 (w=1), 3->1 (w=-3). If you run Floyd-Warshall, what will `dist[1][1]` become?", "A. 0", "B. -1", "C. -2", "D. Infinity", "C"
"FloydWarshall", "Which of these algorithms would you typically choose for a dense graph with negative edge weights (no negative cycles) to find all-pairs shortest paths?", "A. Dijkstra's Algorithm (V times).", "B. Bellman-Ford Algorithm (V times).", "C. Floyd-Warshall Algorithm.", "D. BFS.", "C"
"FloydWarshall", "Which of these algorithms would you typically choose for a sparse graph with positive edge weights to find all-pairs shortest paths?", "A. Floyd-Warshall Algorithm.", "B. Bellman-Ford Algorithm (V times).", "C. Dijkstra's Algorithm (V times with a Fibonacci Heap).", "D. DFS.", "C"
"FloydWarshall", "The Floyd-Warshall algorithm works directly on which graph representation?", "A. Adjacency List.", "B. Adjacency Matrix.", "C. Edge List.", "D. Implicit Graph.", "B"
"FloydWarshall", "What is the crucial initialization for `dist[i][j]` when `i != j` and there's no direct edge?", "A. 0", "B. The maximum integer value (INF)", "C. -1", "D. A random value", "B"
"FloydWarshall", "The concept of 'transitive closure' is directly related to which output of Floyd-Warshall?", "A. The number of paths.", "B. A boolean matrix indicating reachability between all pairs of vertices.", "C. The longest path.", "D. The minimum spanning tree.", "B"
"FloydWarshall", "If the graph has `N` vertices, how many matrices are implicitly or explicitly computed by the Floyd-Warshall algorithm?", "A. 1 (in-place update).", "B. N (one for each `k`).", "C. 2 (current and previous).", "D. N^2.", "B"
"FloydWarshall", "Does the Floyd-Warshall algorithm consider all possible simple paths between any two vertices?", "A. No, only direct paths.", "B. Yes, it implicitly considers all possible intermediate vertices.", "C. Only paths with positive weights.", "D. Only paths with two edges.", "B"
"FloydWarshall", "Can the Floyd-Warshall algorithm be used to check for the existence of any cycle in a graph?", "A. Yes, by checking `dist[i][i] < 0`.", "B. Yes, by checking `dist[i][i] != 0`.", "C. No, it's only for negative cycles.", "D. Only for positive cycles.", "C"
"FloydWarshall", "The property `dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])` is a recursive relationship that forms the basis of the dynamic programming solution. True or False?", "A. True", "B. False", "A"
"FloydWarshall", "If two nodes `i` and `j` are unreachable from each other, what will be their final distance in the `dist` matrix (assuming no negative cycles)?", "A. 0", "B. A large number (infinity).", "C. The largest finite number.", "D. -1", "B"
"FloydWarshall", "What is the primary difference between Bellman-Ford and Floyd-Warshall?", "A. Bellman-Ford is for all-pairs, Floyd-Warshall is for single-source.", "B. Bellman-Ford uses a priority queue, Floyd-Warshall uses a matrix.", "C. Bellman-Ford is single-source and can detect negative cycles from source; Floyd-Warshall is all-pairs and can detect *any* negative cycles.", "D. Bellman-Ford only handles positive weights.", "C"
"FloydWarshall", "Why is the Floyd-Warshall algorithm often considered simpler to implement than V runs of Dijkstra's or Bellman-Ford for all-pairs?", "A. It has fewer lines of code due to its simple triple-nested loop structure.", "B. It uses less memory.", "C. It is inherently recursive.", "D. It does not require adjacency lists.", "A"
"FloydWarshall", "What is the maximum number of intermediate vertices considered in the shortest path between any two vertices `i` and `j` in a graph with `V` vertices?", "A. 1", "B. V", "C. V-1", "D. 2", "V-2" (for simple paths, excluding i and j themselves, there can be at most V-2 intermediate vertices. The k loop runs up to V-1, essentially considering all other vertices as intermediate.)
"FloydWarshall", "Does Floyd-Warshall return the same shortest path lengths as Bellman-Ford if no negative cycles exist?", "A. Yes, for all pairs it will be consistent.", "B. No, they use different methods.", "C. Only for positive weights.", "D. Only for small graphs.", "A"
"FloydWarshall", "If a graph has `V` vertices and `E` edges, is Floyd-Warshall more efficient for dense graphs or sparse graphs?", "A. Dense graphs.", "B. Sparse graphs.", "C. Both equally.", "D. Neither.", "A"
"FloydWarshall", "Which term best describes the process of checking every possible `k` (intermediate vertex) for every pair `(i, j)` in Floyd-Warshall?", "A. Greedy selection.", "B. Exhaustive search (within a DP structure).", "C. Random traversal.", "D. Priority queue management.", "B"
"FloydWarshall", "Can Floyd-Warshall be used to solve the problem of finding the shortest cycle in a graph?", "A. No.", "B. Yes, by examining the diagonal elements and their predecessors.", "C. Only if the cycle is negative.", "D. Only if the cycle is positive.", "B"
"FloydWarshall", "What is the state of the distance matrix after the first iteration (when `k=0`) in Floyd-Warshall (assuming 0-indexed vertices)?", "A. All distances are 0.", "B. Distances are updated to include paths through vertex 0 as an intermediate.", "C. All distances are infinity.", "D. Only direct edge weights are considered.", "B"
"FloydWarshall", "If `dist[i][k] == infinity` or `dist[k][j] == infinity`, what happens to `dist[i][k] + dist[k][j]` in the update rule (assuming infinity + finite = infinity)?", "A. It becomes 0.", "B. It remains infinity, so `min` will likely keep `dist[i][j]` as is unless a direct path exists.", "C. It becomes a very small negative number.", "D. It causes an error.", "B"
"FloydWarshall", "The Floyd-Warshall algorithm computes shortest paths in a bottom-up fashion. True or False?", "A. True", "B. False", "A"
"FloydWarshall", "For graph visualization, if a shortest path is found, how many times is an edge `(u, v)` (which is part of the final shortest path) relaxed or considered for updates?", "A. Exactly once.", "B. Multiple times, as each `k` iteration potentially considers it as part of a path.", "C. Never.", "D. Only if its weight is negative.", "B"
"DisjointSet", "What is the primary purpose of a Disjoint Set (Union-Find) data structure?", "A. To store elements in a sorted order.", "B. To maintain a collection of disjoint sets and perform union and find operations efficiently.", "C. To represent a graph for shortest path algorithms.", "D. To count the frequency of elements.", "B"
"DisjointSet", "What are the two primary operations supported by a Disjoint Set data structure?", "A. Add and Remove.", "B. Union and Intersect.", "C. Find (or FindSet) and Union (or UnionSet).", "D. Push and Pop.", "C"
"DisjointSet", "The `Find` operation in a Disjoint Set data structure typically returns:", "A. The value of the element.", "B. The representative (or root) of the set containing the element.", "C. The size of the set.", "D. A boolean indicating if the element exists.", "B"
"DisjointSet", "The `Union` operation in a Disjoint Set data structure combines:", "A. Two elements into a new set.", "B. Two existing sets into a single set.", "C. An element and a set.", "D. All sets into one.", "B"
"DisjointSet", "What is the initial state of a Disjoint Set data structure with `N` elements?", "A. All elements are in one large set.", "B. Each of the `N` elements is in its own distinct set.", "C. The data structure is empty.", "D. Elements are randomly assigned to sets.", "B"
"DisjointSet", "Which of the following data structures is typically used to implement a Disjoint Set?", "A. Linked List", "B. Adjacency List", "C. Array (to represent parent pointers) or Trees (forest of trees)", "D. Hash Map", "C"
"DisjointSet", "What is 'Path Compression' in the context of Disjoint Set?", "A. Compressing the path of edges in a graph.", "B. During a `Find` operation, making every node on the path from the element to the root point directly to the root.", "C. Reducing the number of sets.", "D. Deleting redundant elements.", "B"
"DisjointSet", "What is 'Union by Rank' (or 'Union by Height') in the context of Disjoint Set?", "A. Always attaching the smaller tree under the root of the taller tree to minimize tree height.", "B. Always attaching the larger tree under the smaller tree.", "C. Unioning based on element values.", "D. Unioning based on insertion order.", "A"
"DisjointSet", "What is 'Union by Size' (or 'Union by Weight') in the context of Disjoint Set?", "A. Always attaching the smaller tree under the root of the larger tree to minimize tree height/depth.", "B. Unioning based on element values.", "C. Unioning based on insertion order.", "D. Always attaching the larger tree under the smaller tree.", "A"
"DisjointSet", "When both Path Compression and Union by Rank/Size optimizations are applied, what is the amortized time complexity for `M` operations on `N` elements?", "A. O(M * log N)", "B. O(M * N)", "C. O(M * alpha(N)) where alpha is the inverse Ackermann function (practically constant).", "D. O(M + N)", "C"
"DisjointSet", "If only Path Compression is used (without Union by Rank/Size), what is the amortized time complexity for `M` operations on `N` elements?", "A. O(M * log N)", "B. O(M * N)", "C. O(M * alpha(N))", "D. O(M + N)", "A"
"DisjointSet", "What is the worst-case time complexity of a single `Find` operation *without* path compression?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(alpha(N))", "C"
"DisjointSet", "What is the worst-case time complexity of a single `Union` operation *without* union by rank/size?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(alpha(N))", "C"
"DisjointSet", "What is the initial value for the parent of each element `i` when initializing a Disjoint Set?", "A. `-1`", "B. `i` (each element is its own parent/root).", "C. `0`", "D. `null`", "B"
"DisjointSet", "In a Disjoint Set implementation using an array `parent[]`, if `parent[i] == i`, what does it signify?", "A. `i` is an invalid element.", "B. `i` is a leaf node.", "C. `i` is the representative (root) of its set.", "D. `i` has been removed.", "C"
"DisjointSet", "Which graph algorithm commonly uses Disjoint Set to efficiently detect cycles and form connected components?", "A. Dijkstra's Algorithm.", "B. Prim's Algorithm for MST.", "C. Kruskal's Algorithm for MST.", "D. Bellman-Ford Algorithm.", "C"
"DisjointSet", "What is the purpose of the `rank` (or `size`) array in the Union-Find data structure?", "A. To store the value of each element.", "B. To keep track of the height (or size) of the trees, used for optimizing `Union` operations.", "C. To store the original index of an element.", "D. To count the number of times `Find` is called.", "B"
"DisjointSet", "When performing `Union(x, y)`, and `rootX` is the root of `x`'s set and `rootY` is the root of `y`'s set, how do you typically combine them with Union by Rank?", "A. Attach `rootY` to `rootX` regardless of rank.", "B. Attach the root of the smaller rank tree as a child of the root of the larger rank tree.", "C. Attach `rootX` to `rootY` regardless of rank.", "D. Create a new root for both.", "B"
"DisjointSet", "If `rootX` and `rootY` have the same rank in Union by Rank, and `rootY` is attached to `rootX`, what happens to `rootX`'s rank?", "A. It decreases by 1.", "B. It increases by 1.", "C. It remains the same.", "D. It becomes 0.", "B"
"DisjointSet", "Is the inverse Ackermann function (alpha(N)) truly constant in practical applications?", "A. No, it grows very rapidly.", "B. Yes, for all practical input sizes, alpha(N) is less than 5.", "C. Only for N < 100.", "D. Only for N > 1 million.", "B"
"DisjointSet", "Can Disjoint Set be used to find the number of connected components in an undirected graph?", "A. No, it's for directed graphs only.", "B. Yes, by iterating through all edges and performing `Union` operations on connected vertices. The number of remaining disjoint sets is the number of components.", "C. Only for weighted graphs.", "D. Only for trees.", "B"
"DisjointSet", "What is the state of the trees in a Disjoint Set structure after many `Find` operations with path compression?", "A. They remain deep and unbalanced.", "B. They become very flat, almost star-like structures.", "C. They grow taller.", "D. They merge into a single tree.", "B"
"DisjointSet", "What happens if `Union(x, y)` is called, but `x` and `y` are already in the same set?", "A. An error occurs.", "B. The operation has no effect (returns false or similar).", "C. A new set is created.", "D. The element `x` is removed.", "B"
"DisjointSet", "Which of the following is NOT an application of Disjoint Set?", "A. Kruskal's algorithm for MST.", "B. Detecting cycles in an undirected graph.", "C. Connected components on a grid (e.g., in image processing).", "D. Finding shortest paths in a graph (like Dijkstra's).", "D"
"DisjointSet", "If you represent the parent array as `parent[i] = p`, where `p` is the parent of `i`, what happens if `p < 0`?", "A. `p` is the representative, and `|p|` could store the rank/size.", "B. `p` is an error code.", "C. `p` indicates a loop.", "D. `p` is an unvisited node.", "A"
"DisjointSet", "In a Disjoint Set data structure, each element belongs to exactly how many sets?", "A. Zero.", "B. One.", "C. Multiple.", "D. Depends on the operation.", "B"
"DisjointSet", "What is the worst-case time complexity of initializing a Disjoint Set for `N` elements?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"DisjointSet", "If elements are 0-indexed, and `parent[i] = i` for all `i`, what does this imply?", "A. All elements are in one set.", "B. Each element is the root of its own set.", "C. The data structure is corrupted.", "D. All elements are uninitialized.", "B"
"DisjointSet", "Is it possible for a Disjoint Set to have elements removed from it directly?", "A. Yes, using a specific `Remove` operation.", "B. No, the standard operations do not support element removal or splitting sets efficiently.", "C. Only if the set is empty.", "D. Only if the element is a root.", "B"
"DisjointSet", "Consider a `Find(x)` operation. If `x` is not the root of its set, what does Path Compression do?", "A. It stops at `x`.", "B. It makes `x`'s parent point to `x`'s grandparent.", "C. It makes `x`'s parent point directly to the true root of the set.", "D. It reverses the path from `x` to the root.", "C"
"DisjointSet", "What is the maximum height of a tree in a Disjoint Set forest when using Union by Rank/Size?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N^2)", "B"
"DisjointSet", "If the trees in a Disjoint Set are initially formed without any optimizations, what could be their worst-case shape?", "A. Bushy trees.", "B. Balanced trees.", "C. Skewed trees (like linked lists).", "D. Star-shaped trees.", "C"
"DisjointSet", "Why is the term 'amortized' used for the time complexity of Union-Find with optimizations?", "A. Because it's always fast.", "B. Because the cost of a single expensive operation is averaged out over a sequence of operations, making the average cost very low.", "C. Because it's an estimation, not exact.", "D. Because operations are performed in parallel.", "B"
"DisjointSet", "In Kruskal's algorithm, when is a Disjoint Set operation performed?", "A. After the MST is built.", "B. When considering an edge, to check if its endpoints are already in the same connected component (set).", "C. Only during initialization.", "D. To sort the edges.", "B"
"DisjointSet", "If `Find(A)` returns `R` and `Find(B)` returns `R`, what does this imply about elements `A` and `B`?", "A. They are in different sets.", "B. They are in the same set.", "C. They are both roots.", "D. They have the same value.", "B"
"DisjointSet", "The Disjoint Set data structure effectively maintains a collection of equivalence classes. True or False?", "A. True", "B. False", "A"
"DisjointSet", "What is the typical representation of a 'rank' for Union by Rank?", "A. The number of elements in the subtree.", "B. The maximum height of the tree (number of edges from root to deepest leaf).", "C. The value of the root.", "D. The index of the root.", "B"
"DisjointSet", "Which data structure would be a poor choice for implementing Disjoint Set's core operations efficiently?", "A. Array.", "B. Hash Map (for parent pointers).", "C. Adjacency Matrix.", "D. Any of these could work, but an array for parent pointers is standard and efficient.", "C"
"DisjointSet", "If `N = 10^5`, what is `alpha(N)` roughly equal to?", "A. 1", "B. 2", "C. 3", "D. 4", "D"
"DisjointSet", "What is the purpose of storing `parent[i]` as a negative number if `i` is a root?", "A. To indicate it's a negative value.", "B. To store the size of the set (e.g., `parent[i] = -size`).", "C. To mark it as visited.", "D. To indicate an error.", "B"
"DisjointSet", "Can Disjoint Set be used for finding cycles in a directed graph?", "A. Yes, directly.", "B. No, it's primarily for undirected graphs and their connected components/cycles.", "C. Only if the graph is small.", "D. Only if there are no negative weights.", "B"
"DisjointSet", "If `Union(x, y)` is called, and `rootX` is the root of `x`'s set and `rootY` is the root of `y`'s set. If `rank[rootX] < rank[rootY]`, then `parent[rootX]` is set to `rootY`. What happens to `rank[rootY]`?", "A. It increases by 1.", "B. It remains unchanged.", "C. It decreases by 1.", "D. It becomes 0.", "B"
"DisjointSet", "Consider a forest of trees representing disjoint sets. What does Path Compression do to the structure of these trees?", "A. Makes them deeper.", "B. Makes them wider.", "C. Makes them flatter.", "D. Makes them more numerous.", "C"
"DisjointSet", "When implementing `Find(i)` with path compression, if `parent[i] != i`, the recursive call is `parent[i] = Find(parent[i])`. True or False?", "A. True", "B. False", "A"
"DisjointSet", "If you have a grid and need to determine which cells are connected (e.g., forming a blob), what data structure is suitable?", "A. Stack.", "B. Queue.", "C. Disjoint Set.", "D. Binary Search Tree.", "C"
"DisjointSet", "What is the primary motivation for using Union by Rank/Size (or both) in Disjoint Set?", "A. To reduce memory usage.", "B. To make the `Find` operation faster on average by keeping trees relatively flat/balanced.", "C. To simplify the implementation.", "D. To guarantee unique elements.", "B"
"DisjointSet", "Does the order of `Union` operations affect the final connected components, assuming all unions are eventually performed?", "A. Yes, always.", "B. No, the final set partitioning is determined by the set of elements and unions, not their order.", "C. Only if path compression is used.", "D. Only if union by rank is used.", "B"
"DisjointSet", "What would be the typical use case for a Disjoint Set where you just need to know if two elements are connected?", "A. Performing a `Find` operation on both elements and comparing their roots.", "B. Performing a `Union` operation on them.", "C. Checking their values.", "D. Counting their neighbors.", "A"
"DisjointSet", "The term 'Disjoint Set Forest' refers to:", "A. A collection of trees where each tree represents a set, and its root is the set's representative.", "B. A single large tree.", "C. A random graph.", "D. A type of linked list.", "A"
"DisjointSet", "For `N` elements, what is the size of the `parent` array and `rank` (or `size`) array typically?", "A. N-1", "B. N", "C. N+1", "D. 2N", "B"
"SlidingWindow", "What is the primary purpose of the Sliding Window technique?", "A. To sort an array efficiently.", "B. To optimize traversal over arrays or strings by maintaining a 'window' of fixed or variable size.", "C. To find the shortest path in a graph.", "D. To perform binary search.", "B"
"SlidingWindow", "The Sliding Window technique is primarily used for problems on which data structures?", "A. Linked Lists", "B. Trees", "C. Arrays and Strings", "D. Graphs", "C"
"SlidingWindow", "When is a 'fixed-size' sliding window typically used?", "A. When the problem asks for a subarray/substring of a specific length.", "B. When the problem asks for the longest possible subarray/substring.", "C. When the problem involves unique characters.", "D. When the problem requires sorting.", "A"
"SlidingWindow", "When is a 'variable-size' sliding window typically used?", "A. When the problem asks for a subarray/substring of a specific length.", "B. When the problem involves finding the shortest/longest subarray/substring that satisfies a certain condition.", "C. When the problem requires counting frequencies.", "D. When the problem involves prime numbers.", "B"
"SlidingWindow", "What are the two main pointers (or indices) that define a sliding window?", "A. `start` and `mid`", "B. `left` and `right` (or `start` and `end`)", "C. `head` and `tail`", "D. `min` and `max`", "B"
"SlidingWindow", "In a fixed-size sliding window, what happens to the `left` pointer when the `right` pointer moves forward?", "A. It moves forward by the same amount, maintaining fixed window size.", "B. It stays in place.", "C. It moves backward.", "D. It moves randomly.", "A"
"SlidingWindow", "In a variable-size sliding window, when might the `left` pointer move?", "A. Only when the `right` pointer reaches the end of the array.", "B. When the current window satisfies a condition and needs to be shrunk from the left, or when the window exceeds a constraint.", "C. Only when the `right` pointer moves backward.", "D. It never moves.", "B"
"SlidingWindow", "What is the typical time complexity of a Sliding Window algorithm for an array/string of length `N`?", "A. O(N^2)", "B. O(N) (linear time)", "C. O(N log N)", "D. O(log N)", "B"
"SlidingWindow", "Why is the Sliding Window technique often more efficient than nested loops (brute force)?", "A. It uses more memory.", "B. It re-evaluates the entire subarray/substring at each step.", "C. It avoids redundant calculations by incrementally updating results as the window slides.", "D. It is only for sorted arrays.", "C"
"SlidingWindow", "Consider the problem: 'Find the maximum sum of a subarray of size `k`.' Which type of sliding window would you use?", "A. Variable-size window.", "B. Fixed-size window.", "C. No window, use dynamic programming.", "D. Brute force.", "B"
"SlidingWindow", "Consider the problem: 'Find the longest substring without repeating characters.' Which type of sliding window would you use?", "A. Fixed-size window.", "B. Variable-size window.", "C. No window, use recursion.", "D. Two pointers (not sliding window).", "B"
"SlidingWindow", "What data structure is often used to efficiently track elements or their frequencies within the current window?", "A. Stack", "B. Queue", "C. Hash Map (or frequency array)", "D. Binary Search Tree", "C"
"SlidingWindow", "In the problem 'Longest Substring with K distinct characters', what is the role of the `left` pointer when the number of distinct characters exceeds `K`?", "A. It moves forward to shrink the window until the condition is met.", "B. It stays in place.", "C. It moves backward.", "D. It moves to the beginning.", "A"
"SlidingWindow", "What is the result of the `max(current_length, max_length)` update often seen in variable-size sliding window problems?", "A. It finds the shortest valid window.", "B. It updates the maximum length found so far that satisfies the condition.", "C. It calculates the average length.", "D. It finds the sum of lengths.", "B"
"SlidingWindow", "What is the result of the `min(current_length, min_length)` update often seen in variable-size sliding window problems?", "A. It finds the longest valid window.", "B. It updates the minimum length found so far that satisfies the condition.", "C. It calculates the average length.", "D. It finds the sum of lengths.", "B"
"SlidingWindow", "Which of these problems is a classic example of fixed-size sliding window?", "A. Finding the smallest subarray with sum greater than X.", "B. Finding the longest substring with at most two distinct characters.", "C. Finding the maximum sum subarray of a specific size.", "D. Finding all anagrams of a pattern in a text.", "C"
"SlidingWindow", "Which of these problems is a classic example of variable-size sliding window?", "A. Maximum average subarray of size K.", "B. Minimum window substring (smallest window containing all characters of another string).", "C. K-th largest element in an array.", "D. Merge two sorted arrays.", "B"
"SlidingWindow", "In a fixed-size window problem, if the window size is `k`, how many elements are in the window at any given time (after initial setup)?", "A. `k-1`", "B. `k`", "C. `k+1`", "D. Variable.", "B"
"SlidingWindow", "When is the `right` pointer typically incremented in a sliding window approach?", "A. When the window is too small.", "B. In every iteration of the main loop, to expand the window.", "C. Only when the condition is met.", "D. Only when the `left` pointer moves.", "B"
"SlidingWindow", "What is a common optimization to apply after updating the window's elements (e.g., in a frequency map)?", "A. Sort the map.", "B. Check if the current window satisfies the problem's condition.", "C. Reset the map.", "D. Reverse the map.", "B"
"SlidingWindow", "Can the Sliding Window technique be used on linked lists?", "A. No, only arrays.", "B. Yes, but it's less common and might involve traversing to find `left` and `right` pointers, potentially losing O(1) pointer movement.", "C. Only if the linked list is sorted.", "D. Only if the linked list is circular.", "B"
"SlidingWindow", "For the problem 'Permutation in String' (check if string S2 contains a permutation of string S1 as a substring), what kind of sliding window is typically used?", "A. Fixed-size window (size of S1).", "B. Variable-size window.", "C. No window, use dynamic programming.", "D. Brute force string comparison.", "A"
"SlidingWindow", "When designing a variable-size sliding window, what are the two main phases of the `left` pointer?", "A. Always expanding, never shrinking.", "B. Expanding to include new elements, and shrinking to satisfy conditions or constraints.", "C. Always shrinking, never expanding.", "D. Only for error handling.", "B"
"SlidingWindow", "What is the space complexity of a typical Sliding Window algorithm that uses a hash map for frequency counting?", "A. O(1) (if alphabet size is fixed, e.g., 26 for English letters).", "B. O(N) (if the number of distinct elements can be N).", "C. O(N^2).", "D. Both A and B, depending on the problem's constraints on distinct elements.", "D"
"SlidingWindow", "If the problem asks for the *smallest* window, what happens when the window *meets* the condition?", "A. You stop and return the current window.", "B. You update the minimum length found so far, and then try to *shrink* the window from the left to find an even smaller valid window.", "C. You expand the window further to the right.", "D. You restart the search.", "B"
"SlidingWindow", "If the problem asks for the *largest* window, what happens when the window *meets* the condition?", "A. You stop and return the current window.", "B. You update the maximum length found so far, and then try to *expand* the window further to the right.", "C. You shrink the window from the left.", "D. You restart the search.", "B"
"SlidingWindow", "The Sliding Window technique is particularly useful for problems that involve:", "A. Sorting large datasets.", "B. Finding an optimal subarray/substring with specific properties.", "C. Graph traversals.", "D. Recursive backtracking.", "B"
"SlidingWindow", "In Python, what is a convenient way to represent a sliding window on a list?", "A. Using `list.pop()` and `list.append()`.", "B. Using two index variables (`left`, `right`) and accessing `arr[left:right+1]`.", "C. Using a `deque` (double-ended queue).", "D. Both B and C are common and efficient.", "D"
"SlidingWindow", "What is the crucial element to manage in a variable-size sliding window to ensure correctness and efficiency?", "A. The starting index of the array.", "B. The state of the window (e.g., count of distinct characters, current sum) and how to update it efficiently as `left` and `right` move.", "C. The maximum possible value in the array.", "D. The minimum possible value in the array.", "B"
"SlidingWindow", "Consider the problem 'Maximum Average Subarray I'. It is a fixed-size window problem. How is the average calculated?", "A. Sum of window elements divided by `k`.", "B. Product of window elements.", "C. Min of window elements.", "D. Max of window elements.", "A"
"SlidingWindow", "What if the input array/string is empty? How should a Sliding Window algorithm generally handle this?", "A. It should proceed normally.", "B. It should return an empty result or handle it as an edge case (e.g., return 0 or null).", "C. It will cause an error.", "D. It will loop infinitely.", "B"
"SlidingWindow", "Is the Sliding Window technique typically applied to problems requiring in-place modification of the array/string?", "A. Yes, always.", "B. No, it primarily focuses on finding subarrays/substrings, not modifying the input in-place.", "C. Only for very small arrays.", "D. Only if the window size is 1.", "B"
"SlidingWindow", "When is a `while` loop often used for the `left` pointer's movement in a variable-size sliding window?", "A. To always expand the window.", "B. To repeatedly shrink the window until a specific condition is no longer violated (or is met).", "C. To check for errors.", "D. To initialize the window.", "B"
"SlidingWindow", "The `right` pointer in a sliding window typically moves in what direction?", "A. Only left.", "B. Only right (forward).", "C. Both directions.", "D. Randomly.", "B"
"SlidingWindow", "The `left` pointer in a sliding window typically moves in what direction?", "A. Only left (backward).", "B. Only right (forward).", "C. Both directions.", "D. Randomly.", "B"
"SlidingWindow", "Can a Sliding Window be applied to problems where elements are not contiguous (e.g., subsequences)?", "A. Yes, always.", "B. No, it is fundamentally designed for contiguous subarrays/substrings.", "C. Only if the subsequence is very short.", "D. Only if the elements are sorted.", "B"
"SlidingWindow", "In a problem asking for the 'Longest Substring with at most K distinct characters', if `K=0`, what is the expected output?", "A. The entire string.", "B. An empty string or length 0.", "C. An error.", "D. The first character.", "B"
"SlidingWindow", "What is the primary benefit of a deque (double-ended queue) in certain advanced sliding window problems?", "A. It allows O(1) insertion/deletion from both ends, useful for maintaining monotonic queues (e.g., for max/min in window).", "B. It sorts elements automatically.", "C. It replaces the need for hash maps.", "D. It prevents infinite loops.", "A"
"SlidingWindow", "Consider the problem 'Number of Subarrays with Product Less Than K'. What type of window would this typically involve?", "A. Fixed-size.", "B. Variable-size (shrinking from left when product >= K).", "C. No window, use binary search.", "D. Sorting the array first.", "B"
"SlidingWindow", "If the problem involves characters from a small, fixed alphabet (e.g., 'a'-'z'), what can be used instead of a generic hash map for frequency counting?", "A. A hash set.", "B. A fixed-size array (e.g., `int[26]`).", "C. A linked list.", "D. A stack.", "B"
"SlidingWindow", "What is the role of a `current_sum` or `current_product` variable in a numerical sliding window problem?", "A. To store the final answer.", "B. To efficiently update the sum/product of elements currently within the window.", "C. To count the number of elements.", "D. To store the maximum element.", "B"
"SlidingWindow", "When applying Sliding Window, what is generally the condition for the `right` pointer to stop moving?", "A. When it reaches the end of the input array/string.", "B. When the window meets the desired condition.", "C. When the `left` pointer moves.", "D. When the sum is negative.", "A"
"SlidingWindow", "The Sliding Window technique is an example of an approach that tries to reduce the number of redundant computations by:", "A. Eliminating all loops.", "B. Reusing previous calculations as the window shifts.", "C. Only processing unique elements.", "D. Sorting the input.", "B"
"SlidingWindow", "Can the Sliding Window technique be applied to 2D arrays (matrices)?", "A. No, only 1D arrays.", "B. Yes, often by applying a 1D sliding window to each row/column, or a 2D window.", "C. Only for square matrices.", "D. Only for unweighted matrices.", "B"
"SlidingWindow", "What is an important edge case to consider when implementing a variable-size sliding window?", "A. The input array having only one element.", "B. The input array being sorted.", "C. The input array having duplicate elements.", "D. The window always being too small.", "A"
"SlidingWindow", "What is the primary benefit of maintaining the window's state (e.g., sum, frequencies) incrementally?", "A. It reduces memory usage significantly.", "B. It makes the solution O(N) time complexity instead of O(N^2) or higher.", "C. It simplifies the code logic.", "D. It prevents the `left` pointer from moving.", "B"
"SlidingWindow", "For a problem like 'Find All Anagrams in a String', where the window size is fixed, what determines the fixed size?", "A. The size of the text string.", "B. The size of the pattern string (the anagram).", "C. A constant value, like 3.", "D. It's variable.", "B"
"SlidingWindow", "If a problem states 'find the *shortest* subarray/substring that satisfies X', and a variable-size sliding window is used, when do you update your `min_length` result?", "A. Only at the very end of the algorithm.", "B. Every time the window satisfies condition X, before attempting to shrink the window.", "C. Only when the `left` pointer moves.", "D. Only when the `right` pointer moves.", "B"
"SlidingWindow", "If a problem states 'find the *longest* subarray/substring that satisfies X', and a variable-size sliding window is used, when do you update your `max_length` result?", "A. Only at the very end of the algorithm.", "B. Every time the window satisfies condition X, before attempting to expand the window further.", "C. Only when the `left` pointer moves.", "D. Only when the `right` pointer moves.", "B"
"SlidingWindow", "What kind of problems can be solved with a sliding window that a simple two-pointer approach (without a moving window concept) might struggle with?", "A. Problems where the "window" needs to maintain a specific property (like distinct chars or sum) as it dynamically adjusts its boundaries.", "B. Simple sorting problems.", "C. Finding the middle element of an array.", "D. Basic array reversals.", "A"
"TwoPointer", "What is the primary purpose of the Two-Pointer technique?", "A. To sort an array in O(N) time.", "B. To efficiently traverse and process elements in sequences (like arrays or strings) by using two pointers that move towards each other, away from each other, or at different speeds.", "C. To find the shortest path in a graph.", "D. To perform binary search on unsorted data.", "B"
"TwoPointer", "The Two-Pointer technique is primarily used for problems on which data structures?", "A. Linked Lists", "B. Trees", "C. Arrays and Strings", "D. Graphs", "C"
"TwoPointer", "What are the common variations of the Two-Pointer approach?", "A. Fast and Slow, Left and Right (converging), Two Pointers in the same direction.", "B. Single pointer, triple pointer.", "C. Recursive pointers, iterative pointers.", "D. Random pointers, fixed pointers.", "A"
"TwoPointer", "In the 'Left and Right (converging)' approach, how are the pointers typically initialized?", "A. Both at the beginning of the sequence.", "B. Both at the end of the sequence.", "C. One at the beginning (`left`) and one at the end (`right`).", "D. Both at the middle of the sequence.", "C"
"TwoPointer", "When do the pointers stop moving in the 'Left and Right (converging)' approach?", "A. When they are at the same index or cross each other.", "B. When they reach the end of the array.", "C. When they find the target sum.", "D. When the array is sorted.", "A"
"TwoPointer", "What is a classic problem solved using the 'Left and Right (converging)' two-pointer approach (often on sorted arrays)?", "A. Finding the maximum element.", "B. Finding a pair of elements that sum to a target value.", "C. Reversing a linked list.", "D. Binary search.", "B"
"TwoPointer", "In the 'Fast and Slow' pointer approach, how are the pointers typically initialized?", "A. Both at the beginning of the sequence.", "B. Both at the end of the sequence.", "C. One at the beginning, the other at the end.", "D. One at the beginning, the other one or more steps ahead.", "A"
"TwoPointer", "What is a classic problem solved using the 'Fast and Slow' pointer approach?", "A. Finding the sum of two numbers.", "B. Detecting a cycle in a linked list.", "C. Sorting an array.", "D. Merging two sorted arrays.", "B"
"TwoPointer", "What is the typical time complexity of a Two-Pointer algorithm for an array/string of length `N`?", "A. O(N^2)", "B. O(N) (linear time)", "C. O(N log N)", "D. O(log N)", "B"
"TwoPointer", "Why is the Two-Pointer technique often more efficient than nested loops (brute force)?", "A. It uses more memory.", "B. It re-evaluates the entire subarray/substring at each step.", "C. It avoids redundant calculations by exploiting some ordering or property to move pointers incrementally.", "D. It is only for unsorted arrays.", "C"
"TwoPointer", "Consider the problem 'Reverse a string'. Which type of two-pointer approach would be most suitable?", "A. Fast and Slow.", "B. Left and Right (converging).", "C. Two pointers in the same direction.", "D. No pointers needed.", "B"
"TwoPointer", "Consider the problem 'Remove Duplicates from Sorted Array'. Which type of two-pointer approach is commonly used?", "A. Fast and Slow (both moving in the same direction, one fast for finding non-duplicates, one slow for placing).", "B. Left and Right (converging).", "C. Two pointers in opposite directions.", "D. Fixed window.", "A"
"TwoPointer", "What property of the input data is most beneficial for applying the 'Left and Right (converging)' two-pointer approach?", "A. Random order.", "B. Sorted or partially sorted order.", "C. Uniqueness of elements.", "D. Presence of negative numbers.", "B"
"TwoPointer", "If you're finding pairs with a target sum in a sorted array using two pointers (`left` and `right`), and `arr[left] + arr[right] > target`, what should you do?", "A. Increment `left`.", "B. Decrement `right`.", "C. Keep both pointers where they are.", "D. Restart the search.", "B"
"TwoPointer", "If you're finding pairs with a target sum in a sorted array using two pointers (`left` and `right`), and `arr[left] + arr[right] < target`, what should you do?", "A. Increment `left`.", "B. Decrement `right`.", "C. Keep both pointers where they are.", "D. Restart the search.", "A"
"TwoPointer", "What is a key difference between the Two-Pointer technique and the Sliding Window technique?", "A. Two-Pointers always have a fixed window size.", "B. Sliding Window always has two pointers moving in the same direction.", "C. Sliding Window focuses on contiguous subarrays/substrings, while Two-Pointers can be more general (e.g., finding cycle, reversing, processing two separate lists).", "D. Two-Pointers is always O(N^2), Sliding Window is always O(N).", "C"
"TwoPointer", "Can the Two-Pointer technique be used to merge two sorted arrays into a single sorted array?", "A. No, only for single arrays.", "B. Yes, by using two pointers, one for each array, and comparing elements.", "C. Only if the arrays have the same length.", "D. Only if the arrays are unsorted.", "B"
"TwoPointer", "When detecting a cycle in a linked list using the 'Fast and Slow' approach, if the pointers meet, what does it signify?", "A. No cycle exists.", "B. A cycle exists.", "C. The linked list is empty.", "D. The linked list is sorted.", "B"
"TwoPointer", "In the 'Fast and Slow' pointer approach for cycle detection in a linked list, how do the pointers move?", "A. Both move one step at a time.", "B. Fast moves two steps, Slow moves one step.", "C. Fast moves one step, Slow moves two steps.", "D. Both move randomly.", "B"
"TwoPointer", "What is the space complexity of a typical Two-Pointer algorithm?", "A. O(N) (for storing temporary data).", "B. O(1) (constant space, as it only uses a few variables for pointers).", "C. O(log N).", "D. O(N^2).", "B"
"TwoPointer", "Which of the following problems can be efficiently solved using a two-pointer approach?", "A. Finding the maximum subarray sum in an unsorted array.", "B. Checking if a string is a palindrome.", "C. Building a binary search tree.", "D. Calculating permutations.", "B"
"TwoPointer", "When are the two pointers typically initialized at the beginning of the sequence and move in the same direction?", "A. When finding elements from opposite ends.", "B. For problems like removing duplicates from sorted arrays or finding `k`-th element in merged arrays.", "C. For cycle detection.", "D. For searching in unsorted arrays.", "B"
"TwoPointer", "For the problem 'Move Zeros to End' (in an array), what kind of two-pointer strategy is effective?", "A. Left and Right (converging).", "B. One pointer for non-zero elements, another for iterating and placing them.", "C. Fast and Slow (for cycle detection).", "D. Fixed window.", "B"
"TwoPointer", "If you are trying to find two elements in a sorted array that are closest to a target sum, which two-pointer variation is most appropriate?", "A. Left and Right (converging).", "B. Fast and Slow.", "C. Two pointers moving in the same direction.", "D. Sliding Window.", "A"
"TwoPointer", "What is the common post-processing step if you use two pointers to modify an array in-place (e.g., removing duplicates or moving zeros)?", "A. Sorting the array again.", "B. Resizing the array or filling remaining slots (if any).", "C. Reversing the array.", "D. Calculating the sum of elements.", "B"
"TwoPointer", "Can the Two-Pointer technique be directly applied to problems that require finding combinations or permutations (without specific ordering constraints)?", "A. Yes, always.", "B. No, its efficiency comes from exploiting order; combinations/permutations usually require backtracking or recursion.", "C. Only for very small inputs.", "D. Only if the elements are unique.", "B"
"TwoPointer", "When checking for a palindrome in a string using two pointers, if `str[left] != str[right]`, what does it signify?", "A. The string is a palindrome.", "B. The string is not a palindrome.", "C. The pointers need to move further.", "D. The string is empty.", "B"
"TwoPointer", "In a problem like 'Container With Most Water', where two pointers converge, what is the strategy for moving pointers?", "A. Always move both inwards.", "B. Move the pointer pointing to the shorter line inwards to potentially find a taller line.", "C. Move the pointer pointing to the taller line inwards.", "D. Randomly move either pointer.", "B"
"TwoPointer", "For a problem involving three pointers (e.g., '3Sum' on a sorted array), how is it often structured?", "A. One fixed pointer, and two inner pointers using the 'Left and Right (converging)' approach on the remaining subarray.", "B. Three pointers moving at different speeds.", "C. Three pointers always at the beginning.", "D. Recursively calling a two-pointer function three times.", "A"
"TwoPointer", "What is the main advantage of using two pointers over hash sets for problems like 'Two Sum' in sorted arrays?", "A. Better time complexity.", "B. Simpler implementation.", "C. Better space complexity (O(1) vs O(N)).", "D. Can handle unsorted arrays.", "C"
"TwoPointer", "If the input array is not sorted, can the 'Left and Right (converging)' two-pointer approach be directly applied for problems like 'Two Sum'?", "A. Yes, always.", "B. No, sorting is usually a prerequisite, which would add O(N log N) time complexity.", "C. Only if the target is 0.", "D. Only if all elements are positive.", "B"
"TwoPointer", "When might a two-pointer approach (both moving in the same direction) be used for a string compression problem?", "A. One pointer to read, another to write to a compressed string/array.", "B. For detecting cycles.", "C. For reversing the string.", "D. For finding the longest palindrome.", "A"
"TwoPointer", "What is a 'pointer' in the context of the Two-Pointer technique?", "A. A physical pointer in memory.", "B. An index or reference to an element in a sequence.", "C. A separate data structure.", "D. A specific function.", "B"
"TwoPointer", "Does the Two-Pointer technique modify the original array/string in-place?", "A. Always.", "B. Never.", "C. It depends on the specific problem; many problems allow in-place modification, others use it for read-only traversal.", "D. Only if the array is small.", "C"
"TwoPointer", "Consider a problem where you need to find all triplets in a sorted array that sum to zero. How many pointers would you typically use?", "A. One.", "B. Two.", "C. Three.", "D. Four.", "C"
"TwoPointer", "If two pointers are used to track the start and end of a window (e.g., `left` and `right`), and the window size is variable, this specific pattern is often called:", "A. Two-Pointer technique (general).", "B. Sliding Window technique.", "C. Fast and Slow pointers.", "D. Merge sort.", "B"
"TwoPointer", "What is the initial state of the `left` pointer in most two-pointer variations?", "A. The last element.", "B. The first element (index 0).", "C. The middle element.", "D. A random element.", "B"
"TwoPointer", "In the problem 'Sort Colors' (Dutch National Flag problem, sort 0s, 1s, 2s), how many pointers are commonly used?", "A. One.", "B. Two.", "C. Three (low, mid, high).", "D. Four.", "C"
"TwoPointer", "When is it beneficial to have one pointer moving faster than the other?", "A. When searching for a target value.", "B. When dealing with cyclic structures or when needing to find a specific point relative to another (e.g., middle of a list).", "C. When sorting in descending order.", "D. When merging arrays.", "B"
"TwoPointer", "Can the Two-Pointer technique be used to find the intersection of two sorted arrays?", "A. No, only union.", "B. Yes, by advancing the pointer of the smaller element until equality or one pointer reaches end.", "C. Only if the arrays are unsorted.", "D. Only for unique elements.", "B"
"TwoPointer", "What is the primary advantage of a two-pointer solution over a hash-based solution for problems like 'Two Sum' on sorted arrays?", "A. Time complexity (both are O(N)).", "B. Space complexity (O(1) vs O(N)).", "C. Readability of code.", "D. Ease of debugging.", "B"
"TwoPointer", "If the problem involves finding a specific element's position in a sorted array, which algorithm is generally more efficient than two-pointers?", "A. Linear search.", "B. Binary search (which can be seen as a specific type of two-pointer/divide and conquer).", "C. Hashing.", "D. Sorting.", "B"
"TwoPointer", "The Two-Pointer technique is often used when the order of elements within a sequence matters for the problem's solution. True or False?", "A. True", "B. False", "A"
"TwoPointer", "If you are using two pointers to remove elements from an array (conceptually, not actually shrinking size), one pointer typically writes the valid elements and the other reads. True or False?", "A. True", "B. False", "A"
"TwoPointer", "Can two pointers be used effectively on unsorted arrays for problems that require finding pairs or triplets with a specific sum?", "A. Yes, without any pre-processing.", "B. No, usually sorting the array first is required, making the overall complexity O(N log N).", "C. Only if all numbers are positive.", "D. Only if the target sum is zero.", "B"
"TwoPointer", "What is a common task for the 'Fast and Slow' pointers when dealing with linked lists?", "A. Finding the middle element of the linked list.", "B. Reversing the linked list.", "C. Sorting the linked list.", "D. Appending elements to the linked list.", "A"
"TwoPointer", "The Two-Pointer technique is primarily a strategy for optimizing which kind of search?", "A. Graph search.", "B. Linear search (by making it more efficient).", "C. Tree search.", "D. Hashing.", "B"
"TwoPointer", "For a string 'racecar', if `left` starts at 'r' and `right` starts at the last 'r', what happens to `left` if `str[left] == str[right]`?", "A. `left` increments.", "B. `left` decrements.", "C. `left` stays.", "D. `left` moves to the end.", "A"
"TwoPointer", "What if a problem involves finding the `k`-th element from the end of a linked list?", "A. Use two pointers: one moves `k` steps ahead, then both move together until the first reaches the end.", "B. Reverse the list and find the `k`-th from the beginning.", "C. Traverse the list `k` times.", "D. Use a hash map.", "A"
"TwoPointer", "The core idea of two-pointers is to reduce the nested loop complexity of O(N^2) to O(N) by intelligent pointer movement. True or False?", "A. True", "B. False", "A"
"PrefixSum", "What is the primary purpose of the Prefix Sum technique?", "A. To sort an array in linear time.", "B. To efficiently calculate the sum of elements within any subarray or range in constant time after a linear pre-computation.", "C. To find the minimum element in an array.", "D. To detect cycles in a graph.", "B"
"PrefixSum", "For which type of queries is Prefix Sum most beneficial?", "A. Point updates.", "B. Range sum queries (sum of elements between two indices `i` and `j`).", "C. Element search.", "D. Sorting queries.", "B"
"PrefixSum", "What is the time complexity to build a prefix sum array for an input array of size `N`?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N^2)", "C"
"PrefixSum", "Once the prefix sum array `P` is built, what is the time complexity to find the sum of elements from index `i` to `j` (inclusive)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(j - i + 1)", "A"
"PrefixSum", "If `P[k]` stores the sum of elements from index 0 to `k-1` (1-indexed input array), how would you calculate the sum of `arr[i...j]`?", "A. `P[j] - P[i]`", "B. `P[j+1] - P[i]`", "C. `P[j+1] - P[i+1]`", "D. `P[j] - P[i-1]`", "B"
"PrefixSum", "If `P[k]` stores the sum of elements from index 0 to `k` (0-indexed input array), how would you calculate the sum of `arr[i...j]`?", "A. `P[j] - P[i]`", "B. `P[j] - P[i-1]` (handle i=0 as P[-1]=0 or similar).", "C. `P[j+1] - P[i]`", "D. `P[j] - P[i+1]`", "B"
"PrefixSum", "What is the space complexity to store the prefix sum array for an input array of size `N`?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N^2)", "C"
"PrefixSum", "What is the base case for building a prefix sum array `P` (assuming `P[0]` stores sum up to `arr[0]` or an empty prefix)?", "A. `P[0] = arr[0]` (if 0-indexed and `P[k]` sums up to `k`).", "B. `P[0] = 1`", "C. `P[0] = infinity`", "D. `P[0] = N`", "A"
"PrefixSum", "Which of the following is NOT a direct application of the Prefix Sum technique?", "A. Finding a subarray with a given sum.", "B. Calculating the average of subarrays.", "C. Finding the maximum subarray sum (Kadane's Algorithm).", "D. Merging two sorted arrays.", "D"
"PrefixSum", "To find the average of a subarray `arr[i...j]` using prefix sums, after calculating the sum, what is the next step?", "A. Multiply by `(j - i + 1)`.", "B. Divide by `(j - i + 1)`.", "C. Add `(j - i + 1)`.", "D. Subtract `(j - i + 1)`.", "B"
"PrefixSum", "What is a common modification of the Prefix Sum technique for 2D arrays (matrices)?", "A. Row-wise prefix sums only.", "B. Column-wise prefix sums only.", "C. 2D Prefix Sum (or Integral Image) where `P[r][c]` stores sum of submatrix `(0,0)` to `(r,c)`.", "D. Diagonal prefix sums.", "C"
"PrefixSum", "If `PS[r][c]` is the 2D prefix sum, how would you calculate the sum of a submatrix with top-left `(r1, c1)` and bottom-right `(r2, c2)`?", "A. `PS[r2][c2] - PS[r1-1][c1-1]`", "B. `PS[r2][c2] - PS[r1-1][c2] - PS[r2][c1-1] + PS[r1-1][c1-1]`", "C. `PS[r2][c2] + PS[r1][c1]`", "D. `PS[r2][c2] - PS[r1][c1]`", "B"
"PrefixSum", "What is the time complexity to build a 2D prefix sum matrix for an `M x N` matrix?", "A. O(M + N)", "B. O(M * N)", "C. O(M^2 * N^2)", "D. O(log(M * N))", "B"
"PrefixSum", "What is the space complexity to store a 2D prefix sum matrix for an `M x N` matrix?", "A. O(1)", "B. O(M + N)", "C. O(M * N)", "D. O(M^2 * N^2)", "C"
"PrefixSum", "Can Prefix Sum handle negative numbers in the input array?", "A. No, only positive numbers.", "B. Yes, the sums will simply reflect the negative values correctly.", "C. Only if the sum remains positive.", "D. Only if the sum remains negative.", "B"
"PrefixSum", "For problems like 'Subarray Sum Equals K', why is a hash map often used in conjunction with prefix sums?", "A. To store the elements of the subarray.", "B. To store the frequency of elements.", "C. To store previously encountered prefix sums and check if `current_prefix_sum - K` exists.", "D. To sort the prefix sums.", "C"
"PrefixSum", "If you're looking for a subarray with a sum of 0, using prefix sums and a hash map, what value would you search for in the hash map for each `current_prefix_sum`?", "A. `current_prefix_sum + 1`", "B. `current_prefix_sum` (indicates a sum of 0 between the current index and where this sum was first seen or if current sum is 0).", "C. `K`", "D. `0`", "B"
"PrefixSum", "What happens to the prefix sum array if the input array is modified frequently (point updates)?", "A. It needs to be recomputed entirely for each update.", "B. It can be updated in O(1) time.", "C. It can be updated in O(log N) time using specialized data structures (e.g., Fenwick Tree, Segment Tree).", "D. It becomes invalid.", "A"
"PrefixSum", "When is Prefix Sum *not* the most efficient approach for range sum queries?", "A. When there are many range sum queries and no updates.", "B. When there are frequent point updates to the original array.", "C. When the array contains only positive numbers.", "D. When the array is very small.", "B"
"PrefixSum", "Consider an array `arr = [1, 2, 3, 4]`. What is its prefix sum array (0-indexed, `P[k]` sums up to `arr[k]`)?", "A. `[1, 2, 3, 4]`", "B. `[1, 3, 6, 10]`", "C. `[0, 1, 3, 6, 10]`", "D. `[10, 6, 3, 1]`", "B"
"PrefixSum", "For `arr = [1, 2, 3, 4]`, using the prefix sum `P = [1, 3, 6, 10]` (0-indexed), what is the sum of `arr[1...3]`?", "A. `P[3] - P[1]` (10 - 3 = 7)", "B. `P[3] - P[0]` (10 - 1 = 9)", "C. `P[2]` (6)", "D. `P[3]` (10)", "A"
"PrefixSum", "The Prefix Sum technique is essentially an application of which broader algorithmic concept?", "A. Greedy algorithms.", "B. Divide and conquer.", "C. Dynamic Programming (specifically, memoization of sums).", "D. Backtracking.", "C"
"PrefixSum", "What is the alternative name for a 2D Prefix Sum array in image processing?", "A. Gaussian Blur.", "B. Integral Image.", "C. Sobel Filter.", "D. Fourier Transform.", "B"
"PrefixSum", "Can prefix sums be used to find subarray products in constant time?", "A. Yes, by taking logarithms and then using prefix sums of logarithms.", "B. No, the sum property doesn't directly extend to products.", "C. Only if all numbers are positive.", "D. Only if all numbers are 1.", "A"
"PrefixSum", "If the problem requires finding the number of subarrays that sum to `K`, and the input array contains negative numbers, what issue does a direct two-pointer approach face that prefix sums with a hash map avoids?", "A. Two pointers always work for negative numbers.", "B. The sum might decrease when the `right` pointer moves, making the monotonic property for two pointers invalid.", "C. Two pointers are faster.", "D. Hash maps are slower.", "B"
"PrefixSum", "What is `P[-1]` (or `P[0]` if 1-indexed for the input array) typically initialized to in a prefix sum array to handle sums starting from index 0 correctly?", "A. 1", "B. 0", "C. Infinity", "D. -1", "B"
"PrefixSum", "The Prefix Sum technique is also known as Cumulative Sum. True or False?", "A. True", "B. False", "A"
"PrefixSum", "If you need to find the count of subarrays whose sum is an *even* number, how could prefix sums be used?", "A. Count subarrays where `(prefix_sum[j] - prefix_sum[i-1]) % 2 == 0`.", "B. Count even numbers in the array directly.", "C. This is not possible with prefix sums.", "D. Only if all numbers are positive.", "A"
"PrefixSum", "What is the main benefit of using a prefix sum array over recomputing sums every time for multiple range sum queries?", "A. Less memory usage.", "B. Reduces query time from O(N) to O(1).", "C. Handles updates efficiently.", "D. Automatically sorts the array.", "B"
"PrefixSum", "Consider `arr = [2, -1, 3, -2, 4]`. What is its prefix sum array (0-indexed, `P[k]` sums up to `arr[k]`)?", "A. `[2, 1, 4, 2, 6]`", "B. `[-2, 1, -4, 2, -6]`", "C. `[2, 3, 6, 4, 8]`", "D. `[0, 2, 1, 4, 2, 6]`", "A"
"PrefixSum", "Using the prefix sum `P = [2, 1, 4, 2, 6]` for `arr = [2, -1, 3, -2, 4]`, find the sum of `arr[0...4]`.", "A. `P[4]` (6)", "B. `P[4] - P[0]` (4)", "C. `P[3]` (2)", "D. `P[4] - P[1]` (5)", "A"
"PrefixSum", "Using the prefix sum `P = [2, 1, 4, 2, 6]` for `arr = [2, -1, 3, -2, 4]`, find the sum of `arr[2...3]` (which is `3 + (-2) = 1`).", "A. `P[3] - P[2]` (2 - 4 = -2)", "B. `P[3] - P[1]` (2 - 1 = 1)", "C. `P[2] - P[0]` (4 - 2 = 2)", "D. `P[1]` (1)", "B"
"PrefixSum", "If you use a hash map with prefix sums to find subarrays summing to `K`, what do the keys and values in the hash map typically represent?", "A. Key: array element, Value: its frequency.", "B. Key: prefix sum, Value: index where that prefix sum occurred.", "C. Key: index, Value: element value.", "D. Key: K, Value: count of subarrays.", "B"
"PrefixSum", "What is the approach to handle negative numbers in the `prefix_sum - K` lookup with a hash map?", "A. It works the same way.", "B. You must add N to all sums.", "C. You must use a balanced BST instead of a hash map.", "D. It only works if K is positive.", "A"
"PrefixSum", "Is the Prefix Sum technique useful for finding the maximum or minimum element in a range?", "A. Yes, very efficient.", "B. No, it's specifically for sums; range min/max requires different data structures (e.g., Segment Tree, Sparse Table).", "C. Only if the array is sorted.", "D. Only if the range is small.", "B"
"PrefixSum", "For a 2D matrix, if `PS[r][c]` is the sum of rectangle from `(0,0)` to `(r,c)`, what is the formula for `PS[r][c]` calculation?", "A. `matrix[r][c] + PS[r-1][c] + PS[r][c-1] - PS[r-1][c-1]` (with boundary checks for r-1 or c-1).", "B. `matrix[r][c] + PS[r-1][c]`", "C. `matrix[r][c] + PS[r][c-1]`", "D. `matrix[r][c] - PS[r-1][c-1]`", "A"
"PrefixSum", "The Prefix Sum method works best for problems where the input data does not change (static array). True or False?", "A. True", "B. False", "A"
"PrefixSum", "What is the primary conceptual similarity between 1D and 2D Prefix Sums?", "A. Both compute sums of rows.", "B. Both involve iteratively building up a sum based on previous calculated sums and the current element.", "C. Both require sorted input.", "D. Both use hash maps extensively.", "B"
"PrefixSum", "If `P[j]` is the prefix sum up to index `j`, and `P[i-1]` is the prefix sum up to index `i-1`, then `P[j] - P[i-1]` gives the sum of elements from:", "A. Index `i` to `j-1`.", "B. Index `i` to `j` (inclusive).", "C. Index `0` to `j`.", "D. Index `0` to `i-1`.", "B"
"PrefixSum", "What would be the effect of having floating-point numbers in the input array for Prefix Sum?", "A. It would cause errors.", "B. The technique works correctly, but floating-point precision issues might arise with very large sums.", "C. It only works with integers.", "D. It becomes much faster.", "B"
"PrefixSum", "Can Prefix Sum be used to find the number of elements equal to a value `X` in a range `[i, j]`?", "A. Yes, directly.", "B. No, this requires a different technique (e.g., counting sort + prefix sum on counts, or segment tree).", "C. Only if X is 0.", "D. Only if the range is small.", "B"
"PrefixSum", "If you need to find the longest subarray with a positive sum, can prefix sums be directly used?", "A. Yes, by finding `max(P[j] - P[i])`.", "B. Not directly, but it can be combined with other techniques (e.g., finding min prefix sum to subtract for maximum positive subarray).", "C. No, this is Kadane's algorithm.", "D. Only if all numbers are positive.", "B"
"PrefixSum", "The core recurrence relation for building a 1D prefix sum array `P` is:", "A. `P[i] = P[i-1] + arr[i]`", "B. `P[i] = arr[i]`", "C. `P[i] = P[i-1] - arr[i]`", "D. `P[i] = P[i-1] * arr[i]`", "A"
"PrefixSum", "If a problem involves frequent range updates (adding a value to a range of elements) and range sum queries, what alternative data structure is typically more efficient than Prefix Sum?", "A. Hash Map.", "B. Linked List.", "C. Segment Tree or Fenwick Tree (BIT).", "D. Simple array.", "C"
"PrefixSum", "What happens to the prefix sum array if elements are added or removed from the *middle* of the original array?", "A. It needs to be fully rebuilt from that point onward.", "B. It's updated in O(1).", "C. It becomes irrelevant.", "D. Only the last element changes.", "A"
"PrefixSum", "The Prefix Sum array stores what kind of sums?", "A. Suffix sums.", "B. Running sums (sums from the beginning up to each point).", "C. Averages.", "D. Products.", "B"
"PrefixSum", "When is a 'difference array' often used, which is related to prefix sums in concept?", "A. For range sum queries.", "B. For point updates.", "C. For applying range updates and then getting final array elements in linear time.", "D. For finding maximum sum subarrays.", "C"
"PrefixSum", "If `P[j]` is the prefix sum up to `j`, and `P[i]` is the prefix sum up to `i`. What is `P[i] - P[j]`? (Assuming `i > j`)", "A. Sum of `arr[j+1]` to `arr[i]`.", "B. Sum of `arr[j]` to `arr[i]`.", "C. Sum of `arr[0]` to `arr[j]`.", "D. Sum of `arr[0]` to `arr[i]`.", "A"
"PrefixSum", "For problems like 'Equilibrium Index' (an index where the sum of elements to its left equals the sum of elements to its right), how can prefix sums be used?", "A. Calculate total sum, then iterate and check `prefix_sum[i-1] == (total_sum - prefix_sum[i])`.", "B. Only by brute force.", "C. Using a hash map without prefix sums.", "D. It cannot be used.", "A"
"PrefixSum", "If the original array `arr` has `N` elements, how many elements does the prefix sum array `P` usually have?", "A. `N` (if 0-indexed and `P[i]` stores sum up to `arr[i]`).", "B. `N+1` (if `P[0]` is 0 for empty prefix and `P[i]` for sum up to `arr[i-1]` for 1-indexed queries).", "C. Both A and B are common, depending on indexing convention.", "D. `2N`.", "C"
"PrefixSum", "The Prefix Sum technique excels when you have many range sum queries on a static array. True or False?", "A. True", "B. False", "A"
"NumberTheory", "What is a prime number?", "A. A natural number greater than 1 that has no positive divisors other than 1 and itself.", "B. Any odd number.", "C. Any number that is not divisible by 2.", "D. A natural number that can be divided by exactly two distinct prime numbers.", "A"
"NumberTheory", "What is a composite number?", "A. A natural number greater than 1 that is not prime.", "B. Any even number.", "C. A number that has only two divisors.", "D. A number that is divisible by 1 and itself only.", "A"
"NumberTheory", "What is the Greatest Common Divisor (GCD) of two integers 'a' and 'b'?", "A. The largest integer that divides both 'a' and 'b' without leaving a remainder.", "B. The smallest integer that 'a' and 'b' can both divide.", "C. The product of 'a' and 'b'.", "D. The sum of 'a' and 'b'.", "A"
"NumberTheory", "Which algorithm is commonly used to find the GCD of two numbers efficiently?", "A. Sieve of Eratosthenes.", "B. Euclidean Algorithm.", "C. Quick Sort.", "D. Binary Search.", "B"
"NumberTheory", "What is the Least Common Multiple (LCM) of two integers 'a' and 'b'?", "A. The largest integer that 'a' and 'b' can both divide.", "B. The smallest positive integer that is divisible by both 'a' and 'b'.", "C. The sum of 'a' and 'b'.", "D. The difference between 'a' and 'b'.", "B"
"NumberTheory", "How is LCM(a, b) related to GCD(a, b)?", "A. LCM(a, b) = a * b * GCD(a, b)", "B. LCM(a, b) = (a * b) / GCD(a, b)", "C. LCM(a, b) = a + b - GCD(a, b)", "D. LCM(a, b) = GCD(a, b) / (a * b)", "B"
"NumberTheory", "What is a modular inverse of 'a' modulo 'm'?", "A. An integer 'x' such that (a * x) % m = 0.", "B. An integer 'x' such that (a * x) % m = 1.", "C. An integer 'x' such that (a + x) % m = 1.", "D. An integer 'x' such that (a / x) % m = 1.", "B"
"NumberTheory", "For a modular inverse of 'a' modulo 'm' to exist, what condition must be true?", "A. 'm' must be a prime number.", "B. 'a' and 'm' must be coprime (GCD(a, m) = 1).", "C. 'a' must be greater than 'm'.", "D. 'm' must be greater than 'a'.", "B"
"NumberTheory", "Which theorem is often used to find modular inverses when the modulus 'm' is a prime number?", "A. Fermat's Little Theorem.", "B. Chinese Remainder Theorem.", "C. Master Theorem.", "D. Pythagorean Theorem.", "A"
"NumberTheory", "Which algorithm can be used to find modular inverses even when the modulus 'm' is not prime (but GCD(a, m) = 1)?", "A. Extended Euclidean Algorithm.", "B. Sieve of Eratosthenes.", "C. Binary Exponentiation.", "D. Pollard's Rho Algorithm.", "A"
"NumberTheory", "What does 'a is congruent to b modulo m' (a ≡ b (mod m)) mean?", "A. a + b is divisible by m.", "B. a - b is divisible by m.", "C. a * b is divisible by m.", "D. a / b is divisible by m.", "B"
"NumberTheory", "What is the Sieve of Eratosthenes used for?", "A. Finding the GCD of two numbers.", "B. Generating all prime numbers up to a specified limit.", "C. Factoring large numbers.", "D. Solving linear congruences.", "B"
"NumberTheory", "The Euler's Totient function (φ(n)) counts what?", "A. The number of divisors of n.", "B. The number of prime factors of n.", "C. The number of positive integers less than or equal to n that are relatively prime to n.", "D. The sum of the divisors of n.", "C"
"NumberTheory", "Which theorem states that if 'p' is a prime number, then for any integer 'a' not divisible by 'p', a^(p-1) ≡ 1 (mod p)?", "A. Euler's Totient Theorem.", "B. Chinese Remainder Theorem.", "C. Fermat's Little Theorem.", "D. Wilson's Theorem.", "C"
"NumberTheory", "The Chinese Remainder Theorem (CRT) is used to solve what kind of problems?", "A. Finding the remainder when a number is divided by another.", "B. Solving systems of linear congruences with coprime moduli.", "C. Factoring large composite numbers.", "D. Generating prime numbers.", "B"
"NumberTheory", "What is Prime Factorization?", "A. Expressing a composite number as a sum of prime numbers.", "B. Expressing a composite number as a product of its prime factors.", "C. Finding the largest prime number less than a given number.", "D. Finding the smallest prime number greater than a given number.", "B"
"NumberTheory", "What is a perfect number?", "A. A number that is prime.", "B. A number that is equal to the sum of its proper positive divisors (excluding itself).", "C. A number that is a perfect square.", "D. A number that is a multiple of 10.", "B"
"NumberTheory", "What is an abundant number?", "A. A number where the sum of its proper divisors is less than the number itself.", "B. A number where the sum of its proper divisors is greater than the number itself.", "C. A prime number.", "D. A number with many factors.", "B"
"NumberTheory", "What is a deficient number?", "A. A number where the sum of its proper divisors is less than the number itself.", "B. A number where the sum of its proper divisors is greater than the number itself.", "C. A composite number.", "D. A number with few factors.", "A"
"NumberTheory", "What is Binary Exponentiation (or Exponentiation by Squaring) primarily used for?", "A. Calculating a^b efficiently.", "B. Calculating a * b efficiently.", "C. Finding prime numbers.", "D. Solving linear equations.", "A"
"NumberTheory", "What is the time complexity of Binary Exponentiation to calculate a^b (mod m)?", "A. O(b)", "B. O(log b)", "C. O(sqrt(b))", "D. O(b^2)", "B"
"NumberTheory", "What is a Diophantine equation?", "A. An equation involving complex numbers.", "B. A polynomial equation for which integer solutions are sought.", "C. An equation involving derivatives.", "D. An equation with infinitely many solutions.", "B"
"NumberTheory", "Bézout's identity states that for integers 'a' and 'b' with GCD(a, b) = d, there exist integers 'x' and 'y' such that ax + by = d. This identity is a core concept for which algorithm?", "A. Euclidean Algorithm.", "B. Extended Euclidean Algorithm.", "C. Sieve of Eratosthenes.", "D. Pollard's Rho Algorithm.", "B"
"NumberTheory", "What does 'relatively prime' (or coprime) mean for two integers 'a' and 'b'?", "A. Their GCD is 1.", "B. They are both prime numbers.", "C. They are both odd numbers.", "D. Their LCM is 1.", "A"
"NumberTheory", "What is the fundamental theorem of arithmetic?", "A. Every integer greater than 1 is either a prime number itself or can be represented as a unique product of prime numbers.", "B. The sum of two prime numbers is always even.", "C. Every even number greater than 2 is the sum of two primes.", "D. There are infinitely many prime numbers.", "A"
"NumberTheory", "What is Wilson's Theorem about?", "A. (p-1)! ≡ -1 (mod p) for any prime number p.", "B. (p-1)! ≡ 1 (mod p) for any prime number p.", "C. a^(p-1) ≡ 1 (mod p) for prime p.", "D. There are infinitely many primes.", "A"
"NumberTheory", "A prime number `p` is called a Mersenne prime if it is of the form:", "A. 2^n - 1, where n is also a prime number.", "B. n^2 + 1, where n is an integer.", "C. 3n + 1, where n is an integer.", "D. Any prime number that ends with 7.", "A"
"NumberTheory", "What are twin primes?", "A. Two prime numbers that are consecutive (e.g., 2, 3).", "B. Two prime numbers that differ by 2 (e.g., 3, 5).", "C. Two prime numbers that sum to an even number.", "D. Any two prime numbers.", "B"
"NumberTheory", "What is the concept of a 'primitive root modulo n'?", "A. A number 'g' such that g^k ≡ 1 (mod n) for the smallest possible k.", "B. A number 'g' whose powers modulo n generate all integers coprime to n.", "C. A number 'g' that is a prime factor of n.", "D. The smallest prime number dividing n.", "B"
"NumberTheory", "What is the Legendre symbol used for?", "A. Determining if a number is prime.", "B. Determining if an integer 'a' is a quadratic residue modulo an odd prime 'p'.", "C. Calculating the GCD.", "D. Solving linear congruences.", "B"
"NumberTheory", "Which property is useful for checking primality of a large number quickly, but is probabilistic (not deterministic)?", "A. Trial division.", "B. Miller-Rabin Primality Test.", "C. Sieve of Eratosthenes.", "D. Fermat's Little Theorem (as a test).", "B"
"NumberTheory", "What is the concept of 'discrete logarithm'?", "A. Finding 'x' such that a^x = b (mod m).", "B. Finding 'x' such that x^a = b (mod m).", "C. Finding the logarithm of a number.", "D. Finding a prime factor.", "A"
"NumberTheory", "What is the smallest prime number?", "A. 0", "B. 1", "C. 2", "D. 3", "C"
"NumberTheory", "Are negative numbers considered in the context of GCD and LCM in elementary number theory?", "A. Yes, fully.", "B. Not typically; GCD/LCM are usually defined for positive integers, but properties extend with absolute values.", "C. Only for prime numbers.", "D. Never.", "B"
"NumberTheory", "What is the 'modulus' in modular arithmetic (a % m)?", "A. The dividend.", "B. The divisor.", "C. The remainder.", "D. The quotient.", "B"
"NumberTheory", "What is the result of 7 % 3?", "A. 0", "B. 1", "C. 2", "D. 3", "B"
"NumberTheory", "If a number `N` has prime factorization `p1^a1 * p2^a2 * ... * pk^ak`, how many divisors does `N` have?", "A. a1 + a2 + ... + ak", "B. a1 * a2 * ... * ak", "C. (a1+1) * (a2+1) * ... * (ak+1)", "D. (a1-1) * (a2-1) * ... * (ak-1)", "C"
"NumberTheory", "What is the Mobius function (μ(n)) used for in number theory?", "A. Counting primes.", "B. Inverting arithmetic functions; related to Mobius inversion formula.", "C. Checking primality.", "D. Calculating GCD.", "B"
"NumberTheory", "What is a Carmichael number?", "A. A composite number 'n' that satisfies the modular arithmetic congruence relation b^(n-1) ≡ 1 (mod n) for all integers b which are relatively prime to n, just like a prime number would.", "B. A prime number that is also a perfect square.", "C. A number that is divisible by every prime number.", "D. A number that cannot be factored.", "A"
"NumberTheory", "What is the property of Euclidean algorithm that makes it efficient?", "A. It uses prime factorization.", "B. It uses repeated division with remainder, significantly reducing the numbers in each step.", "C. It uses sorting.", "D. It is a greedy algorithm.", "B"
"NumberTheory", "What is the definition of a 'linear congruence'?", "A. An equation of the form ax ≡ b (mod m).", "B. An equation of the form ax + by = c.", "C. An equation with a single variable.", "D. An equation involving only prime numbers.", "A"
"NumberTheory", "For a linear congruence ax ≡ b (mod m) to have solutions, what condition must be met?", "A. gcd(a, m) must divide b.", "B. a must be prime.", "C. m must be prime.", "D. a must be less than m.", "A"
"NumberTheory", "What is a 'square-free' integer?", "A. An integer that is a perfect square.", "B. An integer that is not divisible by any perfect square other than 1.", "C. An integer whose prime factorization contains only distinct prime factors (each with exponent 1).", "D. Both B and C.", "D"
"NumberTheory", "What is the 'order of an integer a modulo n'?", "A. The smallest positive integer 'k' such that a^k ≡ 1 (mod n).", "B. The number of divisors of 'n'.", "C. The sum of 'a' and 'n'.", "D. The prime factors of 'a'.", "A"
"NumberTheory", "What is 'Euler's Criterion' related to?", "A. Primality testing.", "B. Determining if a number is a quadratic residue modulo a prime.", "C. Finding GCD.", "D. Solving congruences.", "B"
"NumberTheory", "If GCD(a, b) = 1, then a and b are called:", "A. Composite numbers.", "B. Relatively prime or coprime.", "C. Prime numbers.", "D. Even numbers.", "B"
"NumberTheory", "What is the concept of 'primitive Pythagorean triples'?", "A. Triples of integers (a, b, c) that satisfy a^2 + b^2 = c^2, where a, b, c are coprime.", "B. Any set of three integers.", "C. Triples of prime numbers.", "D. Triples that sum to a perfect square.", "A"
"NumberTheory", "The process of breaking down a composite number into its prime factors is called:", "A. Primality Testing.", "B. Prime Factorization.", "C. Sieve Method.", "D. Modular Arithmetic.", "B"
"NumberTheory", "What is a 'pseudoprime'?", "A. A prime number that is very large.", "B. A composite number that behaves like a prime number with respect to a certain primality test (e.g., Fermat primality test).", "C. A number that is not prime but is close to a prime.", "D. A number that can be divided by exactly two numbers.", "B"
"NumberTheory", "Which type of numbers are central to public-key cryptography (e.g., RSA)?", "A. Small prime numbers.", "B. Very large prime numbers and their products.", "C. Perfect numbers.", "D. Abundant numbers.", "B"
"GCD", "What does GCD stand for?", "A. Great Common Division", "B. Greatest Common Divisor", "C. General Common Denominator", "D. Grand Common Digit", "B"
"GCD", "The GCD of two integers 'a' and 'b' is the largest integer that:", "A. Divides both 'a' and 'b' without leaving a remainder.", "B. Is divisible by both 'a' and 'b'.", "C. Is equal to 'a' or 'b'.", "D. Is the sum of 'a' and 'b'.", "A"
"GCD", "What is the GCD of 12 and 18?", "A. 2", "B. 3", "C. 6", "D. 9", "C"
"GCD", "What is the GCD of two prime numbers?", "A. 0", "B. 1", "C. The smaller prime number.", "D. The larger prime number.", "B"
"GCD", "What is the GCD of a prime number and a composite number that is a multiple of the prime number?", "A. 1", "B. The prime number itself.", "C. The composite number itself.", "D. The product of the two numbers.", "B"
"GCD", "Which algorithm is most commonly used to find the GCD of two numbers efficiently?", "A. Sieve of Eratosthenes", "B. Euclidean Algorithm", "C. Quick Sort", "D. Binary Search", "B"
"GCD", "The Euclidean Algorithm for GCD is based on the principle that GCD(a, b) = GCD(b, a % b). True or False?", "A. True", "B. False", "A"
"GCD", "What is the base case for the Euclidean Algorithm (recursive version)?", "A. When `a` is 0.", "B. When `b` is 0, GCD(a, 0) = a.", "C. When `a` and `b` are equal.", "D. When `a` is 1.", "B"
"GCD", "What is GCD(0, 5)?", "A. 0", "B. 1", "C. 5", "D. Undefined", "C"
"GCD", "What is GCD(7, 7)?", "A. 0", "B. 1", "C. 7", "D. 49", "C"
"GCD", "If GCD(a, b) = 1, then 'a' and 'b' are said to be:", "A. Composite", "B. Relatively prime (or coprime)", "C. Perfect numbers", "D. Even numbers", "B"
"GCD", "The GCD of two numbers 'a' and 'b' can also be found using their prime factorization. If a = p1^x1 * p2^x2 * ... and b = p1^y1 * p2^y2 * ..., then GCD(a, b) = p1^min(x1, y1) * p2^min(x2, y2) * ... True or False?", "A. True", "B. False", "A"
"GCD", "What is the relationship between GCD and LCM?", "A. GCD(a, b) * LCM(a, b) = a + b", "B. GCD(a, b) * LCM(a, b) = a * b", "C. GCD(a, b) / LCM(a, b) = a * b", "D. GCD(a, b) + LCM(a, b) = a * b", "B"
"GCD", "What is GCD(4, 6, 8)?", "A. 1", "B. 2", "C. 4", "D. 8", "B"
"GCD", "How do you find the GCD of three numbers (a, b, c)?", "A. GCD(GCD(a, b), c)", "B. GCD(a, GCD(b, c))", "C. Both A and B are correct (GCD is associative).", "D. It cannot be found for three numbers.", "C"
"GCD", "What is the time complexity of the Euclidean Algorithm for finding GCD(a, b)?", "A. O(min(a, b))", "B. O(log(min(a, b))) (roughly proportional to the number of digits)", "C. O(a * b)", "D. O(1)", "B"
"GCD", "The GCD of any number 'n' and 1 is:", "A. 0", "B. 1", "C. n", "D. Undefined", "B"
"GCD", "If 'b' divides 'a' evenly, what is GCD(a, b)?", "A. 1", "B. a", "C. b", "D. a * b", "C"
"GCD", "Which of the following is NOT a property of GCD?", "A. Commutative: GCD(a, b) = GCD(b, a)", "B. Associative: GCD(a, GCD(b, c)) = GCD(GCD(a, b), c)", "C. Distributive: GCD(a, b + c) = GCD(a, b) + GCD(a, c)", "D. GCD(a, a) = |a|", "C"
"GCD", "Can the Euclidean Algorithm be used for negative numbers?", "A. No, it only works for positive integers.", "B. Yes, by taking the absolute value of the numbers, i.e., GCD(a, b) = GCD(|a|, |b|).", "C. Only if both numbers are negative.", "D. Only if one number is negative.", "B"
"GCD", "What is the GCD of 10 and 25?", "A. 2", "B. 5", "C. 10", "D. 25", "B"
"GCD", "If a = k * b for some integer k, then GCD(a, b) = ?", "A. k", "B. a", "C. b", "D. 1", "C"
"GCD", "The GCD is always less than or equal to the smallest of the two numbers. True or False?", "A. True", "B. False", "A"
"GCD", "What is the first step in finding the GCD of two numbers using the division method (Euclidean Algorithm)?", "A. Divide the smaller number by the larger number.", "B. Divide the larger number by the smaller number and find the remainder.", "C. Add the two numbers.", "D. Subtract the two numbers.", "B"
"GCD", "When the remainder in the Euclidean Algorithm becomes 0, what is the GCD?", "A. The last non-zero remainder.", "B. The number that yielded the remainder of 0.", "C. The original larger number.", "D. The original smaller number.", "A"
"GCD", "GCD is commonly used in simplifying fractions. If you have a fraction a/b, how do you simplify it using GCD?", "A. Divide both 'a' and 'b' by their GCD.", "B. Multiply both 'a' and 'b' by their GCD.", "C. Add GCD to both 'a' and 'b'.", "D. Subtract GCD from both 'a' and 'b'.", "A"
"GCD", "What is GCD(15, 0)?", "A. 0", "B. 1", "C. 15", "D. Undefined", "C"
"GCD", "Which mathematical concept is deeply related to GCD?", "A. Exponents", "B. Logarithms", "C. Modular Arithmetic", "D. Derivatives", "C"
"GCD", "Bézout's identity states that for integers 'a' and 'b' with GCD(a, b) = d, there exist integers 'x' and 'y' such that ax + by = d. This is directly found using which algorithm?", "A. Standard Euclidean Algorithm", "B. Extended Euclidean Algorithm", "C. Binary Exponentiation", "D. Sieve of Eratosthenes", "B"
"GCD", "Can GCD be used to determine if two numbers are coprime?", "A. No, only LCM can.", "B. Yes, if GCD(a, b) = 1, they are coprime.", "C. Only if both numbers are prime.", "D. Only if one number is 1.", "B"
"GCD", "What is the GCD of 36 and 48?", "A. 6", "B. 12", "C. 18", "D. 24", "B"
"GCD", "If a number 'd' divides both 'a' and 'b', then 'd' must also divide GCD(a, b). True or False?", "A. True", "B. False", "A"
"GCD", "In an iterative implementation of the Euclidean Algorithm, what variables are updated?", "A. Only the remainder.", "B. The larger number becomes the smaller number, and the smaller number becomes the remainder.", "C. The quotient and remainder.", "D. The sum and difference.", "B"
"GCD", "Which of these is equivalent to GCD(a, b)?", "A. GCD(a, a - b)", "B. GCD(a, b - a)", "C. GCD(a, b % a)", "D. All of the above are valid when applied appropriately within the Euclidean algorithm steps.", "D"
"GCD", "If you need to find GCD of many numbers (e.g., an array of numbers), what is the general approach?", "A. Find GCD of all pairs and pick the smallest.", "B. Find GCD of the first two, then find GCD of the result with the third, and so on.", "C. Find GCD of the smallest and largest.", "D. It is not possible for more than two numbers.", "B"
"GCD", "The GCD of any positive integer 'n' and 0 is 'n'. True or False?", "A. True", "B. False", "A"
"GCD", "Is the GCD always positive?", "A. Yes, by convention, GCD is usually defined as the positive common divisor.", "B. No, it can be negative.", "C. Only if both numbers are positive.", "D. Only if one number is positive.", "A"
"GCD", "If you have a set of numbers {x1, x2, ..., xk}, and you want to find their GCD, what property is used recursively?", "A. GCD(x1, x2, ..., xk) = GCD(x1 + x2, ..., xk)", "B. GCD(x1, x2, ..., xk) = GCD(x1, GCD(x2, ..., GCD(xk-1, xk)...))", "C. GCD(x1, x2, ..., xk) = x1 * x2 * ... * xk", "D. It is not possible to find GCD for a set.", "B"
"GCD", "The property `GCD(a, b) = GCD(a + kb, b)` for any integer `k` is part of the Euclidean Algorithm's proof. True or False?", "A. True", "B. False", "A"
"GCD", "What is the GCD of 21 and 35?", "A. 1", "B. 3", "C. 7", "D. 21", "C"
"GCD", "Can the binary GCD algorithm (Stein's Algorithm) be faster than Euclidean Algorithm for large numbers?", "A. No, it's always slower.", "B. Yes, by avoiding division operations and using shifts, it can be faster for very large numbers.", "C. They are exactly the same speed.", "D. Only for prime numbers.", "B"
"GCD", "If GCD(a, b) = g, then a/g and b/g are always:", "A. Prime numbers.", "B. Composite numbers.", "C. Relatively prime (coprime).", "D. Even numbers.", "C"
"GCD", "What is the GCD of 99 and 11?", "A. 1", "B. 3", "C. 9", "D. 11", "D"
"GCD", "The concept of GCD is fundamental in which area of mathematics?", "A. Calculus", "B. Linear Algebra", "C. Number Theory", "D. Geometry", "C"
"GCD", "If `a` is a multiple of `b`, what is `GCD(a, b)`?", "A. `a`", "B. `b`", "C. `a * b`", "D. `1`", "B"
"GCD", "What is the GCD of two odd numbers?", "A. Always an even number.", "B. Always an odd number.", "C. Can be even or odd.", "D. Always 1.", "B"
"GCD", "The `math.gcd()` function in Python implements which algorithm typically?", "A. Prime Factorization.", "B. Euclidean Algorithm.", "C. Brute Force.", "D. Recursive descent.", "B"
"GCD", "If a and b are very large numbers, which method is computationally efficient for finding GCD?", "A. Listing all common divisors.", "B. Using the Euclidean algorithm (or its binary variant).", "C. Repeated subtraction only.", "D. Trying all numbers from 1 up to min(a,b).", "B"
"GCD", "What is the GCD of 100 and 0?", "A. 0", "B. 1", "C. 100", "D. Undefined", "C"
"GCD", "The concept of GCD is used in modular arithmetic for finding:", "A. Modular exponentiation.", "B. Modular inverse.", "C. Modular addition.", "D. Modular subtraction.", "B"
"Sieve", "What is the primary purpose of the Sieve of Eratosthenes algorithm?", "A. To find the greatest common divisor of two numbers.", "B. To factorize a single large number into its prime components.", "C. To generate all prime numbers up to a specified limit (N).", "D. To check if a single given number is prime.", "C"
"Sieve", "The Sieve of Eratosthenes is an efficient algorithm for finding:", "A. Composite numbers within a range.", "B. Prime numbers within a range.", "C. Twin primes only.", "D. Mersenne primes only.", "B"
"Sieve", "What is the main idea behind the Sieve of Eratosthenes?", "A. To repeatedly divide numbers by potential factors.", "B. To mark multiples of prime numbers as composite, starting from the smallest prime.", "C. To check divisibility for each number individually.", "D. To use recursion to find prime numbers.", "B"
"Sieve", "What data structure is typically used to implement the Sieve of Eratosthenes?", "A. Linked List", "B. Hash Map", "C. A boolean array (or bitset) where `is_prime[i]` is true if `i` is prime.", "D. A binary search tree", "C"
"Sieve", "What is the initial state of the boolean array `is_prime` (or similar) when running the Sieve?", "A. All entries are set to `false` (assuming `false` means prime).", "B. All entries are set to `true` (assuming `true` means prime).", "C. Only `is_prime[0]` and `is_prime[1]` are `false`, others `true`.", "D. All entries are set to `0`.", "B"
"Sieve", "Why are 0 and 1 explicitly handled in the Sieve of Eratosthenes?", "A. They are the only even numbers.", "B. They are neither prime nor composite by definition.", "C. They are used as base cases for recursion.", "D. They are special prime numbers.", "B"
"Sieve", "The Sieve algorithm starts iterating from which number to mark multiples?", "A. 0", "B. 1", "C. 2 (the first prime number).", "D. The specified limit `N`.", "C"
"Sieve", "When considering a number `p` in the Sieve, which multiples of `p` are marked as composite?", "A. All multiples of `p` starting from `p*1`.", "B. All multiples of `p` starting from `p*2`.", "C. All multiples of `p` starting from `p*p` (as smaller multiples would have already been marked by smaller prime factors).", "D. Only `p*p`.", "C"
"Sieve", "What is the time complexity of the Sieve of Eratosthenes up to a limit `N`?", "A. O(N)", "B. O(N log N)", "C. O(N log log N)", "D. O(sqrt(N))", "C"
"Sieve", "What is the space complexity of the Sieve of Eratosthenes up to a limit `N`?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(sqrt(N))", "C"
"Sieve", "Why does the Sieve algorithm only need to iterate up to `sqrt(N)` for the outer loop (checking primes)?", "A. Because all composite numbers less than or equal to `N` must have at least one prime factor less than or equal to `sqrt(N)`.", "B. It's an optimization that doesn't affect correctness.", "C. Larger numbers are prime anyway.", "D. It only checks even numbers.", "A"
"Sieve", "When `p` is marked as prime, the multiples `p*p, p*(p+1), p*(p+2), ...` are marked as composite. True or False?", "A. True", "B. False", "A"
"Sieve", "After running the Sieve up to `N`, how do you find all prime numbers?", "A. All indices `i` where `is_prime[i]` is `false` are prime.", "B. All indices `i` where `is_prime[i]` is `true` (and `i > 1`) are prime.", "C. You need to perform an additional check.", "D. The algorithm only counts them, not lists them.", "B"
"Sieve", "What is the largest prime number found by Sieve of Eratosthenes up to N?", "A. N itself (if N is prime).", "B. The largest prime less than or equal to N.", "C. The first prime greater than N.", "D. 2.", "B"
"Sieve", "What happens if a number `p` is encountered in the outer loop and `is_prime[p]` is already `false`?", "A. It means `p` is a prime number and its multiples should be marked.", "B. It means `p` is a composite number, and its multiples have already been marked by an earlier prime factor; so, you skip it.", "C. It means an error occurred.", "D. It means `p` is 0 or 1.", "B"
"Sieve", "Which of these numbers would be marked as composite by the Sieve when processing prime `3` (and starting marking from `p*p`)?", "A. 3, 6, 9, 12, ...", "B. 9, 12, 15, 18, ...", "C. 6, 9, 12, 15, ...", "D. Only 9.", "B"
"Sieve", "The Sieve of Eratosthenes is a deterministic algorithm. True or False?", "A. True", "B. False", "A"
"Sieve", "Can the Sieve of Eratosthenes be used to find prime factors of a single large number?", "A. Yes, very efficiently.", "B. No, it's designed for generating a list of primes, not for factoring individual numbers.", "C. Only if the number is prime.", "D. Only if the number is even.", "B"
"Sieve", "What is the main limitation of the Sieve of Eratosthenes for extremely large N (e.g., N = 10^12)?", "A. It becomes too slow (time complexity).", "B. It requires too much memory (space complexity).", "C. It cannot handle numbers that large.", "D. It finds too few primes.", "B"
"Sieve", "What is a 'segmented sieve' used for?", "A. To make the Sieve faster for small N.", "B. To reduce the memory requirements of the Sieve for very large N by processing ranges of numbers separately.", "C. To find prime numbers in specific segments of an array.", "D. To parallelize the Sieve algorithm.", "B"
"Sieve", "If you need to find primes only up to 100, is Sieve of Eratosthenes a good choice?", "A. No, it's too complex for small N.", "B. Yes, it's very efficient for typical competitive programming limits like 10^6 to 10^7.", "C. Only if you have infinite memory.", "D. Only if you need one prime.", "B"
"Sieve", "What is the value of `is_prime[4]` after the Sieve processes up to 4?", "A. True (prime)", "B. False (composite)", "C. Undefined", "D. 4", "B"
"Sieve", "After the Sieve processes the prime number 2, which numbers become `false` (composite)?", "A. All odd numbers.", "B. All even numbers greater than 2.", "C. Only 4.", "D. Only 6.", "B"
"Sieve", "What is the smallest number greater than 1 that remains `true` after processing 2 and 3 in the Sieve?", "A. 4", "B. 5", "C. 6", "D. 9", "B"
"Sieve", "Is the Sieve of Eratosthenes suitable for online queries (checking primality of numbers one by one as they arrive)?", "A. Yes, very efficient.", "B. No, it's designed for pre-computing all primes up to a limit.", "C. Only if the number is small.", "D. Only if the number is prime.", "B"
"Sieve", "The optimized Sieve often initializes marking from `i*i` instead of `2*i`. Why?", "A. To avoid re-marking numbers already marked by smaller prime factors.", "B. It's computationally simpler.", "C. It allows for parallelization.", "D. It helps find prime factors faster.", "A"
"Sieve", "If the limit `N` is 30, what is the largest number `p` that the outer loop needs to iterate up to (i.e., `p*p <= N`)?", "A. `2`", "B. `3`", "C. `5` (since 5*5 = 25 <= 30, but 7*7 = 49 > 30).", "D. `7`", "C"
"Sieve", "The Sieve of Eratosthenes can be extended to find prime factorizations of all numbers up to N by storing the smallest prime factor (SPF) for each number. True or False?", "A. True", "B. False", "A"
"Sieve", "What is the benefit of storing the SPF (Smallest Prime Factor) during Sieve execution?", "A. It helps in primality testing for single numbers.", "B. It allows for efficient factorization of all numbers up to N in O(log N) per number after precomputation.", "C. It reduces memory usage.", "D. It makes the Sieve faster.", "B"
"Sieve", "The term 'Eratosthenes' refers to:", "A. A type of number.", "B. A Greek mathematician who invented the algorithm.", "C. A type of computer.", "D. A mathematical theorem.", "B"
"Sieve", "Consider `N=10`. The primes processed are 2, 3. Multiples of 2 (from 4): 4, 6, 8, 10. Multiples of 3 (from 9): 9. What are the primes up to 10?", "A. 2, 3, 5, 7", "B. 2, 3, 5, 7, 9", "C. 1, 2, 3, 5, 7", "D. 2, 3, 4, 5, 6, 7, 8, 9, 10", "A"
"Sieve", "Is the Sieve of Eratosthenes memory-intensive?", "A. No, it uses minimal memory.", "B. Yes, it requires an array proportional to N, which can be large for very high N.", "C. Only for small N.", "D. It uses constant memory.", "B"
"Sieve", "When implementing the Sieve, why is it typically more efficient to use a `std::vector<bool>` or a bitset instead of `std::vector<char>` for the boolean array?", "A. `char` is not supported.", "B. `std::vector<bool>` and `bitset` are space-optimized, storing one boolean per bit.", "C. `char` is faster.", "D. It's a stylistic choice with no performance impact.", "B"
"Sieve", "The Sieve of Eratosthenes is an example of which type of algorithm?", "A. Greedy Algorithm", "B. Divide and Conquer", "C. Dynamic Programming (due to building up results for primes iteratively)", "D. Brute Force", "C"
"Sieve", "What is the common range of N for which Sieve of Eratosthenes is practical in competitive programming?", "A. Up to 100", "B. Up to 10^3", "C. Up to 10^7 (or 10^8 with careful implementation/segmented sieve)", "D. Up to 10^18", "C"
"Sieve", "What is the smallest odd composite number?", "A. 3", "B. 5", "C. 7", "D. 9", "D"
"Sieve", "If `is_prime` array is 0-indexed, and `N` is the limit, what size should the array be?", "A. `N`", "B. `N+1` (to include index N).", "C. `N-1`", "D. `2*N`", "B"
"Sieve", "The Sieve of Eratosthenes calculates primes in what order?", "A. Random order.", "B. Ascending order.", "C. Descending order.", "D. From composite to prime.", "B"
"Sieve", "Which numbers are initially marked as `false` (composite) or skipped in the Sieve setup?", "A. All numbers.", "B. Only 0 and 1.", "C. Only even numbers.", "D. Only numbers greater than `N`.", "B"
"Sieve", "What is the direct consequence of the `p*p` optimization for starting marking multiples?", "A. It increases the time complexity.", "B. It prevents redundant marking of multiples by smaller primes, improving constant factors.", "C. It requires more memory.", "D. It makes the algorithm incorrect.", "B"
"Sieve", "Is the Sieve of Eratosthenes useful for generating a small number of primes, say just the first 10?", "A. Yes, but trial division might be simpler for very small counts.", "B. No, it's overkill.", "C. Only if N is huge.", "D. It's only for specific numbers.", "A"
"Sieve", "Consider the number 13. When the Sieve runs, by which prime will 13 be marked as composite?", "A. By 2.", "B. By 3.", "C. By 5.", "D. It will not be marked as composite (it's prime).", "D"
"Sieve", "If a number `i` is composite, it must have a prime factor less than or equal to `sqrt(i)`. This is why the Sieve works. True or False?", "A. True", "B. False", "A"
"Sieve", "What is the primary advantage of the Sieve over trial division for finding multiple primes in a range?", "A. Sieve is simpler to implement.", "B. Sieve has a much better average-case time complexity (closer to linear) than repeated trial division.", "C. Sieve uses less memory.", "D. Sieve finds primes faster for individual numbers.", "B"
"Sieve", "The Sieve of Atkin is a more advanced prime-generating algorithm. What is its typical advantage over Sieve of Eratosthenes for very large N?", "A. Simpler implementation.", "B. Better space complexity (can be O(sqrt(N)) or less) and sometimes better time complexity (O(N / log log N)).", "C. It works for negative numbers.", "D. It is always faster.", "B"
"Sieve", "What is the time complexity of a simple trial division test for primality of a single number `n`?", "A. O(1)", "B. O(log n)", "C. O(sqrt(n))", "D. O(n)", "C"
"Sieve", "The number of primes up to `N` is approximately `N / ln(N)`. This is related to which theorem?", "A. Fermat's Little Theorem.", "B. Prime Number Theorem.", "C. Chinese Remainder Theorem.", "D. Wilson's Theorem.", "B"
"Sieve", "If you want to store a list of actual prime numbers found by the Sieve, what would be an efficient way?", "A. Store them directly in the boolean array.", "B. Create a separate `std::vector<int>` and add `i` to it if `is_prime[i]` is true.", "C. Print them to console only.", "D. Store them in a hash map.", "B"
"Sieve", "For the Sieve, what is the value of `p` when we start marking multiples of 7?", "A. 2", "B. 3", "C. 5", "D. 7", "D"
"Sieve", "Does the Sieve of Eratosthenes work for generating primes in an infinite range?", "A. Yes, with infinite memory.", "B. No, it requires a finite upper limit `N`.", "C. Only if all numbers are even.", "D. Only for small primes.", "B"
"ModularExponentiation", "What is the primary purpose of Modular Exponentiation?", "A. To calculate the sum of large numbers modulo M.", "B. To calculate a^b efficiently, especially when 'a', 'b', or 'a^b' are very large, and we need the result modulo M.", "C. To find prime numbers.", "D. To calculate the Greatest Common Divisor (GCD).", "B"
"ModularExponentiation", "The problem it solves is calculating (base ^ exponent) % modulus. True or False?", "A. True", "B. False", "A"
"ModularExponentiation", "What is the time complexity of a naive approach to calculate a^b % m (multiplying 'a' 'b' times)?", "A. O(log b)", "B. O(b)", "C. O(b^2)", "D. O(1)", "B"
"ModularExponentiation", "What is the principle behind the efficient Modular Exponentiation algorithm (Exponentiation by Squaring)?", "A. Using prime factorization of the exponent.", "B. Using logarithms to reduce the exponent.", "C. Breaking down the exponent into powers of 2, and using properties of modular arithmetic for squaring.", "D. Iterating through all possible remainders.", "C"
"ModularExponentiation", "If `b` is an even number, what is `(a^b) % m` equivalent to?", "A. `(a^(b/2) * a^(b/2)) % m`", "B. `((a^(b/2) % m) * (a^(b/2) % m)) % m`", "C. `(a^2 % m) * (a^(b/2) % m)`", "D. `(a % m) * (b % m)`", "B"
"ModularExponentiation", "If `b` is an odd number, what is `(a^b) % m` equivalent to?", "A. `(a * a^(b-1)) % m`", "B. `((a % m) * (a^(b-1) % m)) % m`", "C. `(a^(b/2) * a^(b/2) * a) % m`", "D. Both A and B are conceptually correct, but B ensures intermediate results stay within modulo bounds.", "D"
"ModularExponentiation", "What is the time complexity of the efficient Modular Exponentiation algorithm (Exponentiation by Squaring)?", "A. O(b)", "B. O(log b)", "C. O(b^2)", "D. O(sqrt(b))", "B"
"ModularExponentiation", "What is the space complexity of the iterative Modular Exponentiation algorithm?", "A. O(log b)", "B. O(b)", "C. O(1)", "D. O(N)", "C"
"ModularExponentiation", "What is the result of 2^3 % 5?", "A. 1", "B. 2", "C. 3", "D. 4", "C"
"ModularExponentiation", "What is the result of 3^4 % 7?", "A. 1", "B. 2", "C. 3", "D. 4", "D"
"ModularExponentiation", "Which property of modular arithmetic is crucial for Modular Exponentiation: (X * Y) % M = ((X % M) * (Y % M)) % M? True or False?", "A. True", "B. False", "A"
"ModularExponentiation", "What is the base case for the recursive Modular Exponentiation function?", "A. If exponent is 0, return 1.", "B. If exponent is 1, return base % modulus.", "C. If exponent is negative, return 0.", "D. If modulus is 0, return 0.", "A"
"ModularExponentiation", "What happens if the modulus `m` is 1?", "A. The result is always 0 (any number % 1 is 0).", "B. The result is always 1.", "C. It causes an error.", "D. It is treated as if m is 0.", "A"
"ModularExponentiation", "Can Modular Exponentiation handle a negative base?", "A. No, only positive bases.", "B. Yes, by converting the negative base to a positive equivalent modulo M (e.g., -5 % 3 = (-5 + 3*k) % 3 until positive).", "C. Only if the exponent is even.", "D. Only if the exponent is odd.", "B"
"ModularExponentiation", "What applications commonly use Modular Exponentiation?", "A. Sorting algorithms.", "B. Primality testing (e.g., Fermat's Little Theorem, Miller-Rabin) and Public-Key Cryptography (e.g., RSA).", "C. Graph traversal algorithms.", "D. String matching algorithms.", "B"
"ModularExponentiation", "Fermat's Little Theorem states that if 'p' is a prime number, then for any integer 'a' not divisible by 'p', a^(p-1) ≡ 1 (mod p). How is this related to Modular Exponentiation?", "A. It's used to calculate a^p directly.", "B. It allows for efficient calculation of modular inverses when 'p' is prime.", "C. It's a method for finding the exponent 'b'.", "D. It determines the modulus 'm'.", "B"
"ModularExponentiation", "How would you calculate the modular inverse of `a` modulo prime `p` using Fermat's Little Theorem?", "A. `(a^p) % p`", "B. `(a^(p-2)) % p`", "C. `(a^(p-1)) % p`", "D. `(a^(-1)) % p`", "B"
"ModularExponentiation", "What is the purpose of multiplying `result = (result * base) % modulus` when the current bit of the exponent is 1?", "A. To handle the `base` term for the odd exponent case.", "B. To prepare for the next squaring step.", "C. To check for primality.", "D. To reset the base.", "A"
"ModularExponentiation", "What is the purpose of `base = (base * base) % modulus` in each iteration?", "A. To reduce the exponent by half.", "B. To square the base for the next power-of-2 component of the exponent.", "C. To calculate the GCD.", "D. To find the remainder.", "B"
"ModularExponentiation", "If the exponent is 0, what should the function return?", "A. 0", "B. 1", "C. base", "D. modulus", "B"
"ModularExponentiation", "Can Modular Exponentiation be used to calculate large factorials modulo M?", "A. Yes, directly.", "B. No, factorials involve products, not just powers of a single base; it might be used for individual terms in a product, but not the overall factorial efficiently.", "C. Only for small M.", "D. Only for prime M.", "B"
"ModularExponentiation", "Is there a significant difference in the logic for iterative vs. recursive Modular Exponentiation?", "A. Yes, completely different algorithms.", "B. No, they follow the same mathematical principle (exponentiation by squaring), just implemented differently.", "C. Recursive is always faster.", "D. Iterative uses more memory.", "B"
"ModularExponentiation", "What happens if the modulus `m` is a very large prime number?", "A. The algorithm breaks down.", "B. It works efficiently because 'm' being large prime is typical for cryptography applications.", "C. It slows down significantly.", "D. It requires a different algorithm.", "B"
"ModularExponentiation", "Euler's Totient Theorem states that if GCD(a, n) = 1, then a^φ(n) ≡ 1 (mod n). How does this extend modular inverse calculation?", "A. It helps find modular inverse when 'n' is not prime: a^(φ(n)-1) % n.", "B. It's only for prime moduli.", "C. It complicates the calculation.", "D. It provides a way to calculate φ(n).", "A"
"ModularExponentiation", "What is the first step in the iterative Modular Exponentiation algorithm loop (besides initialization)?", "A. Check if the exponent is odd or even.", "B. Square the base.", "C. Divide the exponent by 2.", "D. Multiply the result by base.", "A"
"ModularExponentiation", "If the exponent `b` is a very large number (e.g., `10^18`), which data type should `b` be to avoid overflow in typical programming languages?", "A. `int`", "B. `long long` (C++/Java) or arbitrary-precision integer.", "C. `short`", "D. `float`", "B"
"ModularExponentiation", "What is `(A - B) % M` equivalent to if A < B?", "A. `(A % M - B % M) % M`", "B. `(A - B + M) % M` (to ensure positive remainder).", "C. `(B - A) % M`", "D. `(A + B) % M`", "B"
"ModularExponentiation", "What is `(A / B) % M`?", "A. `(A % M / B % M) % M`", "B. `(A * (B^(-1) % M)) % M` (requires modular inverse of B).", "C. It's not a standard operation in modular arithmetic unless B is a unit.", "D. Both B and C are relevant.", "D"
"ModularExponentiation", "The term 'modulus' refers to the divisor in a division operation. True or False?", "A. True", "B. False", "A"
"ModularExponentiation", "If `base` is 0, what is `0^b % m` when `b > 0`?", "A. 1", "B. 0", "C. `m - 1`", "D. Undefined", "B"
"ModularExponentiation", "If `base` is 0 and `exponent` is 0, what is `0^0 % m`? (Commonly defined as 1 in many contexts)", "A. 0", "B. 1", "C. Undefined", "D. `m-1`", "B"
"ModularExponentiation", "What value is `result` initialized to in the iterative Modular Exponentiation?", "A. `base`", "B. `exponent`", "C. `1`", "D. `0`", "C"
"ModularExponentiation", "Which bitwise operation is commonly used to check if an exponent `b` is odd?", "A. `b & 1`", "B. `b | 1`", "C. `b ^ 1`", "D. `b << 1`", "A"
"ModularExponentiation", "Which bitwise operation is commonly used to divide an exponent `b` by 2?", "A. `b & 1`", "B. `b | 1`", "C. `b >> 1`", "D. `b << 1`", "C"
"ModularExponentiation", "If `a = 5, b = 2, m = 13`, what is `(5^2) % 13`?", "A. 25", "B. 12", "C. 0", "D. 1", "B"
"ModularExponentiation", "If `a = 2, b = 10, m = 100`, what is the final `result` after Modular Exponentiation?", "A. 24", "B. 1024", "C. 0", "D. 4", "A"
"ModularExponentiation", "Modular Exponentiation forms the backbone of which cryptographic system?", "A. AES", "B. DES", "C. RSA", "D. SHA-256", "C"
"ModularExponentiation", "When dealing with large `base` values, `base % modulus` should be performed at the very beginning. True or False?", "A. True", "B. False", "A"
"ModularExponentiation", "If `base = -2, exponent = 3, modulus = 5`, what is `(-2)^3 % 5`?", "A. `-8 % 5` which is `2` (since -8 + 5*2 = 2)", "B. `2`", "C. `3`", "D. `4`", "A"
"ModularExponentiation", "Can Modular Exponentiation be applied when `modulus` is a non-prime number?", "A. No, only for prime moduli.", "B. Yes, the algorithm works correctly for any positive integer modulus.", "C. Only if the base is prime.", "D. Only if the exponent is 1.", "B"
"ModularExponentiation", "What is a major advantage of using `long long` for intermediate products `(base * base)` or `(result * base)` in C++/Java before taking the modulo?", "A. To avoid compilation errors.", "B. To prevent overflow when `base * base` or `result * base` exceeds the maximum value of `int` before the modulo operation.", "C. To make the code run faster.", "D. To reduce memory usage.", "B"
"ModularExponentiation", "The property `(A + B) % M = ((A % M) + (B % M)) % M` is also crucial in modular arithmetic. True or False?", "A. True", "B. False", "A"
"ModularExponentiation", "In Diffie-Hellman key exchange, what mathematical operation is used to calculate shared secrets?", "A. GCD", "B. Prime factorization.", "C. Modular Exponentiation.", "D. Linear congruences.", "C"
"ModularExponentiation", "What is the primary reason why `base` is squared in each step (e.g., `base = (base * base) % modulus`)?", "A. To reduce the number of multiplications needed.", "B. To ensure `base` always becomes 1.", "C. To check for divisibility.", "D. To make the exponent even.", "A"
"ModularExponentiation", "If `exponent` is `1`, what is the iterative loop's behavior?", "A. It runs `log(1)` times, which is 0.", "B. It runs one iteration, `result` becomes `base % modulus`, and `exponent` becomes 0, then loop terminates.", "C. It enters an infinite loop.", "D. It returns 0.", "B"
"ModularExponentiation", "The sequence of operations `(b & 1)` and `(b >>= 1)` effectively processes the exponent `b` in what form?", "A. Decimal representation.", "B. Binary representation (bit by bit).", "C. Prime factorization.", "D. Hexadecimal representation.", "B"
"ModularExponentiation", "If `a = 7, b = 2, m = 4`, what is `(7^2) % 4`?", "A. `(49 % 4)` which is `1`.", "B. `(7 % 4)^2 % 4 = 3^2 % 4 = 9 % 4 = 1`.", "C. Both A and B are correct ways to think about it and yield 1.", "D. 0", "C"
"ModularExponentiation", "Modular exponentiation is particularly useful when the numbers `a` and `b` are extremely large (e.g., thousands of digits) and cannot fit in standard data types. True or False?", "A. True (requires arbitrary-precision arithmetic for `base`, but `log b` still applies for the exponent).", "B. False", "A"
"ModularExponentiation", "In cryptography, the security of systems like RSA relies on the difficulty of solving which problem, for which Modular Exponentiation is the forward operation?", "A. Integer factorization.", "B. Discrete Logarithm problem.", "C. Traveling Salesman Problem.", "D. Knapsack Problem.", "B"
"ModularExponentiation", "What would be the result of `(10^5) % 1`?", "A. 0", "B. 1", "C. 10", "D. Undefined", "A"
"ChineseRemainderTheorem", "What is the primary purpose of the Chinese Remainder Theorem (CRT)?", "A. To find the greatest common divisor of multiple numbers.", "B. To solve systems of linear congruences.", "C. To determine if a number is prime.", "D. To calculate modular inverses.", "B"
"ChineseRemainderTheorem", "A system of linear congruences solvable by CRT is typically of the form:", "A. x ≡ a (mod m)", "B. x ≡ a1 (mod m1), x ≡ a2 (mod m2), ..., x ≡ ak (mod mk)", "C. ax ≡ b (mod m)", "D. x^n ≡ a (mod m)", "B"
"ChineseRemainderTheorem", "What is the crucial condition for a system of linear congruences to have a unique solution modulo the product of the moduli, according to the standard CRT?", "A. All moduli (m_i) must be prime.", "B. All remainders (a_i) must be positive.", "C. All moduli (m_i) must be pairwise coprime (GCD(m_i, m_j) = 1 for i != j).", "D. All moduli (m_i) must be even.", "C"
"ChineseRemainderTheorem", "If the moduli are not pairwise coprime, does CRT guarantee a unique solution?", "A. Yes, always.", "B. No, a solution might not exist, or there might be multiple solutions modulo a different value.", "C. Only if the remainders are 0.", "D. It means the problem is unsolvable.", "B"
"ChineseRemainderTheorem", "What is the general form of the solution provided by the CRT for a system x ≡ a_i (mod m_i)?", "A. A single integer x.", "B. A unique solution modulo M, where M is the product of all m_i.", "C. A set of multiple solutions.", "D. A modular inverse.", "B"
"ChineseRemainderTheorem", "Consider the system: x ≡ 2 (mod 3), x ≡ 3 (mod 5). What is M (the product of moduli)?", "A. 8", "B. 15", "C. 2", "D. 5", "B"
"ChineseRemainderTheorem", "What is the first step in solving a CRT problem with a system of two congruences x ≡ a1 (mod m1) and x ≡ a2 (mod m2)?", "A. Find GCD(m1, m2).", "B. Check if m1 and m2 are coprime.", "C. Express x = a1 + k * m1 for some integer k.", "D. Calculate M = m1 * m2.", "C"
"ChineseRemainderTheorem", "In the general solution formula for CRT, `M_i` is defined as `M / m_i`. What is `y_i`?", "A. The modular inverse of `M_i` modulo `m_i` (i.e., `M_i * y_i ≡ 1 (mod m_i)`).", "B. The remainder `a_i`.", "C. The modulus `m_i`.", "D. The product of `a_i` and `m_i`.", "A"
"ChineseRemainderTheorem", "The formula for the unique solution x modulo M is given by:", "A. x = Σ (a_i * M_i) % M", "B. x = Σ (a_i * M_i * y_i) % M", "C. x = Π (a_i * m_i) % M", "D. x = Σ (m_i * y_i) % M", "B"
"ChineseRemainderTheorem", "To find `y_i` (the modular inverse of `M_i` modulo `m_i`), which algorithm is commonly used?", "A. Sieve of Eratosthenes.", "B. Euclidean Algorithm.", "C. Extended Euclidean Algorithm.", "D. Binary Exponentiation.", "C"
"ChineseRemainderTheorem", "What happens if a solution to a system of congruences exists, but the moduli are NOT pairwise coprime?", "A. The standard CRT formula still applies.", "B. The system has no solution.", "C. A modified (constructive) approach using GCD and consistency checks can often find solutions, but they might not be unique modulo the product of moduli.", "D. It means the system has infinite solutions.", "C"
"ChineseRemainderTheorem", "Consider x ≡ 0 (mod 2) and x ≡ 0 (mod 4). Do these congruences satisfy the coprime moduli condition?", "A. Yes.", "B. No, GCD(2, 4) = 2 ≠ 1.", "C. Only if x = 0.", "D. It depends on x.", "B"
"ChineseRemainderTheorem", "For x ≡ 0 (mod 2) and x ≡ 0 (mod 4), what is the smallest non-negative integer solution?", "A. 0", "B. 2", "C. 4", "D. 6", "C"
"ChineseRemainderTheorem", "Is the solution to a CRT problem unique among all integers?", "A. Yes, it's a single integer.", "B. No, it's unique modulo M (the product of moduli), meaning there are infinitely many solutions of the form x + kM.", "C. Only if M is prime.", "D. Only if M is 1.", "B"
"ChineseRemainderTheorem", "Which of the following is an application of the Chinese Remainder Theorem?", "A. Determining primality of large numbers.", "B. Solving systems where a quantity leaves different remainders when divided by different numbers.", "C. Calculating the sum of a sequence.", "D. Finding shortest paths in graphs.", "B"
"ChineseRemainderTheorem", "Historically, the CRT was used for problems involving what?", "A. Astronomy and calendar calculations.", "B. Engineering designs.", "C. Economic forecasting.", "D. Military strategy.", "A"
"ChineseRemainderTheorem", "If you have a system x ≡ a1 (mod m1), x ≡ a2 (mod m2), ..., x ≡ ak (mod mk), what is the smallest positive integer solution?", "A. The solution x found by CRT modulo M, if x is non-negative. If negative, add M until positive.", "B. Always 0.", "C. Always 1.", "D. The smallest of a1, a2, ..., ak.", "A"
"ChineseRemainderTheorem", "What is the mathematical concept that states that an integer can be uniquely reconstructed from its remainders modulo a set of pairwise coprime integers?", "A. Prime Factorization Theorem.", "B. Fundamental Theorem of Arithmetic.", "C. Chinese Remainder Theorem.", "D. Fermat's Little Theorem.", "C"
"ChineseRemainderTheorem", "If GCD(m_i, m_j) = 1 for all i ≠ j, this means the moduli are:", "A. Prime.", "B. Composite.", "C. Relatively prime (coprime).", "D. Even.", "C"
"ChineseRemainderTheorem", "The numbers `M_i` in the CRT formula are called:", "A. Moduli factors.", "B. Partial products.", "C. Co-factors.", "D. Modular inverses.", "B"
"ChineseRemainderTheorem", "In the context of CRT, what does it mean for a solution `x` to be 'unique modulo M'?", "A. There is only one possible integer solution.", "B. All solutions are of the form `x + kM`, where `k` is an integer, and `x` is the smallest non-negative solution.", "C. The solution `x` is always 0.", "D. The solution `x` is always M.", "B"
"ChineseRemainderTheorem", "Consider the system: x ≡ 1 (mod 2), x ≡ 1 (mod 3). What is M?", "A. 5", "B. 6", "C. 1", "D. 2", "B"
"ChineseRemainderTheorem", "For x ≡ 1 (mod 2), x ≡ 1 (mod 3), what is the smallest non-negative integer solution?", "A. 1", "B. 3", "C. 5", "D. 7", "A"
"ChineseRemainderTheorem", "If you are trying to find a number `x` that leaves a remainder of 3 when divided by 7, and a remainder of 5 when divided by 11, which theorem would you use?", "A. Euclidean Algorithm.", "B. Chinese Remainder Theorem.", "C. Fermat's Little Theorem.", "D. Master Theorem.", "B"
"ChineseRemainderTheorem", "Can CRT be used for negative remainders (a_i)?", "A. No, remainders must be positive.", "B. Yes, by converting negative `a_i` to a positive equivalent modulo `m_i` first (e.g., -1 mod 5 is 4).", "C. Only if the modulus is also negative.", "D. Only if the solution is negative.", "B"
"ChineseRemainderTheorem", "The step where you find `x = a_1 + k * m_1` and substitute into the next congruence is known as the:", "A. Direct substitution method (for constructive CRT).", "B. Recursive method.", "C. Iterative method.", "D. Trial and error method.", "A"
"ChineseRemainderTheorem", "When applying the constructive method (iterative two-congruence solution), if you find `x_k` for the first `k` congruences, to solve for `k+1`, you set up `x_k + j * M_k ≡ a_{k+1} (mod m_{k+1})`. What is `M_k` here?", "A. The current solution.", "B. The product of the first `k` moduli.", "C. The `(k+1)`-th modulus.", "D. The remainder.", "B"
"ChineseRemainderTheorem", "What is the crucial check when using the constructive approach for non-coprime moduli?", "A. Check if `a_{k+1}` is prime.", "B. Check if `(a_{k+1} - x_k)` is divisible by `GCD(M_k, m_{k+1})`.", "C. Check if `m_{k+1}` is even.", "D. Check if `x_k` is 0.", "B"
"ChineseRemainderTheorem", "If a system with non-coprime moduli has a solution, the solution is unique modulo what value?", "A. The product of all moduli.", "B. The LCM of all moduli.", "C. The GCD of all moduli.", "D. 1.", "B"
"ChineseRemainderTheorem", "What is the computational bottleneck in solving a CRT problem with very large moduli?", "A. Summing the terms.", "B. Calculating the modular inverses using Extended Euclidean Algorithm.", "C. Checking for primality of moduli.", "D. Finding the initial remainders.", "B"
"ChineseRemainderTheorem", "The Chinese Remainder Theorem can be generalized to rings other than integers. True or False?", "A. True", "B. False", "A"
"ChineseRemainderTheorem", "Consider x ≡ 5 (mod 6), x ≡ 1 (mod 4). Are the moduli coprime?", "A. Yes, 6 and 4 are coprime.", "B. No, GCD(6, 4) = 2 ≠ 1.", "C. Only if x is even.", "D. It depends on the remainder.", "B"
"ChineseRemainderTheorem", "For x ≡ 5 (mod 6), x ≡ 1 (mod 4). If we try to find a solution, what does the first congruence give us?", "A. x = 6k + 5", "B. x = 4k + 1", "C. x = 5", "D. x = 1", "A"
"ChineseRemainderTheorem", "Substitute `x = 6k + 5` into `x ≡ 1 (mod 4)`: `6k + 5 ≡ 1 (mod 4)`. What does this simplify to?", "A. 2k + 1 ≡ 1 (mod 4)", "B. 2k + 5 ≡ 1 (mod 4)", "C. 6k ≡ -4 (mod 4)", "D. 6k ≡ 1 (mod 4)", "A"
"ChineseRemainderTheorem", "From `2k + 1 ≡ 1 (mod 4)`, we get `2k ≡ 0 (mod 4)`. What is the general solution for `k`?", "A. k = 0", "B. k = 2j for any integer j (since 2k must be a multiple of 4).", "C. k = 4j", "D. k = 1", "B"
"ChineseRemainderTheorem", "If `k = 2j`, substitute back into `x = 6k + 5`. What is the general form of x?", "A. x = 6(2j) + 5 = 12j + 5", "B. x = 6j + 5", "C. x = 2j + 5", "D. x = 12j", "A"
"ChineseRemainderTheorem", "What is the smallest non-negative solution for x ≡ 5 (mod 6), x ≡ 1 (mod 4)?", "A. 1", "B. 5", "C. 12", "D. 17 (from 12j + 5, for j=1)", "B"
"ChineseRemainderTheorem", "What is the LCM of 6 and 4?", "A. 2", "B. 12", "C. 24", "D. 1", "B"
"ChineseRemainderTheorem", "The solution for x ≡ 5 (mod 6), x ≡ 1 (mod 4) is unique modulo what value?", "A. 24", "B. 12 (which is LCM(6,4))", "C. 6", "D. 4", "B"
"ChineseRemainderTheorem", "The existence of a solution for ax ≡ b (mod m) depends on GCD(a, m) dividing b. This is distinct from the coprime moduli condition in standard CRT, but both relate to modular equations. True or False?", "A. True", "B. False", "A"
"ChineseRemainderTheorem", "If M is the product of pairwise coprime moduli m1, m2, ..., mk, then the integers modulo M form an isomorphic ring to the product of rings of integers modulo m_i. True or False?", "A. True (This is the essence of the CRT statement).", "B. False", "A"
"ChineseRemainderTheorem", "What is a 'system of congruences' in the context of CRT?", "A. A single equation involving modulo.", "B. A set of two or more linear congruences, each with the same variable 'x' but different moduli and remainders.", "C. A set of equations without moduli.", "D. A system of non-linear equations.", "B"
"ChineseRemainderTheorem", "The original purpose of CRT in ancient China was related to:", "A. Counting soldiers after a battle.", "B. Dividing land among farmers.", "C. Predicting celestial events.", "D. Building bridges.", "A"
"ChineseRemainderTheorem", "Can CRT be used if one of the moduli is 1?", "A. Yes, but a congruence modulo 1 (x ≡ a (mod 1)) always holds for any integer x and remainder a, effectively providing no new constraint and can be ignored.", "B. No, it breaks the theorem.", "C. Only if 'a' is 0.", "D. Only if all other moduli are prime.", "A"
"ChineseRemainderTheorem", "When solving CRT, the property `(A * B) % M = ((A % M) * (B % M)) % M` is used to keep intermediate calculations manageable. True or False?", "A. True", "B. False", "A"
"ChineseRemainderTheorem", "If you have a very large number, and you want to calculate its value modulo several different small primes, can CRT help in reconstructing the original large number from these remainders?", "A. Yes, if the product of the small primes is greater than the large number.", "B. No, it only works for small numbers.", "C. Only if the large number is prime.", "D. Only if the large number is even.", "A"
"ChineseRemainderTheorem", "The method of 'successive substitution' is an alternative way to solve CRT problems. True or False?", "A. True", "B. False", "A"
"ChineseRemainderTheorem", "Consider the system: x ≡ 1 (mod 7), x ≡ 1 (mod 13). What is the smallest non-negative integer solution?", "A. 1", "B. 7", "C. 13", "D. 91", "A"
"ChineseRemainderTheorem", "If a CRT system has only one congruence, does it still have a solution?", "A. Yes, trivially, x ≡ a1 (mod m1) is its own solution set.", "B. No, it requires at least two.", "C. Only if m1 is prime.", "D. Only if a1 is 0.", "A"
"ChineseRemainderTheorem", "What kind of numbers are the moduli `m_i` in the CRT typically assumed to be?", "A. Any integers.", "B. Positive integers.", "C. Prime numbers.", "D. Even numbers.", "B"
"ChineseRemainderTheorem", "The Chinese Remainder Theorem ensures that a unique solution exists under specific conditions. What happens if those conditions are not met, specifically that `GCD(m_i, m_j) != 1` for some pair `i, j`?", "A. The system always has no solution.", "B. The system always has multiple solutions.", "C. The system may have no solution, or it may have a unique solution modulo LCM(m1, m2, ..., mk).", "D. The system requires a different theorem entirely.", "C"
"EulerTotient", "What does Euler's Totient Function, φ(n), count?", "A. The number of prime numbers less than or equal to n.", "B. The number of divisors of n.", "C. The number of positive integers less than or equal to n that are relatively prime to n (coprime to n).", "D. The sum of the divisors of n.", "C"
"EulerTotient", "What is another name for Euler's Totient Function?", "A. Euler's Sigma function.", "B. Euler's Pi function.", "C. Euler's Phi function.", "D. Euler's Zeta function.", "C"
"EulerTotient", "What is φ(1)?", "A. 0", "B. 1", "C. Undefined", "D. 2", "B"
"EulerTotient", "If `p` is a prime number, what is φ(p)?", "A. p", "B. p - 1", "C. 1", "D. 0", "B"
"EulerTotient", "What is φ(7)?", "A. 6", "B. 7", "C. 1", "D. 0", "A"
"EulerTotient", "If `p` is a prime number and `k` is a positive integer, what is φ(p^k)?", "A. p^k - 1", "B. p^k", "C. p^k - p^(k-1)", "D. p^(k-1)", "C"
"EulerTotient", "What is φ(8)?", "A. 8 (Numbers: 1,2,3,4,5,6,7,8. Coprime: 1,3,5,7)", "B. 4", "C. 6", "D. 2", "B"
"EulerTotient", "What is φ(9)?", "A. 9 (Numbers: 1,2,3,4,5,6,7,8,9. Coprime: 1,2,4,5,7,8)", "B. 6", "C. 8", "D. 3", "B"
"EulerTotient", "Euler's Totient Function is a multiplicative function. What does this mean?", "A. φ(mn) = φ(m) * φ(n) always.", "B. φ(mn) = φ(m) + φ(n) always.", "C. If GCD(m, n) = 1, then φ(mn) = φ(m) * φ(n).", "D. If GCD(m, n) = 1, then φ(mn) = φ(m) + φ(n).", "C"
"EulerTotient", "What is the formula for φ(n) if `n` has prime factorization `p1^a1 * p2^a2 * ... * pk^ak`?", "A. `φ(n) = (p1-1) * (p2-1) * ... * (pk-1)`", "B. `φ(n) = n * (1 - 1/p1) * (1 - 1/p2) * ... * (1 - 1/pk)`", "C. `φ(n) = n / (p1 * p2 * ... * pk)`", "D. `φ(n) = p1^a1 * p2^a2 * ... * pk^ak`", "B"
"EulerTotient", "Calculate φ(10).", "A. 10 (Coprime: 1,3,7,9)", "B. 4", "C. 8", "D. 5", "B"
"EulerTotient", "Calculate φ(12).", "A. 12 (Coprime: 1,5,7,11)", "B. 6", "C. 4", "D. 8", "C"
"EulerTotient", "What is Euler's Totient Theorem?", "A. For any integers a and n, a^n ≡ 1 (mod n).", "B. If a and n are coprime positive integers, then a^φ(n) ≡ 1 (mod n).", "C. For any prime p, a^(p-1) ≡ 1 (mod p).", "D. The sum of all integers coprime to n is n * φ(n) / 2.", "B"
"EulerTotient", "Fermat's Little Theorem is a special case of Euler's Totient Theorem where:", "A. n is any composite number.", "B. n is a prime number.", "C. a is equal to n.", "D. φ(n) is 1.", "B"
"EulerTotient", "What is the purpose of Euler's Totient Theorem?", "A. To find the greatest common divisor.", "B. To simplify modular exponentiation with large exponents.", "C. To check if a number is prime.", "D. To factorize large numbers.", "B"
"EulerTotient", "If we want to calculate `a^b % n` where `GCD(a, n) = 1`, and `b` is very large, how can Euler's Totient Theorem help?", "A. Replace `b` with `b % n`.", "B. Replace `b` with `b % φ(n)`.", "C. Replace `a` with `a % n`.", "D. Replace `n` with `φ(n)`.", "B"
"EulerTotient", "What is `7^100 % 10` using Euler's Totient Theorem? (φ(10) = 4)", "A. `7^(100 % 10) % 10 = 7^0 % 10 = 1`", "B. `7^(100 % 4) % 10 = 7^0 % 10 = 1`", "C. `7^10 % 10 = 7`", "D. `7^4 % 10 = 1`", "B"
"EulerTotient", "For `a^b % n`, if `GCD(a, n) ≠ 1`, can Euler's Totient Theorem still be directly applied to reduce the exponent?", "A. Yes, always.", "B. No, the condition `GCD(a, n) = 1` is crucial.", "C. Only if `n` is prime.", "D. Only if `b` is small.", "B"
"EulerTotient", "What is the result of `2^10 % 5`? (φ(5) = 4)", "A. `2^(10 % 5) % 5 = 2^0 % 5 = 1`", "B. `2^(10 % 4) % 5 = 2^2 % 5 = 4`", "C. `2^1 % 5 = 2`", "D. `2^4 % 5 = 1`", "B"
"EulerTotient", "One significant application of Euler's Totient Function and Theorem is in which cryptographic algorithm?", "A. DES", "B. AES", "C. RSA", "D. SHA-256", "C"
"EulerTotient", "In RSA, if `n = p * q` (where p and q are large primes), what is `φ(n)` used to calculate?", "A. The public key `e`.", "B. The private key `d`.", "C. The message `m`.", "D. The ciphertext `c`.", "B"
"EulerTotient", "What does the sum `Σ_{d|n} φ(d)` equal? (where the sum is over all positive divisors `d` of `n`)", "A. `φ(n)`", "B. `n`", "C. `2n`", "D. `n^2`", "B"
"EulerTotient", "Calculate φ(20).", "A. 20 (Prime factors: 2, 5. φ(20) = 20 * (1 - 1/2) * (1 - 1/5) = 20 * 1/2 * 4/5 = 8)", "B. 10", "C. 8", "D. 16", "C"
"EulerTotient", "For any `n > 2`, φ(n) is always an even number. True or False?", "A. True", "B. False (e.g., φ(1) = 1, φ(2) = 1)", "A"
"EulerTotient", "When is φ(n) equal to n - 1?", "A. When n is composite.", "B. When n is a prime number.", "C. When n is an even number.", "D. When n is 1.", "B"
"EulerTotient", "If `n` is a power of 2, say `n = 2^k` where `k ≥ 1`, what is φ(n)?", "A. `2^k`", "B. `2^(k-1)`", "C. `2^k - 1`", "D. `k`", "B"
"EulerTotient", "What is φ(16)?", "A. 16 (16 = 2^4, φ(16) = 2^4 - 2^3 = 16 - 8 = 8)", "B. 15", "C. 8", "D. 4", "C"
"EulerTotient", "The numbers `k` such that `1 ≤ k ≤ n` and `GCD(k, n) = 1` are sometimes called:", "A. Divisors of n.", "B. Multiples of n.", "C. Totatives of n.", "D. Residues of n.", "C"
"EulerTotient", "If `p` is a prime, and `k >= 1`, then `φ(p^k) = p^k * (1 - 1/p)`. True or False?", "A. True", "B. False", "A"
"EulerTotient", "To compute φ(n) efficiently for a large `n`, what is the most common first step?", "A. Find all divisors of n.", "B. Find the prime factorization of n.", "C. Iterate from 1 to n and check GCD.", "D. Calculate n-1.", "B"
"EulerTotient", "What is the relationship between Euler's Totient Function and the order of the multiplicative group of integers modulo n, denoted (Z/nZ)*?", "A. φ(n) is the number of elements in (Z/nZ)*.", "B. φ(n) is the largest element in (Z/nZ)*.", "C. φ(n) is the sum of elements in (Z/nZ)*.", "D. There is no direct relationship.", "A"
"EulerTotient", "Consider the problem of finding the last digit of `3^2023`. Which aspect of Euler's Totient Theorem is relevant here?", "A. Finding `φ(10)`.", "B. Finding `φ(3)`.", "C. Finding `2023 % 3`.", "D. Factoring 2023.", "A"
"EulerTotient", "For `3^2023 % 10`, what is `φ(10)`?", "A. 10 (Prime factors: 2, 5. φ(10) = 10 * (1 - 1/2) * (1 - 1/5) = 10 * 1/2 * 4/5 = 4)", "B. 9", "C. 6", "D. 4", "D"
"EulerTotient", "Using Euler's Totient Theorem, `3^2023 % 10` can be simplified as `3^(2023 % φ(10)) % 10`. What is `2023 % 4`?", "A. 0", "B. 1", "C. 2", "D. 3", "D"
"EulerTotient", "What is the final result of `3^2023 % 10`?", "A. `3^0 % 10 = 1`", "B. `3^1 % 10 = 3`", "C. `3^2 % 10 = 9`", "D. `3^3 % 10 = 27 % 10 = 7`", "D"
"EulerTotient", "Is Euler's Totient Function always odd for `n > 2`?", "A. Yes", "B. No (e.g., φ(4) = 2, φ(6) = 2, φ(8) = 4)", "B"
"EulerTotient", "Can φ(n) be equal to 1 for `n > 2`?", "A. Yes, for some composite numbers.", "B. No, only for n = 1 and n = 2.", "C. Only if n is prime.", "D. Yes, if n is a power of a prime.", "B"
"EulerTotient", "What is the smallest number `n > 1` for which `φ(n) = 1`?", "A. 2", "B. 3", "C. 4", "D. No such number exists.", "A"
"EulerTotient", "If `n` is odd, then `φ(2n) = φ(n)`. True or False?", "A. True (Since GCD(2, n) = 1, φ(2n) = φ(2) * φ(n) = 1 * φ(n) = φ(n))", "B. False", "A"
"EulerTotient", "The sum `Σ_{k=1 to n, GCD(k,n)=1} k` is equal to `n * φ(n) / 2` for `n > 1`. True or False?", "A. True", "B. False", "A"
"EulerTotient", "For `n=6`, what are the numbers coprime to `n` (totatives)?", "A. {1, 2, 3, 4, 5, 6}", "B. {1, 5}", "C. {1, 3, 5}", "D. {1, 2, 3}", "B"
"EulerTotient", "For `n=6`, what is `φ(6)`?", "A. 6", "B. 2", "C. 4", "D. 3", "B"
"EulerTotient", "What is the computational complexity of calculating `φ(n)` for a single large `n` if you first find its prime factorization?", "A. O(sqrt(n)) (dominated by factorization)", "B. O(log n)", "C. O(n)", "D. O(1)", "A"
"EulerTotient", "To calculate `φ(i)` for all `i` from 1 to `N` efficiently, which algorithm is typically used?", "A. Simple iteration.", "B. Sieve-like approach (e.g., modified Sieve of Eratosthenes).", "C. Recursive approach.", "D. Divide and conquer.", "B"
"EulerTotient", "Euler's Totient Theorem is a generalization of which other significant theorem in number theory?", "A. Chinese Remainder Theorem.", "B. Wilson's Theorem.", "C. Lagrange's Theorem.", "D. Fermat's Little Theorem.", "D"
"EulerTotient", "If `p` is a prime number, then the numbers `1, 2, ..., p-1` are all coprime to `p`. True or False?", "A. True", "B. False", "A"
"EulerTotient", "What is the maximum possible value for `φ(n)`?", "A. `n`", "B. `n - 1`", "C. `n / 2`", "D. It has no upper bound.", "B"
"EulerTotient", "The property `φ(n) < n` for `n > 1` is always true. True or False?", "A. True", "B. False", "A"
"EulerTotient", "If `n` is a prime power, say `n = p^k`, then the numbers not coprime to `n` are multiples of `p`. How many such multiples are there in the range `1` to `n`?", "A. `p`", "B. `p^k`", "C. `p^(k-1)`", "D. `k`", "C"
"EulerTotient", "What is `φ(100)`?", "A. 100 * (1 - 1/2) * (1 - 1/5) = 100 * 1/2 * 4/5 = 40", "B. 50", "C. 20", "D. 99", "A"
"InclusionExclusion", "What is the primary purpose of the Inclusion-Exclusion Principle?", "A. To calculate the Greatest Common Divisor (GCD) of numbers.", "B. To count the elements in the union of multiple finite sets.", "C. To find prime numbers up to a limit.", "D. To sort elements in an array.", "B"
"InclusionExclusion", "For two sets A and B, the principle states: |A ∪ B| = ?", "A. |A| + |B|", "B. |A| + |B| - |A ∩ B|", "C. |A| * |B|", "D. |A| - |B|", "B"
"InclusionExclusion", "For three sets A, B, and C, the principle states: |A ∪ B ∪ C| = ?", "A. |A| + |B| + |C|", "B. |A| + |B| + |C| - |A ∩ B| - |A ∩ C| - |B ∩ C|", "C. |A| + |B| + |C| - |A ∩ B| - |A ∩ C| - |B ∩ C| + |A ∩ B ∩ C|", "D. |A| * |B| * |C|", "C"
"InclusionExclusion", "What is the general pattern of signs in the Inclusion-Exclusion Principle for `n` sets?", "A. All terms are positive.", "B. All terms are negative.", "C. Alternating signs: positive for odd-sized intersections, negative for even-sized intersections.", "D. Alternating signs: positive for single sets, negative for pairs, positive for triplets, and so on.", "D"
"InclusionExclusion", "The Inclusion-Exclusion Principle is used to correct for what in simple summation?", "A. Errors in calculation.", "B. Elements that have been counted multiple times.", "C. Missing elements.", "D. Overlapping sets.", "B"
"InclusionExclusion", "If a problem asks to count items that satisfy 'at least one' of several properties, which principle is likely applicable?", "A. Pigeonhole Principle", "B. Inclusion-Exclusion Principle", "C. Multiplication Principle", "D. Sum Principle", "B"
"InclusionExclusion", "A survey found 50 people like apples, 60 like bananas, and 20 like both. How many people like apples OR bananas?", "A. 110", "B. 90", "C. 70", "D. 130", "B"
"InclusionExclusion", "In a group of 100 students, 30 take Math, 40 take Physics, and 10 take both. How many students take at least one of Math or Physics?", "A. 80", "B. 70", "C. 60", "D. 90", "C"
"InclusionExclusion", "What is the complexity of applying Inclusion-Exclusion for `N` properties?", "A. O(N)", "B. O(N^2)", "C. O(2^N) because it involves iterating through all subsets of properties.", "D. O(log N)", "C"
"InclusionExclusion", "Which of the following problems can be solved using Inclusion-Exclusion?", "A. Finding the shortest path in a graph.", "B. Counting permutations with specific restrictions (e.g., derangements).", "C. Calculating the sum of an arithmetic series.", "D. Sorting a list of numbers.", "B"
"InclusionExclusion", "What does a 'derangement' refer to?", "A. A permutation where no element appears in its original position.", "B. A permutation where all elements appear in their original position.", "C. A sorted permutation.", "D. A permutation with an even number of inversions.", "A"
"InclusionExclusion", "The number of derangements of `n` elements, denoted `!n` or `D_n`, can be calculated using Inclusion-Exclusion. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "What is the formula for Euler's Totient Function `φ(n)` using Inclusion-Exclusion (where `p_i` are distinct prime factors of `n`)?", "A. `n * (1 - 1/p1 - 1/p2 - ...)`", "B. `n - Σ(n/p_i) + Σ(n/(p_i*p_j)) - ...`", "C. `n + Σ(n/p_i) - Σ(n/(p_i*p_j)) + ...`", "D. `n / (p1 * p2 * ...)`", "B"
"InclusionExclusion", "When applying Inclusion-Exclusion to Euler's Totient Function, what do the 'properties' represent?", "A. Being prime.", "B. Being a multiple of a prime factor of n.", "C. Being relatively prime to n.", "D. Being less than n.", "B"
"InclusionExclusion", "How many integers from 1 to 100 are divisible by 2 or 3?", "A. 50 (divisible by 2) + 33 (divisible by 3) - 16 (divisible by 6) = 67", "B. 83", "C. 66", "D. 50", "A"
"InclusionExclusion", "What is the key idea when defining 'properties' for Inclusion-Exclusion?", "A. Each property should be mutually exclusive.", "B. Each property defines a set of elements to be counted.", "C. Properties must be ordered.", "D. Properties should be prime numbers.", "B"
"InclusionExclusion", "Consider a scenario where you want to count numbers that are NOT divisible by any of a set of primes. How would Inclusion-Exclusion be applied?", "A. Directly calculate using the principle for divisibility.", "B. Calculate the total numbers, then subtract the count of numbers divisible by at least one prime, which is found using Inclusion-Exclusion.", "C. It's not applicable for 'NOT' conditions.", "D. Use a sieve method instead.", "B"
"InclusionExclusion", "If we have a universe `U`, and sets `A_1, A_2, ..., A_n`, the number of elements in `U` that are in NONE of these sets is `|U| - |A_1 ∪ A_2 ∪ ... ∪ A_n|`. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "In a scenario with 4 sets, `|A ∪ B ∪ C ∪ D|` would involve how many terms with single intersections?", "A. 1", "B. 4", "C. 6", "D. 10", "B"
"InclusionExclusion", "In a scenario with 4 sets, `|A ∪ B ∪ C ∪ D|` would involve how many terms with double intersections?", "A. 1", "B. 4", "C. 6", "D. 10", "C"
"InclusionExclusion", "In a scenario with 4 sets, `|A ∪ B ∪ C ∪ D|` would involve how many terms with triple intersections?", "A. 1", "B. 4", "C. 6", "D. 10", "B"
"InclusionExclusion", "In a scenario with 4 sets, `|A ∪ B ∪ C ∪ D|` would involve how many terms with quadruple intersections?", "A. 1", "B. 4", "C. 6", "D. 10", "A"
"InclusionExclusion", "The number of terms in the Inclusion-Exclusion Principle for `n` sets is `2^n - 1`. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "Which sign corresponds to terms representing intersections of an odd number of sets?", "A. Positive (+)", "B. Negative (-)", "C. Alternating based on value.", "D. Always zero.", "A"
"InclusionExclusion", "Which sign corresponds to terms representing intersections of an even number of sets?", "A. Positive (+)", "B. Negative (-)", "C. Alternating based on value.", "D. Always zero.", "B"
"InclusionExclusion", "In combinatorial problems, Inclusion-Exclusion is useful when direct counting leads to what issue?", "A. Too few items being counted.", "B. Overcounting certain elements.", "C. Incorrect ordering of elements.", "D. Prime numbers appearing.", "B"
"InclusionExclusion", "The problem of counting permutations where certain elements are fixed in their positions can be simplified by considering properties of fixed positions and applying Inclusion-Exclusion. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "If a problem asks for elements that satisfy `exactly k` properties, can Inclusion-Exclusion be used?", "A. No, only 'at least one'.", "B. Yes, by using a more advanced form or combining with binomial coefficients.", "C. Only if k = 1.", "D. Only if k = N.", "B"
"InclusionExclusion", "Consider counting integers up to N that are not divisible by any of `p1, p2, p3`. The solution starts with `N - (count of multiples of p1 + count of multiples of p2 + ...)` and then adjusts for overcounting. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "The Inclusion-Exclusion Principle is derived from the principle of mathematical induction. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "What is the common term for applying Inclusion-Exclusion to count derangements?", "A. Euler's Derangement Formula.", "B. De Montmort's Formula (or just Derangement Formula).", "C. Principle of Permutations.", "D. Fibonacci Sequence.", "B"
"InclusionExclusion", "If you want to count elements that have property P1 and P2, but NOT P3. Can Inclusion-Exclusion be used?", "A. Yes, but it's more complex, often by defining new sets for the intersection of P1 and P2, and then applying IE for P3 on that set.", "B. No, it only works for unions.", "C. Only if P1, P2, P3 are primes.", "D. Only for small sets.", "A"
"InclusionExclusion", "The Inclusion-Exclusion Principle is a fundamental concept in:", "A. Calculus.", "B. Linear Algebra.", "C. Combinatorics and Probability.", "D. Geometry.", "C"
"InclusionExclusion", "A variant of Inclusion-Exclusion for probability states: P(A ∪ B) = P(A) + P(B) - P(A ∩ B). True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "What is the primary challenge in applying Inclusion-Exclusion for many sets?", "A. Defining the sets correctly.", "B. Calculating the sizes of all possible intersections, which can be numerous.", "C. Remembering the signs.", "D. Finding the union.", "B"
"InclusionExclusion", "Counting surjective functions from a set of size `m` to a set of size `n` often involves Inclusion-Exclusion. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "If `n` is a square-free integer, what is `φ(n)` using Inclusion-Exclusion directly?", "A. `n * (1 - Σ 1/p_i + Σ 1/(p_i p_j) - ...)`", "B. `n - Σ (n/p_i) + Σ (n/(p_i p_j)) - ...` (This is the formula where p_i are distinct prime factors)", "C. `n - 1`", "D. `n`", "B"
"InclusionExclusion", "Which of the following is a common mistake when using Inclusion-Exclusion?", "A. Forgetting to alternate signs.", "B. Incorrectly calculating the size of intersections.", "C. Not considering all possible subsets of properties.", "D. All of the above.", "D"
"InclusionExclusion", "For `N` sets, how many terms are there in the first level of inclusion (single sets)?", "A. `N`", "B. `N choose 2`", "C. `N choose 3`", "D. `2^N`", "A"
"InclusionExclusion", "For `N` sets, how many terms are there in the first level of exclusion (pairwise intersections)?", "A. `N`", "B. `N choose 2`", "C. `N choose 3`", "D. `2^N`", "B"
"InclusionExclusion", "What is the maximum number of people in a group of 30 that can speak at least one of English, French, or German, if 15 speak English, 10 speak French, 5 speak German, and no one speaks more than one language?", "A. 30", "B. 20", "C. 15", "D. 0", "B"
"InclusionExclusion", "If a problem mentions 'none of the properties' or 'exactly none', how does Inclusion-Exclusion apply?", "A. Directly, as the final term in the formula.", "B. By calculating the total universe size minus the result of the standard Inclusion-Exclusion for 'at least one'.", "C. It's irrelevant.", "D. Only by brute force.", "B"
"InclusionExclusion", "Can Inclusion-Exclusion be used to count numbers divisible by `A` OR `B` OR `C` if `A`, `B`, `C` are not necessarily prime?", "A. No, only primes.", "B. Yes, the principle applies to any sets, not just those defined by prime divisibility.", "C. Only if `A`, `B`, `C` are coprime.", "D. Only if `A`, `B`, `C` are even.", "B"
"InclusionExclusion", "What does the symbol `|S|` represent in set theory?", "A. The sum of elements in set S.", "B. The number of elements in set S (cardinality).", "C. The absolute value of elements in set S.", "D. The product of elements in set S.", "B"
"InclusionExclusion", "The Inclusion-Exclusion Principle can be visualized using what?", "A. A number line.", "B. Venn diagrams.", "C. A Cartesian coordinate system.", "D. A truth table.", "B"
"InclusionExclusion", "When dealing with a universe of elements `U`, the number of elements with *none* of the properties `P_1, ..., P_n` is `N(P_1' P_2' ... P_n')`, where `P_i'` denotes not having property `P_i`. This equals `|U| - N(P_1 or P_2 or ... or P_n)`. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "Which famous combinatorial problem involves counting the number of ways to seat `n` couples at a round table so that no couple sits next to each other, often solved with Inclusion-Exclusion?", "A. The Handshaking Lemma.", "B. The Problème des Ménages.", "C. The Traveling Salesman Problem.", "D. The Bridge Problem.", "B"
"InclusionExclusion", "If a problem requires counting arrangements with 'at least one' restriction, the Inclusion-Exclusion Principle is a direct method. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "The Inclusion-Exclusion Principle is primarily an enumerative combinatorics technique. True or False?", "A. True", "B. False", "A"
"InclusionExclusion", "What is the coefficient for an intersection of `k` sets in the Inclusion-Exclusion Principle formula?", "A. `1`", "B. `(-1)^(k-1)`", "C. `k`", "D. `N`", "B"
"FastExponentiation", "What is another common name for Fast Exponentiation?", "A. Quick Power", "B. Exponentiation by Squaring", "C. Rapid Multiplication", "D. Logarithmic Exponentiation", "B"
"FastExponentiation", "The primary goal of Fast Exponentiation is to calculate `a^b` efficiently. What is the naive approach's time complexity?", "A. O(1)", "B. O(log b)", "C. O(b)", "D. O(b^2)", "C"
"FastExponentiation", "Fast Exponentiation reduces the number of multiplications required from `b` to approximately:", "A. `b/2`", "B. `log b`", "C. `sqrt(b)`", "D. `2b`", "B"
"FastExponentiation", "What is the core idea behind Fast Exponentiation?", "A. Repeated addition.", "B. Repeated squaring of the base.", "C. Prime factorization of the base.", "D. Using logarithms directly.", "B"
"FastExponentiation", "If `b` is an even exponent, `a^b` can be rewritten as:", "A. `(a^(b/2))^2`", "B. `a * a^(b-1)`", "C. `a + a`", "D. `a^(b/2) + a^(b/2)`", "A"
"FastExponentiation", "If `b` is an odd exponent, `a^b` can be rewritten as:", "A. `(a^(b/2))^2`", "B. `a * a^(b-1)`", "C. `(a^(b/2))^2 * a`", "D. Both B and C are valid conceptual steps in the algorithm.", "D"
"FastExponentiation", "What is the time complexity of Fast Exponentiation for `a^b`?", "A. O(b)", "B. O(log b)", "C. O(sqrt(b))", "D. O(b log b)", "B"
"FastExponentiation", "What is the space complexity of the iterative Fast Exponentiation algorithm?", "A. O(log b)", "B. O(b)", "C. O(1)", "D. O(N)", "C"
"FastExponentiation", "What is the base case for the recursive Fast Exponentiation function?", "A. If `b` is 0, return 0.", "B. If `b` is 0, return 1.", "C. If `b` is 1, return `a`.", "D. If `b` is negative, return 0.", "B"
"FastExponentiation", "In an iterative Fast Exponentiation implementation, the exponent `b` is typically processed bit by bit. Which bit indicates if the current base (which represents a power of 2) should be multiplied into the result?", "A. The most significant bit.", "B. The least significant bit.", "C. Any bit at random.", "D. Only if the bit is 0.", "B"
"FastExponentiation", "If the current bit of the exponent is 1, what action is taken in the iterative Fast Exponentiation loop?", "A. The base is squared.", "B. The exponent is divided by 2.", "C. The current `result` is multiplied by the current `base`.", "D. The loop terminates.", "C"
"FastExponentiation", "What is `a` continually updated to in each step of the iterative Fast Exponentiation loop (before checking the next bit of the exponent)?", "A. `a + a`", "B. `a * a`", "C. `a / 2`", "D. `a - 1`", "B"
"FastExponentiation", "What is the result of `2^5` using Fast Exponentiation steps?", "A. `2^1 * 2^2 * 2^4`", "B. `(2^2)^2 * 2`", "C. `2 * 2 * 2 * 2 * 2`", "D. `((2^2)^2)^2`", "B"
"FastExponentiation", "Calculate `3^4` using Fast Exponentiation.", "A. `3 * 3 * 3 * 3 = 81`", "B. `(3^2)^2 = 9^2 = 81`", "C. `(3^1)^4 = 81`", "D. `(3^4)` is not suitable for Fast Exponentiation.", "B"
"FastExponentiation", "Can Fast Exponentiation be used to calculate `a^b % m` (Modular Exponentiation)?", "A. No, it only works without modulo.", "B. Yes, by applying the modulo operation at each multiplication step.", "C. Only if `m` is prime.", "D. Only if `b` is small.", "B"
"FastExponentiation", "Which property of modular arithmetic is crucial for Modular Fast Exponentiation: `(X * Y) % M = ((X % M) * (Y % M)) % M`?", "A. True", "B. False", "A"
"FastExponentiation", "What is the initial value of `result` in an iterative Fast Exponentiation implementation?", "A. `0`", "B. `1`", "C. `a`", "D. `b`", "B"
"FastExponentiation", "When performing `a^b % m`, what should be done to the `base` at the very beginning to prevent overflow if `a` is large?", "A. No special handling needed.", "B. `base = base % m`", "C. `base = base / 2`", "D. `base = base + m`", "B"
"FastExponentiation", "What is the main application of Fast Exponentiation in number theory and cryptography?", "A. Finding prime factors.", "B. Solving linear equations.", "C. Implementing primality tests (e.g., Fermat, Miller-Rabin) and Diffie-Hellman/RSA.", "D. Calculating derivatives.", "C"
"FastExponentiation", "If the exponent `b` is negative, how can Fast Exponentiation be adapted for integer results?", "A. It cannot be used for negative exponents.", "B. Compute `a^|b|`, then take its reciprocal (for floating-point or rational results). For modular inverse, it's `(a^(-1))^|b| % m`.", "C. Simply negate the final result.", "D. Add `m` to `b` until it's positive.", "B"
"FastExponentiation", "What is the common bitwise operation used to divide the exponent `b` by 2 in each iteration?", "A. `b & 1`", "B. `b | 1`", "C. `b >> 1`", "D. `b << 1`", "C"
"FastExponentiation", "What is the common bitwise operation used to check if the exponent `b` is odd?", "A. `b & 1`", "B. `b | 1`", "C. `b >> 1`", "D. `b << 1`", "A"
"FastExponentiation", "If `a = 2, b = 3, m = 3`, what is `2^3 % 3` using Modular Fast Exponentiation?", "A. 0", "B. 1", "C. 2", "D. 3", "C"
"FastExponentiation", "For `a^b % m`, if `m = 1`, what is the result?", "A. 1", "B. 0", "C. Undefined", "D. `a`", "B"
"FastExponentiation", "If `b` is a very large number (e.g., `10^18`), which data type should `b` be to avoid overflow in C++/Java?", "A. `int`", "B. `long long`", "C. `short`", "D. `float`", "B"
"FastExponentiation", "When computing `(X * Y) % M`, why is it important to use a larger data type (e.g., `long long` in C++) for the intermediate product `X * Y` before taking the modulo, if `X` and `Y` are already `int` and `M` is also large?", "A. To make the code compile faster.", "B. To avoid overflow of the intermediate product `X * Y` if it exceeds the max value of `int`.", "C. It's only for aesthetic purposes.", "D. To reduce memory usage.", "B"
"FastExponentiation", "What is `(-3)^3 % 5` using modular fast exponentiation?", "A. `((-3 % 5)^3 % 5) = (2^3 % 5) = 8 % 5 = 3`", "B. `(-27 % 5) = 3`", "C. Both A and B give 3.", "D. 2", "C"
"FastExponentiation", "Fast Exponentiation can be extended to matrices. True or False?", "A. True (Matrix Exponentiation for problems like Fibonacci numbers).", "B. False", "A"
"FastExponentiation", "What is the primary advantage of Fast Exponentiation over repeated multiplication for calculating `a^b`?", "A. Uses less memory.", "B. Significantly reduces the number of multiplications, leading to faster computation for large exponents.", "C. Always produces an exact integer result.", "D. Simplifies the code.", "B"
"FastExponentiation", "Is Fast Exponentiation also known as 'binary squaring'?", "A. Yes, it's another common term.", "B. No, it's unrelated.", "C. Only in specific contexts.", "D. Only for binary bases.", "A"
"FastExponentiation", "If `exponent = 1`, what is the outcome of the iterative loop?", "A. The loop doesn't run.", "B. The loop runs once, `result` becomes `base`, `exponent` becomes 0, and then it terminates.", "C. It results in an infinite loop.", "D. It returns 0.", "B"
"FastExponentiation", "How does the recursive version of Fast Exponentiation handle the odd exponent case?", "A. `return a * pow(a, b-1)`", "B. `return a * pow(a*a, (b-1)/2)`", "C. `return a * pow(a*a, b/2)`", "D. `return a + pow(a, b-1)`", "C"
"FastExponentiation", "Which of the following is NOT directly a use case for Fast Exponentiation?", "A. Calculating `pow(x, y)` in general programming.", "B. Finding modular inverse using Fermat's Little Theorem (for prime moduli).", "C. Solving systems of linear equations.", "D. Generating pseudorandom numbers in some PRNGs.", "C"
"FastExponentiation", "The term 'exponentiation by squaring' implies that the algorithm uses the binary representation of the exponent. True or False?", "A. True", "B. False", "A"
"FastExponentiation", "What is `1^b` for any positive integer `b`?", "A. `b`", "B. `0`", "C. `1`", "D. `Undefined`", "C"
"FastExponentiation", "If `base = 0` and `exponent > 0`, what is the result of `0^exponent`?", "A. `1`", "B. `0`", "C. `Undefined`", "D. `exponent`", "B"
"FastExponentiation", "If `base = 0` and `exponent = 0`, what is the result of `0^0`? (Conventionally 1 in many contexts)", "A. `0`", "B. `1`", "C. `Undefined`", "D. `Depends on context`", "B"
"FastExponentiation", "The `result` variable accumulates the product of bases corresponding to which bits of the exponent?", "A. Only odd bits.", "B. Only even bits.", "C. The '1' bits in the exponent's binary representation.", "D. All bits.", "C"
"FastExponentiation", "Consider `a=5, b=2`. How many multiplications does Fast Exponentiation perform (ignoring modulo)?", "A. 1 (5*5)", "B. 2 (5*5 then 25*1)", "C. 3 (5*5, then 5^2*5^2, then pick one)", "D. 4", "A"
"FastExponentiation", "Consider `a=2, b=7`. Binary of 7 is 111. Iterations: 1. b=1, res=2, base=4. 2. b=1, res=2*4=8, base=16. 3. b=1, res=8*16=128, base=256. This calculation path is correct. True or False?", "A. True", "B. False (the base is squared in each step regardless of the bit, result is updated only if bit is 1).", "B"
"FastExponentiation", "A more accurate trace for `a=2, b=7`: `res=1, base=2`. `b=7 (odd)` -> `res = 1*2 = 2`. `base = 2*2 = 4`. `b=3`. `b=3 (odd)` -> `res = 2*4 = 8`. `base = 4*4 = 16`. `b=1`. `b=1 (odd)` -> `res = 8*16 = 128`. `base = 16*16 = 256`. `b=0`. Loop ends. Result 128. True or False?", "A. True", "B. False", "A"
"FastExponentiation", "The term 'Fast Exponentiation' is synonymous with 'Modular Exponentiation'. True or False?", "A. False (Fast Exponentiation is the algorithm, Modular Exponentiation is the application with modulo).", "B. True", "A"
"FastExponentiation", "Which of the following problems can *not* be solved by matrix exponentiation (an extension of Fast Exponentiation)?", "A. Finding the Nth Fibonacci number.", "B. Counting paths of length K in a graph.", "C. Determining if a graph is planar.", "D. Solving linear recurrence relations.", "C"
"FastExponentiation", "Does the efficiency of Fast Exponentiation depend on the size of the base `a`?", "A. Yes, larger `a` means more operations.", "B. No, only the exponent `b` affects the number of multiplications.", "C. Only if `a` is prime.", "D. Only if `a` is odd.", "B"
"FastExponentiation", "The core idea of Fast Exponentiation can be applied to any associative operation, not just multiplication. True or False?", "A. True (e.g., matrix multiplication, function composition).", "B. False", "A"
"FastExponentiation", "If `base` is large but `modulus` is small, using Fast Exponentiation (with modulo at each step) is more important for:", "A. Speed.", "B. Preventing intermediate overflow.", "C. Accuracy.", "D. Simplicity.", "B"
"FastExponentiation", "In C++, the `std::pow()` function typically uses Fast Exponentiation for integer types. True or False?", "A. False, `std::pow` is primarily for floating-point numbers and doesn't guarantee integer fast exponentiation. Custom implementation is needed for integer types or modular arithmetic.", "B. True", "A"
"FastExponentiation", "What is the value of `2^10 % 10`?", "A. 0", "B. 2", "C. 4", "D. 6", "C"
"FastExponentiation", "The `log b` complexity comes from the fact that the exponent `b` is reduced by half in each step. True or False?", "A. True", "B. False", "A"
"FastExponentiation", "If the exponent `b` is 0, the result is `1`. This is because `x^0 = 1` for any non-zero `x`. How is `0^0` usually handled in this context?", "A. As 0.", "B. As 1 (by convention in many programming contexts and discrete math).", "C. As undefined.", "D. As infinity.", "B"
"BitManipulation", "What is a 'bit' in computer science?", "A. A unit of data representing a single digit in a binary number (0 or 1).", "B. A small piece of code.", "C. A logical operation.", "D. A character in a string.", "A"
"BitManipulation", "Which of the following is the bitwise AND operator in C++/Java?", "A. `|`", "B. `&`", "C. `^`", "D. `~`", "B"
"BitManipulation", "What is the result of `5 & 3` (binary: `101 & 011`)?", "A. 1 (binary `001`)", "B. 3 (binary `011`)", "C. 5 (binary `101`)", "D. 7 (binary `111`)", "A"
"BitManipulation", "Which of the following is the bitwise OR operator in C++/Java?", "A. `|`", "B. `&`", "C. `^`", "D. `~`", "A"
"BitManipulation", "What is the result of `5 | 3` (binary: `101 | 011`)?", "A. 1 (binary `001`)", "B. 3 (binary `011`)", "C. 5 (binary `101`)", "D. 7 (binary `111`)", "D"
"BitManipulation", "Which of the following is the bitwise XOR operator in C++/Java?", "A. `|`", "B. `&`", "C. `^`", "D. `~`", "C"
"BitManipulation", "What is the result of `5 ^ 3` (binary: `101 ^ 011`)?", "A. 1 (binary `001`)", "B. 2 (binary `010`)", "C. 6 (binary `110`)", "D. 7 (binary `111`)", "C"
"BitManipulation", "Which of the following is the bitwise NOT (complement) operator in C++/Java?", "A. `|`", "B. `&`", "C. `^`", "D. `~`", "D"
"BitManipulation", "What does `~5` typically represent (assuming a 32-bit signed integer)?", "A. -5", "B. 4", "C. -6 (two's complement representation)", "D. 6", "C"
"BitManipulation", "What is the left shift operator in C++/Java?", "A. `>>`", "B. `<<`", "C. `>>>`", "D. `<<<`", "B"
"BitManipulation", "What is the result of `5 << 1` (binary `101 << 1`)?", "A. 2 (binary `010`)", "B. 6 (binary `110`)", "C. 10 (binary `1010`)", "D. 12 (binary `1100`)", "C"
"BitManipulation", "What is the right shift operator in C++/Java?", "A. `>>`", "B. `<<`", "C. `>>>`", "D. `<<<`", "A"
"BitManipulation", "What is the result of `10 >> 1` (binary `1010 >> 1`)?", "A. 2 (binary `010`)", "B. 4 (binary `100`)", "C. 5 (binary `101`)", "D. 10 (binary `1010`)", "C"
"BitManipulation", "How do you check if the `k`-th bit (0-indexed from right) of a number `n` is set (1)?", "A. `(n | (1 << k))`", "B. `(n & (1 << k)) != 0`", "C. `(n ^ (1 << k)) == 0`", "D. `(n >> k) == 1`", "B"
"BitManipulation", "How do you set (turn to 1) the `k`-th bit of a number `n`?", "A. `(n & ~(1 << k))`", "B. `(n | (1 << k))`", "C. `(n ^ (1 << k))`", "D. `(n << k)`", "B"
"BitManipulation", "How do you clear (turn to 0) the `k`-th bit of a number `n`?", "A. `(n & ~(1 << k))`", "B. `(n | (1 << k))`", "C. `(n ^ (1 << k))`", "D. `(n >> k)`", "A"
"BitManipulation", "How do you toggle (flip) the `k`-th bit of a number `n`?", "A. `(n & ~(1 << k))`", "B. `(n | (1 << k))`", "C. `(n ^ (1 << k))`", "D. `(n >> k)`", "C"
"BitManipulation", "What is the property of XOR that makes it useful for swapping two numbers without a temporary variable (`a = a ^ b; b = a ^ b; a = a ^ b;`)?", "A. Associativity.", "B. Commutativity.", "C. `x ^ x = 0` and `x ^ 0 = x`.", "D. Distributivity.", "C"
"BitManipulation", "What does `n & (n - 1)` do?", "A. Checks if `n` is even.", "B. Clears the least significant set bit (rightmost 1) of `n`.", "C. Sets the least significant bit of `n`.", "D. Checks if `n` is a power of 2.", "B"
"BitManipulation", "How do you check if a number `n` is a power of 2 (assuming `n > 0`)?", "A. `(n & 1) == 0`", "B. `(n & (n - 1)) == 0`", "C. `(n | (n - 1)) == n`", "D. `(n >> 1) == 0`", "B"
"BitManipulation", "What is the purpose of `count set bits` (population count)?", "A. To count the total number of bits in a number.", "B. To count the number of '1' bits in the binary representation of a number.", "C. To count the number of '0' bits in a number.", "D. To count leading zeros.", "B"
"BitManipulation", "Which built-in function (in C++ or Java) can be used for counting set bits?", "A. `__builtin_popcount()` (C++), `Integer.bitCount()` (Java).", "B. `__builtin_count()`", "C. `__builtin_setbits()`", "D. `count_ones()`", "A"
"BitManipulation", "How can you turn off the rightmost set bit of a number `n`?", "A. `n | (n - 1)`", "B. `n & (n - 1)`", "C. `n ^ (n - 1)`", "D. `n + 1`", "B"
"BitManipulation", "How can you find the `k`-th bit from the right of a number `n` (0-indexed)?", "A. `(n >> k) & 1`", "B. `(n << k) & 1`", "C. `(n & k)`", "D. `(n | k)`", "A"
"BitManipulation", "What is a 'mask' in bit manipulation?", "A. A value used to hide certain bits.", "B. A value used to isolate, set, or clear specific bits.", "C. A cryptographic key.", "D. A type of data structure.", "B"
"BitManipulation", "To check if a number `n` is odd, which bitwise operation is most efficient?", "A. `(n % 2) == 1`", "B. `(n & 1) == 1`", "C. `(n / 2) != 0`", "D. `(n ^ 1) == (n + 1)`", "B"
"BitManipulation", "What is `~0` (bitwise NOT of 0) in a typical 32-bit signed integer system?", "A. 0", "B. 1", "C. -1 (all bits set to 1, which is -1 in two's complement)", "D. `Integer.MAX_VALUE`", "C"
"BitManipulation", "If you want to swap the values of two integers `a` and `b` without using a temporary variable, using XOR is effective. What is the three-step sequence?", "A. `a=b; b=a;`", "B. `a=a^b; b=a^b; a=a^b;`", "C. `a=a+b; b=a-b; a=a-b;`", "D. `a=a*b; b=a/b; a=a/b;`", "B"
"BitManipulation", "What does `(x >> k) & 1` achieve?", "A. Shifts `x` right by `k` positions and then checks if the least significant bit is 1.", "B. Shifts `x` left by `k` positions and checks if the most significant bit is 1.", "C. Checks if `x` is divisible by `2^k`.", "D. Sets the `k`-th bit of `x`.", "A"
"BitManipulation", "What is the typical use of bit masks in competitive programming?", "A. To hide data.", "B. To represent subsets of items or states in dynamic programming.", "C. To encrypt strings.", "D. To draw graphics.", "B"
"BitManipulation", "The bitwise `~` operator (complement) results in what in two's complement arithmetic?", "A. `-(x+1)`", "B. `x-1`", "C. `x+1`", "D. `x`", "A"
"BitManipulation", "What is `(1 << k)` useful for?", "A. Multiplying by `k`.", "B. Creating a number with only the `k`-th bit set (a mask).", "C. Dividing by `k`.", "D. Converting `k` to binary.", "B"
"BitManipulation", "To get the absolute value of an integer `n` using bit manipulation (and assuming two's complement, `n` is not `Integer.MIN_VALUE`):", "A. `(n ^ (n >> 31)) - (n >> 31)`", "B. `n & (n >> 31)`", "C. `n | (n >> 31)`", "D. `n + 1`", "A"
"BitManipulation", "How can you find the position of the least significant set bit (LSB) of `n`?", "A. `__builtin_ctz()` (C++), `Integer.numberOfTrailingZeros()` (Java).", "B. `__builtin_clz()`", "C. `__builtin_popcount()`", "D. `Integer.lowestSetBit()`", "A"
"BitManipulation", "What does `__builtin_clz(n)` (count leading zeros) or `Integer.numberOfLeadingZeros(n)` do?", "A. Counts trailing zeros.", "B. Counts leading zeros in the binary representation of `n`.", "C. Counts set bits.", "D. Counts total bits.", "B"
"BitManipulation", "Bit manipulation is typically faster than arithmetic operations (like multiplication or division) involving powers of 2. True or False?", "A. True", "B. False", "A"
"BitManipulation", "Which operator is typically used to extract a specific range of bits?", "A. `|` followed by `&`", "B. `&` with a crafted mask and then `>>`", "C. `^` only", "D. `~` only", "B"
"BitManipulation", "If `n` is `01011000` (binary), what is `n & (n - 1)`?", "A. `01010000` (clears the rightmost 1)", "B. `01011111`", "C. `00001000`", "D. `01011000`", "A"
"BitManipulation", "To clear all bits from the most significant bit (MSB) down to the `k`-th bit (inclusive) of `n` (leaving bits 0 to `k-1`), you can use:", "A. `n & ((1 << k) - 1)`", "B. `n | ((1 << k) - 1)`", "C. `n ^ ((1 << k) - 1)`", "D. `n >> k`", "A"
"BitManipulation", "What does `n & (-n)` yield in two's complement?", "A. The value of `n`.", "B. The largest power of 2 that divides `n` (the LSB mask).", "C. The negation of `n`.", "D. 0.", "B"
"BitManipulation", "Can bit manipulation be used to efficiently multiply a number by 4?", "A. No, only addition.", "B. Yes, `n << 2`.", "C. Yes, `n >> 2`.", "D. Yes, `n & 4`.", "B"
"BitManipulation", "Can bit manipulation be used to efficiently divide a number by 8?", "A. No, only multiplication.", "B. Yes, `n >> 3`.", "C. Yes, `n << 3`.", "D. Yes, `n | 8`.", "B"
"BitManipulation", "What is the result of `~(~x)`?", "A. 0", "B. -x", "C. x", "D. 1", "C"
"BitManipulation", "To count the number of trailing zeros in a binary representation of `n`:", "A. `__builtin_ctz()`", "B. `__builtin_clz()`", "C. `__builtin_popcount()`", "D. `__builtin_parity()`", "A"
"BitManipulation", "What does `__builtin_parity(n)` do in C++?", "A. Checks if `n` is even.", "B. Checks if `n` is odd.", "C. Returns 1 if the number of set bits in `n` is odd, and 0 if it's even.", "D. Returns 1 if `n` is negative, 0 otherwise.", "C"
"BitManipulation", "Bit manipulation is most effective when dealing with integers as sequences of bits. True or False?", "A. True", "B. False", "A"
"BitManipulation", "What is the primary benefit of using bit manipulation in competitive programming?", "A. It makes code shorter.", "B. It often leads to highly optimized and faster code for certain operations.", "C. It avoids using loops.", "D. It's easier to debug.", "B"
"BitManipulation", "Consider two integers `a` and `b`. Which operation will yield a number where bits are set only if they are set in `a` AND `b`?", "A. `a | b`", "B. `a & b`", "C. `a ^ b`", "D. `~a`", "B"
"BitManipulation", "If you want to clear the `k`-th bit and all subsequent bits (from `k` to MSB) in a number `n`, which mask would you typically use?", "A. `(1 << k) - 1` (to keep lower bits)", "B. `~( (1 << (k+1)) - 1 )` (to clear upper bits)", "C. `1 << k`", "D. `~0`", "A"
"BitManipulation", "The bitwise `XOR` operator can be used to find the unique number in an array where all other numbers appear twice. True or False?", "A. True", "B. False", "A"
"BitManipulation", "In Java, what is the difference between `>>` and `>>>` for right shift?", "A. No difference.", "B. `>>` is arithmetic right shift (sign-extended), `>>>` is logical right shift (zero-filled).", "C. `>>` is logical, `>>>` is arithmetic.", "D. `>>>` is left shift.", "B"
"DivideAndConquer", "What is the core principle of the Divide and Conquer paradigm?", "A. To solve a problem by iterating through all possible solutions.", "B. To break down a problem into smaller, independent subproblems of the same type, solve them recursively, and combine their solutions.", "C. To greedily make the best choice at each step.", "D. To store and reuse solutions to overlapping subproblems.", "B"
"DivideAndConquer", "The three main steps of a Divide and Conquer algorithm are:", "A. Initialize, Iterate, Terminate", "B. Divide, Conquer, Combine", "C. Explore, Exploit, Evaluate", "D. Read, Process, Write", "B"
"DivideAndConquer", "In the 'Divide' step, the problem is:", "A. Solved directly.", "B. Broken into smaller subproblems.", "C. Combined with other problems.", "D. Optimized for space.", "B"
"DivideAndConquer", "In the 'Conquer' step, the subproblems are:", "A. Ignored.", "B. Solved recursively.", "C. Merged.", "D. Analyzed for complexity.", "B"
"DivideAndConquer", "In the 'Combine' step, the solutions to subproblems are:", "A. Discarded.", "B. Used to form the solution to the original problem.", "C. Re-evaluated.", "D. Stored in a hash table.", "B"
"DivideAndConquer", "Which of the following sorting algorithms is a classic example of Divide and Conquer?", "A. Bubble Sort", "B. Insertion Sort", "C. Merge Sort", "D. Selection Sort", "C"
"DivideAndConquer", "Which of the following sorting algorithms is also a classic example of Divide and Conquer?", "A. Counting Sort", "B. Quick Sort", "C. Radix Sort", "D. Heap Sort", "B"
"DivideAndConquer", "What is the time complexity of Merge Sort in the worst case?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(log N)", "B"
"DivideAndConquer", "What is the worst-case time complexity of Quick Sort?", "A. O(N log N)", "B. O(N^2)", "C. O(N)", "D. O(log N)", "B"
"DivideAndConquer", "Why is Quick Sort often faster than Merge Sort in practice, despite having a worst-case O(N^2) complexity?", "A. It uses less memory.", "B. It has a smaller constant factor in its average-case O(N log N) complexity, and its inner loop is highly optimized.", "C. It avoids recursion.", "D. It is always stable.", "B"
"DivideAndConquer", "Binary Search is an example of which algorithmic paradigm?", "A. Greedy", "B. Dynamic Programming", "C. Divide and Conquer", "D. Brute Force", "C"
"DivideAndConquer", "What is the time complexity of Binary Search?", "A. O(N)", "B. O(log N)", "C. O(N log N)", "D. O(1)", "B"
"DivideAndConquer", "The Master Theorem is used to analyze the time complexity of which type of algorithms?", "A. Iterative algorithms.", "B. Recursive algorithms, particularly those following Divide and Conquer patterns.", "C. Greedy algorithms.", "D. Dynamic programming algorithms.", "B"
"DivideAndConquer", "What is the recurrence relation for Merge Sort?", "A. T(N) = T(N-1) + O(1)", "B. T(N) = 2T(N/2) + O(N)", "C. T(N) = T(N-1) + O(N)", "D. T(N) = 2T(N/2) + O(1)", "B"
"DivideAndConquer", "The Strassen's algorithm for matrix multiplication uses Divide and Conquer. What is its time complexity (approximately)?", "A. O(N^3)", "B. O(N^2)", "C. O(N^log2(7)) ≈ O(N^2.81)", "D. O(N log N)", "C"
"DivideAndConquer", "When does a Divide and Conquer algorithm terminate its recursion?", "A. When the subproblems are large.", "B. When the subproblems become base cases (small enough to be solved directly).", "C. After a fixed number of steps.", "D. When an optimal solution is found.", "B"
"DivideAndConquer", "What is a potential disadvantage of recursive Divide and Conquer algorithms?", "A. They always use less memory.", "B. They can lead to high stack memory usage due to deep recursion.", "C. They are always slower than iterative solutions.", "D. They cannot be parallelized.", "B"
"DivideAndConquer", "Karatsuba algorithm for fast multiplication of large integers is an example of:", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Divide and Conquer", "D. Brute Force", "C"
"DivideAndConquer", "What is the time complexity of Karatsuba algorithm for multiplying two N-digit numbers?", "A. O(N^2)", "B. O(N^(log2 3)) ≈ O(N^1.585)", "C. O(N log N)", "D. O(N)", "B"
"DivideAndConquer", "Searching for the maximum/minimum element in an array can be done efficiently using Divide and Conquer. True or False?", "A. True", "B. False", "A"
"DivideAndConquer", "Finding the Kth smallest element (Selection Problem) can be efficiently solved using a Divide and Conquer approach similar to Quick Sort (Quickselect). True or False?", "A. True", "B. False", "A"
"DivideAndConquer", "Which of the following is NOT a characteristic of problems typically solved by Divide and Conquer?", "A. They can be broken into similar subproblems.", "B. Subproblems are often independent.", "C. Overlapping subproblems are common (leading to inefficiency without memoization).", "D. Base cases are easily solvable.", "C"
"DivideAndConquer", "If a problem has overlapping subproblems, which paradigm is generally more efficient than a naive Divide and Conquer?", "A. Greedy Algorithms", "B. Dynamic Programming", "C. Brute Force", "D. Backtracking", "B"
"DivideAndConquer", "The Tower of Hanoi puzzle is a classic example illustrating which algorithmic paradigm?", "A. Greedy", "B. Dynamic Programming", "C. Divide and Conquer (recursive solution)", "D. Backtracking", "C"
"DivideAndConquer", "What is the recurrence relation for the Tower of Hanoi puzzle with `N` disks?", "A. T(N) = T(N-1) + 1", "B. T(N) = 2T(N-1) + 1", "C. T(N) = T(N/2) + 1", "D. T(N) = N^2", "B"
"DivideAndConquer", "Counting inversions in an array can be efficiently done by modifying which Divide and Conquer algorithm?", "A. Quick Sort", "B. Merge Sort", "C. Bubble Sort", "D. Insertion Sort", "B"
"DivideAndConquer", "The time complexity of finding closest pair of points in a plane can be solved using Divide and Conquer with a complexity of:", "A. O(N^2)", "B. O(N log N)", "C. O(N)", "D. O(N log^2 N)", "B"
"DivideAndConquer", "What is the primary benefit of Divide and Conquer in terms of parallelization?", "A. It inherently allows subproblems to be solved in parallel.", "B. It always runs on a single core.", "C. It simplifies debugging for sequential execution.", "D. It reduces memory consumption.", "A"
"DivideAndConquer", "A common way to implement Divide and Conquer algorithms is through:", "A. Iteration using loops.", "B. Recursion.", "C. Memoization.", "D. Dynamic programming tables.", "B"
"DivideAndConquer", "When designing a Divide and Conquer algorithm, it's important that the subproblems are:", "A. Completely different from the original problem.", "B. Of the same type as the original problem, just smaller instances.", "C. Solvable by brute force only.", "D. Independent of each other.", "B"
"DivideAndConquer", "The recursive calls in a Divide and Conquer algorithm form what kind of structure?", "A. A linear list.", "B. A tree structure (recursion tree).", "C. A graph with cycles.", "D. A hash table.", "B"
"DivideAndConquer", "The 'median of medians' algorithm for finding the k-th smallest element has a worst-case time complexity of:", "A. O(N^2)", "B. O(N log N)", "C. O(N)", "D. O(log N)", "C"
"DivideAndConquer", "Does the quicksort algorithm always divide the array into roughly equal halves?", "A. Yes, always.", "B. No, the partition depends on the pivot choice, which can lead to unbalanced partitions in the worst case.", "C. Only for sorted arrays.", "D. Only for random arrays.", "B"
"DivideAndConquer", "The space complexity of Merge Sort (not in-place) is generally:", "A. O(1)", "B. O(log N)", "C. O(N) (for the auxiliary array in the merge step).", "D. O(N^2)", "C"
"DivideAndConquer", "The space complexity of Quick Sort (recursive) is generally:", "A. O(1)", "B. O(log N) on average (due to recursion stack depth).", "C. O(N) in worst case (due to recursion stack depth).", "D. Both B and C are correct depending on the case.", "D"
"DivideAndConquer", "Can Divide and Conquer be used for integer factorization problems?", "A. Yes, trial division is a form of D&C.", "B. Yes, certain algorithms like Pollard's Rho or Shor's algorithm use D&C principles.", "C. No, factorization is a different paradigm.", "D. Only for prime numbers.", "B"
"DivideAndConquer", "Solving convex hull problems can sometimes utilize a Divide and Conquer approach. True or False?", "A. True", "B. False", "A"
"DivideAndConquer", "The problem of finding a majority element in an array (an element that appears more than N/2 times) can be solved using Divide and Conquer (e.g., Boyer-Moore Voting Algorithm concept). True or False?", "A. True", "B. False", "A"
"DivideAndConquer", "What type of problem structure often suggests a Divide and Conquer approach?", "A. Problems with optimal substructure and overlapping subproblems.", "B. Problems that can be reduced to smaller instances of the same problem.", "C. Problems that can be solved by making locally optimal choices.", "D. Problems that require exhaustive search.", "B"
"DivideAndConquer", "The solution to a Divide and Conquer recurrence `T(N) = aT(N/b) + f(N)` using the Master Theorem depends on comparing `f(N)` with:", "A. `N^(log_b a)`", "B. `log_b a`", "C. `N * f(N)`", "D. `a * b`", "A"
"DivideAndConquer", "Which of the following is typically a small constant in the base case of a Divide and Conquer algorithm?", "A. `N`", "B. `0` or `1` (for problem size).", "C. `log N`", "D. `N^2`", "B"
"DivideAndConquer", "Is it always beneficial to use Divide and Conquer for every recursive problem?", "A. Yes, always.", "B. No, sometimes overhead of recursion or combining solutions can outweigh benefits for small problems or overlapping subproblems.", "C. Only for problems with O(log N) complexity.", "D. Only for very large problems.", "B"
"DivideAndConquer", "The classic algorithm for multiplying two N-bit binary numbers, which involves dividing them into two N/2-bit halves, is an example of:", "A. Brute Force", "B. Divide and Conquer", "C. Greedy", "D. Dynamic Programming", "B"
"DivideAndConquer", "In a Divide and Conquer algorithm, the subproblems are typically of what size compared to the original problem?", "A. Larger.", "B. Equal.", "C. Smaller.", "D. Unrelated.", "C"
"DivideAndConquer", "The merge step in Merge Sort requires `O(N)` time because:", "A. It involves sorting the subarrays.", "B. It involves iterating through both sorted subarrays once to combine them.", "C. It involves recursive calls.", "D. It is a constant time operation.", "B"
"DivideAndConquer", "The partition step in Quick Sort (Hoare's or Lomuto's) takes `O(N)` time because:", "A. It involves recursive calls.", "B. It iterates through the array once to rearrange elements around the pivot.", "C. It sorts the array.", "D. It's a constant time operation.", "B"
"DivideAndConquer", "Can Divide and Conquer be used to find the maximum subarray sum?", "A. Yes, Kadane's algorithm is a D&C approach.", "B. Yes, there's a specific D&C algorithm that splits the array and handles crossing subarrays.", "C. No, only dynamic programming.", "D. Only for sorted arrays.", "B"
"DivideAndConquer", "Is Divide and Conquer always faster than iterative approaches for the same problem?", "A. Yes, always.", "B. No, sometimes the overhead of recursion makes iterative approaches faster, especially for small inputs.", "C. Only for sorting problems.", "D. Only for search problems.", "B"
"DivideAndConquer", "What does 'optimal substructure' mean in the context of Divide and Conquer?", "A. That the optimal solution to a problem can be constructed from optimal solutions to its subproblems.", "B. That the problem can be solved by making a sequence of locally optimal choices.", "C. That the problem has many overlapping subproblems.", "D. That the problem can be represented as a graph.", "A"
"DivideAndConquer", "While Divide and Conquer problems often have optimal substructure, if they also have **overlapping subproblems**, what technique is typically combined with D&C to optimize performance?", "A. Brute force.", "B. Memoization or Dynamic Programming.", "C. Greedy choice.", "D. Randomization.", "B"
"MergeSort", "What algorithmic paradigm does Merge Sort fall under?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Divide and Conquer", "D. Brute Force", "C"
"MergeSort", "Merge Sort works by recursively breaking down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. This describes the _______ step.", "A. Combine", "B. Conquer", "C. Divide", "D. Base Case", "C"
"MergeSort", "What is the second main step in Merge Sort, where sub-problems are solved recursively?", "A. Divide", "B. Conquer", "C. Combine", "D. Base Case", "B"
"MergeSort", "What is the third and final main step in Merge Sort, where solutions to sub-problems are built up to solve the original problem?", "A. Divide", "B. Conquer", "C. Combine (or Merge)", "D. Base Case", "C"
"MergeSort", "What is the base case for the Merge Sort recursion?", "A. When the array size is 0.", "B. When the array size is 1 (or 0 and 1).", "C. When the array is fully sorted.", "D. When the array contains duplicate elements.", "B"
"MergeSort", "What is the time complexity of Merge Sort in the best case?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(log N)", "B"
"MergeSort", "What is the time complexity of Merge Sort in the average case?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(log N)", "B"
"MergeSort", "What is the time complexity of Merge Sort in the worst case?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(log N)", "B"
"MergeSort", "The `O(N)` factor in Merge Sort's time complexity comes from which step?", "A. The division of the array.", "B. The recursive calls.", "C. The merging (combine) step.", "D. The base case handling.", "C"
"MergeSort", "What is the space complexity of Merge Sort (non-in-place implementation)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N^2)", "C"
"MergeSort", "Why does Merge Sort typically require O(N) auxiliary space?", "A. For the recursion stack.", "B. For the temporary array used in the merge operation.", "C. For storing input elements.", "D. It doesn't require auxiliary space.", "B"
"MergeSort", "Is Merge Sort a stable sorting algorithm?", "A. Yes", "B. No", "C. Sometimes", "D. Only for small arrays", "A"
"MergeSort", "What does 'stable' mean in the context of sorting algorithms?", "A. Elements with equal values maintain their relative order in the sorted output.", "B. The algorithm's performance is consistent regardless of input.", "C. It uses a fixed amount of memory.", "D. It guarantees the same output for the same input.", "A"
"MergeSort", "Merge Sort is typically implemented using:", "A. Iteration only.", "B. Recursion.", "C. A combination of iteration and direct loops.", "D. Hash tables.", "B"
"MergeSort", "What is the recurrence relation that describes the time complexity of Merge Sort?", "A. T(N) = T(N-1) + O(1)", "B. T(N) = 2T(N/2) + O(N)", "C. T(N) = T(N-1) + O(N)", "D. T(N) = T(N/2) + O(1)", "B"
"MergeSort", "In the recurrence T(N) = 2T(N/2) + O(N), what does `2T(N/2)` represent?", "A. The time taken to merge two subarrays.", "B. The time taken to solve two subproblems of half the size.", "C. The time taken to divide the array.", "D. The base case time.", "B"
"MergeSort", "Which of the following is an advantage of Merge Sort over Quick Sort?", "A. It has better average-case performance.", "B. It is an in-place sorting algorithm.", "C. It guarantees O(N log N) worst-case time complexity.", "D. It is easier to implement.", "C"
"MergeSort", "Which of the following is a disadvantage of Merge Sort compared to Quick Sort?", "A. Higher worst-case time complexity.", "B. Typically requires O(N) auxiliary space.", "C. Not a stable sort.", "D. More complex to implement.", "B"
"MergeSort", "Can Merge Sort be easily parallelized?", "A. No, it's inherently sequential.", "B. Yes, the independent sub-problems can be sorted in parallel, and merging can also be parallelized to some extent.", "C. Only for very small arrays.", "D. Only if implemented iteratively.", "B"
"MergeSort", "If an array has 7 elements, how many times will the array be split (recursively) until individual elements are reached?", "A. 1", "B. 2", "C. 3 (log2(7) rounds up to 3 for splitting to single elements)", "D. 7", "C"
"MergeSort", "The merge operation takes two _______ lists and combines them into one _______ list.", "A. Unsorted, sorted", "B. Sorted, unsorted", "C. Sorted, sorted", "D. Unsorted, unsorted", "C"
"MergeSort", "What is the maximum recursion depth for Merge Sort on an array of size N?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"MergeSort", "When is Merge Sort a good choice of sorting algorithm?", "A. When memory is extremely limited.", "B. When worst-case performance guarantees are critical (e.g., real-time systems).", "C. When the data is almost sorted.", "D. When the input size is very small.", "B"
"MergeSort", "How does Merge Sort handle arrays that are already sorted?", "A. It sorts them in O(N) time.", "B. It still performs the full O(N log N) operations for splitting and merging.", "C. It becomes O(N^2).", "D. It swaps elements in place.", "B"
"MergeSort", "The process of combining two sorted sub-arrays is done by comparing elements from the beginning of both arrays and placing the smaller one into a temporary array. True or False?", "A. True", "B. False", "A"
"MergeSort", "What happens if one of the sub-arrays being merged becomes empty?", "A. The merging process stops.", "B. All remaining elements from the other (non-empty) sub-array are copied directly to the result.", "C. The algorithm crashes.", "D. It indicates an error in the sort.", "B"
"MergeSort", "Merge Sort is often used as a basis for external sorting. Why?", "A. Because it's an in-place sort.", "B. Because it effectively sorts large datasets that don't fit into memory by processing chunks.", "C. Because it's very fast for small inputs.", "D. Because it has low recursion depth.", "B"
"MergeSort", "Which common data structure is generally suited for Merge Sort?", "A. Linked Lists (due to efficient merging without extra space for linking, compared to arrays).", "B. Hash Tables", "C. Stacks", "D. Queues", "A"
"MergeSort", "If you implement Merge Sort for linked lists, what is the space complexity?", "A. O(1) (if links are rearranged directly).", "B. O(N) (for auxiliary pointers).", "C. O(log N) (for recursion stack).", "D. O(N log N)", "A"
"MergeSort", "A 'bottom-up' Merge Sort implementation typically uses what instead of explicit recursion?", "A. A loop to merge increasingly larger subarrays.", "B. A stack to manage recursion.", "C. A queue for elements.", "D. A hash map for visited nodes.", "A"
"MergeSort", "What is an advantage of bottom-up Merge Sort over top-down (recursive)?", "A. It uses less memory for the recursion stack.", "B. It's always faster.", "C. It's simpler to implement.", "D. It becomes an in-place sort.", "A"
"MergeSort", "What is the main idea behind 'in-place' Merge Sort variations?", "A. To eliminate the need for an auxiliary array during merging, often by complex element rotations.", "B. To sort the array in reverse order.", "C. To use a hash table for sorting.", "D. To avoid any comparisons.", "A"
"MergeSort", "Are in-place Merge Sort variations commonly used in practice?", "A. Yes, they are the standard.", "B. No, they are often significantly more complex and slower than the standard O(N) space version.", "C. Only for very small arrays.", "D. Only for specific data types.", "B"
"MergeSort", "If you use Merge Sort to sort an array of `N` objects, what comparison method does it rely on?", "A. Hashing the objects.", "B. Direct equality check.", "C. A custom comparison function or natural ordering.", "D. Bitwise operations.", "C"
"MergeSort", "Merge Sort is a comparison sort. True or False?", "A. True", "B. False", "A"
"MergeSort", "Can Merge Sort be used to count inversions in an array?", "A. No, it's not possible.", "B. Yes, by modifying the merge step to count pairs that are out of order.", "C. Only if the array is already sorted.", "D. Only for small arrays.", "B"
"MergeSort", "How many comparisons does Merge Sort make in the worst case?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(log N)", "B"
"MergeSort", "The 'divide' step in Merge Sort does minimal work. True or False?", "A. True (it's mostly just calculating midpoints).", "B. False", "A"
"MergeSort", "For very small subarrays (e.g., size < 7), some Merge Sort implementations switch to Insertion Sort. Why?", "A. Insertion Sort has better worst-case complexity for small inputs.", "B. Insertion Sort has lower constant factors for small inputs, making it faster due to less overhead.", "C. Insertion Sort uses less memory.", "D. Insertion Sort is stable.", "B"
"MergeSort", "Is Merge Sort a good choice for sorting data stored in a linked list?", "A. No, Quick Sort is better.", "B. Yes, because splitting and merging linked lists can be done efficiently without excessive copying.", "C. Only if the list is small.", "D. Only if the list is unsorted.", "B"
"MergeSort", "What is the primary factor limiting Merge Sort's use in memory-constrained environments?", "A. Its O(N log N) time complexity.", "B. Its recursive nature and stack usage.", "C. Its O(N) auxiliary space requirement.", "D. Its instability.", "C"
"MergeSort", "If an array has duplicate elements, how does Merge Sort handle them while maintaining stability?", "A. It swaps them to preserve order.", "B. Elements with equal values from the left sub-array are placed before those from the right sub-array during merge.", "C. It arbitrarily places them.", "D. It removes duplicates.", "B"
"MergeSort", "What is the role of the 'mid' point calculation in Merge Sort?", "A. To find the pivot element.", "B. To divide the array into two (approximately) equal halves.", "C. To determine the base case.", "D. To calculate the number of inversions.", "B"
"MergeSort", "Could Merge Sort be considered a 'non-comparison' sort?", "A. Yes", "B. No (it relies heavily on comparisons between elements)", "B"
"MergeSort", "Compared to Heap Sort, Merge Sort is generally:", "A. Faster on average but uses more memory.", "B. Slower on average but uses less memory.", "C. Always faster and uses less memory.", "D. Always slower and uses more memory.", "A"
"MergeSort", "What type of data benefits most from Merge Sort's stability property?", "A. Simple integers.", "B. Objects with multiple attributes, where stable sorting on one attribute is important to preserve previous ordering on another.", "C. Floating-point numbers.", "D. Characters.", "B"
"MergeSort", "The recursion tree for Merge Sort has a depth of approximately `log N`. True or False?", "A. True", "B. False", "A"
"MergeSort", "At each level of the recursion tree, the total work done in the 'merge' step across all subproblems is `O(N)`. True or False?", "A. True", "B. False", "A"
"MergeSort", "If you have an array `[8, 3, 1, 6]` and apply Merge Sort, what are the two sub-arrays after the first split?", "A. `[8, 3]` and `[1, 6]`", "B. `[8]` and `[3, 1, 6]`", "C. `[8, 3, 1]` and `[6]`", "D. `[8, 3, 1, 6]` and `[]`", "A"
"MergeSort", "After sorting `[8, 3]` to `[3, 8]` and `[1, 6]` to `[1, 6]`, what is the result of merging `[3, 8]` and `[1, 6]`?", "A. `[1, 3, 6, 8]`", "B. `[3, 1, 8, 6]`", "C. `[8, 6, 3, 1]`", "D. `[1, 6, 3, 8]`", "A"
"QuickSort", "What algorithmic paradigm does Quick Sort fall under?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Divide and Conquer", "D. Brute Force", "C"
"QuickSort", "What is the primary operation that divides the array into sub-problems in Quick Sort?", "A. Merging", "B. Partitioning", "C. Swapping", "D. Insertion", "B"
"QuickSort", "What is the element chosen to divide the array in Quick Sort called?", "A. Divider", "B. Separator", "C. Pivot", "D. Splitter", "C"
"QuickSort", "In the partition step of Quick Sort, elements smaller than the pivot are moved to one side, and elements larger than the pivot are moved to the other. True or False?", "A. True", "B. False", "A"
"QuickSort", "What is the average-case time complexity of Quick Sort?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(log N)", "B"
"QuickSort", "What is the worst-case time complexity of Quick Sort?", "A. O(N log N)", "B. O(N^2)", "C. O(N)", "D. O(log N)", "B"
"QuickSort", "When does the worst-case time complexity of Quick Sort occur?", "A. When the array is randomly ordered.", "B. When the pivot repeatedly results in highly unbalanced partitions (e.g., already sorted or reverse sorted array, or all elements are same).", "C. When the array has many duplicate elements.", "D. When the array size is small.", "B"
"QuickSort", "What is the space complexity of Quick Sort in the best/average case (due to recursion stack)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "B"
"QuickSort", "What is the space complexity of Quick Sort in the worst case (due to recursion stack)?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N log N)", "C"
"QuickSort", "Is Quick Sort a stable sorting algorithm?", "A. Yes", "B. No", "C. Sometimes", "D. Only for small arrays", "B"
"QuickSort", "What does 'unstable' mean for a sorting algorithm?", "A. Its performance varies greatly.", "B. Elements with equal values may not maintain their relative order in the sorted output.", "C. It uses a variable amount of memory.", "D. It crashes frequently.", "B"
"QuickSort", "What are common strategies for choosing a pivot in Quick Sort to avoid worst-case scenarios?", "A. Always pick the first element.", "B. Always pick the last element.", "C. Pick a random element, or median-of-three pivot selection.", "D. Always pick the middle element.", "C"
"QuickSort", "What is the purpose of the 'median-of-three' pivot selection?", "A. To always pick the exact median.", "B. To make the partition more balanced and reduce the chance of worst-case behavior.", "C. To improve space complexity.", "D. To make the algorithm stable.", "B"
"QuickSort", "Which partitioning scheme moves elements smaller than the pivot to the left and larger to the right, and the pivot ends up in its final sorted position?", "A. Lomuto partition scheme", "B. Hoare partition scheme", "C. Random partition scheme", "D. Merge partition scheme", "A"
"QuickSort", "Which partitioning scheme is generally more efficient in terms of swaps, but the pivot's final position is not guaranteed?", "A. Lomuto partition scheme", "B. Hoare partition scheme", "C. Random partition scheme", "D. Merge partition scheme", "B"
"QuickSort", "Quick Sort is typically implemented using:", "A. Iteration only.", "B. Recursion.", "C. A combination of iteration and direct loops.", "D. Hash tables.", "B"
"QuickSort", "What is the recurrence relation that describes the average-case time complexity of Quick Sort?", "A. T(N) = T(N-1) + O(1)", "B. T(N) = 2T(N/2) + O(N)", "C. T(N) = T(N-1) + O(N)", "D. T(N) = T(N/2) + T(N/2) + O(N) (approximately for average case)", "D"
"QuickSort", "What is an advantage of Quick Sort over Merge Sort in terms of space?", "A. Quick Sort is always stable.", "B. Quick Sort is an in-place sorting algorithm (in its common implementations), requiring O(log N) or O(N) stack space.", "C. Quick Sort has a guaranteed O(N log N) worst-case time.", "D. Quick Sort is easier to implement for linked lists.", "B"
"QuickSort", "What is a disadvantage of Quick Sort compared to Merge Sort?", "A. Higher average-case time complexity.", "B. Lower worst-case time complexity.", "C. Not a stable sort and has O(N^2) worst-case time complexity.", "D. Requires O(N) auxiliary space.", "C"
"QuickSort", "When is Quick Sort a good choice of sorting algorithm?", "A. When worst-case performance guarantees are critical.", "B. When in-place sorting and good average-case performance are desired.", "C. When the data is highly correlated.", "D. When the input size is very small.", "B"
"QuickSort", "How does Quick Sort handle arrays that are already sorted?", "A. It sorts them in O(N log N) time.", "B. It may lead to its worst-case O(N^2) performance if the first/last element is always chosen as pivot.", "C. It becomes O(N).", "D. It swaps elements in place.", "B"
"QuickSort", "For very small subarrays, some Quick Sort implementations switch to Insertion Sort. Why?", "A. Insertion Sort has better worst-case complexity for small inputs.", "B. Insertion Sort has lower constant factors for small inputs, making it faster due to less recursion overhead.", "C. Insertion Sort uses less memory.", "D. Insertion Sort is stable.", "B"
"QuickSort", "What is tail recursion optimization in the context of Quick Sort?", "A. A technique to eliminate the need for a pivot.", "B. A technique to reduce the recursion depth (and thus stack space) by iteratively sorting the larger sub-array and recursively sorting the smaller one.", "C. A method to make Quick Sort stable.", "D. A way to change the pivot selection strategy.", "B"
"QuickSort", "Does Quick Sort typically perform well on data that contains many duplicate elements?", "A. Yes, it's unaffected by duplicates.", "B. It can degrade to O(N^2) if duplicates are handled poorly (e.g., all elements are equal to pivot).", "C. It becomes O(N log N) faster.", "D. It removes duplicates automatically.", "B"
"QuickSort", "What is 3-way partitioning (Dijkstra's 3-way partition) used for in Quick Sort?", "A. To handle 3 pivots simultaneously.", "B. To efficiently handle arrays with many duplicate elements by partitioning into 'less than pivot', 'equal to pivot', and 'greater than pivot' regions.", "C. To divide the array into three equal parts.", "D. To sort three arrays at once.", "B"
"QuickSort", "Quick Sort is a comparison sort. True or False?", "A. True", "B. False", "A"
"QuickSort", "What is the typical advantage of Quick Sort over Merge Sort in competitive programming?", "A. It's stable.", "B. It uses less memory due to its in-place nature (lower constant factor for auxiliary space).", "C. Its worst-case is better.", "D. It is easier to parallelize.", "B"
"QuickSort", "Which of the following describes the 'Conquer' step in Quick Sort?", "A. Dividing the array around a pivot.", "B. Recursively sorting the two sub-arrays.", "C. Combining the sorted sub-arrays.", "D. Choosing the pivot element.", "B"
"QuickSort", "Which of the following describes the 'Combine' step in Quick Sort?", "A. Merging sorted sub-arrays.", "B. There is no explicit 'combine' step; the sorted sub-arrays directly form the sorted array.", "C. Finding the pivot.", "D. Swapping elements.", "B"
"QuickSort", "If an array has 7 elements, what is the maximum possible recursion depth for Quick Sort (worst case)?", "A. log N (approx 3)", "B. N (approx 7)", "C. N^2", "D. 1", "B"
"QuickSort", "The 'tail recursion' in Quick Sort occurs at which part of the recursive calls?", "A. Before the pivot selection.", "B. After processing one sub-array, the other sub-array call can be optimized.", "C. Only in the base case.", "D. Never in Quick Sort.", "B"
"QuickSort", "What happens if all elements in the array are identical when using a standard Quick Sort with Lomuto partitioning (pivot as last element)?", "A. It runs in O(N log N).", "B. It runs in O(N^2) as the partition will always result in one sub-array of size N-1 and one of size 0.", "C. It performs only 1 comparison.", "D. It is stable.", "B"
"QuickSort", "What is a major reason why Quick Sort is popular in practice?", "A. Its guaranteed worst-case performance.", "B. Its high constant factor in average-case performance.", "C. Its in-place nature and good average-case performance often make it faster than other O(N log N) sorts.", "D. It works well with linked lists.", "C"
"QuickSort", "Can Quick Sort be used for external sorting?", "A. Yes, it's ideal for external sorting.", "B. No, its in-place nature and random access requirements make it less suitable than Merge Sort for external sorting.", "C. Only if memory is abundant.", "D. Only for small files.", "B"
"QuickSort", "The `left` and `right` pointers in Hoare's partition scheme move towards each other until they cross. True or False?", "A. True", "B. False", "A"
"QuickSort", "What type of partitioning is typically preferred for arrays with many duplicate values?", "A. Lomuto Partitioning", "B. Hoare Partitioning", "C. 3-Way Partitioning", "D. Single-sided Partitioning", "C"
"QuickSort", "If an array `[5, 2, 8, 1, 9]` uses 5 as the pivot (Lomuto, last element), what's the state of the array after the first partition, before recursive calls?", "A. `[1, 2, 5, 8, 9]`", "B. `[2, 1, 5, 8, 9]`", "C. `[2, 1, 5, 9, 8]`", "D. `[1, 2, 8, 9, 5]`", "B"
"QuickSort", "What is the main idea behind randomized Quick Sort?", "A. To randomize the input array before sorting.", "B. To randomly choose the pivot element to achieve average-case O(N log N) behavior with high probability.", "C. To randomize the comparison function.", "D. To randomize the sub-array sizes.", "B"
"QuickSort", "Why is randomization often used in Quick Sort in practical implementations?", "A. To guarantee the worst-case scenario.", "B. To make it stable.", "C. To reduce the probability of encountering the worst-case O(N^2) time complexity, especially with hostile inputs.", "D. To reduce space complexity.", "C"
"QuickSort", "The base case for Quick Sort recursion is when the sub-array size becomes:", "A. 0 or 1 (or a small constant, switching to insertion sort).", "B. N/2.", "C. N.", "D. log N.", "A"
"QuickSort", "What happens to the pivot element after the partition step?", "A. It is discarded.", "B. It is moved to the beginning of the array.", "C. It is placed in its final sorted position.", "D. It is swapped with the smallest element.", "C"
"QuickSort", "Is Quick Sort always faster than Merge Sort?", "A. Yes, always.", "B. No, Merge Sort has better worst-case guarantee, and for certain data distributions or hardware, Merge Sort might be faster.", "C. Only for small arrays.", "D. Only for random data.", "B"
"QuickSort", "Quick Sort is generally preferred over Merge Sort when _________ is a critical constraint.", "A. Time complexity in worst case.", "B. Space complexity (auxiliary space).", "C. Stability of the sort.", "D. Parallelizability.", "B"
"QuickSort", "What is an 'in-place' sorting algorithm?", "A. An algorithm that sorts elements without using any additional memory beyond a constant amount (or logarithmic for stack space).", "B. An algorithm that sorts elements by copying them to a new array.", "C. An algorithm that sorts elements by comparing them in place.", "D. An algorithm that sorts elements by rearranging them on a tape drive.", "A"
"QuickSort", "What is the primary function of the `partition` method in Quick Sort?", "A. To sort the entire array.", "B. To rearrange the elements such that all elements smaller than the pivot come before it, and all larger elements come after it.", "C. To find the median element.", "D. To merge two sorted subarrays.", "B"
"QuickSort", "If the pivot is chosen poorly and the array is always split into sub-arrays of size `N-1` and `0`, the recurrence relation becomes:", "A. T(N) = 2T(N/2) + O(N)", "B. T(N) = T(N-1) + O(N)", "C. T(N) = T(N-1) + T(0) + O(N)", "D. Both B and C represent the worst-case scenario.", "D"
"QuickSort", "Compared to Heap Sort, Quick Sort is generally:", "A. Slower on average but better worst-case.", "B. Faster on average and uses less memory (in practice).", "C. Always faster but uses more memory.", "D. Always slower and uses more memory.", "B"
"QuickSort", "The `std::sort` function in C++ is often implemented as an introsort, which is a hybrid algorithm. What does it typically combine?", "A. Quick Sort, Merge Sort, and Heap Sort.", "B. Quick Sort, Insertion Sort, and Heap Sort.", "C. Merge Sort, Insertion Sort, and Bubble Sort.", "D. Quick Sort, Counting Sort, and Radix Sort.", "B"
"QuickSort", "In Quick Sort, if `low >= high` for a sub-array, what does it signify?", "A. The sub-array is sorted.", "B. The sub-array has 0 or 1 element, acting as a base case for recursion.", "C. An error has occurred.", "D. The pivot is at its correct position.", "B"
"QuickSort", "Which of the following is true regarding Quick Sort?", "A. It is always faster than Merge Sort.", "B. It is generally faster in practice due to better cache performance and lower constant factors.", "C. It is typically slower than Bubble Sort for large inputs.", "D. It requires a linked list as input.", "B"
"BinarySearch", "What is the primary requirement for an array to be searchable using Binary Search?", "A. It must contain only unique elements.", "B. It must be sorted.", "C. It must be unsorted.", "D. It must be a linked list.", "B"
"BinarySearch", "What algorithmic paradigm does Binary Search fall under?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Divide and Conquer", "D. Brute Force", "C"
"BinarySearch", "What is the time complexity of Binary Search in the worst case?", "A. O(N)", "B. O(N log N)", "C. O(log N)", "D. O(1)", "C"
"BinarySearch", "What is the time complexity of Binary Search in the best case?", "A. O(N)", "B. O(log N)", "C. O(1)", "D. O(N log N)", "C"
"BinarySearch", "What is the space complexity of iterative Binary Search?", "A. O(N)", "B. O(log N)", "C. O(1)", "D. O(N log N)", "C"
"BinarySearch", "What is the space complexity of recursive Binary Search?", "A. O(1)", "B. O(log N) (due to recursion stack)", "C. O(N)", "D. O(N log N)", "B"
"BinarySearch", "If an array has `N` elements, how many comparisons does Binary Search make in the worst case?", "A. `N`", "B. `log2(N)` (approximately)", "C. `N/2`", "D. `1`", "B"
"BinarySearch", "In Binary Search, after each comparison, the search space is approximately reduced by what factor?", "A. `1/4`", "B. `1/2`", "C. `1/3`", "D. `1/N`", "B"
"BinarySearch", "What are the common variables used to define the search space in Binary Search?", "A. `start` and `end` (or `low` and `high`).", "B. `i` and `j`.", "C. `min` and `max`.", "D. `left` and `right` (or `first` and `last`).", "A"
"BinarySearch", "How is the `mid` element calculated in Binary Search?", "A. `(start + end) / 2`", "B. `start + (end - start) / 2`", "C. `(start + end + 1) / 2`", "D. Both A and B are common, with B preferred to avoid overflow.", "D"
"BinarySearch", "If the `target` element is found at `mid`, what happens?", "A. The search continues in the left half.", "B. The search continues in the right half.", "C. The index `mid` is returned, and the search terminates.", "D. The array is sorted.", "C"
"BinarySearch", "If the `target` element is less than `array[mid]`, where does the search continue?", "A. In the left half (`end = mid - 1`).", "B. In the right half (`start = mid + 1`).", "C. In the whole array again.", "D. The target is not in the array.", "A"
"BinarySearch", "If the `target` element is greater than `array[mid]`, where does the search continue?", "A. In the left half (`end = mid - 1`).", "B. In the right half (`start = mid + 1`).", "C. In the whole array again.", "D. The target is not in the array.", "B"
"BinarySearch", "What is the condition that typically terminates the Binary Search loop when the element is not found?", "A. `start == end`", "B. `start > end`", "C. `mid == 0`", "D. `array[mid] == target`", "B"
"BinarySearch", "Which of the following data structures is suitable for Binary Search?", "A. Unsorted Linked List", "B. Sorted Array", "C. Hash Table", "D. Stack", "B"
"BinarySearch", "Can Binary Search be used on a rotated sorted array (e.g., `[4, 5, 6, 7, 0, 1, 2]`)?", "A. No, it requires a fully sorted array.", "B. Yes, with modifications to handle the rotation point.", "C. Only if the rotation point is known.", "D. Only if the array size is small.", "B"
"BinarySearch", "Binary Search is effective for finding a specific element. What else can it be used for?", "A. Finding all prime numbers.", "B. Finding the first or last occurrence of an element in an array with duplicates.", "C. Sorting an array.", "D. Calculating Fibonacci numbers.", "B"
"BinarySearch", "Consider `[2, 5, 8, 12, 16, 23, 38, 56, 72]`. Search for 23. Initial `start=0, end=8`. `mid=(0+8)/2=4`. `array[4]=16`. Target > 16. What's the next search range?", "A. `start=0, end=3`", "B. `start=5, end=8`", "C. `start=4, end=8`", "D. `start=0, end=4`", "B"
"BinarySearch", "After `start=5, end=8`. `mid=(5+8)/2=6`. `array[6]=38`. Target < 38. What's the next search range?", "A. `start=5, end=5`", "B. `start=6, end=8`", "C. `start=5, end=6`", "D. `start=5, end=7`", "A"
"BinarySearch", "After `start=5, end=5`. `mid=(5+5)/2=5`. `array[5]=23`. Target == 23. What's the result?", "A. Not found.", "B. Index 5 found.", "C. Index 6 found.", "D. Search continues.", "B"
"BinarySearch", "What is the potential issue with `mid = (start + end) / 2` in some programming languages/environments for very large `start` and `end` values?", "A. Division by zero.", "B. Integer overflow if `start + end` exceeds the maximum integer value.", "C. Infinite loop.", "D. Incorrect result due to floating-point precision.", "B"
"BinarySearch", "When searching for the 'first occurrence' of an element in a sorted array with duplicates, if `array[mid] == target`, how should the search space be adjusted?", "A. `start = mid + 1` (continue search in right half).", "B. `end = mid - 1` (continue search in left half, possibly store `mid` as potential answer).", "C. Return `mid` immediately.", "D. Adjust `mid` to the right.", "B"
"BinarySearch", "When searching for the 'last occurrence' of an element in a sorted array with duplicates, if `array[mid] == target`, how should the search space be adjusted?", "A. `start = mid + 1` (continue search in right half, possibly store `mid` as potential answer).", "B. `end = mid - 1` (continue search in left half).", "C. Return `mid` immediately.", "D. Adjust `mid` to the left.", "A"
"BinarySearch", "If the array is empty, what should Binary Search typically return?", "A. 0", "B. -1 (or an indicator that element is not found).", "C. The element itself.", "D. An error.", "B"
"BinarySearch", "Can Binary Search be applied to a `std::set` or `std::map` in C++ directly by index?", "A. Yes, directly.", "B. No, these are tree-based structures, search is O(log N) but not by direct index access. `std::lower_bound` etc. work on sorted ranges, not on sets directly.", "C. Only if the set is small.", "D. Only for primitive types.", "B"
"BinarySearch", "Which standard library function in C++ implements a form of Binary Search to find the first element not less than a given value?", "A. `std::find`", "B. `std::sort`", "C. `std::lower_bound`", "D. `std::upper_bound`", "C"
"BinarySearch", "Which standard library function in C++ implements a form of Binary Search to find the first element greater than a given value?", "A. `std::find`", "B. `std::sort`", "C. `std::lower_bound`", "D. `std::upper_bound`", "D"
"BinarySearch", "Binary Search can be used on problems where the search space is monotonic (e.g., finding the square root of a number to a certain precision). True or False?", "A. True (This is often called 'Binary Search on the answer').", "B. False", "A"
"BinarySearch", "What is an advantage of Binary Search over Linear Search?", "A. Easier to implement.", "B. Works on unsorted arrays.", "C. Significantly faster for large datasets.", "D. Uses less memory.", "C"
"BinarySearch", "What is a disadvantage of Binary Search compared to Linear Search?", "A. Slower for small datasets.", "B. Requires the data to be sorted.", "C. Uses more memory.", "D. Only works for integers.", "B"
"BinarySearch", "If an array is `[1, 1, 1, 1, 1, 1, 1]`, and we search for 1, how many comparisons will Binary Search (standard implementation) make until it finds *a* 1?", "A. 1", "B. `log N`", "C. `N/2`", "D. `N`", "B"
"BinarySearch", "Does Binary Search always find the element if it's present in the array?", "A. Yes, if implemented correctly and the array is sorted.", "B. No, only if the array contains unique elements.", "C. Only if the target is at the beginning or end.", "D. Only if the target is prime.", "A"
"BinarySearch", "Binary search is typically implemented using arrays. Can it be effectively used on linked lists?", "A. Yes, directly.", "B. No, because random access to elements (needed for `mid`) is inefficient in linked lists (O(N) for each access).", "C. Only if the linked list is small.", "D. Only if the linked list is circular.", "B"
"BinarySearch", "When implementing Binary Search for integers, what is the best practice to avoid integer overflow when calculating `mid` for `long long` type?", "A. `mid = (start + end) / 2`", "B. `mid = start + (end - start) / 2`", "C. `mid = (start + end) >> 1`", "D. Both B and C are safe and commonly used.", "D"
"BinarySearch", "If an element is not found, what range does `[start, end]` usually represent after the loop terminates?", "A. `start` is the insertion point, `end` is `start - 1` (or vice-versa, depending on loop conditions).", "B. `start` and `end` are both -1.", "C. `start` and `end` are both N.", "D. The original range.", "A"
"BinarySearch", "Can Binary Search be used on floating-point numbers?", "A. No, only integers.", "B. Yes, but it typically requires iterating a fixed number of times for desired precision rather than relying on exact equality, or handling a small epsilon.", "C. Only if the numbers are positive.", "D. Only if they are perfectly sorted.", "B"
"BinarySearch", "The concept of Binary Search can be extended to search in a 2D sorted matrix. True or False?", "A. True (e.g., search each row, or use a specific 2D search algorithm that leverages sortedness).", "B. False", "A"
"BinarySearch", "What is the key property of the search space that enables Binary Search?", "A. Random distribution of elements.", "B. Monotonicity (either strictly increasing or strictly decreasing).", "C. Presence of duplicates.", "D. Small size.", "B"
"BinarySearch", "In a scenario where `low <= high` is the loop condition, and `array[mid] < target`, the `low` pointer typically moves to `mid + 1`. True or False?", "A. True", "B. False", "A"
"BinarySearch", "If the array is sorted in descending order, how would the comparison logic in Binary Search change?", "A. `if array[mid] < target` then search left, `if array[mid] > target` then search right.", "B. `if array[mid] < target` then search right, `if array[mid] > target` then search left.", "C. No change, it works the same.", "D. It cannot work for descending order.", "B"
"BinarySearch", "What is the typical base case for a recursive Binary Search?", "A. When `start > end` (element not found).", "B. When `start == end`.", "C. When the array is empty.", "D. When `mid == target`.", "A"
"BinarySearch", "The process of repeatedly halving the search space is what gives Binary Search its logarithmic time complexity. True or False?", "A. True", "B. False", "A"
"BinarySearch", "Binary Search can be used to solve the 'peak element' problem in an array (where an element is greater than its neighbors). True or False?", "A. True (if the array has a specific structure that allows for monotonic behavior).", "B. False", "A"
"BinarySearch", "If `array[mid] == target`, and you need to find *any* occurrence, what is the best course of action?", "A. Return `mid` immediately.", "B. Continue searching to the left.", "C. Continue searching to the right.", "D. Throw an exception.", "A"
"BinarySearch", "Binary Search is well-suited for scenarios where data is stored in a sequential access medium (like a tape drive). True or False?", "A. True", "B. False (random access is crucial for efficiency).", "B"
"BinarySearch", "What is the difference between `lower_bound` and `upper_bound` in C++ standard library?", "A. `lower_bound` finds the first element *equal to* target, `upper_bound` finds the first element *greater than or equal to* target.", "B. `lower_bound` finds the first element *not less than* target, `upper_bound` finds the first element *greater than* target.", "C. `lower_bound` finds the first element *greater than* target, `upper_bound` finds the first element *not less than* target.", "D. They are identical.", "B"
"BinarySearch", "In `lower_bound` scenarios, if `array[mid]` is less than `target`, what should happen to `start`?", "A. `start = mid`", "B. `start = mid + 1`", "C. `start = mid - 1`", "D. `end = mid`", "B"
"BinarySearch", "In `lower_bound` scenarios, if `array[mid]` is greater than or equal to `target`, what should happen to `end`?", "A. `end = mid` (as `mid` could be the answer).", "B. `end = mid - 1`", "C. `start = mid + 1`", "D. `start = mid`", "A"
"BinarySearch", "If the array contains `[1, 3, 5, 7, 9]` and you search for `4`, what index does a standard Binary Search (returning -1 if not found) typically return after termination?", "A. -1", "B. 2 (index where 4 would be inserted if low ends up after high)", "C. 1", "D. 3", "A"
"BinarySearch", "What type of problems are most effectively solved using 'Binary Search on the Answer'?", "A. Problems where the answer is an integer within a known range, and a monotonic check function exists.", "B. Problems involving string searching.", "C. Problems requiring graph traversal.", "D. Problems with very small input sizes.", "A"
"ClosestPair", "What is the primary objective of the Closest Pair of Points problem?", "A. To find two points that are farthest apart in a given set of points.", "B. To find two points with the minimum distance between them in a given set of points.", "C. To find the median point in a set of points.", "D. To find the centroid of a set of points.", "B"
"ClosestPair", "What is the brute-force time complexity to solve the Closest Pair of Points problem?", "A. O(N)", "B. O(N log N)", "C. O(N^2) (by checking all pairs of points).", "D. O(N^3)", "C"
"ClosestPair", "Which algorithmic paradigm is typically used to solve the Closest Pair of Points problem efficiently?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Divide and Conquer", "D. Backtracking", "C"
"ClosestPair", "What is the time complexity of the efficient Divide and Conquer algorithm for Closest Pair of Points?", "A. O(N^2)", "B. O(N log N)", "C. O(N log^2 N)", "D. O(N)", "B"
"ClosestPair", "The Divide and Conquer algorithm for Closest Pair of Points usually begins by sorting the points based on which coordinate?", "A. Only X-coordinate.", "B. Only Y-coordinate.", "C. Both X and Y coordinates (separately).", "D. Manhattan distance.", "A"
"ClosestPair", "After sorting by X-coordinate, the set of points is divided into two halves. This is the _______ step.", "A. Conquer", "B. Combine", "C. Divide", "D. Base Case", "C"
"ClosestPair", "What is done in the 'Conquer' step of the Closest Pair algorithm?", "A. Calculate distances between all pairs in the subproblems.", "B. Recursively find the closest pair in the left and right halves.", "C. Merge the sorted lists.", "D. Filter out points.", "B"
"ClosestPair", "After recursively finding the minimum distance `d` in the left half (`dL`) and right half (`dR`), what is the initial candidate for the overall minimum distance?", "A. `max(dL, dR)`", "B. `min(dL, dR)`", "C. `dL + dR`", "D. `0`", "B"
"ClosestPair", "The critical part of the 'Combine' step involves finding a pair of points (one from each half) that are closer than the current minimum `d`. Where must these points lie?", "A. Anywhere in the plane.", "B. Within a strip of width `d` centered on the dividing line.", "C. Within the left half only.", "D. Within the right half only.", "B"
"ClosestPair", "Why is it sufficient to consider points within a strip of width `d` on either side of the dividing line?", "A. Points outside this strip cannot be closer than `d`.", "B. It simplifies the algorithm.", "C. It reduces the number of points to 7.", "D. It's a heuristic, not a guarantee.", "A"
"ClosestPair", "After selecting points within the `d`-width strip, these points are then sorted based on which coordinate?", "A. X-coordinate.", "B. Y-coordinate.", "C. Z-coordinate.", "D. Distance from the origin.", "B"
"ClosestPair", "When iterating through the Y-sorted points in the strip, for each point `P`, how many subsequent points (approximately) do we need to check to find a potential closer pair?", "A. All remaining points in the strip.", "B. Only the next point.", "C. A constant number (e.g., 7 or 8 points) because points outside a certain bounding box cannot be closer than `d`.", "D. N/2 points.", "C"
"ClosestPair", "The reason we only need to check a constant number of points in the Y-sorted strip is related to:", "A. The Pigeonhole Principle and the geometric properties of a square with side `d`.", "B. Randomization.", "C. Hashing.", "D. Binary search.", "A"
"ClosestPair", "What is the recurrence relation for the Closest Pair of Points algorithm's time complexity?", "A. T(N) = T(N-1) + O(N)", "B. T(N) = 2T(N/2) + O(N)", "C. T(N) = 2T(N/2) + O(1)", "D. T(N) = T(N/2) + O(N log N)", "B"
"ClosestPair", "The `O(N)` term in the recurrence relation `T(N) = 2T(N/2) + O(N)` primarily comes from which step?", "A. Sorting points by X-coordinate initially.", "B. The recursive calls.", "C. The merge-like step for points within the strip (which involves sorting by Y and then linear scan).", "D. The base case.", "C"
"ClosestPair", "What is the base case for the Closest Pair of Points recursion?", "A. When the number of points is 0.", "B. When the number of points is 1.", "C. When the number of points is 2 or 3 (direct calculation).", "D. When the number of points is N/2.", "C"
"ClosestPair", "If the initial sorting by X-coordinate takes O(N log N), and the recursive calls take T(N) = 2T(N/2) + O(N), what is the overall time complexity?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(N log^2 N)", "B"
"ClosestPair", "If we re-sort the points by Y-coordinate in the 'Combine' step for the strip, what would be the total time complexity?", "A. O(N log N)", "B. O(N log^2 N) (because of repeated N log N sorting in each level of recursion).", "C. O(N^2)", "D. O(N)", "B"
"ClosestPair", "To achieve O(N log N) overall, how is the Y-sorted list for the strip efficiently maintained or generated without re-sorting each time?", "A. By hashing points.", "B. By using a data structure that maintains sorted order (e.g., balanced BST).", "C. By merging the two Y-sorted sub-lists during the combine step, similar to Merge Sort.", "D. By ignoring Y-coordinates.", "C"
"ClosestPair", "What is the space complexity of the efficient Closest Pair algorithm?", "A. O(1)", "B. O(log N) (for recursion stack).", "C. O(N) (for auxiliary arrays in merge-like operations).", "D. O(N^2)", "C"
"ClosestPair", "Can the Closest Pair algorithm handle duplicate points?", "A. No, it requires unique points.", "B. Yes, if distance is 0, it means duplicate points are found.", "C. Only if duplicates are ignored.", "D. It depends on the sorting implementation.", "B"
"ClosestPair", "The Closest Pair algorithm is a good example of how a problem can be solved more efficiently by leveraging which property of the input?", "A. Randomness.", "B. Sortedness.", "C. Sparsity.", "D. Density.", "B"
"ClosestPair", "If the points are in 3D space, can the Closest Pair algorithm (Divide and Conquer) be extended?", "A. No, it only works for 2D.", "B. Yes, with increased complexity (e.g., O(N log^2 N) or O(N log N) with more complex data structures).", "C. Yes, it remains O(N log N) without changes.", "D. Only if points are on a plane.", "B"
"ClosestPair", "What is the Euclidean distance formula between two points `(x1, y1)` and `(x2, y2)`?", "A. `|x1 - x2| + |y1 - y2|`", "B. `sqrt((x1 - x2)^2 + (y1 - y2)^2)`", "C. `max(|x1 - x2|, |y1 - y2|)`", "D. `(x1 - x2)^2 + (y1 - y2)^2`", "B"
"ClosestPair", "Why is it important to use `long double` or `double` for distance calculations to maintain precision?", "A. Integers are not large enough for coordinates.", "B. Floating-point numbers are faster.", "C. Square roots and distances can result in non-integer values, and precision is critical for comparison.", "D. It's a stylistic choice.", "C"
"ClosestPair", "Consider a set of points already sorted by X-coordinate. If the closest pair happens to be across the dividing line, and their distance is `d_min`, then both points must be within `d_min` distance from the dividing line. True or False?", "A. True", "B. False", "A"
"ClosestPair", "The constant factor (e.g., 7 or 8) for checking points in the strip arises from the fact that no more than a certain number of points can fit into a `d x 2d` (or `2d x d`) rectangle without violating the `d` minimum distance found so far. True or False?", "A. True", "B. False", "A"
"ClosestPair", "If all points are collinear (e.g., lie on a straight line), what is the time complexity of finding the closest pair using the D&C algorithm?", "A. O(N^2)", "B. O(N log N)", "C. O(N) (after initial sort, just a single pass).", "D. O(log N)", "C"
"ClosestPair", "What is the expected behavior of the Closest Pair algorithm if all points are identical?", "A. It will find a distance of 0.", "B. It will loop infinitely.", "C. It will return an error.", "D. It will sort them.", "A"
"ClosestPair", "Which common algorithm's merge step is analogous to the 'Combine' step in Closest Pair, particularly for maintaining Y-sorted lists?", "A. Quick Sort", "B. Bubble Sort", "C. Merge Sort", "D. Insertion Sort", "C"
"ClosestPair", "If we use a `std::set` (or `TreeSet` in Java) to maintain Y-sorted points in the strip, what would be the impact on the time complexity?", "A. It would remain O(N log N).", "B. It would degrade to O(N log^2 N) due to log N insertions/deletions for each point.", "C. It would become O(N^2).", "D. It would be O(N).", "B"
"ClosestPair", "The Closest Pair problem has applications in which field?", "A. Financial trading.", "B. Computational geometry, pattern recognition, and computer graphics.", "C. Text processing.", "D. Network routing.", "B"
"ClosestPair", "What is the `d` in the `d`-width strip called?", "A. Delta", "B. Threshold", "C. Minimum distance found so far from recursive calls", "D. Strip width", "C"
"ClosestPair", "Consider points `P = {(0,0), (1,1), (0,1), (1,0)}`. What is the closest pair distance?", "A. `sqrt(2)`", "B. `1`", "C. `0`", "D. `2`", "B"
"ClosestPair", "If the input points are integers, should intermediate distance squares (`dx*dx + dy*dy`) be calculated using `long long` to prevent overflow?", "A. No, `int` is sufficient.", "B. Yes, especially if coordinates can be large, to prevent overflow before taking the square root.", "C. Only if the final distance is integer.", "D. Only if the number of points is large.", "B"
"ClosestPair", "What is the primary benefit of the Divide and Conquer approach over brute force for Closest Pair?", "A. Reduced memory usage.", "B. Improved clarity of code.", "C. Significant reduction in time complexity for large datasets.", "D. Simpler implementation.", "C"
"ClosestPair", "Does the initial X-sort need to be performed only once?", "A. Yes", "B. No, it needs to be done at each recursive step.", "A"
"ClosestPair", "How is the `Y` sorted list of points for each subproblem typically generated recursively?", "A. By re-sorting all points in the subproblem by Y.", "B. By splitting the parent's Y-sorted list into two Y-sorted sub-lists.", "C. By using a hash map.", "D. By generating random points.", "B"
"ClosestPair", "The process of splitting the Y-sorted list into two Y-sorted sub-lists takes `O(N)` time. True or False?", "A. True", "B. False", "A"
"ClosestPair", "If the points are in a general position (no two points share the same X or Y coordinate), does this simplify the algorithm significantly?", "A. Yes, it removes edge cases like vertical lines.", "B. No, the algorithm remains the same.", "C. Only for small datasets.", "D. Only for points on a circle.", "A"
"ClosestPair", "The Closest Pair algorithm is sensitive to floating-point precision issues. True or False?", "A. True (due to square root calculations and comparisons of distances).", "B. False", "A"
"ClosestPair", "What is the purpose of the `min(dL, dR)` step before considering the strip?", "A. To set a lower bound for distances.", "B. To establish the current smallest distance found in the 'conquer' steps, against which potential 'crossing' pairs will be compared.", "C. To check for empty sets.", "D. To sum distances.", "B"
"ClosestPair", "Can the Closest Pair problem be solved using a sweep-line algorithm (which is related to D&C but often iterative)?", "A. No.", "B. Yes, this is another common and efficient approach.", "C. Only for specific types of points.", "D. Only for small N.", "B"
"ClosestPair", "What defines the 'mid-line' for dividing the points?", "A. The average of all X-coordinates.", "B. The X-coordinate of the median point in the X-sorted list.", "C. The midpoint of the Y-coordinates.", "D. A random line.", "B"
"ClosestPair", "If all points are on a single vertical line, what is the distance between the closest pair?", "A. Infinity.", "B. The minimum difference between their Y-coordinates.", "C. 0.", "D. Depends on X-coordinates.", "B"
"ClosestPair", "The number of points to check in the strip is a constant because a square of side `d` can contain at most `k` points such that no two are closer than `d`. What is `k` approximately?", "A. 2", "B. 4", "C. 7-8 (varies slightly by proof)", "D. N/2", "C"
"ClosestPair", "What happens in the base case when there are only 2 points?", "A. Return infinity.", "B. Return 0.", "C. Calculate the Euclidean distance between them.", "D. Recursively call for one point.", "C"
"ClosestPair", "If there are 3 points (base case), how do you find the closest pair?", "A. Calculate all 3 pairwise distances and take the minimum.", "B. Return infinity.", "C. Return 0.", "D. Recursively call for 1 point.", "A"
"ClosestPair", "The Closest Pair algorithm is a prime example of which design principle?", "A. Greedy choice property.", "B. Optimal substructure.", "C. Overlapping subproblems.", "D. All of the above.", "B"
"ClosestPair", "If you need to find the `k` closest pairs, would the same Divide and Conquer algorithm be directly applicable?", "A. Yes, with minor modifications.", "B. No, a different approach is needed.", "C. Only if `k` is very small.", "D. Only if `k` is very large.", "B"
"StrassenMatrix", "What algorithmic paradigm does Strassen's Matrix Multiplication algorithm fall under?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Divide and Conquer", "D. Brute Force", "C"
"StrassenMatrix", "What is the time complexity of the naive (standard) matrix multiplication algorithm for two N x N matrices?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(N^3)", "D"
"StrassenMatrix", "What is the time complexity of Strassen's Matrix Multiplication algorithm?", "A. O(N^3)", "B. O(N^2.81) (or more precisely, O(N^log2(7)))", "C. O(N^2)", "D. O(N log N)", "B"
"StrassenMatrix", "Strassen's algorithm improves upon the naive method by reducing the number of what operation?", "A. Additions", "B. Subtractions", "C. Multiplications of sub-matrices", "D. Divisions", "C"
"StrassenMatrix", "How many multiplications of sub-matrices does the naive Divide and Conquer matrix multiplication perform for N x N matrices divided into N/2 x N/2 sub-matrices?", "A. 4", "B. 7", "C. 8", "D. 9", "C"
"StrassenMatrix", "How many multiplications of sub-matrices does Strassen's algorithm perform for N x N matrices divided into N/2 x N/2 sub-matrices?", "A. 4", "B. 7", "C. 8", "D. 9", "B"
"StrassenMatrix", "What is the recurrence relation for the time complexity of Strassen's algorithm?", "A. T(N) = 8T(N/2) + O(N^2)", "B. T(N) = 7T(N/2) + O(N^2)", "C. T(N) = 4T(N/2) + O(N)", "D. T(N) = T(N-1) + O(N^2)", "B"
"StrassenMatrix", "The `O(N^2)` term in Strassen's recurrence relation `T(N) = 7T(N/2) + O(N^2)` represents the time spent on:", "A. Recursive calls.", "B. Addition and subtraction of sub-matrices.", "C. Base cases.", "D. Initializing matrices.", "B"
"StrassenMatrix", "Strassen's algorithm is beneficial for matrices of what size?", "A. Very small matrices (e.g., 2x2, 4x4).", "B. Large matrices (typically N > 100 or so).", "C. Any size, always.", "D. Only square matrices.", "B"
"StrassenMatrix", "What is the base case for Strassen's algorithm recursion?", "A. When the matrix size is 1x1 (or a small constant size where naive multiplication is faster).", "B. When the matrix size is N/2 x N/2.", "C. When the matrix is sparse.", "D. When the matrix is an identity matrix.", "A"
"StrassenMatrix", "What is the space complexity of Strassen's algorithm?", "A. O(1)", "B. O(log N)", "C. O(N^2) (for storing sub-matrices and intermediate results).", "D. O(N^3)", "C"
"StrassenMatrix", "Why is Strassen's algorithm not always used in practice, despite its better asymptotic complexity?", "A. Higher constant factors and increased overhead for additions/subtractions.", "B. It's not stable.", "C. It's difficult to parallelize.", "D. It only works for real numbers.", "A"
"StrassenMatrix", "When the matrix dimension `N` is not a power of 2, how is Strassen's algorithm typically handled?", "A. It cannot be used.", "B. The matrix is padded with zeros to the next power of 2.", "C. The algorithm is modified to handle odd dimensions directly.", "D. It converts to a linked list.", "B"
"StrassenMatrix", "Strassen's algorithm was developed by Volker Strassen in what year?", "A. 1969", "B. 1976", "C. 1985", "D. 1999", "A"
"StrassenMatrix", "The traditional matrix multiplication requires 8 recursive calls and 4 additions to multiply two 2x2 matrices after splitting. How many recursive calls and additions/subtractions does Strassen use?", "A. 8 multiplications, 10 additions/subtractions", "B. 7 multiplications, 10 additions/subtractions", "C. 7 multiplications, 18 additions/subtractions", "D. 4 multiplications, 10 additions/subtractions", "C"
"StrassenMatrix", "Which of the following is a drawback of Strassen's algorithm for certain applications?", "A. It is less memory intensive.", "B. It can have reduced numerical stability due to accumulation of floating-point errors from more additions/subtractions.", "C. It is simpler to implement.", "D. It is faster for all matrix sizes.", "B"
"StrassenMatrix", "Strassen's algorithm's performance advantage over naive multiplication typically becomes significant for `N` values greater than a certain threshold. What is this threshold generally around?", "A. 2", "B. 16-32", "C. 1000", "D. 1,000,000", "B"
"StrassenMatrix", "If you consider two 2x2 matrices A and B, Strassen's algorithm defines 7 products (M1 to M7) from combinations of A and B's sub-blocks. True or False?", "A. True", "B. False", "A"
"StrassenMatrix", "The final result matrix C is constructed by combining these 7 products using additions and subtractions. True or False?", "A. True", "B. False", "A"
"StrassenMatrix", "What is the definition of `P1` in Strassen's algorithm (where matrices are A, B and their sub-blocks A11, A12, etc.)?", "A. `(A11 + A22) * (B11 + B22)`", "B. `(A21 + A22) * B11`", "C. `A11 * (B12 - B22)`", "D. `A12 * (B21 + B22)`", "A"
"StrassenMatrix", "What is the definition of `P2` in Strassen's algorithm?", "A. `(A11 + A22) * (B11 + B22)`", "B. `(A21 + A22) * B11`", "C. `A11 * (B12 - B22)`", "D. `(A11 + A12) * B22`", "B"
"StrassenMatrix", "What is the definition of `C11` in terms of Strassen's products `P_i`?", "A. `P1 + P4 - P5 + P7`", "B. `P1 + P2 - P3 + P6`", "C. `P1 + P4`", "D. `P1 + P3 + P5 + P7`", "A"
"StrassenMatrix", "What is the definition of `C12` in terms of Strassen's products `P_i`?", "A. `P1 + P4 - P5 + P7`", "B. `P2 + P4`", "C. `P3 + P5`", "D. `P1 + P3`", "C"
"StrassenMatrix", "What is the definition of `C21` in terms of Strassen's products `P_i`?", "A. `P1 + P4 - P5 + P7`", "B. `P2 + P4`", "C. `P3 + P5`", "D. `P6 + P7`", "D"
"StrassenMatrix", "What is the definition of `C22` in terms of Strassen's products `P_i`?", "A. `P1 - P2 + P3 + P6`", "B. `P1 + P4 - P5 + P7`", "C. `P2 + P4`", "D. `P6 + P7`", "A"
"StrassenMatrix", "The core idea of Strassen's algorithm is to reduce the number of what arithmetic operation in the recursive step?", "A. Addition", "B. Subtraction", "C. Multiplication", "D. Division", "C"
"StrassenMatrix", "Is Strassen's algorithm practical for very small matrices in typical programming environments?", "A. Yes, always.", "B. No, the overhead of recursion and block operations outweighs the asymptotic advantage for small matrices.", "C. Only if the matrices are sparse.", "D. Only for 1x1 matrices.", "B"
"StrassenMatrix", "What is a major challenge in implementing Strassen's algorithm effectively?", "A. Determining the base case size for switching to naive multiplication.", "B. Handling non-square matrices.", "C. Managing the large number of additions/subtractions.", "D. All of the above.", "D"
"StrassenMatrix", "The exponent of the time complexity for matrix multiplication is a significant area of research. What is the current theoretical best exponent?", "A. 2.0", "B. 2.81", "C. Around 2.37 (e.g., Coppersmith-Winograd variant).", "D. 3.0", "C"
"StrassenMatrix", "Strassen's algorithm is an example of what type of approach to algorithm design?", "A. Greedy", "B. Brute Force", "C. Divide and Conquer with a non-standard recursive structure.", "D. Dynamic Programming", "C"
"StrassenMatrix", "If you double the size of matrices (from N to 2N), how much faster (asymptotically) does Strassen's algorithm perform compared to naive multiplication?", "A. Roughly `(2^3) / (2^log2(7))` = `8 / 7` times faster. No, this asks for speedup of Strassen vs Naive. (2N)^3 vs (2N)^log2(7). Ratio (2^3)/(2^log2(7)) = 8/7.", "B. Roughly `2^log2(7)` times faster.", "C. Roughly `2^(3 - log2(7))` times faster. No, (2N)^3 / (2N)^log2(7) = 2^(3-log2(7)) * N^(3-log2(7)). This is the factor by which the *ratio* changes. The question is how much *faster*. For N -> 2N, Strassen's factor is 2^log2(7) vs Naive's 2^3. The speedup *ratio* of Naive/Strassen is still (N^3)/(N^log2(7)). This speedup increases as N grows. When N doubles, Naive multiplies by 8, Strassen by 7. So Strassen is comparatively faster.", "D. The question is a bit ambiguous. Let's rephrase: if you go from N to 2N, the work for naive goes up by factor 8, for strassen by 7. So for larger N, Strassen gains relatively more compared to naive.", "C"
"StrassenMatrix", "When performing matrix additions/subtractions in Strassen's algorithm, what is the time complexity for two N x N matrices?", "A. O(N)", "B. O(N^2)", "C. O(N log N)", "D. O(N^3)", "B"
"StrassenMatrix", "The constant factors for Strassen's algorithm are generally ______ than for naive matrix multiplication.", "A. Smaller", "B. Larger", "C. Equal", "D. Irrelevant", "B"
"StrassenMatrix", "Is Strassen's algorithm an 'in-place' algorithm?", "A. Yes, always.", "B. No, it requires significant auxiliary space for sub-matrices and intermediate products.", "C. Only for 2x2 matrices.", "D. It can be made in-place with significant complexity.", "B"
"StrassenMatrix", "Can Strassen's algorithm be applied to non-square matrices directly?", "A. Yes.", "B. No, they must be converted to square matrices (e.g., by padding with zeros).", "C. Only if rows equals columns.", "D. Only if the smaller dimension is a power of 2.", "B"
"StrassenMatrix", "What is the primary advantage of Strassen's algorithm in theoretical computer science?", "A. It proves that O(N^3) is not the lower bound for matrix multiplication.", "B. It's the simplest algorithm to implement.", "C. It is numerically stable.", "D. It uses less memory.", "A"
"StrassenMatrix", "The `log2(7)` exponent is approximately:", "A. 2.0", "B. 2.37", "C. 2.81", "D. 3.0", "C"
"StrassenMatrix", "What is a potential disadvantage of Strassen's algorithm when memory is constrained?", "A. It's faster.", "B. Its O(N^2) space complexity (for temporary matrices) might be an issue for very large matrices.", "C. It's simpler to implement.", "D. It works well with cache.", "B"
"StrassenMatrix", "Strassen's algorithm's recursive nature makes it well-suited for what kind of computing?", "A. Single-threaded computation.", "B. Parallel and distributed computing.", "C. Mobile computing.", "D. Embedded systems.", "B"
"StrassenMatrix", "If `N=1`, what is the time complexity of both naive and Strassen's algorithms?", "A. O(1)", "B. O(N)", "C. O(log N)", "D. O(N^2)", "A"
"StrassenMatrix", "The number of arithmetic operations (additions and multiplications) for naive multiplication is `2N^3 - N^2`. True or False?", "A. True", "B. False", "A"
"StrassenMatrix", "Which of the following is NOT typically a real-world application where matrix multiplication algorithms are critical?", "A. Computer graphics and image processing.", "B. Machine learning (e.g., neural networks).", "C. Solving systems of linear equations.", "D. Managing a linked list.", "D"
"StrassenMatrix", "The 'divide' step in Strassen's algorithm involves splitting each N x N matrix into how many N/2 x N/2 sub-matrices?", "A. 2", "B. 4", "C. 7", "D. 8", "B"
"StrassenMatrix", "The 'combine' step in Strassen's algorithm involves synthesizing the final matrix from the 7 products using how many total matrix additions/subtractions?", "A. 7", "B. 10", "C. 18", "D. 24", "C"
"StrassenMatrix", "The asymptotic improvement from `N^3` to `N^log2(7)` is significant because:", "A. It means a linear speedup.", "B. It means a polynomial reduction in complexity, leading to much faster computation for very large N.", "C. It only applies to small matrices.", "D. It makes the algorithm simpler.", "B"
"StrassenMatrix", "If the recursion depth of Strassen's algorithm is `log2(N)`, how many levels of recursion are there?", "A. `N`", "B. `log2(N)`", "C. `N/2`", "D. `2*N`", "B"
"StrassenMatrix", "What is the result of `[[1, 2], [3, 4]] * [[5, 6], [7, 8]]` using any method?", "A. `[[19, 22], [43, 50]]`", "B. `[[5, 12], [21, 32]]`", "C. `[[19, 22], [50, 43]]`", "D. `[[19, 43], [22, 50]]`", "A"
"StrassenMatrix", "Can Strassen's algorithm be used for sparse matrices efficiently?", "A. Yes, it's ideal for sparse matrices.", "B. Not directly; specialized sparse matrix multiplication algorithms are usually more efficient.", "C. Only if the sparse matrices are very large.", "D. Only if the sparse matrices are diagonal.", "B"
"StrassenMatrix", "What is the general relationship between the theoretical best algorithm and practical implementations for matrix multiplication?", "A. The theoretical best is always used in practice.", "B. Practical implementations often use hybrid approaches, combining Strassen's for large matrices with naive for smaller ones, and highly optimized for specific hardware.", "C. Practical implementations only use the naive algorithm.", "D. Theoretical algorithms are never implemented.", "B"
"StrassenMatrix", "The development of Strassen's algorithm opened the door for further research into algorithms with even lower exponents for matrix multiplication. True or False?", "A. True", "B. False", "A"
"Karatsuba", "What problem does the Karatsuba algorithm solve?", "A. Matrix multiplication.", "B. Fast multiplication of large integers.", "C. Sorting a list of numbers.", "D. Searching for an element in an array.", "B"
"Karatsuba", "What algorithmic paradigm does Karatsuba's algorithm fall under?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Divide and Conquer", "D. Brute Force", "C"
"Karatsuba", "What is the time complexity of the naive multiplication algorithm for two N-digit numbers?", "A. O(N)", "B. O(N log N)", "C. O(N^2)", "D. O(N^3)", "C"
"Karatsuba", "What is the time complexity of the Karatsuba algorithm for two N-digit numbers?", "A. O(N^2)", "B. O(N log N)", "C. O(N^(log2 3)) (approximately O(N^1.585))", "D. O(N)", "C"
"Karatsuba", "Karatsuba's algorithm improves upon the naive method by reducing the number of what operation?", "A. Additions", "B. Subtractions", "C. Multiplications of sub-problems.", "D. Divisions", "C"
"Karatsuba", "How many multiplications of sub-problems (of half the original size) does the naive Divide and Conquer multiplication perform?", "A. 2", "B. 3", "C. 4", "D. 5", "C"
"Karatsuba", "How many multiplications of sub-problems (of half the original size) does Karatsuba's algorithm perform?", "A. 2", "B. 3", "C. 4", "D. 5", "B"
"Karatsuba", "What is the recurrence relation for the time complexity of Karatsuba's algorithm?", "A. T(N) = 4T(N/2) + O(N)", "B. T(N) = 3T(N/2) + O(N)", "C. T(N) = 2T(N/2) + O(N)", "D. T(N) = T(N-1) + O(N)", "B"
"Karatsuba", "The `O(N)` term in Karatsuba's recurrence relation `T(N) = 3T(N/2) + O(N)` represents the time spent on:", "A. Recursive calls.", "B. Addition and subtraction of intermediate results.", "C. Base cases.", "D. Initializing numbers.", "B"
"Karatsuba", "Karatsuba's algorithm is beneficial for numbers of what size?", "A. Very small numbers (e.g., single digits).", "B. Large numbers (typically hundreds or thousands of digits).", "C. Any size, always.", "D. Only prime numbers.", "B"
"Karatsuba", "What is the base case for Karatsuba's algorithm recursion?", "A. When the numbers have 0 digits.", "B. When the numbers have 1 digit (or a small constant number of digits where naive multiplication is faster).", "C. When the numbers are prime.", "D. When the numbers are zero.", "B"
"Karatsuba", "What is the primary advantage of Karatsuba's algorithm over naive multiplication?", "A. Simpler implementation.", "B. Significant reduction in time complexity for large numbers.", "C. Less memory usage.", "D. It handles negative numbers directly.", "B"
"Karatsuba", "When multiplying two N-digit numbers `X` and `Y`, they are typically split into two halves. If `N` is odd, how is this handled?", "A. Karatsuba cannot be used.", "B. One half has `N/2` digits, the other `N/2 + 1` (integer division).", "C. The numbers are padded with leading zeros to make `N` even.", "D. It converts to a floating-point multiplication.", "B"
"Karatsuba", "The core idea is that multiplying `X = a*10^(N/2) + b` and `Y = c*10^(N/2) + d` can be done with fewer than 4 recursive multiplications. Which expression is key to this reduction?", "A. `(a+b)*(c+d)`", "B. `(a*c) + (b*d)`", "C. `a*d + b*c`", "D. `(a+c)*(b+d)`", "A"
"Karatsuba", "Let `P1 = a*c`, `P2 = b*d`, and `P3 = (a+b)*(c+d)`. How is the middle term `a*d + b*c` calculated using these products?", "A. `P1 + P2 + P3`", "B. `P3 - P1 - P2`", "C. `P1 * P2`", "D. `P1 + P2`", "B"
"Karatsuba", "What is the primary drawback of Karatsuba's algorithm in practice for very small numbers?", "A. Higher constant factors and increased overhead for additions/subtractions/splitting.", "B. It's not stable.", "C. It's difficult to parallelize.", "D. It only works for positive integers.", "A"
"Karatsuba", "Karatsuba's algorithm's performance advantage over naive multiplication typically becomes significant for `N` values greater than a certain threshold. What is this threshold generally around?", "A. 2-4 digits.", "B. 10-20 digits (or more for practical implementations).", "C. 1000 digits.", "D. 1,000,000 digits.", "B"
"Karatsuba", "What is the contribution of Anatoly Karatsuba to this algorithm?", "A. He invented the first O(N^2) multiplication algorithm.", "B. He proved that matrix multiplication could be faster than O(N^3).", "C. He showed that two N-digit numbers could be multiplied in sub-quadratic time (O(N^log2 3)).", "D. He developed the first quantum algorithm for multiplication.", "C"
"Karatsuba", "The space complexity of Karatsuba's algorithm is primarily determined by:", "A. The size of the input numbers.", "B. The recursion depth and storage for intermediate sums.", "C. The number of digits in the result.", "D. Hash table usage.", "B"
"Karatsuba", "What is `log2(3)` approximately?", "A. 1.0", "B. 1.585", "C. 2.0", "D. 3.0", "B"
"Karatsuba", "If `X = 1234` and `Y = 5678`, and `N=4`, how would they be split into `a, b, c, d` where `N/2 = 2`?", "A. `a=1, b=234, c=5, d=678`", "B. `a=12, b=34, c=56, d=78`", "C. `a=123, b=4, c=567, d=8`", "D. `a=1, b=2, c=3, d=4`", "B"
"Karatsuba", "When multiplying `a` and `c`, `b` and `d`, `(a+b)` and `(c+d)` in the recursive steps, these are all multiplications of numbers with approximately what number of digits?", "A. `N`", "B. `N/2`", "C. `N/4`", "D. `2N`", "B"
"Karatsuba", "Can Karatsuba's algorithm be used for polynomial multiplication?", "A. No, only integers.", "B. Yes, the same principles apply by treating coefficients as 'digits'.", "C. Only for polynomials of degree 1.", "D. Only for real coefficients.", "B"
"Karatsuba", "The time taken for additions and subtractions of numbers with `N` digits is `O(N)`. True or False?", "A. True", "B. False", "A"
"Karatsuba", "What is a potential challenge when implementing Karatsuba's algorithm with arbitrary precision integers?", "A. Fixed-size integer types are sufficient.", "B. Efficiently handling variable-length arithmetic (addition, subtraction, shifting).", "C. Only positive numbers are allowed.", "D. The algorithm is not recursive.", "B"
"Karatsuba", "What is the primary reason for switching to naive multiplication for small `N` in a practical Karatsuba implementation?", "A. Naive multiplication is asymptotically faster for small N.", "B. The overhead of recursive calls and sub-problem management for Karatsuba is too high for small N.", "C. Naive multiplication uses less memory for small N.", "D. Karatsuba is less accurate for small N.", "B"
"Karatsuba", "Karatsuba's algorithm is an example of a technique to reduce the exponent of complexity. What other algorithm does this for matrix multiplication?", "A. Strassen's algorithm", "B. Quicksort", "C. Merge Sort", "D. Dijkstra's algorithm", "A"
"Karatsuba", "What is `2 * 10^(N/2)` equivalent to in terms of 'shifting' operations?", "A. Left shifting a number `2` by `N/2` places.", "B. Adding `N/2` zeros to the right of `2`. ", "C. Multiplying `2` by `10` `N/2` times.", "D. Both A and C are conceptually similar, depending on base.", "C"
"Karatsuba", "If `X = 21` and `Y = 32`, using Karatsuba, `N=2`. `a=2, b=1, c=3, d=2`. What is `P1 = a*c`?", "A. 2", "B. 3", "C. 6", "D. 21", "C"
"Karatsuba", "Using `X = 21` and `Y = 32`. `a=2, b=1, c=3, d=2`. What is `P2 = b*d`?", "A. 1", "B. 2", "C. 3", "D. 6", "B"
"Karatsuba", "Using `X = 21` and `Y = 32`. `a=2, b=1, c=3, d=2`. What is `P3 = (a+b)*(c+d)`?", "A. `(2+1)*(3+2) = 3*5 = 15`", "B. `(2+3)*(1+2) = 5*3 = 15`", "C. `(2*3)+(1*2) = 8`", "D. `(2+1)*3 + (3+2)*1 = 9+5 = 14`", "A"
"Karatsuba", "Using `P1=6, P2=2, P3=15`. What is the middle term `ad + bc` (`P3 - P1 - P2`)?", "A. `15 - 6 - 2 = 7`", "B. `15 + 6 + 2 = 23`", "C. `6 + 2 = 8`", "D. `15 - 6 = 9`", "A"
"Karatsuba", "The final result of `X*Y` is `P1*10^N + (ad + bc)*10^(N/2) + P2`. For `X=21, Y=32, N=2`, `P1=6, P2=2, ad+bc=7`. What is the final result?", "A. `6*10^2 + 7*10^1 + 2 = 600 + 70 + 2 = 672`", "B. `6*10^1 + 7*10^0 + 2 = 60 + 7 + 2 = 69`", "C. `6*10^2 + 2*10^1 + 7 = 627`", "D. `6 + 7 + 2 = 15`", "A"
"Karatsuba", "Karatsuba's algorithm is generally faster than the schoolbook method for numbers with more than approximately ____ bits (not decimal digits).", "A. 4-8 bits", "B. 32-64 bits (common machine word size)", "C. Thousands of bits", "D. Millions of bits", "B"
"Karatsuba", "The efficiency gain of Karatsuba's algorithm comes from replacing one multiplication with how many additions/subtractions?", "A. 1 addition, 1 subtraction.", "B. 2 additions, 2 subtractions.", "C. 3 additions, 2 subtractions.", "D. 4 additions, 3 subtractions.", "D"
"Karatsuba", "Is Karatsuba's algorithm considered a 'fast Fourier transform (FFT) based' multiplication algorithm?", "A. Yes", "B. No (FFT-based algorithms like Schönhage-Strassen are asymptotically faster but have higher constant factors).", "B"
"Karatsuba", "For numbers that fit within standard integer types (e.g., `int`, `long long` in C++), is Karatsuba's algorithm typically used?", "A. Yes, it's the standard library method.", "B. No, direct hardware multiplication is far faster for fixed-size types.", "C. Only for negative numbers.", "D. Only for prime numbers.", "B"
"Karatsuba", "The fundamental idea behind Karatsuba's algorithm can be generalized to algorithms for polynomial multiplication and matrix multiplication (e.g., Strassen's). True or False?", "A. True", "B. False", "A"
"Karatsuba", "What happens if the input numbers have different numbers of digits (e.g., one N digits, one M digits, M < N)?", "A. Karatsuba cannot be used.", "B. The shorter number is typically padded with leading zeros to match the length of the longer number.", "C. The algorithm adjusts dynamically.", "D. It returns an error.", "B"
"Karatsuba", "The initial sorting of digits is not required for Karatsuba. True or False?", "A. True (it operates on segments of digits, not their sorted order).", "B. False", "A"
"Karatsuba", "Karatsuba's algorithm is known for its numerical stability. True or False?", "A. True (as it's exact integer arithmetic).", "B. False", "A"
"Karatsuba", "Compared to the naive O(N^2) method, Karatsuba's algorithm demonstrates a _______ improvement in asymptotic complexity.", "A. Linear", "B. Logarithmic", "C. Polynomial (from N^2 to N^1.585)", "D. Constant", "C"
"Karatsuba", "If the recursion depth for multiplying N-digit numbers is `log2(N)`, how many levels of recursion are there?", "A. `N`", "B. `log2(N)`", "C. `N/2`", "D. `2*N`", "B"
"Karatsuba", "The development of Karatsuba's algorithm was a significant breakthrough because it was the first sub-quadratic algorithm for multiplication. True or False?", "A. True", "B. False", "A"
"Karatsuba", "What is an important optimization often applied to Karatsuba's algorithm?", "A. Using floating-point numbers instead of integers.", "B. Switching to the naive algorithm when the numbers become small enough.", "C. Avoiding recursive calls entirely.", "D. Using a hash table for intermediate results.", "B"
"Karatsuba", "Can Karatsuba's algorithm be parallelized?", "A. No, it's inherently sequential.", "B. Yes, the three recursive multiplication calls can be executed in parallel.", "C. Only for very small numbers.", "D. Only on a single core.", "B"
"Karatsuba", "What kind of data structure would be suitable for representing the large integers in a Karatsuba implementation?", "A. A single `int` variable.", "B. An array or vector of digits (e.g., base 10 or base `2^k`).", "C. A linked list of digits.", "D. A hash map.", "B"
"Karatsuba", "The time savings of Karatsuba's algorithm become more pronounced as the number of digits `N`:", "A. Decreases.", "B. Stays the same.", "C. Increases.", "D. Becomes prime.", "C"
"Karatsuba", "What is the result of `10^1 * 10^1` using Karatsuba? (Base case: 1 digit multiplication `1*1=1`)", "A. `10`", "B. `100` (`X=10, Y=10`, a=1,b=0,c=1,d=0. P1=1*1=1, P2=0*0=0, P3=(1+0)*(1+0)=1. middle=P3-P1-P2=1-1-0=0. Result = 1*10^2 + 0*10^1 + 0 = 100)", "C. `1`", "D. `0`", "B"
"Karatsuba", "Which of the following is an example of an algorithm that is asymptotically faster than Karatsuba for extremely large numbers?", "A. Schoolbook Multiplication", "B. Toom-Cook algorithm", "C. Insertion Sort", "D. Bubble Sort", "B"
"BranchAndBound", "What is the primary goal of the Branch and Bound algorithm?", "A. To find all possible solutions to a problem.", "B. To find an optimal solution to optimization problems (often integer or combinatorial).", "C. To determine if a solution exists.", "D. To sort a list of elements efficiently.", "B"
"BranchAndBound", "Which algorithmic paradigm is Branch and Bound most closely related to?", "A. Greedy Algorithms", "B. Dynamic Programming", "C. Backtracking", "D. Divide and Conquer", "C"
"BranchAndBound", "The 'Branch' step in Branch and Bound refers to:", "A. Pruning branches that cannot lead to an optimal solution.", "B. Exploring only one path at a time.", "C. Dividing the problem's solution space into smaller subproblems.", "D. Merging solutions from subproblems.", "C"
"BranchAndBound", "The 'Bound' step in Branch and Bound refers to:", "A. Limiting the search depth.", "B. Calculating an upper or lower bound on the optimal solution for a subproblem.", "C. Bounding the number of variables.", "D. Bounding the execution time.", "B"
"BranchAndBound", "What is the purpose of pruning in Branch and Bound?", "A. To discard subproblems that are too complex.", "B. To eliminate portions of the search space that cannot contain an optimal solution better than the current best known solution.", "C. To limit the number of branches explored.", "D. To reduce memory usage regardless of optimality.", "B"
"BranchAndBound", "Branch and Bound is particularly effective for which class of problems?", "A. Problems with polynomial time complexity.", "B. NP-hard (or NP-complete) optimization problems.", "C. Problems with greedy choice property.", "D. Problems with overlapping subproblems.", "B"
"BranchAndBound", "What type of search strategy is typically used to explore the state space tree in Branch and Bound?", "A. Breadth-First Search (BFS).", "B. Depth-First Search (DFS).", "C. Best-First Search (using a priority queue).", "D. Any of the above, depending on the specific implementation/problem.", "D"
"BranchAndBound", "In a minimization problem, what kind of bound is typically used to prune branches?", "A. An upper bound (current best solution found so far).", "B. A lower bound (on the current subproblem's potential solution).", "C. Both A and B are used: if a subproblem's lower bound is worse than the current overall upper bound, prune it.", "D. Neither.", "C"
"BranchAndBound", "In a maximization problem, what kind of bound is typically used to prune branches?", "A. An upper bound (on the current subproblem's potential solution).", "B. A lower bound (current best solution found so far).", "C. Both A and B are used: if a subproblem's upper bound is worse than the current overall lower bound, prune it.", "D. Neither.", "C"
"BranchAndBound", "What is the 'global optimum' or 'current best' solution found so far called in Branch and Bound?", "A. Candidate solution.", "B. Feasible solution.", "C. Incumbent solution (or 'primal bound').", "D. Local optimum.", "C"
"BranchAndBound", "Which of the following problems can be solved using Branch and Bound?", "A. Merge Sort", "B. Knapsack Problem (0/1 or Fractional)", "C. Shortest Path in a simple graph", "D. Bubble Sort", "B"
"BranchAndBound", "The Traveling Salesperson Problem (TSP) is a classic example often solved using Branch and Bound. True or False?", "A. True", "B. False", "A"
"BranchAndBound", "The Assignment Problem can be solved using Branch and Bound. True or False?", "A. True", "B. False", "A"
"BranchAndBound", "What is the goal of the 'Bounding' function?", "A. To calculate the exact solution for the subproblem.", "B. To estimate the best possible solution for a subproblem (or its worst possible cost) without fully solving it.", "C. To count the number of nodes in the search tree.", "D. To determine if a subproblem is feasible.", "B"
"BranchAndBound", "A good bounding function should be:", "A. Easy to compute and provide a tight estimate (close to the true optimum for the subproblem).", "B. Very complex to compute.", "C. Always return 0.", "D. Always return infinity.", "A"
"BranchAndBound", "In the 0/1 Knapsack problem, how can a lower/upper bound be calculated for a subproblem?", "A. By solving the problem greedily.", "B. By solving its fractional knapsack relaxation.", "C. By using dynamic programming.", "D. By checking all possible subsets.", "B"
"BranchAndBound", "What is the advantage of using Branch and Bound over pure Brute Force for NP-hard problems?", "A. It guarantees a faster polynomial-time solution.", "B. It systematically explores the search space but can prune parts that won't yield optimal solutions, making it often much faster in practice.", "C. It always finds a solution, even if not optimal.", "D. It uses less memory.", "B"
"BranchAndBound", "What is the disadvantage of Branch and Bound?", "A. It is always slower than brute force.", "B. It can still take exponential time in the worst case.", "C. It only works for very small problems.", "D. It does not find an optimal solution.", "B"
"BranchAndBound", "When designing a Branch and Bound algorithm, the order of node (subproblem) selection from the exploration list can impact performance. True or False?", "A. True", "B. False", "A"
"BranchAndBound", "Using a Best-First Search strategy (e.g., expanding the node with the most promising bound) in Branch and Bound aims to:", "A. Find a solution quickly, but not necessarily optimal.", "B. Find the optimal solution faster by prioritizing promising paths.", "C. Reduce memory consumption.", "D. Always explore the deepest path first.", "B"
"BranchAndBound", "What is the state space tree in Branch and Bound?", "A. A tree of all possible final solutions.", "B. A tree where nodes represent subproblems and edges represent choices or assignments.", "C. A tree representing the input data structure.", "D. A tree of only optimal paths.", "B"
"BranchAndBound", "A node in the search tree can be pruned if its bound is _______ the current best solution.", "A. Better than", "B. Equal to", "C. Worse than (e.g., lower bound in minimization problem is greater than current best upper bound).", "D. Different from", "C"
"BranchAndBound", "For the TSP, a common lower bound for a subproblem (partial tour) can be computed using:", "A. Greedy approach to complete the tour.", "B. A minimum spanning tree (MST) of the remaining unvisited cities plus connections to already visited ones.", "C. Dynamic programming on subsets.", "D. Simple summation of edge weights.", "B"
"BranchAndBound", "The efficiency of a Branch and Bound algorithm heavily relies on:", "A. The size of the input.", "B. The quality (tightness) of the bounding function.", "C. The number of variables.", "D. The type of graph used.", "B"
"BranchAndBound", "If the bounding function always returns a very loose bound (e.g., 0 for a minimization problem), what happens?", "A. The algorithm becomes very efficient.", "B. The algorithm degenerates to a nearly brute-force search (very little pruning).", "C. The algorithm finds a non-optimal solution.", "D. The algorithm stops immediately.", "B"
"BranchAndBound", "In Branch and Bound, if a complete, feasible solution is found, and its cost is better than the current incumbent solution, what happens?", "A. The algorithm terminates.", "B. The incumbent solution is updated to this new solution.", "C. The search space is reset.", "D. The bounding function is re-evaluated.", "B"
"BranchAndBound", "What is a 'node' in the context of the Branch and Bound search tree?", "A. A single data element.", "B. A subproblem or partial solution.", "C. A leaf of the tree.", "D. An edge connecting two solutions.", "B"
"BranchAndBound", "Which of the following is NOT a typical component of a Branch and Bound algorithm?", "A. A branching rule.", "B. A bounding function.", "C. A pruning rule.", "D. A fixed iteration count.", "D"
"BranchAndBound", "What is the primary role of the branching rule?", "A. To decide which node to prune next.", "B. To select the next subproblem to explore.", "C. To partition a problem into smaller subproblems.", "D. To calculate the bound.", "C"
"BranchAndBound", "What is a common technique to improve the efficiency of Branch and Bound in practice?", "A. Always using a fixed pivot.", "B. Using heuristics to find good initial incumbent solutions.", "C. Avoiding any form of pruning.", "D. Limiting the search space to only optimal solutions.", "B"
"BranchAndBound", "Branch and Bound methods are often used for problems in which field?", "A. Data compression.", "B. Operations Research and Combinatorial Optimization.", "C. Image processing.", "D. Natural Language Processing.", "B"
"BranchAndBound", "For the Integer Linear Programming (ILP) problem, Branch and Bound often relies on solving what at each node?", "A. A simpler dynamic programming problem.", "B. The relaxed Linear Programming (LP) problem.", "C. A graph traversal problem.", "D. A sorting problem.", "B"
"BranchAndBound", "If a subproblem's bound indicates it cannot yield a solution better than the current best known, that subproblem's entire subtree is discarded. This is known as:", "A. Backtracking.", "B. Greedy choice.", "C. Pruning.", "D. Memoization.", "C"
"BranchAndBound", "Is Branch and Bound a complete algorithm (i.e., guaranteed to find an optimal solution if one exists)?", "A. No, it's a heuristic.", "B. Yes, assuming sufficient time and memory.", "C. Only for specific types of problems.", "D. Only if the search space is infinite.", "B"
"BranchAndBound", "What is an 'active node' in a Branch and Bound algorithm?", "A. A node that has been pruned.", "B. A node that has been fully explored.", "C. A node representing a subproblem that has been created but not yet fully processed or pruned.", "D. A node that contains the optimal solution.", "C"
"BranchAndBound", "Which data structure is commonly used to store active nodes?", "A. Stack (for DFS-like behavior).", "B. Queue (for BFS-like behavior).", "C. Priority Queue (for Best-First Search).", "D. Any of the above, depending on strategy.", "D"
"BranchAndBound", "If the objective function is to minimize `f(x)`, and a node `u` has a lower bound `L(u)`. If the current best solution found so far has cost `C_best`, when can `u` be pruned?", "A. If `L(u) < C_best`", "B. If `L(u) > C_best`", "C. If `L(u) == C_best`", "D. Never, `L(u)` is always relevant.", "B"
"BranchAndBound", "If the objective function is to maximize `f(x)`, and a node `u` has an upper bound `U(u)`. If the current best solution found so far has cost `C_best`, when can `u` be pruned?", "A. If `U(u) < C_best`", "B. If `U(u) > C_best`", "C. If `U(u) == C_best`", "D. Never, `U(u)` is always relevant.", "A"
"BranchAndBound", "The effectiveness of Branch and Bound often depends on the quality of the _______ heuristic.", "A. Sorting", "B. Searching", "C. Initial solution and bounding function.", "D. Graph traversal", "C"
"BranchAndBound", "Is it possible for Branch and Bound to find a non-optimal solution?", "A. Yes, if it's a heuristic variant.", "B. No, if implemented correctly, it guarantees optimality.", "C. Only if the input is unsorted.", "D. Only if the problem is NP-hard.", "B"
"BranchAndBound", "What is the relationship between Branch and Bound and Backtracking?", "A. They are identical.", "B. Branch and Bound is an extension of Backtracking that adds bounding (pruning) to optimize the search.", "C. Backtracking is an extension of Branch and Bound.", "D. They are unrelated.", "B"
"BranchAndBound", "Branch and Bound is often used when a problem cannot be solved efficiently by which other methods?", "A. Polynomial time algorithms (greedy, DP) and brute force is too slow.", "B. Random search.", "C. Simple arithmetic operations.", "D. Data input.", "A"
"BranchAndBound", "What is the main challenge in applying Branch and Bound to a new problem?", "A. Defining the problem statement.", "B. Identifying suitable branching rules and effective bounding functions.", "C. Choosing the right programming language.", "D. Drawing the state space tree.", "B"
"BranchAndBound", "What is the term for the process of reducing the domain of variables or tightening constraints within a subproblem?", "A. Relaxation.", "B. Reduction (or constraint propagation).", "C. Splitting.", "D. Expansion.", "B"
"BranchAndBound", "In a scenario like the 0/1 Knapsack problem, if the capacity is very small relative to item weights, the Branch and Bound tree might be:", "A. Very deep and wide.", "B. Relatively shallow and narrow, as many branches are pruned early.", "C. Non-existent.", "D. Circular.", "B"
"BranchAndBound", "What is the primary difference between a bound and a heuristic estimate?", "A. A bound provides a guaranteed limit (upper or lower) on the optimal solution, while a heuristic is an educated guess.", "B. A heuristic is always exact, a bound is not.", "C. They are the same thing.", "D. Bounds are used only for maximization problems.", "A"
"BranchAndBound", "The problem of finding the maximum clique in a graph can be approached using Branch and Bound. True or False?", "A. True", "B. False", "A"
"BranchAndBound", "What happens if the bounding function is too computationally expensive?", "A. The algorithm will be faster.", "B. The benefits of pruning might be offset by the cost of computing the bounds, slowing down the algorithm overall.", "C. It will always find the optimal solution.", "D. It will lead to an infinite loop.", "B"
"BranchAndBound", "A good Branch and Bound implementation will dynamically switch between DFS and BFS strategies based on problem characteristics or current search progress. True or False?", "A. True (this is part of advanced implementations, e.g., using limited discrepancy search).", "B. False", "A"
"BranchAndBound", "The 'incumbent solution' is updated when a new feasible solution is found that is better than the current best. True or False?", "A. True", "B. False", "A"
"NQueens", "What is the primary objective of the N-Queens problem?", "A. To place N pawns on an N×N chessboard.", "B. To place N queens on an N×N chessboard such that no two queens attack each other.", "C. To find the shortest path between two queens.", "D. To calculate the number of squares a queen can attack.", "B"
"NQueens", "Which algorithmic paradigm is most commonly used to solve the N-Queens problem?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Backtracking", "D. Divide and Conquer", "C"
"NQueens", "How do queens attack each other on a chessboard?", "A. Only horizontally.", "B. Only vertically.", "C. Horizontally, vertically, and diagonally.", "D. Only diagonally.", "C"
"NQueens", "For an N×N board, how many queens need to be placed?", "A. N/2", "B. N", "C. N^2", "D. 1", "B"
"NQueens", "What is the 'state' in the backtracking solution for N-Queens?", "A. The entire chessboard.", "B. The current row being considered for placing a queen.", "C. The number of queens placed so far.", "D. The final solution.", "B"
"NQueens", "In a backtracking approach, what does a 'feasible' placement mean for a queen in a given cell `(row, col)`?", "A. That `(row, col)` is empty.", "B. That no other queen placed in previous rows attacks `(row, col)`.", "C. That `(row, col)` is a black square.", "D. That it's the last square in the row.", "B"
"NQueens", "What is the 'backtrack' step in the N-Queens algorithm?", "A. Moving to the next column in the same row.", "B. Removing the last placed queen and trying a different position in the previous row.", "C. Starting the entire solution from scratch.", "D. Checking for more solutions in the current row.", "B"
"NQueens", "When does the N-Queens algorithm find a valid solution?", "A. When a queen is placed in every column.", "B. When a queen is placed in every row (all N queens are successfully placed).", "C. When all squares are filled.", "D. When no more moves are possible.", "B"
"NQueens", "What is the smallest `N` for which no solution exists for the N-Queens problem?", "A. N=1", "B. N=2", "C. N=3", "D. N=4", "B"
"NQueens", "For N=1, how many solutions are there for the N-Queens problem?", "A. 0", "B. 1", "C. 2", "D. Infinitely many", "B"
"NQueens", "For N=4, how many distinct solutions are there for the N-Queens problem?", "A. 0", "B. 1", "C. 2", "D. 4", "C"
"NQueens", "Which data structure is typically used to represent the chessboard in the N-Queens problem?", "A. Linked list", "B. Adjacency list", "C. A 2D array (matrix) or a 1D array to store column positions for each row.", "D. Stack", "C"
"NQueens", "How can you efficiently check for diagonal attacks?", "A. By checking absolute difference of row and column indices: `abs(row1 - row2) == abs(col1 - col2)`.", "B. By checking `row1 == row2`.", "C. By checking `col1 == col2`.", "D. By checking `row1 + col1 == row2 + col2` only.", "A"
"NQueens", "To check for column attacks, if you store the column position of the queen in `board[row] = col`, what condition needs to be met?", "A. `board[i] == col` for any `i < row`.", "B. `board[i] == row` for any `i < row`.", "C. `board[i] == i` for any `i < row`.", "D. `board[i] == col + 1` for any `i < row`.", "A"
"NQueens", "The time complexity of the N-Queens problem using backtracking is generally:", "A. O(N)", "B. O(N^2)", "C. Closer to O(N!) (as it explores permutations, but pruned).", "D. O(log N)", "C"
"NQueens", "What is the space complexity of the N-Queens problem using backtracking?", "A. O(1)", "B. O(N) (for storing column positions and recursion stack).", "C. O(N^2)", "D. O(N!)", "B"
"NQueens", "The N-Queens problem is a classic example of a problem solved using:", "A. Optimal substructure.", "B. Depth-First Search with pruning.", "C. Greedy choice property.", "D. Breadth-First Search.", "B"
"NQueens", "What is the role of the `isSafe` (or `isValid`) function in the N-Queens solution?", "A. To check if the current row is valid.", "B. To check if a queen can be placed at `(row, col)` without being attacked by previously placed queens.", "C. To check if the entire board is sorted.", "D. To count the number of solutions.", "B"
"NQueens", "If `N=3`, is there any solution to the N-Queens problem?", "A. Yes, 1 solution.", "B. Yes, 2 solutions.", "C. No solutions.", "D. Infinitely many.", "C"
"NQueens", "In a typical recursive N-Queens solution, what parameter often represents the current row being considered?", "A. `N`", "B. `col`", "C. `row`", "D. `count`", "C"
"NQueens", "When implementing the N-Queens solution, how can you efficiently check if a diagonal is attacked without iterating through all previously placed queens?", "A. Using three boolean arrays/sets: `colUsed`, `diag1Used` (for `row+col`), `diag2Used` (for `row-col`).", "B. By checking only adjacent cells.", "C. By using a hash map for all attacked squares.", "D. By sorting the board.", "A"
"NQueens", "For `N=8` (standard chessboard), how many distinct solutions are there for the N-Queens problem?", "A. 1", "B. 2", "C. 4", "D. 92", "D"
"NQueens", "What happens when the `placeQueen(row)` function cannot find a safe column in the current `row`?", "A. It stops and declares no solution.", "B. It increments `row` and tries again.", "C. It backtracks to the previous row (`row-1`) and tries a different column for the queen there.", "D. It clears the entire board.", "C"
"NQueens", "Is the N-Queens problem an optimization problem or a counting/decision problem?", "A. Optimization (find minimum attacks).", "B. Counting/Decision (find all solutions or if a solution exists).", "C. Both.", "D. Neither.", "B"
"NQueens", "Does the order in which columns are tried in a row affect the correctness of the N-Queens solution (finding all solutions)?", "A. Yes, always.", "B. No, as long as all columns are systematically tried.", "C. Only for N > 4.", "D. Only if the board is unsorted.", "B"
"NQueens", "What does a leaf node in the N-Queens recursion tree represent?", "A. A dead end (no solution from this path).", "B. A complete and valid arrangement of N queens.", "C. An invalid arrangement.", "D. The start of the problem.", "A"
"NQueens", "What is the purpose of the 'count' variable in some N-Queens implementations?", "A. To count the number of queens placed in a row.", "B. To count the total number of distinct solutions found.", "C. To count the number of recursive calls.", "D. To count the board size.", "B"
"NQueens", "The N-Queens problem is considered NP-complete. True or False?", "A. False (it's not known to be NP-complete, though the search space is exponential).", "B. True", "A"
"NQueens", "Could a greedy approach work for the N-Queens problem?", "A. Yes, always finds optimal solution.", "B. No, a greedy choice (placing a queen in the first safe spot) might lead to a dead end and not yield a full solution.", "C. Only for small N.", "D. Only if the board is empty.", "B"
"NQueens", "If a queen is placed at `(r, c)`, which cells are on its primary diagonal (`row - col = constant`)?", "A. `(r+k, c+k)` and `(r-k, c-k)` for any `k`.", "B. `(r+k, c-k)` and `(r-k, c+k)` for any `k`.", "C. `(r, c+k)` and `(r, c-k)` for any `k`.", "D. `(r+k, c)` and `(r-k, c)` for any `k`.", "A"
"NQueens", "If a queen is placed at `(r, c)`, which cells are on its secondary diagonal (`row + col = constant`)?", "A. `(r+k, c+k)` and `(r-k, c-k)` for any `k`.", "B. `(r+k, c-k)` and `(r-k, c+k)` for any `k`.", "C. `(r, c+k)` and `(r, c-k)` for any `k`.", "D. `(r+k, c)` and `(r-k, c)` for any `k`.", "B"
"NQueens", "For a solution to the N-Queens problem, how many queens must be in each row and each column?", "A. Any number of queens.", "B. Exactly one queen in each row and each column.", "C. Exactly two queens in each row and each column.", "D. Zero queens in some rows/columns.", "B"
"NQueens", "Can the N-Queens problem be parallelized?", "A. No, it's inherently sequential.", "B. Yes, different branches of the search tree can be explored in parallel.", "C. Only for very small N.", "D. Only for N=1.", "B"
"NQueens", "The maximum possible value for `row + col` for an N×N board (0-indexed) is:", "A. `N-1`", "B. `2N-2`", "C. `N^2`", "D. `N`", "B"
"NQueens", "The minimum possible value for `row - col` for an N×N board (0-indexed) is:", "A. `-(N-1)`", "B. `0`", "C. `N-1`", "D. `N`", "A"
"NQueens", "What is the purpose of the `board` array (or equivalent structure) that stores column positions (e.g., `board[i] = j` means queen in row `i`, col `j`)?", "A. To represent the current partial solution.", "B. To store all possible solutions.", "C. To check for invalid inputs.", "D. To count recursive calls.", "A"
"NQueens", "The N-Queens problem demonstrates the effectiveness of pruning. What does pruning mean in this context?", "A. Eliminating invalid partial solutions early to avoid exploring unpromising paths.", "B. Removing queens from the board.", "C. Reducing the board size.", "D. Sorting the possible solutions.", "A"
"NQueens", "For N=2, why is there no solution?", "A. Because 2 is a prime number.", "B. Any two queens will attack each other horizontally, vertically, or diagonally.", "C. The board is too small.", "D. The problem statement is incorrect.", "B"
"NQueens", "For N=3, why is there no solution?", "A. Due to rotational symmetry.", "B. Any queen placement leads to an attack or a blocked path for subsequent queens.", "C. The board is not square.", "D. It has an odd number of rows.", "B"
"NQueens", "In a typical solution, the recursion depth for an N-Queens problem will be at most:", "A. 1", "B. N", "C. N^2", "D. N!", "B"
"NQueens", "If the N-Queens problem is modified to find *one* solution instead of all, what would change in the algorithm?", "A. The `isSafe` function would be removed.", "B. The recursion would stop and return immediately once the first complete solution is found.", "C. The problem would become O(1).", "D. It would require dynamic programming.", "B"
"NQueens", "Using bit manipulation (bitmasks) can significantly speed up the N-Queens solution for larger N. True or False?", "A. True (by efficiently checking column and diagonal conflicts).", "B. False", "A"
"NQueens", "What information do bitmasks typically store in an optimized N-Queens solution?", "A. Which columns are occupied.", "B. Which primary diagonals are occupied.", "C. Which secondary diagonals are occupied.", "D. All of the above.", "D"
"NQueens", "When using bitmasks, what operations are frequently used to check for conflicts and update the masks?", "A. Addition and subtraction.", "B. Bitwise AND, OR, XOR, and shifts.", "C. Multiplication and division.", "D. String concatenation.", "B"
"NQueens", "A solution to N-Queens means that no two queens share the same: (Select all that apply)", "A. Row", "B. Column", "C. Primary Diagonal", "D. Secondary Diagonal", "A,B,C,D"
"NQueens", "If you are trying to place a queen in `(row, col)`, and `col` is already occupied, what should you do?", "A. Place the queen anyway.", "B. Try the next column in the same row.", "C. Backtrack to the previous row.", "D. Declare failure.", "B"
"NQueens", "The N-Queens problem is a good illustration of how combinatorial problems can be systematically explored. True or False?", "A. True", "B. False", "A"
"NQueens", "What is the main challenge with N-Queens for very large N (e.g., N=100)?", "A. Too many solutions.", "B. The exponential time complexity makes it computationally intractable to find all solutions.", "C. Memory limitations for storing the board.", "D. Difficulty in defining the base case.", "B"
"NQueens", "The 'pruning' in N-Queens directly relates to which part of the `isSafe` check?", "A. Checking for valid row numbers.", "B. Immediately returning `false` if a conflict is detected, avoiding further exploration down that path.", "C. Initializing the board.", "D. Counting solutions.", "B"
"NQueens", "Which of the following problems shares a similar algorithmic approach to N-Queens?", "A. Finding factorial of a number.", "B. Sudoku Solver.", "C. Fibonacci sequence.", "D. Binary Search.", "B"
"TSP", "What is the primary objective of the Traveling Salesperson Problem (TSP)?", "A. To find the shortest path between two specific cities.", "B. To find a tour of a given set of cities, visiting each city exactly once and returning to the starting city, such that the total tour length is minimized.", "C. To find the maximum length tour visiting all cities.", "D. To find any path that visits all cities.", "B"
"TSP", "Which class of computational problems does the TSP belong to?", "A. P (Polynomial time)", "B. NP-complete", "C. P-space complete", "D. Exponential time solvable", "B"
"TSP", "Why is TSP considered an NP-complete problem?", "A. Because it involves finding a path.", "B. Because no known polynomial-time algorithm exists to solve it for all instances, and a given solution can be verified in polynomial time.", "C. Because it is easy to solve.", "D. Because it has only one solution.", "B"
"TSP", "What is the time complexity of the brute-force approach to solve TSP with N cities?", "A. O(N^2)", "B. O(N log N)", "C. O(N!) (N factorial) or O((N-1)!) if starting city is fixed.", "D. O(2^N)", "C"
"TSP", "What does 'symmetric TSP' imply?", "A. All cities are located symmetrically.", "B. The distance from city A to city B is the same as from city B to city A (cost matrix is symmetric).", "C. The tour is always a palindrome.", "D. It has only one unique solution.", "B"
"TSP", "What does 'asymmetric TSP' imply?", "A. The tour starts and ends at different cities.", "B. The distance from city A to city B is not necessarily the same as from city B to city A (cost matrix is not symmetric).", "C. There are multiple optimal solutions.", "D. The graph is directed.", "B"
"TSP", "TSP can be modeled as finding a Hamiltonian cycle with minimum weight in a complete graph. True or False?", "A. True", "B. False", "A"
"TSP", "Which algorithmic paradigm is often used to find exact solutions for small instances of TSP?", "A. Greedy Algorithms", "B. Dynamic Programming (e.g., Held-Karp algorithm)", "C. Divide and Conquer", "D. Backtracking (often combined with Branch and Bound)", "B"
"TSP", "What is the time complexity of the Held-Karp dynamic programming algorithm for TSP with N cities?", "A. O(N^2 * 2^N)", "B. O(N^3)", "C. O(N! * N)", "D. O(N * 2^N)", "A"
"TSP", "What is the space complexity of the Held-Karp dynamic programming algorithm for TSP?", "A. O(N)", "B. O(N^2)", "C. O(N * 2^N)", "D. O(N!)", "C"
"TSP", "For larger instances of TSP, what types of algorithms are often used?", "A. Brute-force algorithms.", "B. Approximation algorithms and heuristics.", "C. Polynomial-time exact algorithms.", "D. Simple sorting algorithms.", "B"
"TSP", "Which of the following is a common greedy heuristic for TSP?", "A. Nearest Neighbor Algorithm", "B. Dijkstra's Algorithm", "C. Prim's Algorithm", "D. Kruskal's Algorithm", "A"
"TSP", "What is a characteristic of the Nearest Neighbor heuristic for TSP?", "A. It always finds the optimal solution.", "B. It is fast but does not guarantee optimality.", "C. It is slow but guarantees optimality.", "D. It works only for symmetric TSP.", "B"
"TSP", "What is the approximation ratio of the Nearest Neighbor algorithm for general TSP?", "A. Always 1 (optimal).", "B. There is no constant approximation ratio; can be arbitrarily bad.", "C. 2", "D. 1.5", "B"
"TSP", "Christofides algorithm provides an approximation ratio for metric TSP. What is its ratio?", "A. 1.5", "B. 2", "C. log N", "D. sqrt(N)", "A"
"TSP", "What does 'metric TSP' (or 'triangle inequality TSP') imply?", "A. All cities form a triangle.", "B. The distances satisfy the triangle inequality: `dist(u, v) <= dist(u, w) + dist(w, v)` for all cities u, v, w.", "C. All edge weights are 1.", "D. The graph is planar.", "B"
"TSP", "Why is the triangle inequality important for some TSP approximation algorithms?", "A. It guarantees a polynomial-time exact solution.", "B. It allows for the construction of tours that are guaranteed to be within a certain factor of the optimal tour.", "C. It simplifies the problem to a P problem.", "D. It means all cities are collinear.", "B"
"TSP", "Which algorithm is related to Christofides algorithm and involves finding an MST and then an Eulerian tour?", "A. Prim's algorithm.", "B. Kruskal's algorithm.", "C. Double MST (or approximation to TSP using MST).", "D. Dijkstra's algorithm.", "C"
"TSP", "What is the core idea behind Branch and Bound for TSP?", "A. To randomly explore tours.", "B. To systematically explore the search space of tours, pruning branches that cannot lead to a better solution than the current best known.", "C. To solve a series of shortest path problems.", "D. To use a greedy approach at each step.", "B"
"TSP", "What is a common lower bound used in Branch and Bound for TSP?", "A. The length of a Hamiltonian path.", "B. The sum of the two shortest edges incident to each vertex, divided by two (or a relaxed assignment problem).", "C. The maximum edge weight.", "D. The number of cities.", "B"
"TSP", "What are the practical implications of TSP being NP-complete?", "A. It can only be solved for extremely small N exactly.", "B. It can be solved quickly for any N.", "C. It implies a linear time solution exists.", "D. It means the problem is easy to approximate.", "A"
"TSP", "TSP has applications in which real-world scenarios?", "A. DNA sequencing.", "B. Logistics and vehicle routing, circuit board drilling.", "C. Image compression.", "D. Text analysis.", "B"
"TSP", "Is the TSP considered a decision problem or an optimization problem?", "A. Decision problem (e.g., does a tour of length K exist?).", "B. Optimization problem (find minimum length tour).", "C. Both (decision version is NP-complete, optimization is NP-hard).", "D. Neither.", "C"
"TSP", "What is the smallest number of cities for which TSP is non-trivial (i.e., not just a direct path and return)?", "A. 1", "B. 2", "C. 3", "D. 4", "C"
"TSP", "If all edge weights in a TSP instance are equal to 1, what is the length of the optimal tour?", "A. 1", "B. N", "C. N-1", "D. N!", "B"
"TSP", "The problem of finding a Hamiltonian cycle is closely related to TSP. True or False?", "A. True", "B. False", "A"
"TSP", "If the graph is complete (every pair of cities is connected), does TSP become easier?", "A. Yes, significantly easier.", "B. No, it remains NP-hard, as the challenge is finding the *minimum* weight cycle.", "C. It becomes a P problem.", "D. Only for small N.", "B"
"TSP", "What is the 2-opt heuristic for TSP?", "A. It randomly swaps two cities in a tour.", "B. It iteratively improves a tour by reversing a segment of the tour if it reduces total length.", "C. It always finds the optimal solution within 2 steps.", "D. It combines two different tours.", "B"
"TSP", "The 2-opt heuristic is an example of what type of algorithm?", "A. Exact algorithm.", "B. Approximation algorithm / Local search heuristic.", "C. Dynamic programming algorithm.", "D. Divide and conquer algorithm.", "B"
"TSP", "Which algorithm guarantees finding the shortest path between two specific nodes in a graph, but is not directly used for finding a full TSP tour?", "A. Floyd-Warshall Algorithm.", "B. Dijkstra's Algorithm.", "C. Bellman-Ford Algorithm.", "D. All of the above are for shortest paths, not TSP directly.", "D"
"TSP", "Can TSP be solved using a greedy approach like Prim's or Kruskal's for finding MSTs?", "A. Yes, directly.", "B. No, because MSTs are trees and do not guarantee a Hamiltonian cycle.", "C. Only for specific graph types.", "D. Only for small N.", "B"
"TSP", "What is the typical output of a TSP algorithm?", "A. The minimum tour length and the sequence of cities in that tour.", "B. A list of all possible tours.", "C. A yes/no answer about tour existence.", "D. The longest tour.", "A"
"TSP", "What is the 'open TSP' (or 'Hamiltonian Path Problem')?", "A. A TSP where the starting and ending cities are different and specified.", "B. A TSP where any city can be visited multiple times.", "C. A TSP without a specific start or end city.", "D. A TSP with no cycle requirement.", "A"
"TSP", "Can Simulated Annealing be used for TSP?", "A. No, it's a sorting algorithm.", "B. Yes, it's a metaheuristic often used to find good approximate solutions for TSP.", "C. Only for exact solutions.", "D. Only for metric TSP.", "B"
"TSP", "What does 'tabu search' aim to do for optimization problems like TSP?", "A. Explore only allowed moves.", "B. Prevent the search from revisiting recently explored solutions to avoid local optima.", "C. Guarantee global optimality.", "D. Use only greedy choices.", "B"
"TSP", "For the general TSP (non-metric), what is the best known polynomial-time approximation ratio?", "A. 1.5", "B. 2", "C. log N", "D. There is no constant-factor polynomial-time approximation unless P=NP.", "D"
"TSP", "What is a common representation for the distances between cities in TSP?", "A. Adjacency List.", "B. Adjacency Matrix (where entries are distances).", "C. Linked List.", "D. Hash Table.", "B"
"TSP", "What is the 'state' in the Held-Karp dynamic programming approach for TSP?", "A. `(current_city, set_of_visited_cities)`.", "B. `(current_city, previous_city)`.", "C. `(number_of_cities, total_distance)`.", "D. `(start_city, end_city)`.", "A"
"TSP", "The complexity of Held-Karp DP algorithm makes it suitable for TSP instances up to what size of N?", "A. Around N=10.", "B. Around N=20-25.", "C. Around N=100.", "D. Any N.", "B"
"TSP", "Is TSP a problem that can benefit from parallel computing for exact solutions?", "A. No, it's inherently sequential.", "B. Yes, by distributing branches of a Branch and Bound search tree across multiple processors.", "C. Only for very small N.", "D. Only for approximation algorithms.", "B"
"TSP", "Which of the following is NOT an exact algorithm for TSP?", "A. Brute Force.", "B. Held-Karp Dynamic Programming.", "C. Branch and Bound.", "D. Nearest Neighbor.", "D"
"TSP", "The problem of finding a shortest path in a graph where edges represent travel time is essentially TSP. True or False?", "A. False (shortest path is between two specific nodes; TSP is a tour of *all* nodes).", "B. True", "A"
"TSP", "What is a 'tour' in TSP terminology?", "A. Any path from start to end.", "B. A closed path that visits every city exactly once and returns to the starting city.", "C. A partial path.", "D. A random walk.", "B"
"TSP", "For practical large-scale TSP instances, algorithms often combine heuristics with optimization techniques to get 'good enough' solutions. True or False?", "A. True", "B. False", "A"
"TSP", "If a TSP problem involves roads that are one-way, what kind of TSP is it?", "A. Symmetric TSP.", "B. Asymmetric TSP.", "C. Planar TSP.", "D. Metric TSP.", "B"
"TSP", "The MST-based approximation algorithm for metric TSP doubles each edge of the MST to create an Eulerian tour. True or False?", "A. True", "B. False", "A"
"TSP", "The complexity class NP-complete suggests that TSP is likely not solvable in polynomial time using a deterministic algorithm. True or False?", "A. True", "B. False", "A"
"TSP", "A TSP instance where cities are points in a plane and distances are Euclidean is called:", "A. Planar TSP.", "B. Euclidean TSP.", "C. Geometric TSP.", "D. All of the above (Euclidean TSP is a type of geometric TSP, which is a type of planar TSP).", "D"
"TSP", "For Euclidean TSP, there are often better approximation algorithms available compared to general TSP. True or False?", "A. True", "B. False", "A"
"TSP", "What is the primary difference between a heuristic and an approximation algorithm for TSP?", "A. Heuristics offer no guarantees on solution quality; approximation algorithms provide a guaranteed bound on how far from optimal the solution will be.", "B. Heuristics are always faster.", "C. Approximation algorithms are always exact.", "D. They are interchangeable terms.", "A"
"JobAssignment", "What is the primary objective of the Job Assignment Problem?", "A. To assign jobs to workers such that each worker gets multiple jobs.", "B. To assign jobs to workers such that each job is assigned to exactly one worker and each worker is assigned to at most one job, optimizing a total cost/profit.", "C. To schedule jobs in a specific order.", "D. To minimize the number of workers.", "B"
"JobAssignment", "What type of problem is the Job Assignment Problem typically classified as?", "A. A shortest path problem.", "B. A bipartite matching problem (often minimum cost perfect matching).", "C. A maximum flow problem.", "D. A sorting problem.", "B"
"JobAssignment", "If there are N jobs and N workers, and each job must be assigned to exactly one worker, and each worker assigned to exactly one job, what is this specific case called?", "A. Unbalanced Assignment Problem.", "B. Balanced Assignment Problem (or Perfect Matching).", "C. Open Assignment Problem.", "D. Max Capacity Assignment Problem.", "B"
"JobAssignment", "What is the time complexity of the brute-force approach to solve the Balanced Job Assignment Problem with N jobs and N workers?", "A. O(N^2)", "B. O(N log N)", "C. O(N!) (N factorial, representing all permutations).", "D. O(2^N)", "C"
"JobAssignment", "Which algorithm is a well-known and efficient method for solving the Balanced Job Assignment Problem?", "A. Dijkstra's Algorithm", "B. Hungarian Algorithm (also known as Munkres' Assignment Algorithm).", "C. Prim's Algorithm", "D. Kruskal's Algorithm", "B"
"JobAssignment", "What is the time complexity of the Hungarian Algorithm for an N x N cost matrix?", "A. O(N^2)", "B. O(N^3)", "C. O(N^4)", "D. O(N!)", "B"
"JobAssignment", "The Hungarian Algorithm is primarily used for which type of assignment problem?", "A. Maximization problems only.", "B. Minimization problems (finding minimum total cost).", "C. Both minimization and maximization problems (with slight modification for maximization).", "D. Unbalanced problems only.", "C"
"JobAssignment", "How can a maximization assignment problem be converted into a minimization problem for the Hungarian Algorithm?", "A. By multiplying all costs by -1.", "B. By subtracting all costs from a large constant value (e.g., the maximum cost in the matrix).", "C. By swapping rows and columns.", "D. It cannot be converted.", "B"
"JobAssignment", "What does it mean if the number of jobs is not equal to the number of workers (unbalanced problem)?", "A. The problem cannot be solved.", "B. Dummy jobs or dummy workers with zero cost are added to balance the matrix.", "C. The Hungarian algorithm is not applicable.", "D. A different algorithm is required.", "B"
"JobAssignment", "The Job Assignment Problem can be formulated as a Linear Programming (LP) problem. True or False?", "A. True", "B. False", "A"
"JobAssignment", "What kind of graph is inherently represented in the Job Assignment Problem?", "A. Directed Acyclic Graph (DAG).", "B. Complete graph.", "C. Bipartite graph (workers on one side, jobs on the other).", "D. Tree.", "C"
"JobAssignment", "What is the primary goal in the 'cost matrix' of the Job Assignment Problem?", "A. To store the profits of each assignment.", "B. To store the cost/effort of assigning a specific job to a specific worker.", "C. To store the time taken for each job.", "D. To store the worker's salary.", "B"
"JobAssignment", "Which algorithmic paradigm can be used to solve the Job Assignment Problem for small instances by systematically exploring possibilities?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Backtracking (often with Branch and Bound)", "D. Divide and Conquer", "C"
"JobAssignment", "In the context of the Job Assignment Problem, what is a 'perfect matching'?", "A. A matching where every worker is assigned to multiple jobs.", "B. A matching where every vertex in the graph (both workers and jobs) is incident to an edge in the matching.", "C. A matching with the highest possible cost.", "D. A matching with no assigned jobs.", "B"
"JobAssignment", "The Hungarian Algorithm relies on finding what in the cost matrix?", "A. Shortest paths.", "B. Zeroes by row/column operations and then finding independent zeroes.", "C. Maximum values.", "D. Minimum spanning trees.", "B"
"JobAssignment", "What is the first step of the Hungarian Algorithm?", "A. Assigning jobs randomly.", "B. Reducing rows (subtracting the smallest element from each row).", "C. Reducing columns.", "D. Drawing lines to cover zeroes.", "B"
"JobAssignment", "After row reduction, what is the next step in the Hungarian Algorithm?", "A. Finding maximum element.", "B. Drawing lines to cover zeroes.", "C. Reducing columns (subtracting the smallest uncovered element from each column).", "D. Adding elements to rows.", "C"
"JobAssignment", "How do you know when an optimal assignment has been found using the Hungarian Algorithm?", "A. When the sum of costs is zero.", "B. When the number of lines required to cover all zeroes is equal to N (the dimension of the matrix).", "C. When all elements are zero.", "D. When the first assignment is made.", "B"
"JobAssignment", "If the number of lines required to cover all zeroes is less than N, what is the next step in the Hungarian Algorithm?", "A. The algorithm terminates.", "B. Adjust the matrix by subtracting the smallest uncovered element from all uncovered elements and adding it to elements covered by two lines.", "C. Redo the initial row reduction.", "D. Add a dummy row/column.", "B"
"JobAssignment", "The Job Assignment Problem is a special case of which more general problem?", "A. Shortest Path Problem.", "B. Minimum Cost Maximum Flow Problem.", "C. Maximum Clique Problem.", "D. Graph Coloring Problem.", "B"
"JobAssignment", "What is the purpose of adding dummy jobs/workers in an unbalanced assignment problem?", "A. To increase the problem's complexity.", "B. To make the cost matrix square, which is required by algorithms like the Hungarian Algorithm.", "C. To ensure some workers get no jobs.", "D. To increase the total cost.", "B"
"JobAssignment", "What cost is usually assigned to dummy jobs or workers?", "A. Infinity.", "B. Negative one.", "C. Zero (for minimization problems).", "D. The average cost.", "C"
"JobAssignment", "Can the Job Assignment Problem be solved using a greedy approach?", "A. Yes, always optimally.", "B. No, a greedy choice (e.g., assigning the cheapest job first) does not guarantee overall optimality.", "C. Only for very small N.", "D. Only if all costs are identical.", "B"
"JobAssignment", "In a Branch and Bound approach for Job Assignment, what could be a lower bound for a partial assignment?", "A. The sum of costs of assigned jobs so far.", "B. The sum of costs of assigned jobs plus the minimum possible cost for the remaining unassigned jobs (e.g., by solving a relaxed version).", "C. The maximum cost in the matrix.", "D. Zero.", "B"
"JobAssignment", "What is a major application area for the Job Assignment Problem?", "A. Route planning for delivery trucks.", "B. Task allocation in project management, resource allocation, scheduling.", "C. Image processing.", "D. Natural language translation.", "B"
"JobAssignment", "If a worker is not suitable for a particular job, how can this be represented in the cost matrix?", "A. By assigning a cost of 0.", "B. By assigning a very high cost (infinity or a very large number).", "C. By leaving the cell empty.", "D. By assigning a negative cost.", "B"
"JobAssignment", "What is the key property of the cost matrix entries that the Hungarian algorithm operates on?", "A. They must be positive integers.", "B. They must be non-negative (can be 0 or positive).", "C. They can be any real number.", "D. They must be unique.", "B"
"JobAssignment", "The Hungarian Algorithm implicitly handles negative costs by converting them to positive. True or False?", "A. True", "B. False (it typically requires non-negative costs; a pre-processing step might be needed if negative costs are allowed).", "B"
"JobAssignment", "What kind of output does the Hungarian Algorithm provide?", "A. Only the total minimum cost.", "B. The total minimum cost and the specific assignment of jobs to workers.", "C. A list of all possible assignments.", "D. A probability distribution of assignments.", "B"
"JobAssignment", "The term 'assignment problem' generally refers to which type of matching?", "A. Any matching.", "B. Maximum cardinality matching.", "C. Minimum cost perfect matching (or maximum weight perfect matching after transformation).", "D. Maximum flow.", "C"
"JobAssignment", "What happens if a row or column in the cost matrix contains all zeros after reduction steps, but no independent zeroes can be found to cover them with N lines?", "A. The algorithm has failed.", "B. The matrix adjustment step (subtracting smallest uncovered, adding to double-covered) is needed.", "C. The problem has no solution.", "D. This state is impossible.", "B"
"JobAssignment", "The 'starring' or 'marking' of zeroes in the Hungarian Algorithm helps to identify what?", "A. Random zeroes.", "B. Independent zeroes that can form a tentative assignment.", "C. Optimal costs.", "D. Elements to be ignored.", "B"
"JobAssignment", "The Job Assignment Problem is a fundamental problem in which field?", "A. Computer Graphics.", "B. Operations Research.", "C. Natural Language Processing.", "D. Cybersecurity.", "B"
"JobAssignment", "What would be the cost of a dummy assignment?", "A. A very large positive number.", "B. Zero.", "C. Negative infinity.", "D. The average cost of real assignments.", "B"
"JobAssignment", "Is it possible for multiple optimal solutions (different assignments with the same minimum total cost) to exist for the Job Assignment Problem?", "A. No, the solution is always unique.", "B. Yes, it's possible.", "C. Only if N is prime.", "D. Only if all costs are zero.", "B"
"JobAssignment", "The Job Assignment Problem can be viewed as finding a minimum weight perfect matching in a complete bipartite graph. True or False?", "A. True", "B. False", "A"
"JobAssignment", "If a worker can perform multiple jobs, is it still a standard Job Assignment Problem?", "A. Yes.", "B. No, this would typically be a more complex scheduling or resource allocation problem (e.g., using network flow).", "C. Only if the jobs are identical.", "D. Only if the workers are identical.", "B"
"JobAssignment", "What is the purpose of the 'trial assignment' phase in some Hungarian Algorithm explanations?", "A. To estimate the final cost.", "B. To find a set of independent zeroes that represent a partial assignment.", "C. To check for errors in the matrix.", "D. To randomly assign jobs.", "B"
"JobAssignment", "The Hopcroft-Karp algorithm is a faster algorithm for finding maximum cardinality matching in bipartite graphs. Is it directly used for minimum cost matching?", "A. Yes.", "B. No, it focuses on cardinality; minimum cost matching often uses algorithms like successive shortest paths (related to Hungarian).", "C. Only for unweighted graphs.", "D. Only for complete graphs.", "B"
"JobAssignment", "If the problem specifies 'at most one job per worker' and 'at most one worker per job', is it still an Assignment Problem?", "A. Yes.", "B. No, it becomes a different problem.", "C. Only if it's a maximization problem.", "D. Only if it's a minimization problem.", "A"
"JobAssignment", "What does 'uncovered' mean in the context of the Hungarian Algorithm's line drawing step?", "A. An element that has been assigned.", "B. An element that has not been crossed out by any drawn lines.", "C. An element that is zero.", "D. An element that is negative.", "B"
"JobAssignment", "What is the primary role of the 'minimum uncovered value' in the Hungarian Algorithm?", "A. To determine the next step in the reduction process, ensuring progress towards an optimal assignment.", "B. To define the total cost.", "C. To identify the assigned jobs.", "D. To mark the zeroes.", "A"
"JobAssignment", "If a job cannot be assigned to any available worker due to a constraint (infinite cost), what happens?", "A. The problem becomes infeasible, or that assignment is simply avoided.", "B. The algorithm will assign it anyway.", "C. The cost for that assignment becomes zero.", "D. The algorithm finds a partial assignment.", "A"
"JobAssignment", "The Job Assignment problem can be a specific case of which problem type?", "A. Vehicle Routing Problem.", "B. Transportation Problem (a special case of Linear Programming).", "C. Network Flow Problem.", "D. Both B and C (it can be modeled as a transportation problem or min-cost max-flow).", "D"
"JobAssignment", "What is an 'independent set of zeroes' in the Hungarian Algorithm?", "A. A set of zeroes where no two zeroes share the same row or column.", "B. A set of zeroes that form a diagonal.", "C. All zeroes in the matrix.", "D. Zeroes that are not covered by lines.", "A"
"JobAssignment", "The output of the Hungarian Algorithm guarantees finding the best possible assignment. True or False?", "A. True (for balanced minimization problems with non-negative costs).", "B. False", "A"
"JobAssignment", "If you have 3 jobs and 4 workers, what must be done to apply the Hungarian Algorithm?", "A. Add a dummy job.", "B. Add a dummy worker.", "C. Remove one worker.", "D. Remove one job.", "A"
"JobAssignment", "The Job Assignment Problem can be seen as finding a permutation `p` of `(1, ..., N)` such that `sum(cost[i][p[i]])` is minimized. True or False?", "A. True", "B. False", "A"
"JobAssignment", "Compared to general integer programming solvers, the Hungarian Algorithm is typically faster and more efficient for the pure assignment problem. True or False?", "A. True", "B. False", "A"
"JobAssignment", "If the costs were profits and you wanted to maximize total profit, how would you modify the initial cost matrix for the Hungarian Algorithm?", "A. No modification needed.", "B. Subtract all profits from the maximum profit in the matrix to convert to a minimization problem.", "C. Multiply all profits by -1 and then apply the algorithm.", "D. Take the inverse of all profits.", "B"
"Math", "Which mathematical concept is fundamental to understanding the efficiency of algorithms?", "A. Geometry", "B. Asymptotic Analysis (Big O Notation)", "C. Topology", "D. Number Theory (specifically prime numbers)", "B"
"Math", "Big O notation describes the _________ of an algorithm as the input size grows.", "A. Exact runtime", "B. Worst-case time or space complexity", "C. Average-case memory usage", "D. Best-case performance", "B"
"Math", "What is the Big O complexity of searching for an element in a sorted array using Binary Search?", "A. O(N)", "B. O(log N)", "C. O(N log N)", "D. O(1)", "B"
"Math", "Which mathematical operation is commonly used in hashing functions to map a key to an index?", "A. Multiplication", "B. Modulo (remainder) operation", "C. Division", "D. Exponentiation", "B"
"Math", "The concept of 'prime numbers' is crucial in the design of which cryptographic algorithms?", "A. Caesar Cipher", "B. RSA (Rivest-Shamir-Adleman)", "C. XOR encryption", "D. Transposition Cipher", "B"
"Math", "What is the base of the logarithm typically used in the analysis of algorithms like Quick Sort or Merge Sort?", "A. Base 10", "B. Base `e` (natural logarithm)", "C. Base 2", "D. Base `N` (where N is input size)", "C"
"Math", "The 'Fibonacci sequence' is a classic example of what programming technique, often involving a specific mathematical recurrence relation?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Brute Force", "D. Backtracking", "B"
"Math", "What mathematical property must a comparison function satisfy for sorting algorithms like Quick Sort and Merge Sort to work correctly?", "A. Commutativity", "B. Transitivity", "C. Associativity", "D. Distributivity", "B"
"Math", "How is 'average case' time complexity typically calculated?", "A. By considering the worst possible input.", "B. By considering the best possible input.", "C. By averaging the performance over all possible inputs, often assuming a uniform distribution.", "D. By running the algorithm once.", "C"
"Math", "The 'modulo' operator (`%` in C++/Java) returns what?", "A. The quotient of a division.", "B. The remainder of a division.", "C. The product of two numbers.", "D. The sum of two numbers.", "B"
"Math", "What is the common application of GCD (Greatest Common Divisor) in programming?", "A. Calculating prime numbers.", "B. Simplifying fractions or in cryptographic algorithms.", "C. Sorting arrays.", "D. Finding shortest paths.", "B"
"Math", "Which algorithm is used to efficiently calculate the GCD of two numbers?", "A. Sieve of Eratosthenes", "B. Euclidean Algorithm", "C. Binary Search", "D. Quick Sort", "B"
"Math", "In graph theory, the concept of a 'cycle' is a fundamental mathematical structure. Which algorithm detects cycles in a graph?", "A. Dijkstra's Algorithm", "B. BFS or DFS (by checking for back edges)", "C. Prim's Algorithm", "D. Kruskal's Algorithm", "B"
"Math", "What mathematical structure is a 'tree' in computer science?", "A. A graph with cycles.", "B. A connected acyclic graph.", "C. A complete graph.", "D. A disconnected graph.", "B"
"Math", "How is the height of a perfectly balanced binary tree with N nodes typically expressed in terms of N?", "A. O(N)", "B. O(log N)", "C. O(N log N)", "D. O(1)", "B"
"Math", "Combinatorics, specifically permutations and combinations, is directly applicable to problems involving:", "A. Numerical integration.", "B. Counting possible arrangements or selections (e.g., in password cracking or puzzle solving).", "C. Solving differential equations.", "D. Matrix decomposition.", "B"
"Math", "The 'pigeonhole principle' is a mathematical concept often used in proofs related to:", "A. The existence of collisions in hash tables.", "B. The sum of series.", "C. The area of shapes.", "D. The speed of algorithms.", "A"
"Math", "What mathematical concept underpins the efficiency of Union-Find data structures?", "A. Set theory and disjoint sets.", "B. Linear algebra.", "C. Calculus.", "D. Geometry.", "A"
"Math", "What is the typical use of 'bit manipulation' in competitive programming?", "A. Drawing graphics.", "B. Performing arithmetic operations on large numbers by treating them as binary strings, often for speed optimization.", "C. Sending network packets.", "D. Storing text data.", "B"
"Math", "Floating-point precision issues in programming are a direct consequence of representing real numbers using a finite number of bits. True or False?", "A. True", "B. False", "A"
"Math", "Which mathematical concept is used to represent relationships between entities in graphs?", "A. Adjacency matrices or adjacency lists.", "B. Determinants.", "C. Derivatives.", "D. Integrals.", "A"
"Math", "Modular arithmetic is essential for which aspects of programming?", "A. Graphics rendering.", "B. Hashing, cryptography, and handling large numbers that wrap around (e.g., fixed-size integers).", "C. File I/O.", "D. User interface design.", "B"
"Math", "The 'Principle of Optimality' is a mathematical property fundamental to which algorithmic paradigm?", "A. Greedy Algorithms", "B. Dynamic Programming", "C. Divide and Conquer", "D. Backtracking", "B"
"Math", "The concept of 'recurrence relations' is used to analyze the time complexity of which type of algorithms?", "A. Iterative algorithms.", "B. Recursive algorithms.", "C. Greedy algorithms.", "D. Brute force algorithms.", "B"
"Math", "What is the definition of a 'permutation' in combinatorics?", "A. A selection of items where the order does not matter.", "B. An arrangement of items where the order matters.", "C. A subset of a set.", "D. A union of sets.", "B"
"Math", "What is the definition of a 'combination' in combinatorics?", "A. An arrangement of items where the order matters.", "B. A selection of items where the order does not matter.", "C. A sequence of numbers.", "D. A Cartesian product.", "B"
"Math", "The problem of finding the maximum number of non-overlapping intervals relies on a greedy approach that is mathematically provable. True or False?", "A. True", "B. False", "A"
"Math", "The use of `long long` in C++ for large integer calculations is to mitigate issues related to what mathematical concept?", "A. Floating-point precision.", "B. Integer overflow.", "C. Logarithmic scales.", "D. Prime factorization.", "B"
"Math", "The 'Birthday Paradox' demonstrates the surprising probability of what event, often relevant to hash function collision rates?", "A. Two people having the same height.", "B. Two people having the same birthday in a relatively small group.", "C. Two people living in the same city.", "D. Two people having the same first name.", "B"
"Math", "Graph traversal algorithms like BFS and DFS are based on exploring nodes and edges, which are fundamental concepts from:", "A. Calculus.", "B. Linear Algebra.", "C. Graph Theory.", "D. Set Theory (exclusively).", "C"
"Math", "What mathematical structure is often used to model hierarchical data in programming?", "A. Array", "B. Linked List", "C. Tree", "D. Queue", "C"
"Math", "Which mathematical problem involves finding a path from a starting point to an ending point in a graph with minimum total edge weights?", "A. Minimum Spanning Tree (MST)", "B. Shortest Path Problem (e.g., Dijkstra's)", "C. Traveling Salesperson Problem (TSP)", "D. Maximum Flow Problem", "B"
"Math", "The concept of 'convex hull' is a common problem in which area of mathematics relevant to programming?", "A. Algebra", "B. Computational Geometry", "C. Number Theory", "D. Statistics", "B"
"Math", "Hashing functions aim to distribute data uniformly across a hash table. What mathematical property is desired for this distribution?", "A. Linearity", "B. Randomness (or pseudo-randomness) and uniform distribution.", "C. Sorted order.", "D. Monotonicity.", "B"
"Math", "What is the expected average time complexity of a hash table operation (insertion, deletion, lookup) assuming a good hash function and sufficient space?", "A. O(N)", "B. O(log N)", "C. O(1)", "D. O(N^2)", "C"
"Math", "What mathematical concept is crucial for understanding the performance of randomized algorithms?", "A. Determinism.", "B. Probability and Expected Value.", "C. Inductive proofs.", "D. Matrix inversion.", "B"
"Math", "The 'Master Theorem' is a mathematical tool used for:", "A. Solving linear equations.", "B. Analyzing the time complexity of divide-and-conquer recurrence relations.", "C. Finding prime numbers.", "D. Calculating permutations.", "B"
"Math", "Which mathematical transformation is used in algorithms for fast polynomial multiplication and image processing?", "A. Fourier Transform (specifically Fast Fourier Transform - FFT).", "B. Laplace Transform.", "C. Z-transform.", "D. Wavelet Transform.", "A"
"Math", "What is the mathematical definition of a 'graph' in discrete mathematics?", "A. A collection of points (vertices) only.", "B. A collection of lines (edges) only.", "C. A set of vertices and a set of edges connecting pairs of vertices.", "D. A sequence of numbers.", "C"
"Math", "The 'Tower of Hanoi' puzzle is a classic example of a problem that can be solved using:", "A. Iteration.", "B. Mathematical induction and recursion.", "C. Greedy approach.", "D. Brute force with memoization.", "B"
"Math", "What is the purpose of 'prefix sums' (or cumulative sums) in array manipulation problems?", "A. To sort the array.", "B. To enable O(1) or O(log N) calculation of sum of elements within any subarray range.", "C. To reverse the array.", "D. To find prime numbers in the array.", "B"
"Math", "The concept of 'disjoint sets' is fundamental to which algorithm for finding Minimum Spanning Trees?", "A. Prim's Algorithm.", "B. Kruskal's Algorithm.", "C. Dijkstra's Algorithm.", "D. Bellman-Ford Algorithm.", "B"
"Math", "What mathematical property defines a 'binary search tree' (BST)?", "A. Each node has at most two children.", "B. For every node, all values in its left subtree are less than its value, and all values in its right subtree are greater.", "C. The tree is always perfectly balanced.", "D. It has a root and leaves.", "B"
"Math", "What does 'logarithmic time complexity' (O(log N)) imply about an algorithm's performance?", "A. It performs poorly for large inputs.", "B. Its runtime grows very slowly as the input size increases (e.g., doubling input size adds a constant amount of work).", "C. Its runtime grows linearly with input size.", "D. It can only solve small problems.", "B"
"Math", "The 'reservoir sampling' algorithm relies heavily on which branch of mathematics?", "A. Linear Algebra.", "B. Probability and Statistics.", "C. Group Theory.", "D. Set Theory.", "B"
"Math", "What is the purpose of 'bitmasking' in problems like the Traveling Salesperson Problem (TSP) with dynamic programming?", "A. To hide the solution.", "B. To represent subsets of visited cities efficiently using binary numbers.", "C. To encrypt the graph data.", "D. To draw the graph on screen.", "B"
"Math", "The maximum number of edges in a simple undirected graph with N vertices is:", "A. `N`", "B. `N * (N-1) / 2` (or N choose 2)", "C. `N^2`", "D. `2^N`", "B"
"Math", "What is the concept of 'memoization' in dynamic programming?", "A. Writing down notes about the algorithm.", "B. Storing the results of expensive function calls and returning the cached result when the same inputs occur again.", "C. Memorizing the entire input.", "D. Randomly generating results.", "B"
"Math", "What is the mathematical idea behind 'amortized analysis' of algorithms?", "A. Analyzing the worst-case time of a single operation.", "B. Averaging the cost of operations over a sequence of operations to provide a more realistic bound.", "C. Analyzing the best-case time of an operation.", "D. Calculating the total memory usage.", "B"
"Math", "The 'Extended Euclidean Algorithm' is used to find GCD and also to find what?", "A. Prime factors of a number.", "B. Modular multiplicative inverses.", "C. Square roots of numbers.", "D. Determinants of matrices.", "B"
"Strings", "What is a string in programming?", "A. A sequence of numbers.", "B. A sequence of characters.", "C. A sequence of boolean values.", "D. A sequence of memory addresses.", "B"
"Strings", "In C/C++, how are strings typically represented?", "A. As an integer array.", "B. As a character array terminated by a null character (`\0`).", "C. As a linked list of characters.", "D. As a boolean array.", "B"
"Strings", "In Python, are strings mutable or immutable?", "A. Mutable.", "B. Immutable.", "C. Depends on the content.", "D. Only when assigned to a variable.", "B"
"Strings", "What is the Big O time complexity to find the length of a null-terminated string in C?", "A. O(1)", "B. O(log N)", "C. O(N) (where N is the length of the string)", "D. O(N^2)", "C"
"Strings", "Which string method is used to convert all characters in a string to lowercase?", "A. `toUpperCase()`", "B. `toLower()`", "C. `lower()` (Python) or `toLowerCase()` (Java)", "D. `convertCase()`", "C"
"Strings", "What is string concatenation?", "A. Dividing a string into smaller parts.", "B. Joining two or more strings together.", "C. Comparing two strings.", "D. Reversing a string.", "B"
"Strings", "Which data structure is often used to implement a string if it needs to be highly efficient for insertions/deletions in the middle?", "A. Array", "B. Linked List (though less common for typical string operations)", "C. Stack", "D. Queue", "B"
"Strings", "What is a 'palindrome' string?", "A. A string that contains only numbers.", "B. A string that reads the same forwards and backwards.", "C. A string that is empty.", "D. A string that contains only vowels.", "B"
"Strings", "Which algorithm is commonly used for efficient pattern searching in strings?", "A. Bubble Sort", "B. Quick Sort", "C. Knuth-Morris-Pratt (KMP) Algorithm", "D. Dijkstra's Algorithm", "C"
"Strings", "What is the time complexity of the KMP algorithm for searching a pattern of length M in a text of length N?", "A. O(N*M)", "B. O(N+M)", "C. O(N log M)", "D. O(M log N)", "B"
"Strings", "What is a 'substring'?", "A. The entire original string.", "B. A sequence of consecutive characters within a string.", "C. A string with only numbers.", "D. A string in reverse order.", "B"
"Strings", "What is the purpose of the `compareTo()` method in Java strings?", "A. To convert a string to an integer.", "B. To check if two strings are identical.", "C. To lexicographically compare two strings.", "D. To concatenate two strings.", "C"
"Strings", "How can you check if two strings are equal in content in Java, ignoring case?", "A. `str1 == str2`", "B. `str1.equals(str2)`", "C. `str1.equalsIgnoreCase(str2)`", "D. `str1.compare(str2)`", "C"
"Strings", "What is the process of replacing specific characters or sequences in a string with others?", "A. Concatenation", "B. Searching", "C. Substitution/Replacement", "D. Extraction", "C"
"Strings", "What is a 'trie' (prefix tree) data structure used for?", "A. Sorting numbers.", "B. Efficient retrieval of keys based on prefixes, often for string searching or autocomplete.", "C. Storing graph data.", "D. Implementing queues.", "B"
"Strings", "What is the worst-case time complexity for inserting a string into a trie?", "A. O(1)", "B. O(log L) (where L is string length)", "C. O(L) (where L is string length)", "D. O(N) (where N is number of strings in trie)", "C"
"Strings", "What is a 'regular expression'?", "A. A fixed sequence of characters.", "B. A pattern used to match character combinations in strings.", "C. A string that represents a number.", "D. A method for string concatenation.", "B"
"Strings", "What is the main challenge when reversing a string 'in-place' in C/C++?", "A. It requires more memory.", "B. Handling the null terminator and swapping characters efficiently.", "C. Strings are immutable.", "D. It's not possible to reverse in-place.", "B"
"Strings", "What is the Big O time complexity to reverse a string of length N?", "A. O(1)", "B. O(log N)", "C. O(N)", "D. O(N^2)", "C"
"Strings", "What is 'string parsing'?", "A. Converting a string to uppercase.", "B. Analyzing a string to extract meaningful parts or validate its structure.", "C. Encrypting a string.", "D. Compressing a string.", "B"
"Strings", "Which string method would you use to remove leading and trailing whitespace characters from a string?", "A. `trim()` (Java/JavaScript) or `strip()` (Python)", "B. `removeSpaces()`", "C. `deleteWhitespace()`", "D. `cleanString()`", "A"
"Strings", "What is 'character encoding'?", "A. The process of converting characters to numbers for storage and processing.", "B. A method for encrypting strings.", "C. A way to measure string length.", "D. A type of string comparison.", "A"
"Strings", "Common character encodings include:", "A. HTML, CSS, XML", "B. ASCII, UTF-8, UTF-16", "C. JPG, PNG, GIF", "D. TCP, UDP, HTTP", "B"
"Strings", "What is a 'hash collision' in the context of string hashing?", "A. When two different strings produce the same hash value.", "B. When a string is too long to be hashed.", "C. When a hash function runs out of memory.", "D. When a string contains special characters.", "A"
"Strings", "What is 'string interning'?", "A. Copying a string to a temporary buffer.", "B. A technique to store only one copy of each unique string value in memory, saving space.", "C. Converting a string to an integer.", "D. Dividing a string into multiple smaller strings.", "B"
"Strings", "Which algorithm is suitable for finding the longest common prefix among a set of strings?", "A. Binary Search", "B. Trie traversal", "C. Depth-First Search", "D. Breadth-First Search", "B"
"Strings", "What is the result of `\"hello\".charAt(1)` in Java or `\"hello\"[1]` in Python?", "A. 'h'", "B. 'e'", "C. 'l'", "D. 'o'", "B"
"Strings", "What is the purpose of the `split()` method for strings?", "A. To combine multiple strings.", "B. To divide a string into an array/list of substrings based on a delimiter.", "C. To reverse a string.", "D. To convert a string to a number.", "B"
"Strings", "What is the concept of 'wildcard matching' in strings?", "A. Exact string comparison.", "B. Matching strings using special characters (wildcards) that represent one or more characters.", "C. Finding random characters in a string.", "D. Converting a string to an unreadable format.", "B"
"Strings", "What is 'edit distance' (or Levenshtein distance) between two strings?", "A. The physical distance between their memory locations.", "B. The minimum number of single-character edits (insertions, deletions, substitutions) required to change one word into the other.", "C. The difference in their lengths.", "D. The number of common characters.", "B"
"Strings", "Which algorithmic paradigm is typically used to solve the Edit Distance problem?", "A. Greedy Algorithm", "B. Dynamic Programming", "C. Backtracking", "D. Divide and Conquer", "B"
"Strings", "What is the Big O time complexity of calculating Levenshtein distance for two strings of length M and N?", "A. O(M+N)", "B. O(M*N)", "C. O(min(M, N))", "D. O(max(M, N))", "B"
"Strings", "What is the 'Longest Common Subsequence' (LCS) problem?", "A. Finding the longest string that is a subsequence of two or more strings.", "B. Finding the longest common substring.", "C. Finding the longest palindromic substring.", "D. Finding the longest sequence of numbers in a string.", "A"
"Strings", "What is the Big O time complexity of finding the Longest Common Subsequence of two strings of length M and N?", "A. O(M+N)", "B. O(M*N)", "C. O(min(M, N))", "D. O(max(M, N))", "B"
"Strings", "What is the 'Rabin-Karp' algorithm primarily used for?", "A. Sorting strings.", "B. String searching using hashing.", "C. String compression.", "D. Generating random strings.", "B"
"Strings", "What is the concept of a 'suffix array'?", "A. An array of all prefixes of a string.", "B. A sorted array of all suffixes of a string.", "C. An array storing string lengths.", "D. An array of unique characters in a string.", "B"
"Strings", "Suffix arrays are used for which type of problems?", "A. Graph traversal.", "B. String searching, pattern matching, and finding repeated substrings.", "C. Numerical computations.", "D. Database management.", "B"
"Strings", "What is a 'Manacher's Algorithm' used for?", "A. Finding all palindromic substrings in a linear time.", "B. Sorting strings alphabetically.", "C. String compression.", "D. Converting string case.", "A"
"Strings", "What is the time complexity of Manacher's Algorithm?", "A. O(N^2)", "B. O(N log N)", "C. O(N)", "D. O(1)", "C"
"Strings", "What is the primary advantage of using a `StringBuilder` or `StringBuffer` (Java) over repeated string concatenation with `+`?", "A. They are immutable.", "B. They are more memory efficient for frequent modifications because they are mutable.", "C. They are faster for single concatenations.", "D. They automatically convert to integers.", "B"
"Strings", "What is a 'Z-algorithm' used for in string processing?", "A. Finding the shortest common supersequence.", "B. Finding all occurrences of a pattern in a text in linear time.", "C. Compressing strings.", "D. Sorting characters.", "B"
"Strings", "What is the 'Boyer-Moore' algorithm known for?", "A. Being a very slow string searching algorithm.", "B. Being an efficient string searching algorithm that often skips characters.", "C. Its use in cryptography.", "D. Its ability to reverse strings in-place.", "B"
"Strings", "What is 'string matching'?", "A. Comparing two strings for equality.", "B. Finding occurrences of a pattern (substring) within a larger text string.", "C. Sorting strings.", "D. Creating new strings.", "B"
"Strings", "When converting a string representation of a number ('123') to an actual integer, what type of mathematical operation is implicitly performed?", "A. Division.", "B. Addition and multiplication by powers of the base (e.g., 10).", "C. Subtraction.", "D. Modulo.", "B"
"Strings", "What is 'String Hashing'?", "A. Encrypting a string.", "B. Converting a string into a numerical hash value to enable fast comparisons or lookups.", "C. Storing strings in a hash map.", "D. Generating random strings.", "B"
"Strings", "A common string compression technique involves replacing repeated consecutive characters with the character and its count. What is this called?", "A. Huffman Coding", "B. Run-Length Encoding (RLE)", "C. LZW compression", "D. LZ77 compression", "B"
"Strings", "What is the basic idea behind 'dictionary-based compression' (like LZW)?", "A. Replacing common phrases/patterns with shorter codes from a dictionary.", "B. Removing all vowels from a string.", "C. Reversing the string and storing it.", "D. Converting the string to binary.", "A"
"Strings", "What is a 'suffix tree'?", "A. A data structure that stores all prefixes of a string.", "B. A compressed trie of all suffixes of a given string, used for fast string operations.", "C. A tree for storing unique characters.", "D. A tree for sorting strings.", "B"
"Strings", "What is the time complexity of building a suffix tree for a string of length N?", "A. O(N^2)", "B. O(N log N)", "C. O(N)", "D. O(N!)", "C"
"Strings", "In many programming languages, indexing a string (e.g., `s[i]`) takes what Big O time?", "A. O(N)", "B. O(log N)", "C. O(1)", "D. O(N^2)", "C"
